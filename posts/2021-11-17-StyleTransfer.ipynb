{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Art Neural Style Transfer\n",
    "\n",
    "> Using neural networks to create images by style transfer.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [tensorflow, deep learning, jupyter]\n",
    "- author: Thomas Simm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1QH7suLmecI"
   },
   "source": [
    "![](ghtop_images/header2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4psxRKAJmauU"
   },
   "source": [
    "## Introduction \n",
    "\n",
    "Use two images a content image and style image to create a new image of the content image in the style of the style image.\n",
    "\n",
    "Source used, Deep Learning Specialization Week 4\n",
    "https://www.coursera.org/lecture/convolutional-neural-networks/what-is-neural-style-transfer-SA5H8\n",
    "\n",
    "> youtube: https://youtu.be/R39tWYYKNcI\n",
    "\n",
    "From [original NST paper](https://arxiv.org/abs/1508.06576) published by the Visual Geometry Group at University of Oxford in 2014 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDeMHjv5nDHh"
   },
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "tt-TNrDam23q",
    "outputId": "6b150b4d-c1ae-4e0c-a01c-2807c71130f6",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "editable": false,
    "id": "I_oSufZ8u6zo",
    "outputId": "15fe32d4-9411-4dff-cdd9-46201dc4bcce",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "style_image = np.array(Image.open(\"/content/drive/MyDrive/Colab Notebooks/Tiles.jpg\"))\n",
    "\n",
    "imshow(style_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/mosaic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the content image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "editable": false,
    "id": "Ryc0ypYEobte",
    "outputId": "2584bdd3-679f-4d35-ab18-14a40336c987",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "content_image = np.array(Image.open(\"/content/drive/MyDrive/Colab Notebooks/boat.jpg\"))\n",
    "\n",
    "print(np.shape(content_image))\n",
    "imshow(content_image)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/house.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "deletable": false,
    "editable": false,
    "id": "6MKddixjuZnV",
    "outputId": "5527c379-85fd-47c0-db3a-c773c229cfd1",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#gonna reduce to a square image of size in pixels of\n",
    "img_size = 1100\n",
    "\n",
    "# get image as array, then resize\n",
    "content_image = Image.fromarray(content_image)\n",
    "content_image =np.array(content_image.resize((img_size, img_size)))\n",
    "\n",
    "# create content image as tf tensor\n",
    "content_image = tf.constant(np.reshape(content_image, ((1,) + content_image.shape)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "deletable": false,
    "editable": false,
    "id": "dpwNK9b4u0zP",
    "outputId": "585a3013-f58c-4174-a1e9-c4940a37542c",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# same for style image\n",
    "\n",
    "style_image = Image.fromarray(style_image)\n",
    "style_image = np.array(style_image.resize((img_size, img_size)))\n",
    "\n",
    "style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OZg1gFhqOP-"
   },
   "source": [
    "Load parameters from the VGG model. A pretrained model for image classification\n",
    "\n",
    "https://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "https://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Y6MBzKb6qNqN",
    "outputId": "7119d593-5e75-4e76-add9-e214f70f4f7e",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x7f84e154af90>\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(272)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False,\n",
    "                                  input_shape=(img_size, img_size, 3),\n",
    "                                  weights='/content/drive/MyDrive/Colab Notebooks/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "vgg.trainable = False\n",
    "pp.pprint(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqEtY9xrxRuV"
   },
   "source": [
    "Now choose layers to represent the style of the image and assign style costs:\n",
    "Lower number more basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mgI0Ag3xxSEE",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', .2),\n",
    "    ('block2_conv1', .2),\n",
    "    ('block3_conv1', .2),\n",
    "    ('block4_conv1', .2),\n",
    "    ('block5_conv1', .2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwAO0HpMqz0f"
   },
   "source": [
    "Compute the \"content cost\" using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RHSeqBb6qMom",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_content_cost(content_output, generated_output):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_content -- scalar that you compute using equation 1 above.\n",
    "    \"\"\"\n",
    "    a_C = content_output[-1]\n",
    "    a_G = generated_output[-1]\n",
    "       \n",
    "    \n",
    "    # Retrieve dimensions from a_G \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # Reshape a_C and a_G \n",
    "    a_C_unrolled = tf.reshape(a_C, shape=[m, n_H * n_W, n_C])\n",
    "    a_G_unrolled = tf.reshape(a_G, shape=[m, n_H * n_W, n_C])\n",
    "    \n",
    "    # compute the cost with tensorflow \n",
    "    J_content =  (1/(4*n_H*n_W*n_C) )*tf.reduce_sum(tf.square( tf.subtract(a_C_unrolled, a_G_unrolled ) ))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IwNvPUa4u2d"
   },
   "source": [
    "the gram matrix of A is ùê∫ùê¥=ùê¥ùê¥ùëá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yeSd0qYG4vF6",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (n_C, n_H*n_W)\n",
    "    \n",
    "    Returns:\n",
    "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
    "    \"\"\"  \n",
    "    \n",
    "    \n",
    "    GA = tf.linalg.matmul(\n",
    "    A, A, transpose_b=True)\n",
    "    \n",
    "\n",
    "    return GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5_KKtj5rJ_u"
   },
   "source": [
    "Compute the style cost for a single layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WvTRZVGFrIvN",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Retrieve dimensions from a_G \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # Reshape the images from (n_H * n_W, n_C) to have them of shape (n_C, n_H * n_W) \n",
    "    a_S = tf.transpose(a_S)\n",
    "    a_S=tf.reshape(a_S, shape=[n_C, n_H * n_W])\n",
    "    a_G = tf.transpose(a_G)#, shape=[n_C, n_H * n_W])\n",
    "    a_G=tf.reshape(a_G, shape=[n_C, n_H * n_W])\n",
    "    \n",
    "    print(np.shape(a_S))\n",
    "    \n",
    "    # Computing gram_matrices for both images S and G \n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "    \n",
    "    # Computing the loss (‚âà1 line)\n",
    "    J_style_layer = J_content =  (1/(4*(n_H*n_W)**2*n_C**2) )*tf.reduce_sum(tf.square( tf.subtract(GS, GG ) ))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruvnsCarrz3F"
   },
   "source": [
    "Compute style cost function, \n",
    "Calls individual layers cost funcxtion and applies a weight based on variable STYLE_LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lyntVCzVr02W",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    style_image_output -- our tensorflow model\n",
    "    generated_image_output --\n",
    "    STYLE_LAYERS -- A python list containing:\n",
    "                        - the names of the layers we would like to extract style from\n",
    "                        - a coefficient for each of them\n",
    "    \n",
    "    Returns: \n",
    "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    J_style = 0\n",
    "\n",
    "    # Set a_S to be the hidden layer activation from the layer we have selected.\n",
    "    # The last element of the array contains the content layer image, which must not to be used.\n",
    "    a_S = style_image_output[:-1]\n",
    "\n",
    "    # Set a_G to be the output of the choosen hidden layers.\n",
    "    # The last element of the array contains the content layer image, which must not to be used.\n",
    "    a_G = generated_image_output[:-1]\n",
    "    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  \n",
    "        # Compute style_cost for the current layer\n",
    "        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])\n",
    "\n",
    "        # Add weight * J_style_layer of this layer to overall style cost\n",
    "        J_style += weight[1] * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T62uZYpXsdCf"
   },
   "source": [
    "A total cost function including both style and content costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vVXTcLBjsiI-",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost function\n",
    "    \n",
    "    Arguments:\n",
    "    J_content -- content cost coded above\n",
    "    J_style -- style cost coded above\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost as defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    J = alpha*J_content +beta*J_style\n",
    "    \n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDfY-WGytBYS"
   },
   "source": [
    "<a name='5-3'></a>\n",
    "### 5.3 Randomly Initialize the Image to be Generated\n",
    "Now, you get to initialize the \"generated\" image as a noisy image created from the content_image.\n",
    "\n",
    "* The generated image is slightly correlated with the content image.\n",
    "* By initializing the pixels of the generated image to be mostly noise but slightly correlated with the content image, this will help the content of the \"generated\" image more rapidly match the content of the \"content\" image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "deletable": false,
    "editable": false,
    "id": "x8IQaz-ns2Rd",
    "outputId": "09691b57-219c-48f8-f68e-13fc7886fe74",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "# noise = tf.random.uniform(tf.shape(generated_image), 0, 0.5)\n",
    "# generated_image = tf.add(generated_image, noise)\n",
    "generated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOiXAPRnxval"
   },
   "source": [
    "define a function which loads the VGG19 model and returns a list of the outputs for the middle layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "liLy3q8Svtj6",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def get_layer_outputs(vgg, layer_names):\n",
    "    \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
    "    outputs = [vgg.get_layer(layer[0]).output for layer in layer_names]\n",
    "\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUmBM_vfx1Tt"
   },
   "source": [
    "Now, define the content layer and build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "II7KxD2WswIr",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "content_layer = [('block5_conv4', 1)]\n",
    "\n",
    "vgg_model_outputs = get_layer_outputs(vgg, STYLE_LAYERS + content_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUPKW_zlx_ib"
   },
   "source": [
    "Save the outputs for the content and style layers in separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MA36-Zanx-m_",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "content_target = vgg_model_outputs(content_image)  # Content encoder\n",
    "style_targets = vgg_model_outputs(style_image)     # Style enconder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "vjFgjBsRyLJm",
    "outputId": "d7086edd-aaaf-4bf5-9879-2e31beea6515",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Assign the content image to be the input of the VGG model.  \n",
    "# Set a_C to be the hidden layer activation from the layer we have selected\n",
    "preprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "a_C = vgg_model_outputs(preprocessed_content)\n",
    "\n",
    "# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n",
    "# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input.\n",
    "a_G = vgg_model_outputs(generated_image)\n",
    "\n",
    "# Compute the content cost\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "print(J_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBZcu_1pyGjX"
   },
   "source": [
    "sets a_S to be the tensor giving the hidden layer activation for STYLE_LAYERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "JA8g6LQwyZQy",
    "outputId": "88529727-ea28-43a7-fcd0-f3882545c9cd",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1210000)\n",
      "(128, 302500)\n",
      "(256, 75625)\n",
      "(512, 18769)\n",
      "(512, 4624)\n",
      "tf.Tensor(2067.7974, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Assign the input of the model to be the \"style\" image \n",
    "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
    "a_S = vgg_model_outputs(preprocessed_style)\n",
    "\n",
    "# Compute the style cost\n",
    "J_style = compute_style_cost(a_S, a_G)\n",
    "print(J_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPr4q44F08fY"
   },
   "source": [
    "Utils that you will need to display the images generated by the style transfer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_-5WGo7U084E",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def clip_0_1(image):\n",
    "    \"\"\"\n",
    "    Truncate all the pixels in the tensor to be between 0 and 1\n",
    "    \n",
    "    Arguments:\n",
    "    image -- Tensor\n",
    "    J_style -- style cost coded above\n",
    "\n",
    "    Returns:\n",
    "    Tensor\n",
    "    \"\"\"\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"\n",
    "    Converts the given tensor into a PIL image\n",
    "    \n",
    "    Arguments:\n",
    "    tensor -- Tensor\n",
    "    \n",
    "    Returns:\n",
    "    Image: A PIL image\n",
    "    \"\"\"\n",
    "    tensor = tensor * 255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor) > 3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNMJGeml0FAc"
   },
   "source": [
    "### Train a step\n",
    "learning rate lower slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uI8qY92E0FPu",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.03)\n",
    "\n",
    "@tf.function()\n",
    "def train_step(generated_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # In this function you must use the precomputed encoded images a_S and a_C\n",
    "        # Compute a_G as the vgg_model_outputs for the current generated image\n",
    "        \n",
    "\n",
    "        a_G = vgg_model_outputs(generated_image)\n",
    "        # Compute the style cost\n",
    "     \n",
    "        J_style = compute_style_cost(a_S, a_G)\n",
    "\n",
    "        \n",
    "        # Compute the content cost\n",
    "        J_content = compute_content_cost(a_C, a_G)\n",
    "        # Compute the total cost\n",
    "        J = total_cost(J_content, J_style, alpha = 10, beta = 40)  \n",
    "        \n",
    "        \n",
    "        \n",
    "    grad = tape.gradient(J, generated_image)\n",
    "\n",
    "    optimizer.apply_gradients([(grad, generated_image)])\n",
    "    generated_image.assign(clip_0_1(generated_image))\n",
    "  \n",
    "    return J\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOZpCA9jypZc"
   },
   "source": [
    "### Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "deletable": false,
    "editable": false,
    "id": "znCVyflVyvr8",
    "outputId": "9be2d378-27f2-4e04-f1ac-7b9dcd0ef37f",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Show the generated image at some epochs\n",
    "# Uncoment to reset the style transfer process. You will need to compile the train_step function again \n",
    "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "epochs = 5001\n",
    "for i in range(epochs):\n",
    "    train_step(generated_image)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Epoch {i} \")\n",
    "    if i % 100 == 0:\n",
    "        image = tensor_to_image(generated_image)\n",
    "        imshow(image)\n",
    "        image.save(f\"image_{i}.jpg\")\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQiDa8Kby1yl"
   },
   "source": [
    "## Some Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQEsZAMX5fFU"
   },
   "source": [
    "![](ghtop_images/image_400.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/image_200.jpg)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of StyleTransfer.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
