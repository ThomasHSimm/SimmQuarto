{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golf body position recognition\n",
    "> Recognising body parts during golf swing, step 1\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- categories: [jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "This is a first step in a project to analyse golf swings.\n",
    "\n",
    "In this first step I try to identify different parts of the body and golf equipment during the golf swing. This step is of limited success for overall analysis but the steps used are useful for the lessons learnt.\n",
    "\n",
    "This work uses deep learning to identify locations (vectors) on images and fitting by regression.\n",
    "\n",
    "\n",
    "\n",
    "In this step I will use a dataSet found at <a href='https://github.com/wmcnally/golfdb'> Git Hub GolfSwing</a> and the paper of the work https://arxiv.org/abs/1903.06528.\n",
    "\n",
    "What this dataset/paper does is split the golf swing into a number of sequences based on the position of the body and golf club, e.g. start, golf club parallel to ground, striking the ball etc. We will call these the golf positions. These positions are shown below.\n",
    "\n",
    "![](ghtop_images/Fig_GolfSwing.png)\n",
    "\n",
    "\n",
    "The dataset includes a series of videos that have been characterised based on the different swing sequences. \n",
    "\n",
    "\n",
    "### Steps in this page\n",
    "\n",
    "1. Download the video dataset and the details of the frames of the different positions\n",
    "\n",
    "1. Create images at the different positions from the videos  \n",
    "\n",
    "1. Classify points on the images and a file for each image of these\n",
    "\n",
    "1. Upload data to GitHub and download on notebook for analysis\n",
    "\n",
    "1. Use deep learning to identify the positions on the images\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the video analysis dataset to create images of golf swings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I cloned the directory (https://github.com/wmcnally/golfdb) onto my local PC. I then need to identify which videos to use- I want the ones behind the golfer and preferably of lower frame rate.\n",
    "\n",
    "Below are the names of the videos I selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "useVids=[1,3,5,7,13,24,43,46,48,71,77,81,83,89,93,242,681,1060]\n",
    "np.shape(useVids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now want to find the frames in each video that represent the selected positions.\n",
    "\n",
    "These exist in a '.pkl' file. So we open the file and then select the videos (rows) we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "file_path= cda + \"\\data\\\\golfDB.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open(file_path,\"rb\"))\n",
    "aa=[]\n",
    "i=0\n",
    "for ii in useVids:\n",
    "    if i==0:\n",
    "        aa=data[ii==data.id]\n",
    "        \n",
    "    else:\n",
    "        aa=aa.append(data[ii==data.id])\n",
    "       \n",
    "    i=i+1\n",
    "aa.reset_index(drop=True,inplace=True)\n",
    "aa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/GOLF1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the DataFrame (aa) the details we want are just the 'events' so we know what frames to save as images from the videos\n",
    "\n",
    "First we create a function that takes a video location and details of the frames (or the selected golf positions) and then creates a new folder containing images of those frames.\n",
    "\n",
    "This uses the library `cv2` and a secondary check to normalise the positions if it is different from that given (this was useful in earlier versions but later ones the frame number matched that given by the aa dataFrame). \n",
    "\n",
    "The function works by finding a frame rate then stepping through the video by adding the time per frame after each step. If the frame is at a position given by the input (from aa) it is saved as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def createImages(fila,pos):\n",
    "    ''' \n",
    "    Given a video file location (fila) it will save as images to a folder\n",
    "    Given positions in video (pos) these images from the video are saved\n",
    "    pos is created based on positions of swings\n",
    "    '''\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    # create a video capture object\n",
    "    cap = cv2.VideoCapture(fila)\n",
    "    \n",
    "    # get details of the video clip\n",
    "    duration = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration_seconds = frame_count / fps\n",
    "    print('duration is ',duration,'. frame_count is ',frame_count,'. fps is ',fps,'. duration sec is',duration_seconds)\n",
    "    \n",
    "    #alter pos based on frame count\n",
    "    posb4=pos\n",
    "    pos=(pos/(np.max(pos)/frame_count))\n",
    "    pos=np.array([int(nn) for nn in pos])\n",
    "    pos=pos[1:-2]#ignore first value and last two\n",
    "    \n",
    "    \n",
    "    # create a folder if it doesn't exist\n",
    "    folder = fila.split('\\\\')[-1].split('.')[0]\n",
    "    folder = '_images'+folder\n",
    "    print(folder)\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    vidcap = cap\n",
    "    \n",
    "    # this function creates an image from part of a video and \n",
    "    # saves as a JPG file\n",
    "    def getFrame(sec,go):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if hasFrames and go:\n",
    "            cv2.imwrite(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)     # save frame as JPG file\n",
    "        return hasFrames\n",
    "    \n",
    "    # goes through the video clip and steps through based on frame rate\n",
    "    sec = 0\n",
    "    frameRate = 1000/fps \n",
    "    count=1\n",
    "    go=0\n",
    "    success = True\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        #only saves images if at positions in pos\n",
    "        if count in pos:\n",
    "            go=1\n",
    "        else:\n",
    "            go=0\n",
    "        success = getFrame(sec,go)\n",
    "\n",
    "    print(\"{} images are extacted in {}.\".format(count,folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below I call the script for the videos I selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "fila = cda + '\\\\data\\\\videos_160\\\\'\n",
    "for ii,aai in enumerate(aa.id):\n",
    "    fold = fila + str(aai)+'.mp4'\n",
    "    pos=aa.iloc[ii,7]\n",
    "    pos=pos-pos[0]\n",
    "    if ii>1:\n",
    "        cII(fold,pos)\n",
    "        cap = createImages.VideoCapture(fold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a series of folders for each video with images given by the selected positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to perform analysis on the images they first need to be labelled.\n",
    "\n",
    "To do this I decided to take the **manual** approach and classify the images myself. I decided to choose the following regions in each image:\n",
    "- The ball\n",
    "- The end of the golf club (clubhead)\n",
    "- The back wrist\n",
    "- the back elbow\n",
    "- the top of the head\n",
    "\n",
    "\n",
    "This is done using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def imDo(im):\n",
    "    \n",
    "    fig=plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(im)\n",
    "\n",
    "    def tellme(s):\n",
    "        print(s)\n",
    "        plt.title(s, fontsize=16)\n",
    "\n",
    "    tellme('You will define golf swing, click to begin')\n",
    "\n",
    "    plt.waitforbuttonpress()\n",
    "\n",
    "    while True:\n",
    "        pts = []\n",
    "        while len(pts) < 5:\n",
    "            tellme('Select golf ball-golf club- wrist- elbow- head with mouse')\n",
    "            pts = np.asarray(plt.ginput(5, timeout=-1))\n",
    "            if len(pts) < 5:\n",
    "                tellme('Too few points, starting over')\n",
    "                time.sleep(1)  # Wait a second\n",
    "        \n",
    "        ph = plt.plot(pts[:, 0], pts[:, 1], marker='x',markersize=20,markeredgewidth=3)\n",
    "\n",
    "        tellme('Happy? Key click for yes, mouse click for no')\n",
    "\n",
    "        if plt.waitforbuttonpress():\n",
    "            break\n",
    "    plt.close(fig)\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can call this function we want to make sure the image appears as a new window\n",
    "\n",
    "Also some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "import matplotlib\n",
    "\n",
    "cda = os.getcwd()\n",
    "\n",
    "matplotlib.use('TKAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each image file created, the script below runs `imDo` which plots the image then asks the user to select 5 points on the image for classification.\n",
    "\n",
    "these points are then save as txt file with the same name as the image file to be used later in modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/golfpos.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "foldOuta=cda+'//_dataSel//'\n",
    "lsa = os.listdir(foldOuta)\n",
    "lsa\n",
    "ptsALL=[]\n",
    "for ii,folds in enumerate(lsa):\n",
    "    if ii>0:\n",
    "        print(folds)\n",
    "        img_files = get_image_files(foldOuta+folds)\n",
    "        for fils in img_files:\n",
    "            im = PILImage.create(fils)\n",
    "            pts=imDo(im)\n",
    "            ptsALL.append(pts)\n",
    "            fnom=str(fils).split('\\\\')[-1].split('.')[0]\n",
    "            \n",
    "            np.savetxt(foldOuta+folds+'\\\\'+fnom+'.txt',pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data for use in modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai has a function called `untar_data` that prepares images in a .tgz folder ready to use for analysis.\n",
    "\n",
    "A tgz file can be made by a Python script, but all the ones I tried produced an error, so instead I used \n",
    "\n",
    "To create a tar file see https://opensource.com/article/17/7/how-unzip-targz-file\n",
    "\n",
    "Open up a terminal go to the folder that contains the folder wanting to compress and then tar with the command line\n",
    "\n",
    "<code>tar --create --ve\n",
    "rbose --file GC.tgz GolfComb</code>\n",
    "\n",
    "I have then uploaded it to GitHub. Go to the file on Github open it and right click on 'view raw' and select copy link.\n",
    "\n",
    "![](ghtop_images/Tar_Link.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest needs to be done with a GPU. I have done this with https://colab.research.google.com/ (free time is limited but details not published) and the code tab for a notebook on https://www.kaggle.com/ (36 h per month for free)\n",
    "\n",
    "First import the fastai stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untar the data and set the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "url='https://github.com/ThomasHSimm/GolfSwingTSimm/blob/main/_dataSel/GC.tgz?raw=true'\n",
    "\n",
    "path = untar_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "(path/'Test').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/GOLF6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results, pretty good for ~10 mins of 81 images of learning although doesn't always get the top of the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/headtestpredict.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "learn.export(fname='headTry1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when this is generalised to other points, such as hands and clubhead, that are less static the results are poor.\n",
    "\n",
    "Presumably a combination of the low resolution of the images making it difficult to identify features and the lack of images.\n",
    "\n",
    "\n",
    "![](ghtop_images/handspredict.png)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
