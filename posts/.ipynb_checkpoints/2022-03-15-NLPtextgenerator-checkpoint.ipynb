{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLP for text generation\n",
    "> Using FastAI to build a NLP text generator\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [NLP, Neural networks,FastAI, Python]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/header2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### NLP\n",
    "\n",
    "NLP, or natural language processing, is a machine learning priocess used on language data. Some applications include:\n",
    "\n",
    "1. search, ranking\n",
    "1. spam detection\n",
    "1. ads recommendation\n",
    "1. email categorization\n",
    "1. machine translation\n",
    "1. speech recognition\n",
    "1. Sentiment analysis\n",
    "\n",
    "From `FastAI FastBooks`:\n",
    "\n",
    "    What we call a language model is a model that has been trained to guess what the next word in a text is (having read the ones before). This kind of task is called self-supervised learning: we do not need to give labels to our model, just feed it lots and lots of texts. It has a process to automatically get labels from the data, and this task isn't trivial: to properly guess the next word in a sentence, the model will have to develop an understanding of the English (or other) language\n",
    "\n",
    "    Even if our language model knows the basics of the language we are using in the task (e.g., our pretrained model is in English), it helps to get used to the style of the corpus we are targeting. It may be more informal language, or more technical, with new words to learn or different ways of composing sentences. In the case of the IMDb dataset, there will be lots of names of movie directors and actors, and often a less formal style of language than that seen in Wikipedia.\n",
    "\n",
    "    We already saw that with fastai, we can download a pretrained English language model and use it to get state-of-the-art results for NLP classification. \n",
    "    \n",
    "## What is below\n",
    "\n",
    "Here I'll use the IMDB dataset and train it on the works of Shakespeare to generate text in the style of his work given a starting few words.\n",
    "\n",
    "Uses fastAI, modified from \"10_nlp.ipynb\" in fastAI/fastbook\n",
    "\n",
    "https://colab.research.google.com/drive/11JRjYu7XsmSzo3IT8oH2KNf-e-v6W5tf?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Some imports\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "from fastai.text.all import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some text to act as a style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# A URL containing the works of Shakespeare\n",
    "url='https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n",
    "\n",
    "# Going to put in a folder called BARD which we create\n",
    "dest='BARD'\n",
    "import os\n",
    "os.mkdir(dest)\n",
    "\n",
    "# get the text from the url and put as data\n",
    "import requests\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "# reduce data to miss start and end guff\n",
    "xstart=10450\n",
    "xend=580\n",
    "data = data[xstart:-xend]\n",
    "\n",
    "# create a text file every 1000\n",
    "# use format number_0.txt seems to work best for DataBlock\n",
    "rr=int(len(data)/1000)\n",
    "for i in range(rr):\n",
    "    with open(dest + '/{}_0.txt'.format(str(i)),'w') as f:\n",
    "        f.writelines(data[ (i-1)*1000:i*1000 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model using DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# create path\n",
    "path=Path()\n",
    "\n",
    "# get's the text parts- will just come from folder dest \n",
    "# where the text files are saved\n",
    "get_shak = partial(get_text_files,folders=dest)\n",
    "\n",
    "# Craete a dataBlock- using the Class of TextBlock and the classes \n",
    "# in-built function from folder\n",
    "dbb = DataBlock(\n",
    "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
    "    get_items=get_shak, splitter=RandomSplitter(0.1)\n",
    ")\n",
    "\n",
    "# Now create the dataLoaders\n",
    "dls =dbb.dataloaders(path, path=path, bs=128, seq_len=80)\n",
    "\n",
    "# Have a look at the batches\n",
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/bard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dls, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/bard2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/bard3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "TEXT = \"Hi Romeo how are you?\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 4\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
    "         for _ in range(N_SENTENCES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Cannot get rid of this spot\" 30 words, 2 sentences\n",
    "\n",
    "    Can not get rid of this spot ? No ; I 'll set a foot to Caesar . If i can tell you , Triumvirate , that know the heads of\n",
    "\n",
    "    Can not get rid of this spot ? When one sees England here , he next is sure to be sent for . If i be not , my King , you must\n",
    "\n",
    "\n",
    "\"Hi Romeo how are you?\" 60words 2sent. 0.75temp.\n",
    "    \n",
    "    Hi Romeo how are you ? What 's your will ? My heart is split . What , my soul ! My body 's as cold as wax ; my heart is now as a nail in my heart ; thou shalt see Romeo set a crown on't ! Come , and that ring i gave him , the ring\n",
    "    \n",
    "\"Where shall i go for my holiday?\"\n",
    "\n",
    "    Where shall i go for my holiday ? Am i to France ? Are you English ? Are you a Spanish man ? [ aside ] i know not what ; nor no other man but this . [ they speak ] If i speak , i am going .\n",
    "    \n",
    "\"Poor me , poor me , poor me another drink\"\n",
    "\n",
    "    Poor me , poor me , poor me another drink , I 'll burn out King Lear 's grave . Thou art too dear to me ; i am perfect i am least of all . I 'll go live i ' th ' middle , and there will i not live in this .\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
