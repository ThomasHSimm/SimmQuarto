[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nAWS Cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nDecision Trees and Random Forests\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFastpages Notebook Blog Post\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAWS Cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nThe operating system\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSome Python Basics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBuilding a Classifier App on the web\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nRegular expressions RE\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGit and Github\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nData Viz\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nData Science\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nPython Imbedding Web\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nHow Does a Bike-Share Navigate Speedy Success\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nDeep Learning and Art Neural Style Transfer\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWeb scraping\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBody position recognition using FastAI\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWorking with videos\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPython Basics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSwansea House Prices- Part 2\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nCreating a property prediction App\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGolf Swing Part II- Separating Swing Positions\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGolf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFastAI CheatSheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nUsing NLP for text generation\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSpeech recognition\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTweepy\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nNatural Language Processing of Travel Tweets\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nDecision Trees and Random Forests\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- height weight and age\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- creating a country table\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- create the tables\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- GDP and population\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- home games\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPresentation of Olympics data with SQL and pandas\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nNLP examples\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPredicting Premier League Matches- Prepare the data\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPredicting Premier League Matches\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow cheat sheet 2\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow Low-Level cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow Images cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow NLP cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAWS terminology\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nData Science\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nAWS Cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nIAM policy\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nChapter 3\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nModifications to code for separating swing video\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nAB Testing\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Maths\n\n\n\n\n\n\n\nneural networks\n\n\nmaths\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nTensorFlow cheat sheet\n\n\nNeural Network Maths\n\n\n\n\nneural networks\n\n\ntensorflow\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nBasics SQL\n\n\nNeural Network Maths\n\n\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-the-cloud",
    "href": "posts/2020-01-01-AWS.html#what-is-the-cloud",
    "title": "ThomasHSimm",
    "section": "What is the Cloud?",
    "text": "What is the Cloud?\nIn the past, companies and organizations hosted and maintained hardware such as compute, storage, and networking equipment in their own data centers. They needed to allocate entire infrastructure departments to take care of them, resulting in a costly operation that made some workloads and experimentation impossible.\nAs internet usage became more widespread, the demand for compute, storage, and networking equipment increased. For some companies and organizations, the cost of maintaining a large physical presence was unsustainable. To solve this problem, cloud computing was created.\nCloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing. You no longer have to manage and maintain your own hardware in your own data centers. Companies like AWS own and maintain these data centers and provide virtualized data center technologies and services to users over the internet.\nTo help differentiate between running workloads on-premises versus in the cloud, consider the scenario where your developers need to deploy a new feature on your application. Before they deploy, the team wants to test the feature in a separate quality assurance (QA) environment that has the exact same configurations as production.\nIf you run your application on-premises, creating this additional environment requires you to buy and install hardware, connect the necessary cabling, provision power, install operating systems, and more. All of these tasks can be time-consuming and take days to perform. Meanwhile, the new product feature’s time-to-market is increasing and your developers are waiting for this environment.\nIf you ran your application in the cloud, you can replicate the entire environment as often as needed in a matter of minutes or even seconds. Instead of physically installing hardware and connecting cabling, you can logically manage your physical infrastructure over the internet.\nUsing cloud computing not only saves you time from the set-up perspective, but it also removes the undifferentiated heavy lifting. If you look at any application, you’ll see that some of the aspects of it are very important to your business, like the code. However, there are other aspects that are no different than any other application you might make: for instance the compute the code runs on. By removing repetitive common tasks that don’t differentiate your business, like installing virtual machines, or storing backups, you can focus on what is strategically unique to your business and let AWS handle the tasks that are time consuming and don’t separate you from your competitors.\nSo where does AWS fit into all of this? Well AWS simply just provides cloud computing services. Those IT resources mentioned in the cloud computing definition are AWS services in this case. We’ll need to use these AWS services to architect a scalable, highly available, and cost effective infrastructure to host our corporate directory application. This way we can get our corporate directory app out into the world quickly, without having to manage any heavy-duty physical hardware. There are the six main advantages to running your workloads on AWS."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#the-six-benefits-of-cloud-computing",
    "href": "posts/2020-01-01-AWS.html#the-six-benefits-of-cloud-computing",
    "title": "ThomasHSimm",
    "section": "The Six Benefits of Cloud Computing",
    "text": "The Six Benefits of Cloud Computing\n\nPay as you go. Instead of investing in data centers and hardware before you know how you are going to use them, you pay only when you use computing resources, and pay only for how much you use.\nBenefit from massive economies of scale. By using cloud computing, you can achieve a lower cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, AWS can achieve higher economies of scale, which translates into lower pay as-you-go prices.\nStop guessing capacity. Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes notice.\nIncrease speed and agility. IT resources are only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization since the cost and time it takes to experiment and develop is significantly lower.\nStop spending money running and maintaining data centers. Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your customers, rather than on the heavy lifting of racking, stacking, and powering physical infrastructure. This is often referred to as undifferentiated heavy lifting.\nGo global in minutes. Easily deploy your application in multiple Regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at a minimal cost.\n\n\nhttps://aws.amazon.com/what-is-cloud-computing/\nhttp://docs.aws.amazon.com/whitepapers/latest/aws-overview/types-of-cloud-computing.html\nhttps://aws.amazon.com/what-is-aws/\n\n\nAWS Global Infrastructure\n\nInfrastructure, like data centers and networking connectivity, still exists as the foundation of every cloud application. In AWS, this physical infrastructure makes up the AWS Global Infrastructure, in the form of Availability Zones and Regions.\nRegions are geographic locations worldwide where AWS hosts its data centers. AWS Regions are named after the location where they reside. For example, in the United States, there is a Region in Northern Virginia called the Northern Virginia Region and a Region in Oregon called the Oregon Region. There are Regions in Asia Pacific, Canada, Europe, the Middle East, and South America, and AWS continues to expand to meet the needs of its customers.\nEach AWS Region is associated with a geographical name and a Region code.\nfor example, - us-east-1: This is the first Region created in the east of the US. The geographical name for this Region is N. Virginia. - ap-northeast-1: The first Region created in the northeast of Asia Pacific. The geographical name for this Region is Tokyo.\n\nChoose the Right AWS Region\nConsider four main aspects when deciding which AWS Region to host your applications and workloads: latency, price, service availability, and compliance.\n\nLatency. If your application is sensitive to latency, choose a Region that is close to your user base. This helps prevent long wait times for your customers. Synchronous applications such as gaming, telephony, WebSockets, and IoT are significantly affected by higher latency, but even asynchronous workloads, such as ecommerce applications, can suffer from an impact on user connectivity.\nPrice. Due to the local economy and the physical nature of operating data centers, prices may vary from one Region to another. The pricing in a Region can be impacted by internet connectivity, prices of imported pieces of equipment, customs, real estate, and more. Instead of charging a flat rate worldwide, AWS charges based on the financial factors specific to the location.\n\nService availability. Some services may not be available in some Regions. The AWS documentation provides a table containing the Regions and the available services within each one.\nData compliance. Enterprise companies often need to comply with regulations that require customer data to be stored in a specific geographic territory. If applicable, you should choose a Region that meets your compliance requirements."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#availability-zones",
    "href": "posts/2020-01-01-AWS.html#availability-zones",
    "title": "ThomasHSimm",
    "section": "Availability Zones",
    "text": "Availability Zones\nInside every Region is a cluster of Availability Zones (AZ). An AZ consists of one or more data centers with redundant power, networking, and connectivity. These data centers operate in discrete facilities with undisclosed locations. They are connected using redundant high-speed and low-latency links.\n\nWhat is low latency link? Low latency describes a computer network that is optimized to process a very high volume of data messages with minimal delay (latency).\n\n\nWhat does redundant mean in routing? Failover or Redundant routing is a network arrangement with several links and paths between the person who places a call and the call recipient. Should at any time a path or link in the network, the other links will automatically route the incoming call to a predetermined number, device or location.\n\nAZs also have a code name. Since they’re located inside Regions, they can be addressed by appending a letter to the end of the Region code name. For example:\n\nus-east-1a: an AZ in us-east-1 (Northern Virginia Region)\nsa-east-1b: an AZ in sa-east-1 (São Paulo Region in South America)\n\nIf you see that a resource exists in us-east-1c, you know this resource is located in AZ c of the us-east-1 Region.\n\nScope AWS Services\nDepending on the AWS Service you use, your resources are either deployed at the AZ, Region, or Global level. Each service is different, so you need to understand how the scope of a service may affect your application architecture.\nWhen you operate a Region-scoped service, you only need to select the Region you want to use. If you are not asked to specify an individual AZ to deploy the service in, this is an indicator that the service operates on a Region-scope level. For region-scoped services, AWS automatically performs actions to increase data durability and availability.\nOn the other hand, some services ask you to specify an AZ. With these services, you are often responsible for increasing the data durability and high availability of these resources.\n\n\nMaintain Resiliency\n\nWhat is resiliency? The capability to recover when stressed by load (more requests for service), attacks (either accidental through a bug, or deliberate through intention), and failure of any component in the workload’s components.\n\nTo keep your application available, you need to maintain high availability and resiliency. A well-known best practice for cloud architecture is to use Region-scoped, managed services. These services come with availability and resiliency built in.\nWhen that is not possible, make sure the workload is replicated across multiple AZs. At a minimum, you should use two AZs. If one entire AZ fails, your application will have infrastructure up and running in at least a second AZ to take over the traffic.\n\nInteracting with AWS\n\n\nAPI call: Application programming interfaces (APIs) are a way for one program to interact with another. API calls are the medium by which they interact. An API call, or API request, is a message sent to a server asking an API to provide a service or information.\n\nEvery action you make in AWS is an API call that is authenticated and authorized. In AWS, you can make API calls to services and resources through the AWS Management Console, the AWS Command Line Interface (CLI), or the AWS Software Development Kits (SDKs).\n\n\nThe AWS Management Console\nOne way to manage cloud resources is through the web-based console, where you log in and click on the desired service. This can be the easiest way to create and manage resources when you first begin working with the cloud. Below is a screenshot that shows the landing page when you first log into the AWS Management Console.\n\nThe services are placed in categories, such as compute, database, storage and security, identity and compliance.\nOn the upper right corner is the Region selector. If you click it and change the Region, you will make requests to the services in the chosen Region. The URL changes, too. Changing the Region directs the browser to make requests to a whole different AWS Region, represented by a different subdomain.\n\n\nThe AWS Command Line Interface (CLI)\nConsider the scenario where you run tens of servers on AWS for your application’s backend. You want to run a report to collect data from all of these servers. You need to do this programmatically every day because the server details may change. Instead of manually logging into the AWS Management Console and copying/pasting information, you can schedule an AWS Command Line Interface (CLI) script with an API call to pull this data for you.\nThe AWS CLI is a unified tool to manage AWS services. With just one tool to download and configure, you control multiple AWS services from the command line and automate them with scripts. The AWS CLI is open-source, and there are installers available for Windows, Linux, and Mac OS.\nHere is an example of running an API call against a service using the AWS CLI: aws ec2 describe-instances\nYou get this response:\n{     \"Reservations\": [         {             \"Groups\": [],             \"Instances\": [                 {                     \"AmiLaunchIndex\": 0,\nand so on.\n\n\nAWS Software Development Kits (SDKs)\nAPI calls to AWS can also be performed by executing code with programming languages. You can do this by using AWS Software Development Kits (SDKs). SDKs are open-source and maintained by AWS for the most popular programming languages, such as C++, Go, Java, JavaScript, .NET, Node.js, PHP, Python, and Ruby.\nDevelopers commonly use AWS SDKs to integrate their application source code with AWS services. Let’s say the backend of the application runs in Python and every time it receives a cat photo, it uploads that photo to a storage service. This action can be achieved from within the source code by using the AWS SDK for Python.\nHere is an example of code you can implement to work with AWS resources using the Python AWS SDK.\nimport boto3 ec2 = boto3.client('ec2') response = ec2.describe_instances() print(response)\n\nBack to contents\n\n\n\nSecurity and the AWS Shared Responsibility Model\n\n\nWhen you begin working with the AWS Cloud, managing security and compliance is a shared responsibility between AWS and you. To depict this shared responsibility, AWS created the shared responsibility model. This distinction of responsibility is commonly referred to as security of the cloud, versus security in the cloud.\n\n\n\nWhat Is AWS Responsible For?\nAWS is responsible for security of the cloud. This means AWS is required to protect and secure the infrastructure that runs all the services offered in the AWS Cloud. AWS is responsible for:\n\nProtecting and securing AWS Regions, Availability Zones, and data centers, down to the physical security of the buildings\nManaging the hardware, software, and networking components that run AWS services, such as the physical server, host operating systems, virtualization layers, and AWS networking components\n\nThe level of responsibility AWS has depends on the service. AWS classifies services into three different categories. The following table provides information about each, as well as the AWS responsibility.\n\n\n\n\n\n\n\n\nCategory\nExamples of AWS Services in the Category\nAWS Responsibility\n\n\n\n\nInfrastructure services\nCompute services, such as Amazon Elastic Compute Cloud (Amazon EC2)\nAWS manages the underlying infrastructure and foundation services.\n\n\nContainer services\nServices that require less management from the customer, such as Amazon Relational Database Service (Amazon RDS)\nAWS manages the underlying infrastructure and foundation services, operating system, and application platform.\n\n\nAbstracted services\nServices that require very little management from the customer, such as Amazon Simple Storage Service (Amazon S3)\nAWS operates the infrastructure layer, operating system, and platforms, as well as server-side encryption and data protection.\n\n\n\nNote Container services refer to AWS abstracting application containers behind the scenes, not Docker container services. This enables AWS to move the responsibility of managing that platform away from customers.\n\n\nWhat Is the Customer Responsible For?\nYou’re responsible for security in the cloud. When using any AWS service, you’re responsible for properly configuring the service and your applications, as well as ensuring your data is secure.\nThe level of responsibility you have depends on the AWS service. Some services require you to perform all the necessary security configuration and management tasks, while other more abstracted services require you to only manage the data and control access to your resources. Using the three categories of AWS services, you can determine your level of responsibility for each AWS service you use.\n\n\n\n\n\n\n\n\nCategory\nAWS Responsibility\nCustomer Responsibility\n\n\n\n\nInfrastructure services\nAWS manages the infrastructure and foundation services.\nYou control the operating system and application platform, as well as encrypting, protecting, and managing customer data.\n\n\nContainer services\nAWS manages the infrastructure and foundation services, operating system, and application platform.\nYou are responsible for customer data, encrypting that data, and protecting it through network firewalls and backups.\n\n\nAbstracted services\nAWS operates the infrastructure layer, operating system, and platforms, as well as server-side encryption and data protection.\nYou are responsible for managing customer data and protecting it through client-side encryption.\n\n\n\nDue to the varying level of effort, it’s important to consider which AWS service you use and review the level of responsibility required to secure the service. It’s also important to review how the shared security model aligns with the security standards in your IT environment, as well as any applicable laws and regulations.\nIt’s important to note that you maintain complete control of your data and are responsible for managing the security related to your content. Here are some examples of your responsibilities in context.\n\nChoosing a Region for AWS resources in accordance with data sovereignty regulations\nImplementing data protection mechanisms, such as encryption and managing backups\nUsing access control to limit who has access to your data and AWS resources\n\n\nProtect the AWS Root User"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#whats-the-big-deal-about-auth",
    "href": "posts/2020-01-01-AWS.html#whats-the-big-deal-about-auth",
    "title": "ThomasHSimm",
    "section": "What’s the Big Deal About Auth?",
    "text": "What’s the Big Deal About Auth?\nWhen you’re configuring access to any account, two terms come up frequently: - authentication - and authorization.\nThough these terms may seem basic, you need to understand them to properly configure access management on AWS. It’s important to keep this in mind as you progress through the course. Let’s define both terms.\n\nUnderstand Authentication\nWhen you create your AWS account, you use a combination of an email address and a password to verify your identity. If the user types in the correct email and password, the system assumes the user is allowed to enter and grants them access. This is the process of authentication.\nAuthentication ensures that the user is who they say they are. Usernames and passwords are the most common types of authentication, but you may also work with other forms, such as token-based authentication or biometric data like a fingerprint. Authentication simply answers the question, “Are you who you say you are?”\n\n\nUnderstand Authorization\nOnce you’re inside your AWS account, you might be curious about what actions you can take. This is where authorization comes in. Authorization is the process of giving users permission to access AWS resources and services. Authorization determines whether the user can perform an action—whether it be to read, edit, delete, or create resources.\nAuthorization answers the question, “What actions can you perform?”\n\n\nWhat Is the AWS Root User?\nWhen you first create an AWS account, you begin with a single sign-in identity that has complete access to all AWS services and resources in the account. This identity is called the AWS root user and is accessed by signing in with the email address and password that you used to create the account.\n\n\nUnderstand the AWS Root User Credentials\nThe AWS root user has two sets of credentials associated with it. One set of credentials is the email address and password used to create the account. This allows you to access the AWS Management Console. The second set of credentials is called access keys, which allow you to make programmatic requests from the AWS Command Line Interface (AWS CLI) or AWS API.\nAccess keys consist of two parts:\n\nAn access key ID, for example, A2lAl5EXAMPLE\nA secret access key, for example, wJalrFE/KbEKxE\n\nSimilar to a username and password combination, you need both the access key ID and secret access key to authenticate your requests via the AWS CLI or AWS API. Access keys should be managed with the same security as an email address and password.\n\n\nFollow Best Practices When Working with the AWS Root User\nKeep in mind that the root user has complete access to all AWS services and resources in your account, as well as your billing and personal information. Due to this, securely lock away the credentials associated with the root user and do not use the root user for everyday tasks.\nTo ensure the safety of the root user:\n\nChoose a strong password for the root user.\nNever share your root user password or access keys with anyone.\nDisable or delete the access keys associated with the root user.\nDo not use the root user for administrative tasks or everyday tasks.\n\nWhen is it OK to use the AWS root user?\nThere are some tasks where it makes sense to use the AWS root user. Check out the links at the end of this section to read about them.\n\n\nDelete Your Keys to Stay Safe\nIf you don’t already have an access key for your AWS account root user, don’t create one unless you absolutely need to. If you do have an access key for your AWS account root user and want to delete the keys:\n\nGo to the My Security Credentials page in the AWS Management Console and sign in with the root user’s email address and password.\nOpen the Access keys section.\nUnder Actions, click Delete.\nClick Yes.\n\n\n\nThe Case for Multi-Factor Authentication\nWhen you create an AWS account and first log in to that account, you use single-factor authentication. Single-factor authentication is the simplest and most common form of authentication. It only requires one authentication method. In this case, you use a username and password to authenticate as the AWS root user. Other forms of single-factor authentication include a security pin or a security token.\nHowever, sometimes a user’s password is easy to guess. For example, your coworker Bob’s password, IloveCats222, might be easy for someone who knows Bob personally to guess, because it’s a combination of information that is easy to remember and describes certain things about Bob (1. Bob loves cats, and 2. Bob’s birthday is February 22).\nIf a bad actor guessed or cracked Bob’s password through social engineering, bots, or scripts, Bob might lose control of his account. Unfortunately, this is a common scenario that users of any website often face.\nThis is why using MFA has become so important in preventing unwanted account access. MFA requires two or more authentication methods to verify an identity, pulling from three different categories of information.\n\nSomething you know, such as a username and password, or pin number\nSomething you have, such as a one-time passcode from a hardware device or mobile app\nSomething you are, such as fingerprint or face scanning technology\n\nUsing a combination of this information enables systems to provide a layered approach to account access. Even though the first method of authentication, Bob’s password, was cracked by a malicious user, it’s very unlikely that a second method of authentication, such as a fingerprint, would also be cracked.\nThis extra layer of security is needed when protecting your most sacred accounts, which is why it’s important to enable MFA on your AWS root user.\n\n\nUse MFA on AWS\nIf you enable MFA on your root user, you are required to present a piece of identifying information from both the something you know category and the something you have category. The first piece of identifying information the user enters is an email and password combination. The second piece of information is a temporary numeric code provided by an MFA device.\nEnabling MFA adds an additional layer of security because it requires users to use a supported MFA mechanism in addition to their regular sign-in credentials. It’s best practice to enable MFA on the root user.\n\nReview Supported MFA Devices\nAWS supports a variety of MFA mechanisms, such as virtual MFA devices, hardware devices, and Universal 2nd Factor (U2F) security keys. For instructions on how to set up each method, check out the Resources section.\n\nIntroduction to AWS Identity and Access Management\n\n\n\n\nWhat Is IAM?\nIAM is a web service that enables you to manage access to your AWS account and resources. It also provides a centralized view of who and what are allowed inside your AWS account (authentication), and who and what have permissions to use and work with your AWS resources (authorization).\nWith IAM, you can share access to an AWS account and resources without having to share your set of access keys or password. You can also provide granular access to those working in your account, so that people and services only have permissions to the resources they need. For example, to provide a user of your AWS account with read-only access to a particular AWS service, you can granularly select which actions and which resources in that service they can access.\n\nGet to Know the IAM Features\nTo help control access and manage identities within your AWS account, IAM offers many features to ensure security.\n\nIAM is global and not specific to any one Region. This means you can see and use your IAM configurations from any Region in the AWS Management Console.\nIAM is integrated with many AWS services by default.\nYou can establish password policies in IAM to specify complexity requirements and mandatory rotation periods for users.\nIAM supports MFA (multi factor auth).\nIAM supports identity federation, which allows users who already have passwords elsewhere—for example, in your corporate network or with an internet identity provider—to get temporary access to your AWS account.\nAny AWS customer can use IAM; the service is offered at no additional charge.\n\n\n\n\nWhat Is an IAM User?\nAn IAM user represents a person or service that interacts with AWS. You define the user within your AWS account. And any activity done by that user is billed to your account. Once you create a user, that user can sign in to gain access to the AWS resources inside your account.\nYou can also add more users to your account as needed. For example, for your cat photo application, you could create individual users in your AWS account that correspond to the people who are working on your application. Each person should have their own login credentials. Providing users with their own login credentials prevents sharing of credentials.\n\n\nIAM User Credentials\nAn IAM user consists of a name and a set of credentials. When creating a user, you can choose to provide the user:\n\nAccess to the AWS Management Console\nProgrammatic access to the AWS Command Line Interface (AWS CLI) and AWS Application Programming Interface (AWS API)\n\nTo access the AWS Management Console, provide the users with a user name and password. For programmatic access, AWS generates a set of access keys that can be used with the AWS CLI and AWS API. IAM user credentials are considered permanent, in that they stay with the user until there’s a forced rotation by admins.\nWhen you create an IAM user, you have the option to grant permissions directly at the user level.\nThis can seem like a good idea if you have only one or a few users. However, as the number of users helping you build your solutions on AWS increases, it becomes more complicated to keep up with permissions. For example, if you have 3,000 users in your AWS account, administering access becomes challenging, and it’s impossible to get a top-level view of who can perform what actions on which resources.\nIf only there were a way to group IAM users and attach permissions at the group level instead. Guess what: There is!\n\n\nWhat Is an IAM Group?\nAn IAM group is a collection of users. All users in the group inherit the permissions assigned to the group. This makes it easy to give permissions to multiple users at once. It’s a more convenient and scalable way of managing permissions for users in your AWS account. This is why using IAM groups is a best practice.\nIf you have an application that you’re trying to build and have multiple users in one account working on the application, you might decide to organize these users by job function. You might want IAM groups organized by developers, security, and admins. You would then place all of your IAM users in the respective group for their job function.\nThis provides a better view to see who has what permissions within your organization and an easier way to scale as new people join, leave, and change roles in your organization.\nConsider the following examples.\n\nA new developer joins your AWS account to help with your application. You simply create a new user and add them to the developer group, without having to think about which permissions they need.\nA developer changes jobs and becomes a security engineer. Instead of editing the user’s permissions directly, you can instead remove them from the old group and add them to the new group that already has the correct level of access.\n\nKeep in mind the following features of groups.\n\nGroups can have many users.\nUsers can belong to many groups.\nGroups cannot belong to groups.\n\nThe root user can perform all actions on all resources inside an AWS account by default. This is in contrast to creating new IAM users, new groups, or new roles. New IAM identities can perform no actions inside your AWS account by default until you explicitly grant them permission.\nThe way you grant permissions in IAM is by using IAM policies.\n\n\nWhat Is an IAM Policy?\nTo manage access and provide permissions to AWS services and resources, you create IAM policies and attach them to IAM users, groups, and roles. Whenever a user or role makes a request, AWS evaluates the policies associated with them.\nFor example, if you have a developer inside the developers group who makes a request to an AWS service, AWS evaluates any policies attached to the developers group and any policies attached to the developer user to determine if the request should be allowed or denied.\n\nIAM Policy Examples\nMost policies are stored in AWS as JSON documents with several policy elements. Take a look at the following example of what providing admin access through an IAM identity-based policy looks like.\n{ \"Version\": \"2012-10-17\",     \"Statement\": [{         \"Effect\": \"Allow\",         \"Action\": \"*\",         \"Resource\": \"*\"      }] }\nIn this policy, there are four major JSON elements: - Version, - Effect, - Action, - Resource.\nThe Version element defines the version of the policy language. It specifies the language syntax rules that are needed by AWS to process a policy. To use all the available policy features, include “Version”: “2012-10-17” before the “Statement” element in all your policies.\nThe Effect element specifies whether the statement will allow or deny access. In this policy, the Effect is “Allow”, which means you’re providing access to a particular resource.\nThe Action element describes the type of action that should be allowed or denied. In the above policy, the action is “*“. This is called a wildcard, and it is used to symbolize every action inside your AWS account.\nThe Resource element specifies the object or objects that the policy statement covers. In the policy example above, the resource is also the wildcard “*“. This represents all resources inside your AWS console.\nPutting all this information together, you have a policy that allows you to perform all actions on all resources inside your AWS account. This is what we refer to as an administrator policy.\nLet’s look at another example of a more granular IAM policy.\n{ \"Version\": \"2012-10-17\",     \"Statement\": [{         \"Effect\": \"Allow\",         \"Action\": [             \"iam: ChangePassword\",             \"iam: GetUser\"             ]         \"Resource\": \"arn:aws:iam::123456789012:user/${aws:username}\"     }] }\nAfter looking at the JSON, you can see that this policy allows the IAM user to change their own IAM password (iam:ChangePassword) and get information about their own user (iam:GetUser).\nIt only permits them to access their own credentials because the resource restricts access with the variable substitution ${aws:username}.\n\n\nUnderstand Policy Structure\nWhen creating a policy, it is required to have each of the following elements inside a policy statement.\n\n\n\n\n\n\n\n\n\nElement\nDescription\nRequired\nExample\n\n\n\n\nEffect\nSpecifies whether the statement results in an allow or an explicit deny\n✔\n“Effect”: “Deny”\n\n\nAction\nDescribes the specific actions that will be allowed or denied\n✔\n“Action”: “iam:CreateUser”\n\n\nResource\nSpecifies the object or objects that the statement covers\n✔\n“Resource”: “arn:aws:iam::account-ID-without-hyphens:user/Bob”\n\n\n\n\nSummary Role Based Access in AWS\n\nThroughout these last few lessons, there have been sprinklings of IAM best practices. It’s helpful to have a brief summary of some of the most important IAM best practices you need to be familiar with before building out solutions on AWS.\n\nLock Down the AWS Root User\n\n\nThe root user is an all-powerful and all-knowing identity within your AWS account. If a malicious user were to gain control of root-user credentials, they would be able to access every resource within your account, including personal and billing information. To lock down the root user:\n\n\nDon’t share the credentials associated with the root user.\nConsider deleting the root user access keys.\nEnable MFA on the root account.\n\n\nFollow the Principle of Least Privilege\n\n\nLeast privilege is a standard security principle that advises you to grant only the necessary permissions to do a particular job and nothing more. To implement least privilege for access control, start with the minimum set of permissions in an IAM policy and then grant additional permissions as necessary for a user, group, or role.\n\n\nUse IAM Appropriately\n\n\nIAM is used to secure access to your AWS account and resources. It simply provides a way to create and manage users, groups, and roles to access resources within a single AWS account. IAM is not used for website authentication and authorization, such as providing users of a website with sign-in and sign-up functionality. IAM also does not support security controls for protecting operating systems and networks.\n\n\nUse IAM Roles When Possible\n\n\nMaintaining roles is easier than maintaining users. When you assume a role, IAM dynamically provides temporary credentials that expire after a defined period of time, between 15 minutes and 36 hours. Users, on the other hand, have long-term credentials in the form of user name and password combinations or a set of access keys.\n\nUser access keys only expire when you or the admin of your account rotates these keys. User login credentials expire if you have applied a password policy to your account that forces users to rotate their passwords.\n\nConsider Using an Identity Provider\n\n\nIf you decide to make your cat photo application into a business and begin to have more than a handful of people working on it, consider managing employee identity information through an identity provider (IdP). Using an IdP, whether it be an AWS service such as AWS Single Sign-On (SSO) or a third-party identity provider, provides you a single source of truth for all identities in your organization.\n\nYou no longer have to create separate IAM users in AWS. You can instead use IAM roles to provide permissions to identities that are federated from your IdP.\nFor example, you have an employee, Martha, that has access to multiple AWS accounts. Instead of creating and managing multiple IAM users named Martha in each of those AWS accounts, you can manage Martha in your company’s IdP. If Martha moves within the company or leaves the company, Martha can be updated in the IdP, rather than in every AWS account you have.\n\nConsider AWS SSO\n\n\nIf you have an organization that spans many employees and multiple AWS accounts, you may want your employees to sign in with a single credential. AWS SSO is an IdP that lets your users sign in to a user portal with a single set of credentials. It then provides them access to all their assigned accounts and applications in one central location.\n\nAWS SSO is similar to IAM, in that it offers a directory where you can create users, organize them in groups, and set permissions across those groups, and grant access to AWS resources. However, AWS SSO has some advantages over IAM. For example, if you’re using a third-party IdP, you can sync your users and groups to AWS SSO.\nThis removes the burden of having to re-create users that already exist elsewhere, and it enables you to manage those users from your IdP. More importantly, AWS SSO separates the duties between your IdP and AWS, ensuring that your cloud access management is not inside or dependent on your IdP.\n\nBack to contents\n\n\n\nCompute as a Service on AWS"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#understanding-servers",
    "href": "posts/2020-01-01-AWS.html#understanding-servers",
    "title": "ThomasHSimm",
    "section": "Understanding Servers",
    "text": "Understanding Servers\nThe first building block you need to host an application is a server. Servers often times can handle Hypertext Transfer Protocol (HTTP) requests and send responses to clients following the client-server model, though any API based communication also falls under this model. A client being a person or computer that sends a request, and a server handling the requests is a computer, or collection of computers, connected to the internet serving websites to internet users.\nThese servers power your application by providing CPU, memory, and networking capacity to process users’ requests and transform them into responses. For context, common HTTP servers include:\n\nWindows options, such as Internet Information Services (IIS).\nLinux options, such as Apache HTTP Web Server, Nginx, and Apache Tomcat.\n\nTo run an HTTP server on AWS, you need to find a service that provides compute power in the AWS Management Console. You can log into the console and view the complete list of AWS compute services."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#choose-the-right-compute-option",
    "href": "posts/2020-01-01-AWS.html#choose-the-right-compute-option",
    "title": "ThomasHSimm",
    "section": "Choose the Right Compute Option",
    "text": "Choose the Right Compute Option\nIf you’re responsible for setting up servers on AWS to run your infrastructure, you have many compute options. You need to know which service to use for which use case. At a fundamental level, there are three types of compute options: - virtual machines, e.g. EC2 - container services, - serverless.\nIf you’re coming to AWS with prior infrastructure knowledge, a virtual machine can often be the easiest compute option in AWS to understand. This is because a virtual machine emulates a physical server and allows you to install an HTTP server to run your applications. To run these virtual machines, you install a hypervisor on a host machine. This hypervisor provisions the resources to create and run your virtual machines.\n\nHow does AWS hypervisor work? A hypervisor is a piece of system software that provides virtual machines (VMs), on which users can run their OS and applications. The hypervisor provides isolation between VMs, which run independent of each other, and allows different VMs to run their own OS\n\nIn AWS, these virtual machines are called Amazon Elastic Compute Cloud or Amazon EC2. Behind the scenes, AWS operates and manages the host machines and the hypervisor layer. AWS also installs the virtual machine operating system, called the guest operating system.\nSome AWS compute services use Amazon EC2 or use virtualization concepts under the hood, therefore it is best to understand this service first before moving on to container services and serverless compute.\n\nIntroduction to Amazon Elastic Compute Cloud\n\n\nWhat Is Amazon EC2?\nAmazon EC2 is a web service that provides secure, resizable compute capacity in the cloud. It allows you to provision virtual servers called EC2 instances. Although AWS uses the phrase “web service” to describe it, it doesn’t mean that you are limited to running just web servers on your EC2 instances.\nYou can create and manage these instances through the AWS Management Console, the AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), or through automation tools and infrastructure orchestration services.\nIn order to create an EC2 instance, you need to define:\n\nHardware specifications, like CPU, memory, network, and storage.\nLogical configurations, like networking location, firewall rules, authentication, and the operating system of your choice.\n\nWhen launching an EC2 instance, the first setting you configure is which operating system you want by selecting an Amazon Machine Image (AMI).\n\n\nWhat Is an Amazon Machine Image (AMI)?\nIn the traditional infrastructure world, the process of spinning up a server consists of installing an operating system from installation disks, installation drives, or installation wizards over the network. In the AWS Cloud, this operating system installation is no longer your responsibility, and is instead built into the AMI that you choose.\nNot only does an AMI let you configure which operating system you want, you can also select storage mappings, the architecture type (such as 32-bit, 64-bit, or 64-bit ARM), and additional software installed.\n\n\nWhat Is the Relationship Between AMIs and EC2 Instances?\nEC2 instances are live instantiations of what is defined in an AMI, much like a cake is a live instantiation of a cake recipe. If you are familiar with software development, you can also see this kind of relationship between a Class and an Object.\nA Class is something you model and define, while an object is something you interact with. In this case, the AMI is how you model and define your instance, while the EC2 instance is the entity you interact with, where you can install your web server, and serve your content to users.\nWhen you launch a new instance, AWS allocates a virtual machine that runs on a hypervisor. Then the AMI you selected is copied to the root device volume, which contains the image used to boot the volume. In the end, you get a server you can connect to and install packages and any additional software. In this case, you install a web server along with the properly configured source code of your employee directory app.\n\nOne advantage of using AMIs is that they are reusable.\nYou might choose a Linux-based AMI and configure the HTTP server, application packages, and any additional software you may need to run your application.\nIf you wanted to create a second EC2 instance with the same configurations, how can you easily do that? One option is to go through the entire instance creation and configuration process and try to match your settings to the first instance. However, this is time consuming and leaves room for human error.\nThe second, better option, is to create an AMI from your running instance and use this AMI to start a new instance. This way, your new instance will have all the same configurations as your current instance, because the configurations set in the AMIs are the same.\n\n\nWhere Can You Find AMIs?\nYou can select an AMI from the following categories.\n\nQuick Start AMIs that are premade by AWS and allow you to get started quickly.\nAWS Marketplace AMIs that provide popular open source and commercial software from third-party vendors.\nMy AMIs that are created from your EC2 instances.\nCommunity AMIs that are provided by the AWS user community.\nBuild your own custom image with EC2 Image Builder.\n\nEach AMI in the AWS Management Console has an AMI ID, which is prefixed by “ami-”, followed by a random hash of numbers and letters. These IDs are unique to each AWS region."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-ec2-instance-lifecycle",
    "href": "posts/2020-01-01-AWS.html#amazon-ec2-instance-lifecycle",
    "title": "ThomasHSimm",
    "section": "Amazon EC2 Instance Lifecycle",
    "text": "Amazon EC2 Instance Lifecycle\nNow that you know how to select an operating system for your EC2 instance, it’s time to choose other configurations to create your EC2 instance, such as the instance type, network, and storage.\nFor an application like the employee directory application, you need instances with enough capacity to run web servers and process incoming customer requests. Your instance sizing will depend on both the demands of your application and the anticipated size of your user base.\nForecasting server capacity for an on-premises application requires difficult decisions involving significant up-front capital spending, while changes to the allocation of your cloud-based services can be made with a simple API call.\nBecause of AWS’s pay-as-you-go model, you can match your infrastructure capacity to your application’s demand, instead of the other way around.\n\nWhat Makes Up an EC2 Instance?\nEC2 instances are a combination of virtual processors (vCPUs), memory, network, and in some cases, instance storage and graphics processing units (GPUs). When you create an EC2 instance, you need to choose how much you need of each of these components.\nAWS offers a variety of instances that differ based on performance. Some instances provide you with more capacity and others provide less. To get an overview of the capacity details for a particular instance, you should look at the instance type.\nInstance types consist of a prefix identifying the type of workloads they’re optimized for, followed by a size. For example, the instance type c5.large can be broken down into the following elements.\n\nc5 determines the instance family and generation number. Here, the instance belongs to the fifth generation of instances in an instance family that’s optimized for generic computation.\nlarge, which determines the amount of instance capacity.\n\n\n\nWhat Are Instance Families?\n\n\n\n\n\n\n\n\nInstance Family\nDescription\nUse Cases\n\n\n\n\nGeneral purpose\nProvides a balance of compute, memory, and networking resources, and can be used for a variety of workloads.\nScale-out workloads such as web servers, containerized microservices, caching fleets, distributed data stores, and development environments.\n\n\nCompute optimized\nIdeal for compute-bound applications that benefit from high-performance processors.\nHigh-performance web servers, scientific modeling, batch processing, distributed analytics, high-performance computing (HPC), machine/deep learning, ad serving, highly scalable multiplayer gaming.\n\n\nMemory optimized\nDesigned to deliver fast performance for workloads that process large data sets in memory.\nMemory-intensive applications such as high-performance databases, distributed web-scale in-memory caches, mid-size in-memory databases, real-time big-data analytics, and other enterprise applications.\n\n\nAccelerated computing\nUse hardware accelerators or co-processors to perform functions such as floating-point number calculations, graphics processing, or data pattern matching more efficiently than is possible with conventional CPUs.\n3D visualizations, graphics-intensive remote workstations, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.\n\n\nStorage optimized\nDesigned for workloads that require high, sequential read and write access to large data sets on local storage. They are optimized to deliver tens of thousands of low-latency random I/O operations per second (IOPS) to applications that replicate their data across different instances.\nNoSQL databases, such as Cassandra, MongoDB, and Redis, in-memory databases, scale-out transactional databases, data warehousing, Elasticsearch, and analytics.\n\n\n\n\nWhere Does Your EC2 Instance Live?\nBy default, your EC2 instances are placed in a network called the default Amazon Virtual Private Cloud (VPC). This network was created so that you can easily get started with Amazon EC2 without having to learn how to create and configure a VPC.\nAny resource you put inside the default VPC will be public and accessible by the internet, so you shouldn’t place any customer data or private information inside of it.\nOnce you get more comfortable with networking on AWS, you should change this default setting to choose your own custom VPCs and restrict access with additional routing and connectivity mechanisms.\n\n\nArchitect for High Availability\nInside this network, your instance resides in an Availability Zone of your choice. AWS services that are scoped at the Availability Zone level must be architected with high availability in mind.\nWhile EC2 instances are typically reliable, two is better than one, and three is better than two. Specifying the instance size gives you an advantage when designing your architecture because you can use more smaller instances instead of a few larger ones.\nIf your frontend only has a single instance and that instance fails, your application goes down. On the other hand, if your workload is distributed across 10 instances and one fails, you lose only 10 percent of your fleet and your application availability is hardly affected.\nWhen architecting any application for high availability, consider using at least two EC2 instances in two separate Availability Zones.\n\n\nExplore the EC2 Instance Lifecycle\nAn EC2 instance transitions between different states from the moment you create it all the way through to its termination.\n\n\nWhen you launch an instance, it enters the pending state (1). When the instance is pending, billing has not started. At this stage, the instance is preparing to enter the running state. Pending is where AWS performs all actions needed to set up an instance, such as copying the AMI content to the root device and allocating the necessary networking components.\nWhen your instance is running (2), it’s ready to use. This is also the stage where billing begins. As soon as an instance is running, you are then able to take other actions on the instance, such as reboot, terminate, stop, and stop-hibernate.\nWhen you reboot an instance (3), it’s different than performing a stop action and then a start action. Rebooting an instance is equivalent to rebooting an operating system. The instance remains on the same host computer and maintains its public and private IP address, and any data on its instance store.\nIt typically takes a few minutes for the reboot to complete. When you stop and start an instance (4), your instance may be placed on a new underlying physical server. Therefore, you lose any data on the instance store that were on the previous host computer. When you stop an instance, the instance gets a new public IP address but maintains the same private IP address.\nWhen you terminate an instance (5), the instance store are erased, and you lose both the public IP address and private IP address of the machine. Termination of an instance means you can no longer access the machine.\n\n\n\nWhat Is the Difference Between Stop and Stop-Hibernate?\nWhen you stop your instance, it enters the stopping state, and then the stopped state. AWS does not charge usage or data transfer fees for your instance after you stop it, but storage for any Amazon EBS volumes is still charged. While your instance is in the stopped state, you can modify some attributes, like the instance type. When you stop your instance, the data stored in memory (RAM) is lost.\nWhen you stop-hibernate your instance, AWS signals the operating system to perform hibernation (suspend-to-disk), which saves the contents from the instance memory (RAM) to the Amazon EBS root volume.\nConsider a scenario where you build a standard three tier application, where you have web servers, application servers and database servers. Turns out, the application you built becomes extremely popular. To relieve some stress on the database that supports your application, you want to implement a custom backend layer that caches database information in memory (RAM). You decide to run this custom backend caching solution on Amazon EC2.\nIn this scenario, the stop-hibernate feature would be instrumental in persisting storage. It would prevent you from having to manually create scripts to save this RAM data before shutting down the server.\n\n\n\nWhat Makes Up the Pricing?\nTo understand EC2 pricing, let’s decouple the instance price from other services attached to it, such as storage and networking costs. In this unit we refer to the instance cost as the cost associated with the instance in terms of specifications and not the total blended cost of running an instance.\nOnce an instance is launched in your AWS account, the billing usually accrues on a per-second basis. For simplicity of calculation, prices are stated per-hour. For example, if you have an instance running for 5 minutes and 38 seconds during a given month, you only pay for 338 seconds of utilization at the end of the month.\nOne exception to this pricing convention may be third-party AMIs purchased from the AWS Marketplace, which may have a minimum billing of 1 hour. For more details, check out the resources section of this unit.\n\nWhat Are the EC2 Pricing Options?\nOne of the ways to reduce costs with Amazon EC2 is to choose the right pricing option for the way your applications run. There are three main purchasing options for EC2 instances: - on-demand, - reserved, and - spot instances.\n\n\nPay As You Go with On-Demand Instances\nWith On-Demand instances, you pay for compute capacity with no long-term commitments. Billing begins whenever the instance is running, and billing stops when the instance is in a stopped or terminated state. The price per second for a running On-Demand instance is fixed.\nFor applications that require servers to be running all the time, you are less likely to benefit from the On-Demand pricing model, simply because there is no situation where you will need to turn servers off. For example, you might want the web server hosting the frontend of your corporate directory application to be running 24/7 so that users can access the website at any time. Even if there are no users connected to your website, you don’t want to shut down the servers supporting the site in case of potential user activity.\nIn the case when servers cannot be stopped, consider using a Reserved Instance to save on costs.\n\n\nReserve Capacity with Reserved Instances (RIs)\nRIs provide you with a significant discount compared to On-Demand instance pricing. RIs provide a discounted hourly rate and an optional capacity reservation for EC2 instances. You can choose between three payment options: - All Upfront, - Partial Upfront, or - No Upfront.\nYou can select for each of these options either a - 1-year or - 3-year term\nDepending on which option you choose, you are discounted differently.\n\nAll Upfront offers a higher discount than Partial Upfront instances.\nPartial Upfront instances offer a higher discount than No Upfront.\nNo Upfront offers a higher discount than On-Demand.\n\nOn-Demand and No Upfront are similar since both do not require any upfront payment. However, there is a major difference. When you choose an On-Demand instance, you stop paying for the instance when you stop or terminate the instance. When you stop an RI, you still pay for it because you committed to a 1-year or 3-year term.\nReserved Instances are associated with an instance type and an Availability Zone depending on how you reserve it. The discount applied by a Reserved Instance purchase is not directly associated with a specific instance ID, but with an instance type.\n\n\nSave on Costs with Spot Instances\nAnother way of paying for EC2 instances is by using Spot Instances. Amazon EC2 Spot Instances allow you to take advantage of unused EC2 capacity in the AWS Cloud. They are available at up to a 90% discount compared to On-Demand prices.\nWith Spot Instances, you set a limit on how much you would like to pay for the instance hour. This is compared against the current Spot price that AWS determines. If the amount you pay is more than the current Spot price and there is capacity, then you will receive an instance. While they are very promising from the billing perspective, there are some architectural considerations you will need to consider in order to use them effectively.\nOne consideration is that your spot instance may be interrupted. For example, if AWS determines that capacity is no longer available for a particular spot instance or if the Spot price exceeds how much you are willing to pay, AWS will give you a 2-minute warning before it interrupts your instance. That means any application or workload that runs on a Spot instance must be able to be interrupted.\nBecause of this unique consideration, inherently fault-tolerant workloads are typically good candidates to use with Spot instances.\nThese include - big data, - containerized workloads, - continuous integration/continuous delivery (CI/CD), - web servers, - high-performance computing (HPC), - image and media rendering, - or other test and development workloads."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#steps-to-create-an-ec2-instance",
    "href": "posts/2020-01-01-AWS.html#steps-to-create-an-ec2-instance",
    "title": "ThomasHSimm",
    "section": "Steps to create an EC2 instance",
    "text": "Steps to create an EC2 instance\n\nClick on Launch instance\nChoose Amazon Machine Image, click select\nChoose instance type (e.g. t2 micro) and click on config details\nEnter values in Network and Subnet field\nClick checkbox to protect against accidental terminaton\nChoose Share-Run a shared hardware instance tenancy.\nSelect storage type\nReview and Launch\nConfigure security group.\nLaunch\nSelect/create key pair\nLaunch Instances\nView Instance.\n\n\nContainer Services on AWS\n\nAWS offers a broad spectrum of compute offerings that give you the flexibility to choose the right tool for the right job. The three main categories of compute are - virtual machines, - containers, and - serverless.\nThere is no one-size-fits-all service because it depends on your needs.\nThe key is to understand what each option has to offer in order to build a more appropriate cloud architecture for your use case."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-a-container",
    "href": "posts/2020-01-01-AWS.html#what-is-a-container",
    "title": "ThomasHSimm",
    "section": "What Is a Container?",
    "text": "What Is a Container?\n\nWhat is the container in AWS? Containers provide a standard way to package your application’s code, configurations, and dependencies into a single object. Containers share an operating system installed on the server and run as resource-isolated processes, ensuring quick, reliable, and consistent deployments, regardless of environment\n\nContainers can host a variety of different workloads, including - web applications, - lift and shift migrations, - distributed applications, and - streamlining of development, test, and production environments.\nWith the evolution of the open source software community, containers evolved. Today, containers are used as a solution to problems of traditional compute, including the issue of getting software to run reliably when it moves from one compute environment to another.\nA container is a standardized unit that packages up your code and all of its dependencies. This package is designed to run reliably on any platform, because the container creates its own independent environment. This makes it easy to carry workloads from one place to another, such as from development to production or from on-premises to the cloud."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-docker",
    "href": "posts/2020-01-01-AWS.html#what-is-docker",
    "title": "ThomasHSimm",
    "section": "What Is Docker?",
    "text": "What Is Docker?\nWhen you hear the word container, you may associate it with Docker. Docker is a popular container runtime that simplifies the management of the entire operating system stack needed for container isolation, including networking and storage. Docker makes it easy to create, package, deploy, and run containers.\n\nWhat Is the Difference Between Containers and VMs?\nContainers share the same operating system and kernel as the host they exist on, whereas virtual machines contain their operating system. Since each virtual machine has to maintain a copy of an operating system, there’s a degree of wasted space.\nA container is more lightweight. They spin up quicker, almost instantly. This difference in startup time becomes instrumental when designing applications that need to scale quickly during input/output (I/O) bursts.\nWhile containers can provide speed, virtual machines offer you the full strength of an operating system and offer more resources, like package installation, a dedicated kernel, and more.\n\n\n\nOrchestrate Containers\nIn AWS, containers run on EC2 instances. For example, you may have a large instance and run a few containers on that instance.\nWhile running one instance is easy to manage, it lacks high availability and scalability. Most companies and organizations run many containers on many EC2 instances across several Availability Zones.\nIf you’re trying to manage your compute at a large scale, you need to know:\n\nHow to place your containers on your instances.\nWhat happens if your container fails.\nWhat happens if your instance fails.\nHow to monitor deployments of your containers.\n\nThis coordination is handled by a container orchestration service. AWS offers two container orchestration services: Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).\n\n\nManage Containers with Amazon Elastic Container Service (Amazon ECS)\n\nAmazon ECS is an end-to-end container orchestration service that allows you to quickly spin up new containers and manage them across a cluster of EC2 instances.\nTo run and manage your containers, you need to install the Amazon ECS Container Agent on your EC2 instances. This agent is open source and responsible for communicating back to the Amazon ECS service about cluster management details. You can run this agent on both Linux and Windows AMIs. An instance with the container agent installed is often called a container instance.\n\nOnce the Amazon ECS container instances are up and running, you can perform actions that include, but are not limited to, - launching and stopping containers, - getting cluster state, - scaling in and out, - scheduling the placement of containers across your cluster, - assigning permissions, and - meeting availability requirements.\nTo prepare your application to run on Amazon ECS, you create a task definition. The task definition is a text file, in JSON format, that describes one or more containers. A task definition is similar to a blueprint that describes the resources you need to run that container, such as CPU, memory, ports, images, storage, and networking information.\nHere is a simple task definition that you can use for your corporate director application. In this example, the runs on the Nginx web server.\n{     \"family\": \"webserver\",     \"containerDefinitions\": [ {         \"name\": \"web\",         \"image\": \"nginx\",         \"memory\": \"100\",         \"cpu\": \"99\"     } ],     \"requiresCompatibilities\": [ \"FARGATE\" ],     \"networkMode\": \"awsvpc\",     \"memory\": \"512\",     \"cpu\": \"256\" }\n\n\nUse Kubernetes with Amazon Elastic Kubernetes Service (Amazon EKS)\nKubernetes is a portable, extensible, open source platform for managing containerized workloads and services. By bringing software development and operations together by design, Kubernetes created a rapidly growing ecosystem that is very popular and well established in the market.\nIf you already use Kubernetes, you can use Amazon EKS to orchestrate these workloads in the AWS Cloud.\nAmazon EKS is conceptually similar to Amazon ECS, but there are some differences.\n\nAn EC2 instance with the ECS Agent installed and configured is called a container instance.\n\nIn Amazon EKS, it is called a worker node.\n\nAn ECS Container is called a task.\n\nIn the Amazon EKS ecosystem, it is called a pod.\n\nWhile Amazon ECS runs on AWS native technology,\n\nAmazon EKS runs on top of Kubernetes.\n\n\nIf you have containers running on Kubernetes and want an advanced orchestration solution that can provide simplicity, high availability, and fine-grained control over your infrastructure, Amazon EKS is the tool for you.\n\nServerless and AWS Lambda\n\n\n\nRemove the Undifferentiated Heavy Lifting\nIf you run your code on Amazon EC2, AWS is responsible for the physical hardware and you are responsible for the logical controls, such as guest operating system, security and patching, networking, security, and scaling.\nIf you run your code in containers on Amazon ECS and Amazon EKS, AWS is responsible for more of the container management, such as deploying containers across EC2 instances and managing the container cluster. However, when running ECS and EKS on EC2, you are still responsible for maintaining the underlying EC2 instances.\nIf you want to deploy your workloads and applications without having to manage any EC2 instances, you can do that on AWS with serverless compute.\n\n\nGo Serverless\n\nWhat is serverless in AWS? A serverless architecture is a way to build and run applications and services without having to manage infrastructure. Your application still runs on servers, but all the server management is done by AWS\n\nEvery definition of serverless mentions four aspects.\n\nNo servers to provision or manage.\nScales with usage.\nYou never pay for idle resources.\nAvailability and fault tolerance are built-in.\n\nWith serverless, spend time on the things that differentiate your application, rather than spending time on ensuring availability, scaling, and managing servers.\nAWS has several serverless compute options, including AWS Fargate and AWS Lambda.\n\n\nExplore Serverless Containers with AWS Fargate\nAmazon ECS and Amazon EKS enable you to run your containers in two modes.\n\nAmazon EC2 mode\nAWS Fargate mode\n\nAWS Fargate is a purpose-built serverless compute engine for containers. Fargate scales and manages the infrastructure, allowing developers to work on what they do best: application development.\nIt achieves this by allocating the right amount of compute, eliminating the need to choose and handle EC2 Instances and cluster capacity and scaling. Fargate supports both Amazon ECS and Amazon EKS architecture and provides workload isolation and improved security by design.\nAWS Fargate abstracts the EC2 instance so you’re not required to manage it. However, with AWS Fargate, you can use all the same ECS primitives, APIs, and AWS integrations. It natively integrates with AWS Identity and Access Management (IAM) and Amazon Virtual Private Cloud (VPC). Having native integration with Amazon VPC allows you to launch Fargate containers inside your network and control connectivity to your applications.\n\n\nRun Your Code on AWS Lambda\nIf you want to deploy your workloads and applications without having to manage any EC2 instances or containers, you can use AWS Lambda.\nAWS Lambda lets you run code without provisioning or managing servers or containers. You can run code for virtually any type of application or backend service, including data processing, real-time stream processing, machine learning, WebSockets, IoT backends, mobile backends, and web apps, like your corporate directory app!\nAWS Lambda requires zero administration from the user. You upload your source code and Lambda takes care of everything required to run and scale your code with high availability. There are no servers to manage, bringing you continuous scaling with subsecond metering and consistent performance.\n\n\nHow Lambda Works\nThere are three primary components of a Lambda function: - the trigger, - code, and - configuration.\nThe code is source code, that describes what the Lambda function should run. This code can be authored in three ways.\n\nYou create the code from scratch.\nYou use a blueprint that AWS provides.\nYou use same code from the AWS Serverless Application Repository, a resource that contains sample applications, such as “hello world” code, Amazon Alexa Skill sample code, image resizing code, video encoding, and more.\n\nWhen you create your Lambda function, you specify the runtime you want your code to run in. There are built-in runtimes such as Python, Node.js, Ruby, Go, Java, .NET Core, or you can implement your Lambda functions to run on a custom runtime.\nThe configuration of a Lambda function consists of information that describes how the function should run. In the configuration, you specify network placement, environment variables, memory, invocation type, permission sets, and other configurations. To dive deeper into these configurations, check out the resources section of this unit.\nTriggers describe when the Lambda function should run. A trigger integrates your Lambda function with other AWS services, enabling you to run your Lambda function in response to certain API calls that occur in your AWS account. This makes you quicker to respond to events in your console without having to perform manual actions.\nAll you need is the what, how, and when of a Lambda function to have functional compute capacity that runs only when you need it to.\nAmazon’s CTO, Werner Vogels, says, “No server is easier to manage than no server.” This quote summarizes the convenience you can have when running serverless solutions, like AWS Fargate and AWS Lambda. In the next unit, you apply all the information you’ve learned about Amazon EC2, Amazon ECS and Amazon EKS, and AWS Fargate and learn the use cases for each service.\n\n\nAWS Lambda function handler\nThe AWS Lambda function handler is the method in your function code that processes events. When your function is invoked, Lambda runs the handler method. When the handler exits or returns a response, it becomes available to handle another event.\nYou can use the following general syntax when creating a function handler in Python:\ndef handler_name(event, context):      ...     return some_value\n\nNaming\nThe Lambda function handler name specified at the time you create a Lambda function is derived from the following: - the name of the file in which the Lambda handler function is located - the name of the Python handler function\nA function handler can be any name; however, the default on the Lambda console is lambda_function.lambda_handler. This name reflects the function name as lambda_handler, and the file where the handler code is stored in lambda_function.py.\nIf you choose a different name for your function handler on the Lambda console, you must update the name on the Runtime settings pane.\n\n\nBilling Granularity\nAWS Lambda lets you run code without provisioning or managing servers, and you pay only for what you use. You are charged for the number of times your code is triggered (requests) and for the time your code executes, rounded up to the nearest 1ms (duration).\nAWS rounds up duration to the nearest millisecond with no minimum execution time.\nWith this pricing, it can be very cost effective to run functions whose execution time is very low, such as functions with durations under 100ms or low latency APIs.\nRead more here: https://aws.amazon.com/blogs/aws/new-for-aws-lambda-1ms-billing-granularity-adds-cost-savings/\n\n\nSource Code\nYou can find a tutorial on creating the AWS Lambda function as well as the code used in the AWS Lambda demo here: https://aws.amazon.com/blogs/compute/resize-images-on-the-fly-with-amazon-s3-aws-lambda-and-amazon-api-gateway/\n\nBack to contents\n\n\n\nNetworking on AWS"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-networking",
    "href": "posts/2020-01-01-AWS.html#what-is-networking",
    "title": "ThomasHSimm",
    "section": "What Is Networking?",
    "text": "What Is Networking?\nNetworking is how you connect computers around the world and allow them to communicate with one another. In this trail, you’ve already seen a few examples of networking. One is the AWS global infrastructure. AWS has created a network of resources using data centers, Availability Zones, and Regions.\n\nKnow the Networking Basics\nThink about sending a letter. When sending a letter, there are three pieces of information you need.\n\nThe payload or letter inside the envelope.\nThe address of the sender in the From section.\nThe address of the recipient in the To section.\n\nLet’s go further. Each address must contain information such as:\n\nName of sender and recipient\nStreet\nCity\nState or province\nZip, area, or postal code\nCountry\n\nYou need all parts of an address to ensure that your letter gets to its destination. Without the correct address, postal workers are not able to properly deliver the message. In the digital world, computers handle the delivery of messages in a similar way. This is called routing."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-are-ip-addresses",
    "href": "posts/2020-01-01-AWS.html#what-are-ip-addresses",
    "title": "ThomasHSimm",
    "section": "What Are IP Addresses?",
    "text": "What Are IP Addresses?\nIn order to properly route your messages to a location, you need an address. Just like each home has a mail address, each computer has an IP address. However, instead of using the combination of street, city, state, zip code, and country, the IP address uses a combination of bits, 0s and 1s.\nHere is an example of a 32-bit address in binary format:\n11000000 10101000 00000001 00011110\nIt’s called 32-bit because you have 32 digits. Feel free to count!\n\nWhat Is IPv4 Notation?\nTypically, you don’t see an IP address in this binary format. Instead, it’s converted into decimal format and noted as an Ipv4 address.\nIn the diagram below, the 32 bits are grouped into groups of 8 bits, also called octets. Each of these groups is converted into decimal format separated by a period.\n11000000 10101000 00000001 00011110\n192.168.1.30\nIn the end, this is what is called an Ipv4 address. This is important to know when trying to communicate to a single computer. But remember, you’re working with a network. This is where CIDR Notation comes in.\n\n\nUse CIDR Notation\n192.168.1.30 is a single IP address. If you wanted to express IP addresses between the range of 192.168.1.0 and 192.168.1.255, how can you do that?\nOne way is by using Classless Inter-Domain Routing (CIDR) notation. CIDR notation is a compressed way of specifying a range of IP addresses. Specifying a range determines how many IP addresses are available to you.\nCIDR notation looks like this:\n192.168.1.0/24\n\n192 is fixed\n168 is fixed\n1 is fixed\n0 is flexible\n\nIt begins with a starting IP address and is separated by a forward slash (the “/” character) followed by a number. The number at the end specifies how many of the bits of the IP address are fixed. In this example, the first 24 bits of the IP address are fixed. The rest are flexible.\n32 total bits subtracted by 24 fixed bits leaves 8 flexible bits. Each of these flexible bits can be either 0 or 1, because they are binary. That means you have two choices for each of the 8 bits, providing 256 IP addresses in that IP range.\nThe higher the number after the /, the smaller the number of IP addresses in your network. For example, a range of 192.168.1.0/24 is smaller than 192.168.1.0/16.\nWhen working with networks in the AWS Cloud, you choose your network size by using CIDR notation. In AWS, the smallest IP range you can have is /28, which provides you 16 IP addresses. The largest IP range you can have is a /16, which provides you with 65,536 IP addresses.\nStanford: Introduction to Computer Networking\nExternal Site: Ionos: CIDR: What is classless inter-domain routing?"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#introduction-to-amazon-vpc",
    "href": "posts/2020-01-01-AWS.html#introduction-to-amazon-vpc",
    "title": "ThomasHSimm",
    "section": "Introduction to Amazon VPC",
    "text": "Introduction to Amazon VPC\nA VPC is an isolated network you create in the AWS cloud, similar to a traditional network in a data center. When you create a VPC, you need to choose three main things.\n\nThe name of your VPC.\nA Region for your VPC to live in. Each VPC spans multiple Availability Zones within the Region you choose.\nA IP range for your VPC in CIDR notation. This determines the size of your network. Each VPC can have up to four /16 IP ranges.\n\nUsing this information, AWS will provision a network and IP addresses for that network.\n\n\nCreate a Subnet\nAfter you create your VPC, you need to create subnets inside of this network.\nThink of subnets as smaller networks inside your base network—or virtual area networks (VLANs) in a traditional, on-premises network. In an on-premises network, the typical use case for subnets is to isolate or optimize network traffic. In AWS, subnets are used for high availability and providing different connectivity options for your resources.\nWhen you create a subnet, you need to choose three settings.\n\nThe VPC you want your subnet to live in, in this case VPC (10.0.0.0/16).\nThe Availability Zone you want your subnet to live in, in this case AZ1.\nA CIDR block for your subnet, which must be a subset of the VPC CIDR block, in this case 10.0.0.0/24.\n\nWhen you launch an EC2 instance, you launch it inside a subnet, which will be located inside the Availability Zone you choose.\n\n\n\nHigh Availability with A VPC\nWhen you create your subnets, keep high availability in mind. In order to maintain redundancy and fault tolerance, create at least two subnets configured in two different Availability Zones.\nAs you learned earlier in the trail, it’s important to consider that “everything fails all the time.” In this case, if one of these AZs fail, you still have your resources in another AZ available as backup.\n\n\n\nReserved IPs\nFor AWS to configure your VPC appropriately, AWS reserves five IP addresses in each subnet. These IP addresses are used for routing, Domain Name System (DNS), and network management.\nFor example, consider a VPC with the IP range 10.0.0.0/22. The VPC includes 1,024 total IP addresses. This is divided into four equal-sized subnets, each with a /24 IP range with 256 IP addresses. Out of each of those IP ranges, there are only 251 IP addresses that can be used because AWS reserves five.\n\nSince AWS reserves these five IP addresses, it can impact how you design your network. A common starting place for those who are new to the cloud is to create a VPC with a IP range of /16 and create subnets with a IP range of /24. This provides a large amount of IP addresses to work with at both the VPC and subnet level.\n\n\nGateways\n\nInternet Gateway\nTo enable internet connectivity for your VPC, you need to create an internet gateway. Think of this gateway as similar to a modem. Just as a modem connects your computer to the internet, the internet gateway connects your VPC to the internet. Unlike your modem at home, which sometimes goes down or offline, an internet gateway is highly available and scalable. After you create an internet gateway, you then need to attach it to your VPC.\n\n\nVirtual Private Gateway\nA virtual private gateway allows you to connect your AWS VPC to another private network. Once you create and attach a VGW to a VPC, the gateway acts as anchor on the AWS side of the connection. On the other side of the connection, you’ll need to connect a customer gateway to the other private network. A customer gateway device is a physical device or software application on your side of the connection. Once you have both gateways, you can then establish an encrypted VPN connection between the two sides.\n\nAmazon VPC Routing and Security"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#the-main-route-table",
    "href": "posts/2020-01-01-AWS.html#the-main-route-table",
    "title": "ThomasHSimm",
    "section": "The Main Route Table",
    "text": "The Main Route Table\nWhen you create a VPC, AWS creates a route table called the main route table. A route table contains a set of rules, called routes, that are used to determine where network traffic is directed. AWS assumes that when you create a new VPC with subnets, you want traffic to flow between them. Therefore, the default configuration of the main route table is to allow traffic between all subnets in the local network. Below is an example of a main route table:\n\n\n\nDestination\nTarget\nStatus\nPropagated\n\n\n\n\n10.2.0.0/16\nlocal\nactive\nno\n\n\n\nThere are two main parts to this route table.\n\nThe destination, which is a range of IP addresses where you want your traffic to go. In the example of sending a letter, you need a destination to route the letter to the appropriate place. The same is true for routing traffic. In this case, the destination is the IP range of our VPC network.\nThe target, which is the connection through which to send the traffic. In this case, the traffic is routed through the local VPC network.\n\n\nCustom Route Tables\nWhile the main route table controls the routing for your VPC, you may want to be more granular about how you route your traffic for specific subnets. For example, your application may consist of a frontend and a database. You can create separate subnets for these resources and provide different routes for each of them.\nIf you associate a custom route table with a subnet, the subnet will use it instead of the main route table. By default, each custom route table you create will have the local route already inside it, allowing communication to flow between all resources and subnets inside the VPC.\n\n\n\nSecure Your Subnets with Network ACLs\nThink of a network ACL as a firewall at the subnet level. A network ACL enables you to control what kind of traffic is allowed to enter or leave your subnet. You can configure this by setting up rules that define what you want to filter. Here’s an example.\n\nInbound\n\n\n\nRule #\nType\nProtocolPort Range\nSource\nAllow/Deny\n\n\n\n\n100\nAll IPv4 traffic\nAll\n0.0.0.0/0\nALLOW\n\n\n*\nAll IPv4 traffic\nAll\n0.0.0.0/0\nDENY\n\n\n\n\n\nOutbound\n\n\n\nRule #\nType\nProtocolPort Range\nSource\nAllow/Deny\n\n\n\n\n100\nAll IPv4 traffic\nAll\n0.0.0.0/0\nALLOW\n\n\n*\nAll IPv4 traffic\nAll\n0.0.0.0/0\nDENY\n\n\n\nThe default network ACL, shown in the table above, allows all traffic in and out of your subnet. To allow data to flow freely to your subnet, this is a good starting place.\nHowever, you may want to restrict data at the subnet level. For example, if you have a web application, you might restrict your network to allow HTTPS traffic and remote desktop protocol (RDP) traffic to your web servers.\n\n\nInbound\n\n\n\n\n\n\n\n\n\n\n\nRule #\nSource IP\nProtocol\nPort\nAllow/Deny\nComments\n\n\n\n\n100\nAll IPv4 traffic\nTCP\n443\nALLOW\nAllows inbound HTTPS traffic from anywhere\n\n\n130\n192.0.2.0/24\nTCP\n3389\nALLOW\nAllows inbound RDP traffic to the web servers from your home network’s public IP address range (over the internet gateway)\n\n\n*\nAll IPv4 traffic\nAll\nAll\nDENY\nDenies all inbound traffic not already handled by a preceding rule (not modifiable)\n\n\n\n\n\nOutbound\n\n\n\n\n\n\n\n\n\n\n\nRule #\nDestination IP\nProtocol\nPort\nAllow/Deny\nComments\n\n\n\n\n120\n0.0.0.0/0\nTCP\n1025-65535\nALLOW\nAllows outbound responses to clients on the internet (serving people visiting the web servers in the subnet)\n\n\n*\n0.0.0.0/0\nAll\nAll\nDENY\nDenies all outbound traffic not already handled by a preceding rule (not modifiable)\n\n\n\nNotice that in the network ACL example above, you allow inbound 443 and outbound range 1025-65535. That’s because HTTP uses port 443 to initiate a connection and will respond to an ephemeral port. Network ACL’s are considered stateless, so you need to include both the inbound and outbound ports used for the protocol. If you don’t include the outbound range, your server would respond but the traffic would never leave the subnet.\nSince network ACLs are configured by default to allow incoming and outgoing traffic, you don’t need to change their initial settings unless you need additional security layers.\n\n\n\nSecure Your EC2 Instances with Security Groups\nThe next layer of security is for your EC2 Instances. Here, you can create a firewall called a security group. The default configuration of a security group blocks all inbound traffic and allows all outbound traffic.\n\nYou might be wondering: “Wouldn’t this block all EC2 instances from receiving the response of any customer requests?” Well, security groups are stateful, meaning they will remember if a connection is originally initiated by the EC2 instance or from the outside and temporarily allow traffic to respond without having to modify the inbound rules.\nIf you want your EC2 instance to accept traffic from the internet, you’ll need to open up inbound ports. If you have a web server, you may need to accept HTTP and HTTPS requests to allow that type of traffic in through your security group. You can create an inbound rule that will allow port 80 (HTTP) and port 443 (HTTPS) as shown below.\n\n\n\nType\nProtocol\nPort Range\nSource\n\n\n\n\nHTTP (80)\nTCP (6)\n80\n0.0.0.0/0\n\n\nHTTP (80)\nTCP (6)\n80\n::/0\n\n\nHTTP (443)\nTCP (6)\n443\n0.0.0.0/0\n\n\nHTTP (443)\nTCP (6)\n443\n::/0\n\n\n\nYou learned in a previous unit that subnets can be used to segregate traffic between computers in your network. Security groups can be used to do the same thing. A common design pattern is organizing your resources into different groups and creating security groups for each to control network communication between them.\n\nThis example allows you to define three tiers and isolate each tier with the security group rules you define. In this case, you only allow internet traffic to the web tier over HTTPS, Web Tier to Application Tier over HTTP, and Application tier to Database tier over MySQL. This is different from traditional on-premises environments, in which you isolate groups of resources via VLAN configuration. In AWS, security groups allow you to achieve the same isolation without tying it to your network.\n\nBack to contents\n\n\n\nStorage Types on AWS\n\n\nAWS storage services are grouped into three different categories: - block storage, e.g. EBS - file storage, e.g. EFS - object storage, e.g. S3"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#file-storage",
    "href": "posts/2020-01-01-AWS.html#file-storage",
    "title": "ThomasHSimm",
    "section": "File Storage",
    "text": "File Storage\nYou may be familiar with file storage if you’ve interacted with file storage systems like Windows File Explorer or Finder on MacOS. You place your files in a tree-like hierarchy that consists of folders and subfolders. For example, if you have hundreds of cat photos on your laptop, you may want to create a folder called Cat photos, and place those images inside that folder to organize them. Since you know these images will be used in an application, you may want to place the cat photos folder inside another folder called Application files.\nEach file has metadata such as file name, file size, and the date the file was created. The file also has a path, for example, computer/Application_files/Cat_photos/cats-03.png. When you need to retrieve a file, your system can use the path to find it in the file hierarchy.\nFile storage is ideal when you require centralized access to files that need to be easily shared and managed by multiple host computers. Typically, this storage is mounted onto multiple hosts and requires file locking and integration with existing file system communication protocols.\nCommon use cases for file storage include:\n\nLarge content repositories\nDevelopment environments\nUser home directories"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#block-storage",
    "href": "posts/2020-01-01-AWS.html#block-storage",
    "title": "ThomasHSimm",
    "section": "Block Storage",
    "text": "Block Storage\nWhile file storage treats files as a singular unit, block storage splits files into fixed-size chunks of data called blocks that have their own addresses. Since each block is addressable, blocks can be retrieved efficiently.\nWhen data is requested, these addresses are used by the storage system to organize the blocks in the correct order to form a complete file to present back to the requestor. Outside of the address, there is no additional metadata associated with each block. So, when you want to change a character in a file, you just change the block, or the piece of the file, that contains the character. This ease of access is why block storage solutions are fast and use less bandwidth.\n\nSince block storage is optimized for low-latency operations, it is a typical storage choice for high-performance enterprise workloads, such as databases or enterprise resource planning (ERP) systems, that require low-latency storage."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#object-storage",
    "href": "posts/2020-01-01-AWS.html#object-storage",
    "title": "ThomasHSimm",
    "section": "Object Storage",
    "text": "Object Storage\nObjects, much like files, are also treated as a single unit of data when stored. However, unlike file storage, these objects are stored in a flat structure instead of a hierarchy. Each object is a file with a unique identifier. This identifier, along with any additional metadata, is bundled with the data and stored.\nChanging just one character in an object is more difficult than with block storage. When you want to change one character in a file, the entire file must be updated.\n\nWith object storage, you can store almost any type of data, and there is no limit to the number of objects stored, making it easy to scale. Object storage is generally useful when storing large data sets, unstructured files like media assets, and static assets, such as photos.\n\nRelate Back to Traditional Storage Systems\nIf you’ve worked with storage on-premises, you may already be familiar with block, file, and object storage. Consider the following technologies and how they relate to systems you may have seen before.\n\nBlock storage in the cloud is analogous to direct-attached storage (DAS) or a storage area network (SAN).\nFile storage systems are often supported with a network attached storage (NAS) server.\n\nAdding more storage in a traditional data center environment is a more rigid process, as you need to purchase, install, and configure these storage solutions. With cloud computing, the process is more flexible. You can create, delete, and modify storage solutions all within a matter of minutes.\n\nAmazon EC2 Instance Storage and Amazon Elastic Block Store"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-ec2-instance-store",
    "href": "posts/2020-01-01-AWS.html#amazon-ec2-instance-store",
    "title": "ThomasHSimm",
    "section": "Amazon EC2 Instance Store",
    "text": "Amazon EC2 Instance Store\nAmazon EC2 Instance Store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. This ties the lifecycle of your data to the lifecycle of your EC2 instance. If you delete your instance, the instance store is deleted as well. Due to this, instance store is considered ephemeral storage (volatile temporary storage attached to your instances which is only present during the running lifetime of the instance).\nInstance store is ideal if you are hosting applications that replicate data to other EC2 instances, such as Hadoop clusters. For these cluster-based workloads, having the speed of locally attached volumes and the resiliency of replicated data helps you achieve data distribution at high performance. It’s also ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-elastic-block-storage-amazon-ebs",
    "href": "posts/2020-01-01-AWS.html#amazon-elastic-block-storage-amazon-ebs",
    "title": "ThomasHSimm",
    "section": "Amazon Elastic Block Storage (Amazon EBS)",
    "text": "Amazon Elastic Block Storage (Amazon EBS)\nAs the name implies, Amazon EBS is a block-level storage device that you can attach to an Amazon EC2 instance. These storage devices are called Amazon EBS volumes. EBS volumes are essentially drives of a user-configured size attached to an EC2 instance, similar to how you might attach an external drive to your laptop.\nEBS volumes act similarly to external drives in more than one way.\n\nMost Amazon EBS volumes can only be connected with one computer at a time. Most EBS volumes have a one-to-one relationship with EC2 instances, so they cannot be shared by or attached to multiple instances at one time. Note: Recently, AWS announced the Amazon EBS multi-attach feature that enables volumes to be attached to multiple EC2 instances at one time. This feature is not available for all instance types and all instances must be in the same Availability Zone.\nDetach and re-attach. You can detach an EBS volume from one EC2 instance and attach it to another EC2 instance in the same Availability Zone, to access the data on it.\nThe external drive is separate from the computer. That means, if an accident happens and the computer goes down, you still have your data on your external drive. The same is true for EBS volumes.\nYou’re limited to the size of the external drive, since it has a fixed limit to how scalable it can be. For example, you may have a 2 TB external drive and that means you can only have 2 TB of content on there. This relates to EBS as well, since volumes also have a max limitation of how much content you can store on the volume.\n\n\nSteps to create EBS\n\nOpen Amazon Ec2 console\nChoose Volumes from navigation pane\nCreate Volume\nChoose Volume type\nEnter volume size in Gb\nEnter min/max input/output operations per second (IOPS)\nEnter Throughput (MiB/s)\nChoose Availability Zone (has to be same as instance)\nSnapshot ID (keep as default)\nCreate volume\n\n\n\nScale Amazon EBS Volumes\nYou can scale Amazon EBS volumes in two ways.\n\nIncrease the volume size, as long as it doesn’t increase above the maximum size limit. For EBS volumes, the maximum amount of storage you can have is 16 TB. That means if you provision a 5 TB EBS volume, you can choose to increase the size of your volume until you get to 16 TB.\nAttach multiple volumes to a single Amazon EC2 instance. EC2 has a one-to-many relationship with EBS volumes. You can add these additional volumes during or after EC2 instance creation to provide more storage capacity for your hosts.\n\n\n\nAmazon EBS Use Cases\nAmazon EBS is useful when you need to retrieve data quickly and have data persist long-term. Volumes are commonly used in the following scenarios.\n\nOperating systems: Boot/root volumes to store an operating system. The root device for an instance launched from an Amazon Machine Image (AMI) is typically an Amazon EBS volume. These are commonly referred to as EBS-backed AMIs.\nDatabases: A storage layer for databases running on Amazon EC2 that rely on transactional reads and writes.\nEnterprise applications: Amazon EBS provides reliable block storage to run business-critical applications.\nThroughput-intensive applications: Applications that perform long, continuous reads and writes.\n\n\n\nAmazon EBS Volume Types\nThere are two main categories of Amazon EBS volumes: solid-state drives (SSDs) and hard-disk drives (HDDs). SSDs provide strong performance for random input/output (I/O), while HDDs provide strong performance for sequential I/O. AWS offers two types of each.\nThe following chart can help you decide which EBS volume is the right option for your workload.\n\nEBS Provisioned IOPS SSD\n\nDescription\n\nHighest performance SSD designed for latency-sensitive transactional workloads\n\nUse Cases\n\nI/O-intensive NoSQL and relational databases\n\nVolume Size\n\n4 GB-16 TB\n\nMax IOPS/Volume\n\n64,000\n\nMax Throughput/Volume\n\n1,000 MB/s\n\n\n\n\nEBS General Purpose SSD\n\nDescription\n\nGeneral purpose SSD that balances price and performance for a wide variety of transactional workloads\n\nUse Cases\n\nBoot volumes, low-latency interactive apps, development, and test\n\nVolume Size\n\n1 GB-16 TB\n\nMax IOPS/Volume\n\n16,000\n\nMax Throughput/Volume\n\n250 MB/s\n\n\n\n\nThroughput Optimized HDD\n\nDescription\n\nLow-cost HDD designed for frequently accessed, throughput intensive workloads\n\nUse Cases\n\nBig data, data warehouses, log processing\n\nVolume Size\n\n500 GB-16 TB\n\nMax IOPS/Volume\n\n500\n\nMax Throughput/Volume\n\n500 MB/s\n\n\n\n\nCold HDD\n\nDescription\n\nLowest cost HDD designed for less frequently accessed workloads\n\nUse Cases\n\nColder data requiring fewer scans per day\n\nVolume Size\n\n500 GB-16 TB\n\nMax IOPS/Volume\n\n250\n\nMax Throughput/Volume\n\n250 MB/s\n\n\n\n\n\nBenefits of Using Amazon EBS\nHere are the following benefits of using Amazon EBS (in case you need a quick cheat sheet).\n\nHigh availability: When you create an EBS volume, it is automatically replicated within its Availability Zone to prevent data loss from single points of failure.\nData persistence: The storage persists even when your instance doesn’t.\nData encryption: All EBS volumes support encryption.\nFlexibility: EBS volumes support on-the-fly changes. You can modify volume type, volume size, and input/output operations per second (IOPS) capacity without stopping your instance.\nBackups: Amazon EBS provides you the ability to create backups of any EBS volume.\n\n\n\nEBS Snapshots\nErrors happen. One of those errors is not backing up data, and then, inevitably losing that data. To prevent this from happening to you, you should back up your data—even in AWS.\nSince your EBS volumes consist of the data from your Amazon EC2 instance, you’ll want to take backups of these volumes, called snapshots.\nEBS snapshots are incremental backups that only save the blocks on the volume that have changed after your most recent snapshot. For example, if you have 10 GB of data on a volume, and only 2 GB of data have been modified since your last snapshot, only the 2 GB that have been changed are written to Amazon Simple Storage Service (Amazon S3).\nWhen you take a snapshot of any of your EBS volumes, these backups are stored redundantly in multiple Availability Zones using Amazon S3. This aspect of storing the backup in Amazon S3 will be handled by AWS, so you won’t need to interact with Amazon S3 to work with your EBS snapshots. You simply manage them in the EBS console (which is part of the EC2 console).\nEBS snapshots can be used to create multiple new volumes, whether they’re in the same Availability Zone or a different one. When you create a new volume from a snapshot, it’s an exact copy of the original volume at the time the snapshot was taken.\n\nObject Storage with Amazon S3"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-amazon-s3",
    "href": "posts/2020-01-01-AWS.html#what-is-amazon-s3",
    "title": "ThomasHSimm",
    "section": "What Is Amazon S3?",
    "text": "What Is Amazon S3?\nUnlike Amazon EBS, Amazon S3 is a standalone storage solution that isn’t tied to compute. It enables you to retrieve your data from anywhere on the web. If you’ve ever used an online storage service to back up the data from your local machine, then you most likely have used a service similar to Amazon S3. The big difference between those online storage services and Amazon S3 is the storage type.\nAmazon S3 is an object storage service. Object storage stores data in a flat structure, using unique identifiers to look up objects when requested. An object is simply a file combined with metadata and that you can store as many of these objects as you’d like. All of these characteristics of object storage are also characteristics of Amazon S3.\n\nUnderstand Amazon S3 Concepts\nIn Amazon S3, you have to store your objects in containers called buckets. You can’t upload any object, not even a single photo, to S3 without creating a bucket first. When you create a bucket, you choose, at the very minimum, two things: the bucket name and the AWS Region you want the bucket to reside in.\nThe first part is choosing the Region you want the bucket to reside in. Typically, this will be a Region that you’ve used for other resources, such as your compute. When you choose a Region for your bucket, all objects you put inside that bucket are redundantly stored across multiple devices, across multiple Availability Zones. This level of redundancy is designed to provide Amazon S3 customers with 99.999999999% durability and 99.99% availability for objects over a given year.\nThe second part is choosing a bucket name which must be unique across all AWS accounts. AWS stops you from choosing a bucket name that has already been chosen by someone else in another AWS account. Once you choose a name, that name is yours and cannot be claimed by anyone else unless you delete that bucket, which then releases the name for others to use.\n\nAWS uses this name as part of the object identifier. In S3, each object is identified using a URL, which looks like this:\nAfter the http://, you see the bucket name. In this example, the bucket is named doc. Then, the identifier uses the service name, s3 and specifies the service provider amazonaws. After that, you have an implied folder inside the bucket called 2006-03-01 and the object inside the folder that is named AmazonS3.html. The object name is often referred to as the key name.\nNote, you can have folders inside of buckets to help you organize objects. However, remember that there’s no actual file hierarchy that supports this on the back end. It is instead a flat structure where all files and folders live at the same level. Using buckets and folders implies a hierarchy, which makes it easy to understand for the human eye.\n\n\nS3 Use Cases\nAmazon S3 is one of the most widely used storage services, with far more use cases than could fit on one screen. The following list summarizes some of the most common ways you can use Amazon S3.\n\nBackup and storage: S3 is a natural place to back up files because it is highly redundant. As mentioned in the last unit, AWS stores your EBS snapshots in S3 to take advantage of its high availability.\nMedia hosting: Because you can store unlimited objects, and each individual object can be up to 5 TBs, S3 is an ideal location to host video, photo, or music uploads.\nSoftware delivery: You can use S3 to host your software applications that customers can download.\nData lakes: S3 is an optimal foundation for a data lake because of its virtually unlimited scalability. You can increase storage from gigabytes to petabytes of content, paying only for what you use.\nStatic websites: You can configure your bucket to host a static website of HTML, CSS, and client-side scripts.\nStatic content: Because of the limitless scaling, the support for large files, and the fact that you access any object over the web at any time, S3 is the perfect place to store static content.\n\n\n\nChoose the Right Connectivity Option for Your Resources\nEverything in Amazon S3 is private by default. This means that all S3 resources, such as buckets, folders, and objects can only be viewed by the user or AWS account that created that resource. Amazon S3 resources are all private and protected to begin with.\nIf you decide that you want everyone on the internet to see your photos, you can choose to make your buckets, folders, and objects public. Keep in mind that a public resource means that everyone on the internet can see it. Most of the time, you don’t want your permissions to be all or nothing. Typically, you want to be more granular about the way you provide access to your resources.\n\nTo be more specific about who can do what with your S3 resources, Amazon S3 provides two main access management features: IAM policies and S3 bucket policies.\n\n\nUnderstand IAM Policies\nPreviously, you learned about creating and using IAM policies, and now you get to apply this to Amazon S3. When IAM policies are attached to IAM users, groups, and roles, the policies define which actions they can perform. IAM policies are not tied to any one AWS service and can be used to define access to nearly any AWS action.\nYou should use IAM policies for private buckets when:\n\nYou have many buckets with different permission requirements. Instead of defining many different S3 bucket policies, you can use IAM policies instead.\nYou want all policies to be in a centralized location. Using IAM policies allows you to manage all policy information in one location.\n\n\n\nUnderstand S3 Bucket Policies\nS3 bucket policies are similar to IAM policies, in that they are both defined using the same policy language in a JSON format. The difference is IAM policies are attached to users, groups, and roles, whereas S3 bucket policies are only attached to buckets. S3 bucket policies specify what actions are allowed or denied on the bucket.\nFor example, if you have a bucket called employeebucket, you can attach an S3 bucket policy to it that allows another AWS account to put objects in that bucket.\nOr if you wanted to allow anonymous viewers to read the objects in employeebucket, then you can apply a policy to that bucket that allows anyone to read objects in the bucket using \"Effect\":Allow on the \"Action:[\"s3:GetObject\"]\".\nHere’s an example of what that S3 bucket policy might look like. {     \"Version\":\"2012-10-17\",         \"Statement\":[{             \"Sid\":\"PublicRead\",             \"Effect\":\"Allow\",             \"Principal\": \"*\",             \"Action\":[\"s3:GetObject\"],             \"Resource\":[\"arn:aws:s3:::employeebucket/*\"]         }] }\nS3 Bucket policies can only be placed on buckets, and cannot be used for folders or objects. However, the policy that is placed on the bucket applies to every object in that bucket.\nYou should use S3 bucket policies when:\n\nYou need a simple way to do cross-account access to S3, without using IAM roles.\nYour IAM policies bump up against the defined size limit. S3 bucket policies have a larger size limit."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#encrypt-s3",
    "href": "posts/2020-01-01-AWS.html#encrypt-s3",
    "title": "ThomasHSimm",
    "section": "Encrypt S3",
    "text": "Encrypt S3\nAmazon S3 reinforces encryption in transit (as it travels to and from Amazon S3) and at rest. To protect data at rest, you can use:\n\nServer-side encryption: This allows Amazon S3 to encrypt your object before saving it on disks in its data centers and then decrypt it when you download the objects.\nClient-side encryption: Encrypt your data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and all related tools.\n\nTo encrypt in transit, you can use client-side encryption or Secure Sockets Layer (SSL).\n\nUse Versioning to Preserve Objects\nAs you know, Amazon S3 identifies objects in part by using the object name. For example, when you upload an employee photo to S3, you may name the object employee.jpg and store it in a folder called employees. If you don’t use Amazon S3 versioning, anytime you upload an object called employee.jpg to the employees folder, it overwrites the original file. This can be an issue for several reasons.\n\nemployee.jpg is a common name for an employee photo object. You or someone else who has access to that bucket might not have intended to overwrite it, and now that you have, you no longer have access to the original file.\nYou may want to preserve different versions of employee.jpg. Without versioning, if you wanted to create a new version of employee.jpg, you would need to upload the object and choose a different name for it. Having several objects all with slight differences in naming variations may cause confusion and clutter in your bucket.\n\nSo, what do you do? You use S3 versioning!\nVersioning enables you to keep multiple versions of a single object in the same bucket. This allows you to preserve old versions of an object without having to use different naming constructs, in case you need to recover from accidental deletions, accidental overwrites, or even application failures. Let’s see how this works.\n\nIf you enable versioning for a bucket, Amazon S3 automatically generates a unique version ID for the object being stored. In one bucket, for example, you can have two objects with the same key, but different version IDs, such as employeephoto.gif (version 111111) and employeephoto.gif (version 121212).\nVersioning-enabled buckets let you recover objects from accidental deletion or overwrite.\n\nDeleting an object does not remove the object permanently. Instead, Amazon S3 puts a marker on the object that shows you tried to delete it. If you want to restore the object, you can remove this marker and it reinstates the object.\nIf you overwrite an object, it results in a new object version in the bucket. You still have access to previous versions of the object.\n\n\n\nUnderstand Versioning States\nBuckets can be in one of three states.\n\nUnversioned (the default): No new or existing objects in the bucket have a version.\nVersioning-enabled: This enables versioning for all objects in the bucket.\nVersioning-suspended: This suspends versioning for new objects. All new objects in the bucket will not have a version. However, all existing objects keep their object versions.\n\nThe versioning state applies to all of the objects in that bucket. Keep in mind that storage costs are incurred for all objects in your bucket and all versions of those objects. To reduce your S3 bill, you may want to delete previous versions of your objects that are no longer in use."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-are-amazon-s3-storage-classes",
    "href": "posts/2020-01-01-AWS.html#what-are-amazon-s3-storage-classes",
    "title": "ThomasHSimm",
    "section": "What Are Amazon S3 Storage Classes?",
    "text": "What Are Amazon S3 Storage Classes?\nWhen you upload an object to Amazon S3 and you don’t specify the storage class, you’re uploading it to the default storage class—often referred to as standard storage. When you learned about Amazon S3 in previous units, you were learning about the standard storage class without even knowing it!\nS3 storage classes let you change your storage tier as your data characteristics change. For example, if you are now accessing your old photos infrequently, you may want to change the storage class those photos are stored in to save on costs.\nThere are six S3 storage classes.\n\nAmazon S3 Standard: This is considered general purpose storage for cloud applications, dynamic websites, content distribution, mobile and gaming applications, and big data analytics.\nAmazon S3 Intelligent-Tiering: This tier is useful if your data has unknown or changing access patterns. S3 Intelligent-Tiering stores objects in two tiers, a frequent access tier and an infrequent access tier. Amazon S3 monitors access patterns of your data, and automatically moves your data to the most cost-effective storage tier based on frequency of access.\nAmazon S3 Standard-Infrequent Access (S3 Standard-IA): S3 Standard-IA is for data that is accessed less frequently, but requires rapid access when needed. S3 Standard-IA offers the high durability, high throughput, and low latency of S3 Standard, with a low per-GB storage price and per-GB retrieval fee. This storage tier is ideal if you want to store long-term backups, disaster recovery files, and so on.\nAmazon S3 One Zone-Infrequent Access (S3 One Zone-IA): Unlike other S3 storage classes which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It’s a good choice for storing secondary backup copies of on-premises data or easily re-creatable data.\nAmazon S3 Glacier: S3 Glacier is a secure, durable, and low-cost storage class for data archiving. You can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. To keep costs low yet suitable for varying needs, S3 Glacier provides three retrieval options that range from a few minutes to hours.\nAmazon S3 Glacier Deep Archive: S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year. It is designed for customers—particularly those in highly regulated industries, such as the Financial Services, Healthcare, and Public Sectors—that retain data sets for 7 to 10 years or longer to meet regulatory compliance requirements.\n\n\nAutomate Tier Transitions with Object Lifecycle Management\nIf you keep manually changing your objects, such as your employee photos, from storage tier to storage tier, you may want to look into automating this process using a lifecycle policy. When you define a lifecycle policy configuration for an object or group of objects, you can choose to automate two actions: transition and expiration actions.\n\nTransition actions are used to define when you should transition your objects to another storage class.\nExpiration actions define when objects expire and should be permanently deleted.\n\nFor example, you might choose to transition objects to S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them.\n\nThe following use cases are good candidates for lifecycle management.\n\nPeriodic logs: If you upload periodic logs to a bucket, your application might need them for a week or a month. After that, you might want to delete them.\nData that changes in access frequency: Some documents are frequently accessed for a limited period of time. After that, they are infrequently accessed. At some point, you might not need real-time access to them, but your organization or regulations might require you to archive them for a specific period. After that, you can delete them.\n\n\nChoose the Right Storage Service\n\nHere’s a recap of all the storage services mentioned so far. By the end of this reading, you should be able to better answer the question “Which storage service should I use?” for some of the more common scenarios."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-ec2-instance-store-1",
    "href": "posts/2020-01-01-AWS.html#amazon-ec2-instance-store-1",
    "title": "ThomasHSimm",
    "section": "Amazon EC2 Instance Store",
    "text": "Amazon EC2 Instance Store\nInstance store is ephemeral block storage. This is preconfigured storage that exists on the same physical server that hosts the EC2 instance and cannot be detached from Amazon EC2. You can think of it as a built-in drive for your EC2 instance.\nInstance store is generally well-suited for temporary storage of information that is constantly changing, such as buffers, caches, and scratch data. It is not meant for data that is persistent or long-lasting.\nIf you need persistent long-term block storage that can be detached from Amazon EC2 and provide you more management flexibility, such as increasing volume size or creating snapshots, then you should use Amazon EBS."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-ebs",
    "href": "posts/2020-01-01-AWS.html#amazon-ebs",
    "title": "ThomasHSimm",
    "section": "Amazon EBS",
    "text": "Amazon EBS\nAmazon EBS is meant for data that changes frequently and needs to persist through instance stops, terminations, or hardware failures. Amazon EBS has two different types of volumes: SSD-backed volumes and HDD-backed volumes.\nSSD-backed volumes have the following characteristics.\n\nPerformance depends on IOPS (input/output operations per second).\nIdeal for transactional workloads such as databases and boot volumes.\n\nHDD-backed volumes have the following characteristics:\n\nPerformance depends on MB/s.\nIdeal for throughput-intensive workloads, such as big data, data warehouses, log processing, and sequential data I/O.\n\nHere are a few important features of Amazon EBS that you need to know when comparing it to other services.\n\nIt is block storage.\nYou pay for what you provision (you have to provision storage in advance).\nEBS volumes are replicated across multiple servers in a single Availability Zone.\nMost EBS volumes can only be attached to a single EC2 instance at a time."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-s3",
    "href": "posts/2020-01-01-AWS.html#amazon-s3",
    "title": "ThomasHSimm",
    "section": "Amazon S3",
    "text": "Amazon S3\nIf your data doesn’t change that often, Amazon S3 might be a more cost-effective and scalable storage solution. S3 is ideal for storing static web content and media, backups and archiving, data for analytics, and can even be used to host entire static websites with custom domain names.\nHere are a few important features of Amazon S3 to know about when comparing it to other services.\n\nIt is object storage.\nYou pay for what you use (you don’t have to provision storage in advance).\nAmazon S3 replicates your objects across multiple Availability Zones in a Region.\nAmazon S3 is not storage attached to compute."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#amazon-elastic-file-system-amazon-efs-and-amazon-fsx",
    "href": "posts/2020-01-01-AWS.html#amazon-elastic-file-system-amazon-efs-and-amazon-fsx",
    "title": "ThomasHSimm",
    "section": "Amazon Elastic File System (Amazon EFS) and Amazon FSx",
    "text": "Amazon Elastic File System (Amazon EFS) and Amazon FSx\nIn this module, you’ve already learned about Amazon S3 and Amazon EBS. You learned that S3 uses a flat namespace and isn’t meant to serve as a standalone file system. You also learned most EBS volumes can only be attached to one EC2 instance at a time. So, if you need file storage on AWS, which service should you use?\nFor file storage that can mount on to multiple EC2 instances, you can use Amazon Elastic File System (Amazon EFS) or Amazon FSx. Use the following table for more information about each of these services.\n\n\n\n\n\n\n\n\nService\nCharacteristic\nMore Information\n\n\n\n\nAmazon Elastic File System (EFS)\nFully managed NFS file system.\nEFS FAQs\n\n\nAmazon FSx for Windows File Server\nFully managed file server built on Windows Server that supports the SMB protocol.\nFSx for Windows File Server FAQs\n\n\nAmazon FSx for Lustre\nFully managed Lustre file system that integrates with S3.\nFSx for Lustre FAQs\n\n\n\nHere are a few important features of Amazon EFS and FSx to know about when comparing them to other services.\n\nIt is file storage.\nYou pay for what you use (you don’t have to provision storage in advance).\nAmazon EFS and Amazon FSx can be mounted onto multiple EC2 instances.\n\n\n\nExplore Databases on AWS"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#understanding-the-history-behind-enterprise-databases",
    "href": "posts/2020-01-01-AWS.html#understanding-the-history-behind-enterprise-databases",
    "title": "ThomasHSimm",
    "section": "Understanding the History Behind Enterprise Databases",
    "text": "Understanding the History Behind Enterprise Databases\nChoosing a database used to be a straightforward decision. There were only a few options to choose from. In the past, you likely considered a few vendors and then inevitably chose one for all of your applications.\nBusinesses often selected the database technology they were going to use, even before they fully understood their use case. Since the 1970s, the database most commonly selected by businesses was a relational database.\n\nWhat Is a Relational Database?\nA relational database organizes data into tables. Data in one table can be linked to data in other tables to create relationships—hence, the relational part of the name.\nA table stores data in rows and columns. A row, often called a record, contains all information about a specific entry. Columns describe attributes of that entry. Here’s an example of three tables in a relational database.\n\nThis shows a table for books, a table for sales, and a table for authors. In the books table, each row includes the book ISBN, the title, the author, and the format. Each of these attributes is stored in its own column. The books table has something in common with the other two tables: the author attribute. That common column creates a relationship between the tables.\nThe tables, rows, columns, and relationships between them is referred to as a logical schema. With relational databases, a schema is fixed. Once the database is operational, it becomes difficult to change the schema. This requires most of the data modeling to be done upfront before the database is active.\n\n\nWhat Is a Relational Database Management System?\nA relational database management system (RDBMS) lets you create, update, and administer a relational database. Here are some common examples of relational database management systems:\n\nMySQL\nPostgresQL\nOracle\nSQL server\nAmazon Aurora\n\nYou communicate with most RDBMS by using Structured Query Language (SQL) queries. Here’s an example: SELECT * FROM table_name.\nThis query selects all of the data from a particular table. However, the real power of SQL queries is in creating more complex queries that let you pull data from several tables to piece together patterns and answers to business problems. For example, querying the sales table and the book table together to see sales in relation to an author’s books. This is made possible by a join, which we talk about next.\n\n\nThe Benefits of Using a Relational Database\nThere are many benefits to using a relational database. A few of them are listed here.\n\nJoins: You can join tables, enabling you to better understand relationships between your data.\nReduced redundancy: You can store data in one table and reference it from other tables instead of saving the same data in different places.\nFamiliarity: Relational databases have been a popular choice since the 1970s. Due to this popularity, technical professionals often have familiarity and experience with this type of database.\nAccuracy: Relational databases ensure that your data is persisted with high integrity and adheres to the ACID (atomicity, consistency, isolation, durability) principle.\n\n\n\nUse Cases for Relational Databases\nMuch of the world runs on relational databases. In fact, they’re at the core of many mission-critical applications, some of which you may use in your day to day life. Here are some common use cases for relational databases.\nApplications that have a solid schema that doesn’t change often, such as:\n\nLift and shift applications that lifts an app from on-premises and shifts it to the cloud, with little or no modifications.\n\nApplications that need persistent storage that follows the ACID principle, such as:\n\nEnterprise Resource Planning (ERP) applications\nCustomer Relationship Management (CRM) applications\nCommerce and financial applications\n\n\n\nChoose Between Unmanaged and Managed Databases\nIf you want to run a relational database on AWS, you first need to select how you want to run it: the unmanaged way or the managed way.\nThe paradigm of managed versus unmanaged services is similar to the Shared Responsibility Model. The Shared Responsibility Model distinguishes between AWS’s and the customer’s security responsibility over a service. Similarly, managed versus unmanaged can be understood as a tradeoff between convenience and control.\n\n\nOn-Premises Database\nLet’s say you operate a relational database on-premises (in your own data center). In this scenario, you are responsible for all aspects of operation, including the security and electricity of the data center, the management of the host machine, the management of the database on that host, as well as optimizing queries and managing customer data. You are responsible for absolutely everything, which means you have control over absolutely everything.\n\n\nUnmanaged Database\n\nNow, let’s say you want to shift some of this work to AWS by running your relational database on Amazon EC2. If you host a database on Amazon EC2, AWS takes care of implementing and maintaining the physical infrastructure and hardware and installing the operating system of the EC2 instance. However, you’re still responsible for managing the EC2 instance, managing the database on that host, optimizing queries, and managing customer data.\nThis is what is often referred to as the unmanaged database option on AWS. AWS is responsible for and has control over the hardware and underlying infrastructure, and you are responsible and have control over management of the host and database.\n\n\nManaged Database\n\nIf you want to shift even more of the work to AWS, you can use a managed database service. These services provide the setup of both the EC2 instance and the database, and they provide systems for high availability, scalability, patching, and backups. However, you’re still responsible for database tuning, query optimization, and of course, ensuring that your customer data is secure. This provides you ultimate convenience, but you have the least amount of control compared to the two previous options."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-amazon-rds",
    "href": "posts/2020-01-01-AWS.html#what-is-amazon-rds",
    "title": "ThomasHSimm",
    "section": "What Is Amazon RDS?",
    "text": "What Is Amazon RDS?\nAmazon RDS enables you to create and manage relational databases in the cloud without the operational burden of traditional database management. For example, if you sell healthcare equipment and your goal is to be the number-one seller in the Pacific Northwest, building out a database doesn’t directly help you achieve that goal though having a database is necessary to achieve the goal.\nAmazon RDS helps you offload some of this unrelated work of creating and managing a database. You can focus on the tasks that differentiate your application, instead of infrastructure-related tasks such as provisioning, patching, scaling, and restoring.\nAmazon RDS supports most of the popular relational database management systems, ranging from commercial options, open source options, and even an AWS-specific option. Here are the supported Amazon RDS engines.\n\nCommercial: Oracle, SQL Server\nOpen Source: MySQL, PostgreSQL, MariaDB\nCloud Native: Amazon Aurora\n\nNote: The cloud native option, Amazon Aurora, is a MySQL and PostgreSQL-compatible database built for the cloud. It is more durable, more available, and provides faster performance than the Amazon RDS version of MySQL and PostgreSQL.\n\nUnderstand DB Instances\nJust like the databases that you would build and manage yourself, Amazon RDS is built off of compute and storage. The compute portion is called the DB (database) instance, which runs the database engine. Depending on the engine of the DB instance you choose, the engine will have different supported features and configurations. A DB instance can contain multiple databases with the same engine, and each database can contain multiple tables.\nUnderneath the DB instance is an EC2 instance. However, this instance is managed through the Amazon RDS console instead of the Amazon EC2 console. When you create your DB instance, you choose the instance type and size. Amazon RDS supports three instance families.\n\nStandard, which include general-purpose instances\nMemory Optimized, which are optimized for memory-intensive applications\nBurstable Performance, which provides a baseline performance level, with the ability to burst to full CPU usage.\n\nThe DB instance you choose affects how much processing power and memory it has. Not all of the options are available to you, depending on the engine that you choose.\nMuch like a regular EC2 instance, the DB instance uses Amazon Elastic Block Store (EBS) volumes as its storage layer. You can choose between three types of EBS volume storage.\n\nGeneral purpose (SSD)\nProvisioned IOPS (SSD)\nMagnetic storage (not recommended)\n\n\n\nWork with Amazon RDS in an Amazon Virtual Private Cloud\nWhen you create a DB instance, you select the Amazon Virtual Private Cloud (VPC) that your databases will live in. Then, you select the subnets that you want the DB instances to be placed in. This is referred to as a DB subnet group. To create a DB subnet group, you specify:\n\nThe Availability Zones (AZs) that include the subnets you want to add\nThe subnets in that AZ where your DB instance are placed\n\nThe subnets you add should be private so they don’t have a route to the internet gateway. This ensures your DB instance, and the cat data inside of it, can only be reached by the app backend.\nAccess to the DB instance can be further restricted by using network access control lists (ACLs) and security groups. With these firewalls, you can control, at a granular level, what type of traffic you want to allow into your database. Using these controls provide layers of security for your infrastructure. It reinforces that only the backend instances have access to the database.\n\n\nUse AWS Identity and Access Management (IAM) Policies to Secure Amazon RDS\nNetwork ACLs and security groups allow you to dictate the flow of traffic. If you want to restrict what actions and resources your employees can access, you can use IAM policies."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#back-up-your-data",
    "href": "posts/2020-01-01-AWS.html#back-up-your-data",
    "title": "ThomasHSimm",
    "section": "Back Up Your Data",
    "text": "Back Up Your Data\nYou don’t want to lose any of that precious cat information. To take regular backups of your RDS instance, you can use:\n\nAutomatic backups\nManual snapshots\n\n\nAutomatic Backups\nAutomated backups are turned on by default. This backs up your entire DB instance (not just individual databases on the instance), and your transaction logs. When you create your DB instance, you set a backup window that is the period of time that automatic backups occur. Typically, you want to set these windows during a time when your database experiences little activity because it can cause increased latency and downtime.\nYou can retain your automated backups between 0 and 35 days. You might ask yourself, “Why set automated backups for 0 days?” The 0 days setting actually disables automatic backups from happening. Keep in mind that if you set it to 0, it will also delete all existing automated backups. This is not ideal, as the benefit of having automated backups is having the ability to do point-in-time recovery.\nIf you restore data from an automated backup, you have the ability to do point-in-time recovery. Point-in-time recovery creates a new DB instance using data restored from a specific point in time. This restoration method provides more granularity by restoring the full backup and rolling back transactions up to the specified time range.\n\n\nManual Snapshots\nIf you want to keep your automated backups longer than 35 days, use manual snapshots. Manual snapshots are similar to taking EBS snapshots, except you manage them in the RDS console. These are backups that you can initiate at any time, that exist until you delete them.\nFor example, to meet a compliance requirement that mandates you to keep database backups for a year, you would need to use manual snapshots to ensure those backups are retained for that period of time.\nIf you restore data from a manual snapshot, it creates a new DB instance using the data from the snapshot.\n\n\nWhich Backup Option Should I Use?\nThe answer, almost always, is both. Automated backups are beneficial for the point-in-time recovery. Manual snapshots allow you to retain backups for longer than 35 days.\n\n\nGet Redundancy with Amazon RDS Multi-AZ\nWhen you enable Amazon RDS Multi-AZ, Amazon RDS creates a redundant copy of your database in another AZ. You end up with two copies of your database: a primary copy in a subnet in one AZ and a standby copy in a subnet in a second AZ.\nThe primary copy of your database provides access to your data so that applications can query and display that information.\nThe data in the primary copy is synchronously replicated to the standby copy. The standby copy is not considered an active database, and does not get queried by applications.\nTo improve availability, Amazon RDS Multi-AZ ensures that you have two copies of your database running and that one of them is in the primary role. If there’s an availability issue, such as the primary database losing connectivity, Amazon RDS triggers an automatic failover.\nWhen you create a DB instance, a domain name system (DNS) name is provided. AWS uses that DNS name to failover to the standby database. In an automatic failover, the standby database is promoted to the primary role and queries are redirected to the new primary database.\nTo ensure that you don’t lose Multi-AZ configuration, a new standby database is created by either:\n\nDemoting the previous primary to standby if it’s still up and running\nOr standing up a new standby DB instance\n\nThe reason you can select multiple subnets for an Amazon RDS database is because of the Multi-AZ configuration. You’ll want to ensure that you have used subnets in different AZs for your primary and standby copies."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-amazon-dynamodb",
    "href": "posts/2020-01-01-AWS.html#what-is-amazon-dynamodb",
    "title": "ThomasHSimm",
    "section": "What Is Amazon DynamoDB?",
    "text": "What Is Amazon DynamoDB?\nAmazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database so that you don’t have to worry about hardware provisioning, setup and configuration, replication, software patching, or cluster scaling.\nWith DynamoDB, you can create database tables that can store and retrieve any amount of data and serve any level of request traffic. You can scale up or scale down your tables’ throughput capacity without downtime or performance degradation. You can use the AWS Management Console to monitor resource utilization and performance metrics.\nDynamoDB automatically spreads the data and traffic for your tables over a sufficient number of servers to handle your throughput and storage requirements, while maintaining consistent and fast performance. All of your data is stored on solid-state disks (SSDs) and is automatically replicated across multiple Availability Zones in an AWS Region, providing built-in high availability and data durability."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#core-components-of-amazon-dynamodb",
    "href": "posts/2020-01-01-AWS.html#core-components-of-amazon-dynamodb",
    "title": "ThomasHSimm",
    "section": "Core Components of Amazon DynamoDB",
    "text": "Core Components of Amazon DynamoDB\nIn DynamoDB, tables, items, and attributes are the core components that you work with. A table is a collection of items, and each item is a collection of attributes. DynamoDB uses primary keys to uniquely identify each item in a table and secondary indexes to provide more querying flexibility.\nThe following are the basic DynamoDB components:\nTables – Similar to other database systems, DynamoDB stores data in tables. A table is a collection of data. For example, see the example table called People that you could use to store personal contact information about friends, family, or anyone else of interest. You could also have a Cars table to store information about vehicles that people drive.\nItems – Each table contains zero or more items. An item is a group of attributes that is uniquely identifiable among all of the other items. In a People table, each item represents a person. For a Cars table, each item represents one vehicle. Items in DynamoDB are similar in many ways to rows, records, or tuples in other database systems. In DynamoDB, there is no limit to the number of items you can store in a table.\nAttributes – Each item is composed of one or more attributes. An attribute is a fundamental data element, something that does not need to be broken down any further. For example, an item in a People table contains attributes called PersonID, LastName, FirstName, and so on. For a Department table, an item might have attributes such as DepartmentID, Name, Manager, and so on. Attributes in DynamoDB are similar in many ways to fields or columns in other database systems.\n\nSecurity with Amazon DynamoDB\nDynamoDB also offers encryption at rest, which eliminates the operational burden and complexity involved in protecting sensitive data. For more information, see DynamoDB Encryption at Rest."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#aws-database-services",
    "href": "posts/2020-01-01-AWS.html#aws-database-services",
    "title": "ThomasHSimm",
    "section": "AWS Database Services",
    "text": "AWS Database Services\nAWS has a variety of different database options for different use cases. Use the table below to get a quick look at the AWS database portfolio.\n\n\n\n\n\n\n\n\nDatabase Type\nUse Cases\nAWS Service\n\n\n\n\nRelational\nTraditional applications, ERP, CRM, e-commerce\nAmazon RDS, Amazon Aurora, Amazon Redshift\n\n\nKey-value\nHigh-traffic web apps, e-commerce systems, gaming applications\nAmazon DynamoDB\n\n\nIn-memory\nCaching, session management, gaming leaderboards, geospatial applications\nAmazon ElastiCache for Memcached, Amazon ElastiCache for Redis\n\n\nDocument\nContent management, catalogs, user profiles\nAmazon DocumentDB (with MongoDB compatibility)\n\n\nWide column\nHigh-scale industrial apps for equipment maintenance, fleet management, and route optimization\nAmazon Keyspaces (for Apache Cassandra)\n\n\nGraph\nFraud detection, social networking, recommendation engines\nAmazon Neptune\n\n\nTime series\nIoT applications, DevOps, industrial telemetry\nAmazon Timestream\n\n\nLedger\nSystems of record, supply chain, registrations, banking transactions\nAmazon QLDB"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#breaking-up-applications-and-databases",
    "href": "posts/2020-01-01-AWS.html#breaking-up-applications-and-databases",
    "title": "ThomasHSimm",
    "section": "Breaking Up Applications and Databases",
    "text": "Breaking Up Applications and Databases\nAs the industry changes, applications and databases change too. Today, with larger applications, you no longer see just one database supporting it. Instead, these applications are being broken into smaller services, each with their own purpose-built database supporting it.\nThis shift removes the idea of a one-size-fits-all database and replaces it with a complementary database strategy. You can give each database the appropriate functionality, performance, and scale that the workload requires.\n\n\nMonitoring on AWS\n\n\nWhen operating a website like the Employee Directory Application on AWS you may have questions like:\n\nHow many people are visiting my site day to day?\nHow can I track the number of visitors over time?\nHow will I know if the website is having performance or availability issues?\nWhat happens if my Amazon Elastic Compute Cloud (EC2) instance runs out of capacity?\nWill I be alerted if my website goes down?\n\nYou need a way to collect and analyze data about the operational health and usage of your resources. The act of collecting, analyzing, and using data to make decisions or answer questions about your IT resources and systems is called monitoring.\nMonitoring enables you to have a near real-time pulse on your system and answer the questions listed above. You can use the data you collect to watch for operational issues caused by events like over-utilization of resources, application flaws, resource misconfiguration, or security-related events.\nThink of the data collected through monitoring as outputs of the system, or metrics."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#use-metrics-to-solve-problems",
    "href": "posts/2020-01-01-AWS.html#use-metrics-to-solve-problems",
    "title": "ThomasHSimm",
    "section": "Use Metrics to Solve Problems",
    "text": "Use Metrics to Solve Problems\nThe resources that host your solutions on AWS all create various forms of data that you might be interested in collecting. You can think of each individual data point that is created by a resource as a metric. Metrics that are collected and analyzed over time become statistics, like the example of average CPU utilization over time.\nConsider this: One way to evaluate the health of an Amazon EC2 instance is through CPU utilization. Generally speaking, if an EC2 instance has a high CPU utilization, it can mean a flood of requests. Or it can reflect a process that has encountered an error and is consuming too much of the CPU. When analyzing CPU utilization, take a process that exceeds a specific threshold for an unusual length of time. Use that abnormal event as a cue to either manually or automatically resolve the issue through actions like scaling the instance.\nThis is one example of a metric. Other examples of metrics EC2 instances have are - network utilization, - disk performance, - memory utilization, and - the logs created by the applications running on top of EC2."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#know-the-different-types-of-metrics",
    "href": "posts/2020-01-01-AWS.html#know-the-different-types-of-metrics",
    "title": "ThomasHSimm",
    "section": "Know the Different Types of Metrics",
    "text": "Know the Different Types of Metrics\nDifferent resources in AWS create different types of metrics. An Amazon Simple Storage Service (S3) bucket would not have CPU utilization like an EC2 instance does. Instead, S3 creates metrics related to - the objects stored in a bucket like the overall size - the number of objects in a bucket - requests made to the bucket such as reading or writing objects.\nAmazon Relational Database Service (RDS) creates metrics such as - database connections, - CPU utilization of an instance, - or disk space consumption.\nThis is not a complete list for any of the services mentioned, but you can see how different resources create different metrics.\nYou could be interested in a wide variety of metrics depending on the types of resources you are using, the goals you have, or the types of questions you want answered."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#understand-the-benefits-of-monitoring",
    "href": "posts/2020-01-01-AWS.html#understand-the-benefits-of-monitoring",
    "title": "ThomasHSimm",
    "section": "Understand the Benefits of Monitoring",
    "text": "Understand the Benefits of Monitoring\nMonitoring gives you visibility into your resources, but the question now is, “Why is that important?” The following are some of the benefits of monitoring.\nRespond to operational issues proactively before your end users are aware of them. It’s a bad practice to wait for end users to let you know your application is experiencing an outage. Through monitoring, you can keep tabs on metrics like error response rate or request latency, over time, that help signal that an outage is going to occur. This enables you to automatically or manually perform actions to prevent the outage from happening—fixing the problem before your end users are aware of it.\nImprove the performance and reliability of your resources. Monitoring the different resources that comprise your application provides you with a full picture of how your solution behaves as a system. Monitoring, if done well, can illuminate bottlenecks and inefficient architectures. This enables you to drive performance and reliability improvement processes.\nRecognize security threats and events. When you monitor resources, events, and systems over time, you create what is called a baseline. A baseline defines what activity is normal. Using a baseline, you can spot anomalies like unusual traffic spikes or unusual IP addresses accessing your resources. When an anomaly occurs, an alert can be sent out or an action can be taken to investigate the event.\nMake data-driven decisions for your business. Monitoring is not only to keep an eye on IT operational health. It also helps drive business decisions. For example, let’s say you launched a new feature for your cat photo app, and want to know whether it’s being used. You can collect application-level metrics and view the number of users who use the new feature. With your findings, you decide whether to invest more time into improving the new feature.\nCreate more cost-effective solutions. Through monitoring, you can view resources that are being underutilized and rightsize your resources to your usage. This helps you optimize cost and make sure you aren’t spending more money than necessary."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#enable-visibility",
    "href": "posts/2020-01-01-AWS.html#enable-visibility",
    "title": "ThomasHSimm",
    "section": "Enable Visibility",
    "text": "Enable Visibility\nAWS resources create data you can monitor through metrics, logs, network traffic, events, and more. This data is coming from components that are distributed in nature, which can lead to difficulty in collecting the data you need if you don’t have a centralized place to review it all. AWS has already done that for you with a service called Amazon CloudWatch.\nAmazon CloudWatch is a monitoring and observability service that collects data like those mentioned in this module. CloudWatch provides actionable insights into your applications, and enables you to respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. This unified view is important.\nYou can use CloudWatch to:\n\nDetect anomalous behavior in your environments.\nSet alarms to alert you when something’s not right.\nVisualize logs and metrics with the AWS Management Console.\nTake automated actions like scaling.\nTroubleshoot issues.\nDiscover insights to keep your applications healthy."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#how-cloudwatch-works",
    "href": "posts/2020-01-01-AWS.html#how-cloudwatch-works",
    "title": "ThomasHSimm",
    "section": "How CloudWatch Works",
    "text": "How CloudWatch Works\nThe great thing about CloudWatch is that all you need to get started is an AWS account. It is a managed service, which enables you to focus on monitoring, without managing any underlying infrastructure.\nThe employee directory app is built with various AWS services working together as building blocks. It would be difficult to monitor all of these different services independently, so CloudWatch acts as one centralized place where metrics are gathered and analyzed. You already learned how EC2 instances post CPU utilization as a metric to CloudWatch. Different AWS resources post different metrics that you can monitor. You can view a list of services that send metrics to CloudWatch in the resources section of this unit.\nMany AWS services send metrics automatically for free to CloudWatch at a rate of one data point per metric per 5-minute interval, without you needing to do anything to turn on that data collection. This by itself gives you visibility into your systems without you needing to spend any extra money to do so. This is known as basic monitoring. For many applications, basic monitoring does the job.\nFor applications running on EC2 instances, you can get more granularity by posting metrics every minute instead of every 5 minutes using a feature like detailed monitoring. Detailed monitoring has an extra fee associated."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#break-down-metrics",
    "href": "posts/2020-01-01-AWS.html#break-down-metrics",
    "title": "ThomasHSimm",
    "section": "Break Down Metrics",
    "text": "Break Down Metrics\nEach metric in CloudWatch has a timestamp and is organized into containers called namespaces. Metrics in different namespaces are isolated from each other—you can think of them as belonging to different categories.\nAWS services that send data to CloudWatch attach dimensions to each metric. A dimension is a name/value pair that is part of the metric’s identity. You can use dimensions to filter the results that CloudWatch returns. For example, you can get statistics for a specific EC2 instance by specifying the InstanceId dimension when you search."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#set-up-custom-metrics",
    "href": "posts/2020-01-01-AWS.html#set-up-custom-metrics",
    "title": "ThomasHSimm",
    "section": "Set Up Custom Metrics",
    "text": "Set Up Custom Metrics\nLet’s say for your application you wanted to record the number of page views your website gets. How would you record this metric to CloudWatch? It’s an application-level metric, meaning that it’s not something the EC2 instance would post to CloudWatch by default. This is where custom metrics come in. Custom metrics allows you to publish your own metrics to CloudWatch.\nIf you want to gain more granular visibility, you can use high-resolution custom metrics, which enable you to collect custom metrics down to a 1-second resolution. This means you can send one data point per second per custom metric.\nOther examples of custom metrics are:\n\nWeb page load times\nRequest error rates\nNumber of processes or threads on your instance\nAmount of work performed by your application\n\nNote: You can get started with custom metrics by programmatically sending the metric to CloudWatch using the PutMetricData API."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#understand-the-cloudwatch-dashboards",
    "href": "posts/2020-01-01-AWS.html#understand-the-cloudwatch-dashboards",
    "title": "ThomasHSimm",
    "section": "Understand the CloudWatch Dashboards",
    "text": "Understand the CloudWatch Dashboards\nOnce you’ve provisioned your AWS resources and they are sending metrics to CloudWatch, you can then visualize and review that data using the CloudWatch console with dashboards. Dashboards are customizable home pages that you use for data visualization for one or more metrics through the use of widgets, such as a graph or text.\nYou can build many custom dashboards, each one focusing on a distinct view of your environment. You can even pull data from different Regions into a single dashboard in order to create a global view of your architecture.\nCloudWatch aggregates statistics according to the period of time that you specify when creating your graph or requesting your metrics. You can also choose whether your metric widgets display live data. Live data is data published within the last minute that has not been fully aggregated.\nYou are not bound to using CloudWatch exclusively for all your visualization needs. You can use external or custom tools to ingest and analyze CloudWatch metrics using the GetMetricData API.\nAs far as security goes, you can control who has access to view or manage your CloudWatch dashboards through AWS Identity and Access Management (IAM) policies that get associated with IAM users, IAM groups, or IAM roles.\n\nGet to Know CloudWatch Logs\nCloudWatch can also be the centralized place for logs to be stored and analyzed, using CloudWatch Logs. CloudWatch Logs can monitor, store, and access your log files from applications running on Amazon EC2 instances, AWS Lambda functions, and other sources.\nCloudWatch Logs allows you to query and filter your log data. For example, let’s say you’re looking into an application logic error for your application, and you know that when this error occurs it will log the stack trace. Since you know it logs the error, you query your logs in CloudWatch Logs to find the stack trace. You also set up metric filters on logs, which turn log data into numerical CloudWatch metrics that you graph and use on your dashboards.\nSome services are set up to send log data to CloudWatch Logs with minimal effort, like AWS Lambda. With AWS Lambda, all you need to do is give the Lambda function the correct IAM permissions to post logs to CloudWatch Logs. Other services require more configuration. For example, if you want to send your application logs from an EC2 instance into CloudWatch Logs, you need to first install and configure the CloudWatch Logs agent on the EC2 instance.\nThe CloudWatch Logs agent enables Amazon EC2 instances to automatically send log data to CloudWatch Logs. The agent includes the following components.\n\nA plug-in to the AWS Command Line Interface (CLI) that pushes log data to CloudWatch Logs.\nA script that initiates the process to push data to CloudWatch Logs.\nA cron job that ensures the daemon is always running.\n\nAfter the agent is installed and configured, you can then view your application logs in CloudWatch Logs.\n\n\nLearn the CloudWatch Logs Terminology\nLog data sent to CloudWatch Logs can come from different sources, so it’s important you understand how they’re organized and the terminology used to describe your logs.\nLog event: A log event is a record of activity recorded by the application or resource being monitored, and it has a timestamp and an event message.\nLog stream: Log events are then grouped into log streams, which are sequences of log events that all belong to the same resource being monitored. For example, logs for an EC2 instance are grouped together into a log stream that you can then filter or query for insights.\nLog groups: Log streams are then organized into log groups. A log group is composed of log streams that all share the same retention and permissions settings. For example, if you have multiple EC2 instances hosting your application and you are sending application log data to CloudWatch Logs, you can group the log streams from each instance into one log group. This helps keep your logs organized."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#configure-a-cloudwatch-alarm",
    "href": "posts/2020-01-01-AWS.html#configure-a-cloudwatch-alarm",
    "title": "ThomasHSimm",
    "section": "Configure a CloudWatch Alarm",
    "text": "Configure a CloudWatch Alarm\nYou can create CloudWatch alarms to automatically initiate actions based on sustained state changes of your metrics. You configure when alarms are triggered and the action that is performed.\nYou first need to decide what metric you want to set up an alarm for, then you define the threshold at which you want the alarm to trigger. Next, you define the specified time period of which the metric should cross the threshold for the alarm to be triggered.\nFor example, if you wanted to set up an alarm for an EC2 instance to trigger when the CPU utilization goes over a threshold of 80%, you also need to specify the time period the CPU utilization is over the threshold. You don’t want to trigger an alarm based on short temporary spikes in the CPU. You only want to trigger an alarm if the CPU is elevated for a sustained amount of time, for example if it is over 80% for 5 minutes or longer, when there is a potential resource issue.\nKeeping all that in mind, to set up an alarm you need to choose the metric, the threshold, and the time period.\nAn alarm has three possible states.\n\nOK: The metric is within the defined threshold. Everything appears to be operating like normal.\nALARM: The metric is outside of the defined threshold. This could be an operational issue.\nINSUFFICIENT_DATA: The alarm has just started, the metric is not available, or not enough data is available for the metric to determine the alarm state.\n\nAn alarm can be triggered when it transitions from one state to another. Once an alarm is triggered, it can initiate an action. Actions can be an Amazon EC2 action, an Auto Scaling action, or a notification sent to Amazon Simple Notification Service (SNS).\n\nUse CloudWatch Alarms to Prevent and Troubleshoot Issues\nCloudWatch Logs uses metric filters to turn the log data into metrics that you can graph or set an alarm on. For the employee directory application, let’s say you set up a metric filter for 500-error response codes.\nThen, you define an alarm for that metric that will go into the ALARM state if 500-error responses go over a certain amount for a sustained time period. Let’s say if it’s more than five 500-error responses per hour, the alarm should enter the ALARM state. Next, you define an action that you want to take place when the alarm is triggered.\nIn this case, it makes sense to send an email or text alert to you so you can start troubleshooting the website, hopefully fixing it before it becomes a bigger issue. Once the alarm is set up, you feel comfortable knowing that if the error happens again, you’ll be notified promptly.\nYou can set up different alarms for different reasons to help you prevent or troubleshoot operational issues. In the scenario just described, the alarm triggered an SNS notification that went to a person who looked into the issue manually. Another option is to have alarms trigger actions that automatically remediate technical issues.\nFor example, you can set up an alarm to trigger an EC2 instance to reboot, or scale services up or down. You can even set up an alarm to trigger an SNS notification, which then triggers an AWS Lambda function. The Lambda function then calls any AWS API to manage your resources, and troubleshoot operational issues. By using AWS services together like this, you respond to events more quickly."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#what-is-availability",
    "href": "posts/2020-01-01-AWS.html#what-is-availability",
    "title": "ThomasHSimm",
    "section": "What Is Availability?",
    "text": "What Is Availability?\nThe availability of a system is typically expressed as a percentage of uptime in a given year or as a number of nines. Below, you can see a list of the percentages of availability based on the downtime per year, as well as its notation in nines.\n\n\n\nAvailability (%)\nDowntime (per year)\n\n\n\n\n90% (“one nine”)\n36.53 days\n\n\n99% (“two nines”)\n3.65 days\n\n\n99.9% (“three nines”)\n8.77 hours\n\n\n99.95% (“three and a half nines”)\n4.38 hours\n\n\n99.99% (“four nines”)\n52.60 minutes\n\n\n99.995% (“four and a half nines”)\n26.30 minutes\n\n\n99.999% (“five nines”)\n5.26 minutes\n\n\n\nTo increase availability, you need redundancy. This typically means more infrastructure: - more data centers, - more servers, - more databases, and - more replication of data.\nYou can imagine that adding more of this infrastructure means a higher cost. Customers want the application to always be available, but you need to draw a line where adding redundancy is no longer viable in terms of revenue."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#improve-application-availability",
    "href": "posts/2020-01-01-AWS.html#improve-application-availability",
    "title": "ThomasHSimm",
    "section": "Improve Application Availability",
    "text": "Improve Application Availability\nIn the current application, there is only one EC2 instance used to host the application, the photos are served from Amazon Simple Storage Service (S3) and the structured data is stored in Amazon DynamoDB. That single EC2 instance is a single point of failure for the application.\nEven if the database and S3 are highly available, customers have no way to connect if the single instance becomes unavailable. One way to solve this single point of failure issue is by adding one more server."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#use-a-second-availability-zone",
    "href": "posts/2020-01-01-AWS.html#use-a-second-availability-zone",
    "title": "ThomasHSimm",
    "section": "Use a Second Availability Zone",
    "text": "Use a Second Availability Zone\nThe physical location of that server is important. On top of having software issues at the operating system or application level, there can be a hardware issue. It could be in the physical server, the rack, the data center or even the Availability Zone hosting the virtual machine. An easy way to fix the physical location issue is by deploying a second EC2 instance in a different Availability Zone.\nThat would also solve issues with the operating system and the application. However, having more than one instance brings new challenges."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#manage-replication-redirection-and-high-availability",
    "href": "posts/2020-01-01-AWS.html#manage-replication-redirection-and-high-availability",
    "title": "ThomasHSimm",
    "section": "Manage Replication, Redirection, and High Availability",
    "text": "Manage Replication, Redirection, and High Availability\n\nCreate a Process for Replication\nThe first challenge is that you need to create a process to replicate the configuration files, software patches, and application itself across instances. The best method is to automate where you can.\n\n\nAddress Customer Redirection\nThe second challenge is how to let the clients, the computers sending requests to your server, know about the different servers. There are different tools that can be used here. The most common is using a Domain Name System (DNS) where the client uses one record which points to the IP address of all available servers. However, the time it takes to update that list of IP addresses and for the clients to become aware of such change, sometimes called propagation, is typically the reason why this method isn’t always used.\nAnother option is to use a load balancer which takes care of health checks and distributing the load across each server. Being between the client and the server, the load balancer avoids propagation time issues. We discuss load balancers later.\n\n\nUnderstand the Types of High Availability\nThe last challenge to address when having more than one server is the type of availability you need—either be an active-passive or an active-active system.\n\nActive-Passive: With an active-passive system, only one of the two instances is available at a time. One advantage of this method is that for stateful applications where data about the client’s session is stored on the server, there won’t be any issues as the customers are always sent to the same server where their session is stored.\nActive-Active: A disadvantage of active-passive and where an active-active system shines is scalability. By having both servers available, the second server can take some load for the application, thus allowing the entire system to take more load. However, if the application is stateful, there would be an issue if the customer’s session isn’t available on both servers. Stateless applications work better for active-active systems."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#whats-a-load-balancer",
    "href": "posts/2020-01-01-AWS.html#whats-a-load-balancer",
    "title": "ThomasHSimm",
    "section": "What’s a Load Balancer?",
    "text": "What’s a Load Balancer?\nLoad balancing refers to the process of distributing tasks across a set of resources. In the case of the corporate directory application, the resources are EC2 instances that host the application, and the tasks are the different requests being sent. It’s time to distribute the requests across all the servers hosting the application using a load balancer.\nTo do this, you first need to enable the load balancer to take all of the traffic and redirect it to the backend servers based on an algorithm. The most popular algorithm is round-robin, which sends the traffic to each server one after the other.\nA typical request for the application would start from the browser of the client. It’s sent to a load balancer. Then, it’s sent to one of the EC2 instances that hosts the application. The return traffic would go back through the load balancer and back to the client browser. Thus, the load balancer is directly in the path of the traffic.\nAlthough it is possible to install your own software load balancing solution on EC2 instances, AWS provides a service for that called Elastic Load Balancing (ELB)."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#features-of-elb",
    "href": "posts/2020-01-01-AWS.html#features-of-elb",
    "title": "ThomasHSimm",
    "section": "Features of ELB",
    "text": "Features of ELB\nThe ELB service provides a major advantage over using your own solution to do load balancing, in that you don’t need to manage or operate it. It can distribute incoming application traffic across EC2 instances as well as containers, IP addresses, and AWS Lambda functions.\n\nThe fact that ELB can load balance to IP addresses means that it can work in a hybrid mode as well, where it also load balances to on-premises servers.\nELB is highly available. The only option you have to ensure is that the load balancer is deployed across multiple Availability Zones.\nIn terms of scalability, ELB automatically scales to meet the demand of the incoming traffic. It handles the incoming traffic and sends it to your backend application."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#health-checks",
    "href": "posts/2020-01-01-AWS.html#health-checks",
    "title": "ThomasHSimm",
    "section": "Health Checks",
    "text": "Health Checks\nTaking the time to define an appropriate health check is critical. Only verifying that the port of an application is open doesn’t mean that the application is working. It also doesn’t mean that simply making a call to the home page of an application is the right way either.\nFor example, the employee directory application depends on a database, and S3. The health check should validate all of those elements. One way to do that would be to create a monitoring webpage like “/monitor” that will make a call to the database to ensure it can connect and get data, and make a call to S3. Then, you point the health check on the load balancer to the “/monitor” page.\n\nAfter determining the availability of a new EC2 instance, the load balancer starts sending traffic to it. If ELB determines that an EC2 instance is no longer working, it stops sending traffic to it and lets EC2 Auto Scaling know. EC2 Auto Scaling’s responsibility is to remove it from the group and replace it with a new EC2 instance. Traffic only sends to the new instance if it passes the health check.\nIn the case of a scale down action that EC2 Auto Scaling needs to take due to a scaling policy, it lets ELB know that EC2 instances will be terminated. ELB can prevent EC2 Auto Scaling from terminating the EC2 instance until all connections to that instance end, while preventing any new connections. That feature is called connection draining."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#elb-components",
    "href": "posts/2020-01-01-AWS.html#elb-components",
    "title": "ThomasHSimm",
    "section": "ELB Components",
    "text": "ELB Components\nThe ELB service is made up of three main components.\n\n\nListeners: The client connects to the listener. This is often referred to as client-side. To define a listener, a port must be provided as well as the protocol, depending on the load balancer type. There can be many listeners for a single load balancer.\nTarget groups: The backend servers, or server-side, is defined in one or more target groups. This is where you define the type of backend you want to direct traffic to, such as EC2 Instances, AWS Lambda functions, or IP addresses. Also, a health check needs to be defined for each target group.\nRules: To associate a target group to a listener, a rule must be used. Rules are made up of a condition that can be the source IP address of the client and a condition to decide which target group to send the traffic to.\n\n\nApplication Load Balancer (ALB)\nHere are some primary features of Application Load Balancer (ALB).\nALB routes traffic based on request data. It makes routing decisions based on the HTTP protocol like the URL path (/upload) and host, HTTP headers and method, as well as the source IP address of the client. This enables granular routing to the target groups.\nSend responses directly to the client. ALB has the ability to reply directly to the client with a fixed response like a custom HTML page. It also has the ability to send a redirect to the client which is useful when you need to redirect to a specific website or to redirect the request from HTTP to HTTPS, removing that work from your backend servers.\nALB supports TLS offloading. Speaking of HTTPS and saving work from backend servers, ALB understands HTTPS traffic. To be able to pass HTTPS traffic through ALB, an SSL certificate is provided by either importing a certificate via Identity and Access Management (IAM) or AWS Certificate Manager (ACM) services, or by creating one for free using ACM. This ensures the traffic between the client and ALB is encrypted.\nAuthenticate users. On the topic of security, ALB has the ability to authenticate the users before they are allowed to pass through the load balancer. ALB uses the OpenID Connect protocol and integrates with other AWS services to support more protocols like SAML, LDAP, Microsoft AD, and more.\nSecure traffic. To prevent traffic from reaching the load balancer, you configure a security group to specify the supported IP address ranges.\nALB uses the round-robin routing algorithm. ALB ensures each server receives the same number of requests in general. This type of routing works for most applications.\nALB uses the least outstanding request routing algorithm. If the requests to the backend vary in complexity where one request may need a lot more CPU time than another, then the least outstanding request algorithm is more appropriate. It’s also the right routing algorithm to use if the targets vary in processing capabilities. An outstanding request is when a request is sent to the backend server and a response hasn’t been received yet.\nFor example, if the EC2 instances in a target group aren’t the same size, one server’s CPU utilization will be higher than the other if the same number of requests are sent to each server using the round-robin routing algorithm. That same server will have more outstanding requests as well. Using the least outstanding request routing algorithm would ensure an equal usage across targets.\nALB has sticky sessions. In the case where requests need to be sent to the same backend server because the application is stateful, then use the sticky session feature. This feature uses an HTTP cookie to remember across connections which server to send the traffic to.\nFinally, ALB is specifically for HTTP and HTTPS traffic. If your application uses a different protocol, then consider the Network Load Balancer (NLB)."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#network-load-balancer",
    "href": "posts/2020-01-01-AWS.html#network-load-balancer",
    "title": "ThomasHSimm",
    "section": "Network Load Balancer",
    "text": "Network Load Balancer\nHere are some primary features of Network Load Balancer (NLB).\nNetwork Load Balancer supports TCP, UDP, and TLS protocols. HTTPS uses TCP and TLS as protocol. However, NLB operates at the connection layer, so it doesn’t understand what a HTTPS request is. That means all features discussed above that are required to understand the HTTP and HTTPS protocol, like routing rules based on that protocol, authentication, and least outstanding request routing algorithm, are not available with NLB.\nNLB uses a flow hash routing algorithm. The algorithm is based on: The protocol\n\nThe source IP address and source port\nThe destination IP address and destination port\nThe TCP sequence number\n\nIf all of these parameters are the same, then the packets are sent to the exact same target. If any of them are different in the next packets, then the request may be sent to a different target.\nNLB has sticky sessions. Different from ALB, these sessions are based on the source IP address of the client instead of a cookie.\nNLB supports TLS offloading. NLB understands the TLS protocol. It can also offload TLS from the backend servers similar to how ALB works.\nNLB handles millions of requests per second. While ALB can also support this number of requests, it needs to scale to reach that number. This takes time. NLB can instantly handle this amount of requests.\nNLB supports static and elastic IP addresses. There are some situations where the application client needs to send requests directly to the load balancer IP address instead of using DNS. For example, this is useful if your application can’t use DNS or if the connecting clients require firewall rules based on IP addresses. In this case, NLB is the right type of load balancer to use.\nNLB preserves source IP address. NLB preserves the source IP address of the client when sending the traffic to the backend. With ALB, if you look at the source IP address of the requests, you will find the IP address of the load balancer. While with NLB, you would see the real IP address of the client, which is required by the backend application in some cases.\n\nSelect Between ELB Types\nSelecting between the ELB service types is done by determining which feature is required for your application. Below you can find a list of the major features that you learned in this unit and the previous.\n\n\n\n\n\n\n\n\nFeature\nApplication Load Balancer\nNetwork Load Balancer\n\n\n\n\nProtocols\nHTTP, HTTPS\n\n\n\nConnection draining (deregistration delay)\n✔\n\n\n\nIP addresses as targets\n✔\n✔\n\n\nStatic IP and Elastic IP address\n\n✔\n\n\nPreserve Source IP address\n\n✔\n\n\nRouting based on Source IP address, path, host, HTTP headers, HTTP method, and query string\n✔\n\n\n\nRedirects\n✔\n\n\n\nFixed response\n✔\n\n\n\nUser authentication\n✔"
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#vertical-scaling",
    "href": "posts/2020-01-01-AWS.html#vertical-scaling",
    "title": "ThomasHSimm",
    "section": "Vertical Scaling",
    "text": "Vertical Scaling\nIf there are too many requests sent to a single active-passive system, the active server will become unavailable and hopefully failover to the passive server. But this doesn’t solve anything.\nWith active-passive, you need vertical scaling. This means increasing the size of the server. With EC2 instances, you select either a larger type or a different instance type. This can only be done while the instance is in a stopped state.\nIn this scenario, the following steps occur:\n\nStop the passive instance. This doesn’t impact the application since it’s not taking any traffic.\nChange the instance size or type, then start the instance again.\nShift the traffic to the passive instance, turning it active.\nThe last step is to stop, change the size, and start the previous active instance as both instances should match.\n\nWhen the amount of requests reduces, the same operation needs to be done. Even though there aren’t that many steps involved, it’s actually a lot of manual work to do. Another disadvantage is that a server can only scale vertically up to a certain limit.\nOnce that limit is reached, the only option is to create another active-passive system and split the requests and functionalities across them. This could require massive application rewriting.\nThis is where the active-active system can help. When there are too many requests, this system can be scaled horizontally by adding more servers."
  },
  {
    "objectID": "posts/2020-01-01-AWS.html#horizontal-scaling",
    "href": "posts/2020-01-01-AWS.html#horizontal-scaling",
    "title": "ThomasHSimm",
    "section": "Horizontal Scaling",
    "text": "Horizontal Scaling\nAs mentioned above, for the application to work in an active-active system, it’s already created as stateless, not storing any client session on the server. This means that having two servers or having four wouldn’t require any application changes. It would only be a matter of creating more instances when required and shutting them down when the traffic decreases.\nThe Amazon EC2 Auto Scaling service can take care of that task by automatically creating and removing EC2 instances based on metrics from Amazon CloudWatch.\nYou can see that there are many more advantages to using an active-active system in comparison with an active-passive. Modifying your application to become stateless enables scalability.\n\nIntegrate ELB with EC2 Auto Scaling\nThe ELB service integrates seamlessly with EC2 Auto Scaling. As soon as a new EC2 instance is added to or removed from the EC2 Auto Scaling group, ELB is notified. However, before it can send traffic to a new EC2 instance, it needs to validate that the application running on that EC2 instance is available.\nThis validation is done via the health checks feature of ELB. Monitoring is an important part of load balancers, as it should route traffic to only healthy EC2 instances. That’s why ELB supports two types of health checks.\n\nEstablishing a connection to a backend EC2 instance using TCP, and marking the instance as available if that connection is successful.\nMaking an HTTP or HTTPS request to a webpage that you specify, and validating that an HTTP response code is returned.\n\n\n\nDifferentiate Between Traditional Scaling and Auto Scaling\nWith a traditional approach to scaling, you buy and provision enough servers to handle traffic at its peak. However, this means that at night time, there is more capacity than traffic. This also means you’re wasting money. Turning off those servers at night or at times where the traffic is lower only saves on electricity.\nThe cloud works differently, with a pay-as-you-go model. It’s important to turn off the unused services, especially EC2 instances that you pay for On-Demand. One could manually add and remove servers at a predicted time. But with unusual spikes in traffic, this solution leads to a waste of resources with over-provisioning or with a loss of customers due to under-provisioning.\nThe need here is for a tool that automatically adds and removes EC2 instances according to conditions you define—that’s exactly what the EC2 Auto Scaling service does.\n\n\nUse Amazon EC2 Auto Scaling\nThe EC2 Auto Scaling service works to add or remove capacity to keep a steady and predictable performance at the lowest possible cost. By adjusting the capacity to exactly what your application uses, you only pay for what your application needs. And even with applications that have steady usage, EC2 Auto Scaling can help with fleet management. If there is an issue with an EC2 instance, EC2 Auto Scaling can automatically replace that instance. This means that EC2 Auto Scaling helps both to scale your infrastructure and ensure high availability.\n\n\nConfigure EC2 Auto Scaling Components\nThere are three main components to EC2 Auto Scaling.\n\nLaunch template or configuration: What resource should be automatically scaled?\nEC2 Auto Scaling Group: Where should the resources be deployed?\nScaling policies: When should the resources be added or removed?\n\n\n\nLearn About Launch Templates\nThere are multiple parameters required to create EC2 instances: Amazon Machine Image (AMI) ID, instance type, security group, additional Amazon Elastic Block Store (EBS) volumes, and more. All this information is also required by EC2 Auto Scaling to create the EC2 instance on your behalf when there is a need to scale. This information is stored in a launch template.\nYou can use a launch template to manually launch an EC2 instance. You can also use it with EC2 Auto Scaling. It also supports versioning, which allows for quickly rolling back if there was an issue or to specify a default version of your launch template. This way, while iterating on a new version, other users can continue launching EC2 instances using the default version until you make the necessary changes.\n\nYou can create a launch template one of three ways.\n\nThe fastest way to create a template is to use an existing EC2 instance. All the settings are already defined.\nAnother option is to create one from an already existing template or a previous version of a launch template.\nThe last option is to create a template from scratch. The following options will need to be defined: AMI ID, instance type, key pair, security group, storage, and resource tags.\n\nNote: Another way to define what Amazon EC2 Auto Scaling needs to scale is by using a launch configuration. It’s similar to the launch template, but it doesn’t allow for versioning using a previously created launch configuration as a template. Nor does it allow for creating one from an already existing EC2 instance. For these reasons and to ensure that you’re getting the latest features from Amazon EC2, use a launch template instead of launch configuration.\n\n\nGet to Know EC2 Auto Scaling Groups\nThe next component that EC2 Auto Scaling needs is an EC2 Auto Scaling Group (ASG). An ASG enables you to define where EC2 Auto Scaling deploys your resources. This is where you specify the Amazon Virtual Private Cloud (VPC) and subnets the EC2 instance should be launched in.\nEC2 Auto Scaling takes care of creating the EC2 instances across the subnets, so it’s important to select at least two subnets that are across different Availability Zones.\nASGs also allow you to specify the type of purchase for the EC2 instances. You can use On-Demand only, Spot only, or a combination of the two, which allows you to take advantage of Spot instances with minimal administrative overhead. To specify how many instances EC2 Auto Scaling should launch, there are three capacity settings to configure for the group size.\n\nMinimum: The minimum number of instances running in your ASG even if the threshold for lowering the amount of instances is reached.\nMaximum: The maximum number of instances running in your ASG even if the threshold for adding new instances is reached.\nDesired capacity: The amount of instances that should be in your ASG. This number can only be within or equal to the minimum or maximum. EC2 Auto Scaling automatically adds or removes instances to match the desired capacity number.\n\n\nWhen EC2 Auto Scaling removes EC2 instances because the traffic is minimal, it keeps removing EC2 instances until it reaches a minimum capacity. Depending on your application, using a minimum of two is a good idea to ensure high availability, but you know how many EC2 instances at a bare minimum your application requires at all times. When reaching that limit, even if EC2 Auto Scaling is instructed to remove an instance, it does not, to ensure the minimum is kept.\nOn the other hand, when the traffic keeps growing, EC2 Auto Scaling keeps adding EC2 instances. This means the cost for your application will also keep growing. That’s why it’s important to set a maximum amount to make sure it doesn’t go above your budget.\nThe desired capacity is the amount of EC2 instances that EC2 Auto Scaling creates at the time the group is created. If that number decreases, then EC2 Auto Scaling removes the oldest instance by default. If that number increases, then EC2 Auto Scaling creates new instances using the launch template.\n\n\nEnsure Availability with EC2 Auto Scaling\n\nUsing different numbers for minimum, maximum, and desired capacity is used for dynamically adjusting the capacity. However, if you prefer to use EC2 Auto Scaling for fleet management, you can configure the three settings to the same number, for example four. EC2 Auto Scaling will ensure that if an EC2 instance becomes unhealthy, it replaces it to always ensure that four EC2 instances are available. This ensures high availability for your applications.\n\n\nEnable Automation with Scaling Policies\nBy default, an ASG will be kept to its initial desired capacity. Although it’s possible to manually change the desired capacity, you can also use scaling policies.\nIn the AWS Monitoring module, you learned about Amazon CloudWatch metrics and alarms. You use metrics to keep information about different attributes of your EC2 instance like the CPU percentage. You use alarms to specify an action when a threshold is reached. Metrics and alarms are what scaling policies use to know when to act. For example, you set up an alarm that says when the CPU utilization is above 70% across the entire fleet of EC2 instances, trigger a scaling policy to add an EC2 instance.\nThere are three types of scaling policies: simple, step, and target tracking scaling.\n\n\nSimple Scaling Policy\nA simple scaling policy allows you to do exactly what’s described above. You use a CloudWatch alarm and specify what to do when it is triggered. This can be a number of EC2 instances to add or remove, or a specific number to set the desired capacity to. You can specify a percentage of the group instead of using an amount of EC2 instances, which makes the group grow or shrink more quickly.\nOnce this scaling policy is triggered, it waits a cooldown period before taking any other action. This is important as it takes time for the EC2 instances to start and the CloudWatch alarm may still be triggered while the EC2 instance is booting. For example, you could decide to add an EC2 instance if the CPU utilization across all instances is above 65%. You don’t want to add more instances until that new EC2 instance is accepting traffic.\nHowever, what if the CPU utilization was now above 85% across the ASG? Only adding one instance may not be the right move here. Instead, you may want to add another step in your scaling policy. Unfortunately, a simple scaling policy can’t help with that.\n\n\nStep Scaling Policy\nThis is where a step scaling policy helps. Step scaling policies respond to additional alarms even while a scaling activity or health check replacement is in progress. Similar to the example above, you decide to add two more instances in case the CPU utilization is at 85%, and four more instances when it’s at 95%.\nDeciding when to add and remove instances based on CloudWatch alarms may seem like a difficult task. This is why the third type of scaling policy exists: target tracking. Target Tracking Scaling Policy\nIf your application scales based on average CPU utilization, average network utilization (in or out), or based on request count, then this scaling policy type is the one to use. All you need to provide is the target value to track and it automatically creates the required CloudWatch alarms."
  },
  {
    "objectID": "posts/2020-07-01-RandomForests-Copy1.html#decision-trees",
    "href": "posts/2020-07-01-RandomForests-Copy1.html#decision-trees",
    "title": "ThomasHSimm",
    "section": "Decision Trees",
    "text": "Decision Trees\nA decision tree asks a series of binary questions about the data, whereupon the data is split into two branches. For each of these branches another question can be asked, or a prediction made. The branches continue until a prediction is made. These are created using training data and can subsequently be used with test data.\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y"
  },
  {
    "objectID": "posts/2020-07-01-RandomForests-Copy1.html#decision-trees-1",
    "href": "posts/2020-07-01-RandomForests-Copy1.html#decision-trees-1",
    "title": "ThomasHSimm",
    "section": "Decision Trees",
    "text": "Decision Trees\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\n\n\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,max_depth=2)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,min_samples_split=30_000)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,min_samples_leaf=30_000)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n# DecisionTreeRegressor?\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\n\nsamp_idx = np.random.permutation(len(y))[:500]\ndtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\nfi = rf_feat_importance(m, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(10,6), legend=False)\n\nplot_fi(fi[:30]);\n\n\n\n\n\npd.\n\n\ndef rf(xs, y, n_estimators=400, max_samples=100_000,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)\n\nm = rf(xs, y)\n\n\nuse=fi[fi.imp>.02].cols\nxs=xs.loc[:,use]\nxs\n\n\n\n\n\n  \n    \n      \n      Elapsed\n      Year\n      Type\n      Index of Multiple Deprivation\n      Latitude\n      Average Income\n      Longitude\n      Introduced\n      Postcode\n    \n  \n  \n    \n      0\n      1.634861e+09\n      2021\n      5\n      749\n      51.622696\n      28200.0\n      -3.918673\n      1\n      906\n    \n    \n      2\n      1.515110e+09\n      2018\n      5\n      749\n      51.622696\n      28200.0\n      -3.918673\n      1\n      906\n    \n    \n      3\n      1.509322e+09\n      2017\n      5\n      749\n      51.622696\n      28200.0\n      -3.918673\n      1\n      906\n    \n    \n      4\n      1.468368e+09\n      2016\n      5\n      749\n      51.622696\n      28200.0\n      -3.918673\n      1\n      906\n    \n    \n      5\n      1.447286e+09\n      2015\n      5\n      749\n      51.622696\n      28200.0\n      -3.918673\n      1\n      906\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195084\n      8.976096e+08\n      1998\n      1\n      1026\n      51.783459\n      30300.0\n      -3.955751\n      1\n      5441\n    \n    \n      195085\n      8.931168e+08\n      1998\n      1\n      491\n      51.829727\n      35200.0\n      -4.005760\n      1\n      5590\n    \n    \n      195086\n      8.574336e+08\n      1997\n      5\n      525\n      51.812675\n      28900.0\n      -3.929074\n      1\n      5516\n    \n    \n      195087\n      8.492256e+08\n      1996\n      4\n      491\n      51.831928\n      35200.0\n      -3.988562\n      1\n      5492\n    \n    \n      195088\n      8.071488e+08\n      1995\n      1\n      1303\n      51.817993\n      35200.0\n      -3.975582\n      1\n      5484\n    \n  \n\n146214 rows × 9 columns\n\n\n\n\nm2 = DecisionTreeRegressor()\nm2.fit(xs, y)\n# m_rmse(m2, xs, y), m_rmse(m2, valid_xs, valid_y)\n\nDecisionTreeRegressor()\n\n\n\nsamp_idx = np.random.permutation(np.shape(y)[0])[:500]\n\n# dtreeviz(m2, xs, y, \n#          feature_names=xs.columns, target_name=dep_var,X=xs.iloc[5,:])\n\ndtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#front-matter",
    "href": "posts/2020-10-10-Template.html#front-matter",
    "title": "ThomasHSimm",
    "section": "Front Matter",
    "text": "Front Matter\nThe first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this:\n# \"My Title\"\n> \"Awesome summary\"\n\n- toc: true\n- branch: master\n- badges: true\n- comments: true\n- author: Hamel Husain & Jeremy Howard\n- categories: [fastpages, jupyter]\n\nSetting toc: true will automatically generate a table of contents\nSetting badges: true will automatically include GitHub and Google Colab links to your notebook.\nSetting comments: true will enable commenting on your blog post, powered by utterances.\n\nThe title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README."
  },
  {
    "objectID": "posts/2020-10-10-Template.html#markdown-shortcuts",
    "href": "posts/2020-10-10-Template.html#markdown-shortcuts",
    "title": "ThomasHSimm",
    "section": "Markdown Shortcuts",
    "text": "Markdown Shortcuts\nA #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post.\nA #hide_input comment at the top of any code cell will only hide the input of that cell.\n\n#hide_input\nprint('The comment #hide_input was used to hide the code that produced this.')\n\nThe comment #hide_input was used to hide the code that produced this.\n\n\nput a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it:\n\n#collapse-hide\nimport pandas as pd\nimport altair as alt\n\nput a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it:\n\n#collapse-show\ncars = 'https://vega.github.io/vega-datasets/data/cars.json'\nmovies = 'https://vega.github.io/vega-datasets/data/movies.json'\nsp500 = 'https://vega.github.io/vega-datasets/data/sp500.csv'\nstocks = 'https://vega.github.io/vega-datasets/data/stocks.csv'\nflights = 'https://vega.github.io/vega-datasets/data/flights-5k.json'\n\nplace a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it:\n\n#collapse-output\nprint('The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.')\n\nThe comment #collapse-output was used to collapse the output of this cell by default but you can expand it."
  },
  {
    "objectID": "posts/2020-10-10-Template.html#interactive-charts-with-altair",
    "href": "posts/2020-10-10-Template.html#interactive-charts-with-altair",
    "title": "ThomasHSimm",
    "section": "Interactive Charts With Altair",
    "text": "Interactive Charts With Altair\nCharts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook.\n\n# hide\ndf = pd.read_json(movies) # load movies data\ndf.columns = [x.replace(' ', '_') for x in df.columns.values]\ngenres = df['Major_Genre'].unique() # get unique field values\ngenres = list(filter(lambda d: d is not None, genres)) # filter out None values\ngenres.sort() # sort alphabetically\n\n\n#hide\nmpaa = ['G', 'PG', 'PG-13', 'R', 'NC-17', 'Not Rated']\n\n\nExample 1: DropDown\n\n# single-value selection over [Major_Genre, MPAA_Rating] pairs\n# use specific hard-wired values as the initial selected values\nselection = alt.selection_single(\n    name='Select',\n    fields=['Major_Genre', 'MPAA_Rating'],\n    init={'Major_Genre': 'Drama', 'MPAA_Rating': 'R'},\n    bind={'Major_Genre': alt.binding_select(options=genres), 'MPAA_Rating': alt.binding_radio(options=mpaa)}\n)\n  \n# scatter plot, modify opacity based on selection\nalt.Chart(df).mark_circle().add_selection(\n    selection\n).encode(\n    x='Rotten_Tomatoes_Rating:Q',\n    y='IMDB_Rating:Q',\n    tooltip='Title:N',\n    opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05))\n)\n\n\n\n\n\n\n\n\n\nExample 2: Tooltips\n\nalt.Chart(df).mark_circle().add_selection(\n    alt.selection_interval(bind='scales', encodings=['x'])\n).encode(\n    alt.X('Rotten_Tomatoes_Rating', type='quantitative'),\n    alt.Y('IMDB_Rating', type='quantitative', axis=alt.Axis(minExtent=30)),\n#     y=alt.Y('IMDB_Rating:Q', ), # use min extent to stabilize axis title placement\n    tooltip=['Title:N', 'Release_Date:N', 'IMDB_Rating:Q', 'Rotten_Tomatoes_Rating:Q']\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\n\nExample 3: More Tooltips\n\n# select a point for which to provide details-on-demand\nlabel = alt.selection_single(\n    encodings=['x'], # limit selection to x-axis value\n    on='mouseover',  # select on mouseover events\n    nearest=True,    # select data point nearest the cursor\n    empty='none'     # empty selection includes no data points\n)\n\n# define our base line chart of stock prices\nbase = alt.Chart().mark_line().encode(\n    alt.X('date:T'),\n    alt.Y('price:Q', scale=alt.Scale(type='log')),\n    alt.Color('symbol:N')\n)\n\nalt.layer(\n    base, # base line chart\n    \n    # add a rule mark to serve as a guide line\n    alt.Chart().mark_rule(color='#aaa').encode(\n        x='date:T'\n    ).transform_filter(label),\n    \n    # add circle marks for selected time points, hide unselected points\n    base.mark_circle().encode(\n        opacity=alt.condition(label, alt.value(1), alt.value(0))\n    ).add_selection(label),\n\n    # add white stroked text to provide a legible background for labels\n    base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n        text='price:Q'\n    ).transform_filter(label),\n\n    # add text labels for stock prices\n    base.mark_text(align='left', dx=5, dy=-5).encode(\n        text='price:Q'\n    ).transform_filter(label),\n    \n    data=stocks\n).properties(\n    width=500,\n    height=400\n)"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#data-tables",
    "href": "posts/2020-10-10-Template.html#data-tables",
    "title": "ThomasHSimm",
    "section": "Data Tables",
    "text": "Data Tables\nYou can display tables per the usual way in your blog:\n\n# display table with pandas\ndf[['Title', 'Worldwide_Gross', \n    'Production_Budget', 'Distributor', 'MPAA_Rating', 'IMDB_Rating', 'Rotten_Tomatoes_Rating']].head()\n\n\n\n\n\n  \n    \n      \n      Title\n      Worldwide_Gross\n      Production_Budget\n      Distributor\n      MPAA_Rating\n      IMDB_Rating\n      Rotten_Tomatoes_Rating\n    \n  \n  \n    \n      0\n      The Land Girls\n      146083.0\n      8000000.0\n      Gramercy\n      R\n      6.1\n      NaN\n    \n    \n      1\n      First Love, Last Rites\n      10876.0\n      300000.0\n      Strand\n      R\n      6.9\n      NaN\n    \n    \n      2\n      I Married a Strange Person\n      203134.0\n      250000.0\n      Lionsgate\n      None\n      6.8\n      NaN\n    \n    \n      3\n      Let's Talk About Sex\n      373615.0\n      300000.0\n      Fine Line\n      None\n      NaN\n      13.0\n    \n    \n      4\n      Slam\n      1087521.0\n      1000000.0\n      Trimark\n      R\n      3.4\n      62.0"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#images",
    "href": "posts/2020-10-10-Template.html#images",
    "title": "ThomasHSimm",
    "section": "Images",
    "text": "Images\n\nLocal Images\nYou can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax:\n![](my_icons/fastai_logo.png)\n\n\n\nRemote Images\nRemote images can be included with the following markdown syntax:\n![](https://image.flaticon.com/icons/svg/36/36686.svg)\n\n\n\nAnimated Gifs\nAnimated Gifs work, too!\n![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif)\n\n\n\nCaptions\nYou can include captions with markdown images like this:\n![](https://www.fast.ai/images/fastai_paper/show_batch.png \"Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/\")"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#github-flavored-emojis",
    "href": "posts/2020-10-10-Template.html#github-flavored-emojis",
    "title": "ThomasHSimm",
    "section": "GitHub Flavored Emojis",
    "text": "GitHub Flavored Emojis\nTyping I give this post two :+1:! will render this:\nI give this post two :+1:!"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#tweetcards",
    "href": "posts/2020-10-10-Template.html#tweetcards",
    "title": "ThomasHSimm",
    "section": "Tweetcards",
    "text": "Tweetcards\nTyping > twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this:\n\ntwitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#youtube-videos",
    "href": "posts/2020-10-10-Template.html#youtube-videos",
    "title": "ThomasHSimm",
    "section": "Youtube Videos",
    "text": "Youtube Videos\nTyping > youtube: https://youtu.be/XfoYk_Z5AkI will render this:\n\nyoutube: https://youtu.be/XfoYk_Z5AkI"
  },
  {
    "objectID": "posts/2020-10-10-Template.html#boxes-callouts",
    "href": "posts/2020-10-10-Template.html#boxes-callouts",
    "title": "ThomasHSimm",
    "section": "Boxes / Callouts",
    "text": "Boxes / Callouts\nTyping > Warning: There will be no second warning! will render this:\n\nWarning: There will be no second warning!\n\nTyping > Important: Pay attention! It's important. will render this:\n\nImportant: Pay attention! It’s important.\n\nTyping > Tip: This is my tip. will render this:\n\nTip: This is my tip.\n\nTyping > Note: Take note of this. will render this:\n\nNote: Take note of this.\n\nTyping > Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs:\n\nNote: A doc link to an example website: fast.ai should also work fine."
  },
  {
    "objectID": "posts/2020-10-10-Template.html#footnotes",
    "href": "posts/2020-10-10-Template.html#footnotes",
    "title": "ThomasHSimm",
    "section": "Footnotes",
    "text": "Footnotes\nYou can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this:\n{% raw %}For example, here is a footnote {% fn 1 %}.\nAnd another {% fn 2 %}\n{{ 'This is the footnote.' | fndetail: 1 }}\n{{ 'This is the other footnote. You can even have a [link](www.github.com)!' | fndetail: 2 }}{% endraw %}\nFor example, here is a footnote {% fn 1 %}.\nAnd another {% fn 2 %}\n{{ ‘This is the footnote.’ | fndetail: 1 }} {{ ‘This is the other footnote. You can even have a link!’ | fndetail: 2 }}"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-the-cloud",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-the-cloud",
    "title": "ThomasHSimm",
    "section": "What is the Cloud?",
    "text": "What is the Cloud?\nIn the past, companies and organizations hosted and maintained hardware such as compute, storage, and networking equipment in their own data centers. They needed to allocate entire infrastructure departments to take care of them, resulting in a costly operation that made some workloads and experimentation impossible.\nAs internet usage became more widespread, the demand for compute, storage, and networking equipment increased. For some companies and organizations, the cost of maintaining a large physical presence was unsustainable. To solve this problem, cloud computing was created.\nCloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing. You no longer have to manage and maintain your own hardware in your own data centers. Companies like AWS own and maintain these data centers and provide virtualized data center technologies and services to users over the internet.\nTo help differentiate between running workloads on-premises versus in the cloud, consider the scenario where your developers need to deploy a new feature on your application. Before they deploy, the team wants to test the feature in a separate quality assurance (QA) environment that has the exact same configurations as production.\nIf you run your application on-premises, creating this additional environment requires you to buy and install hardware, connect the necessary cabling, provision power, install operating systems, and more. All of these tasks can be time-consuming and take days to perform. Meanwhile, the new product feature’s time-to-market is increasing and your developers are waiting for this environment.\nIf you ran your application in the cloud, you can replicate the entire environment as often as needed in a matter of minutes or even seconds. Instead of physically installing hardware and connecting cabling, you can logically manage your physical infrastructure over the internet.\nUsing cloud computing not only saves you time from the set-up perspective, but it also removes the undifferentiated heavy lifting. If you look at any application, you’ll see that some of the aspects of it are very important to your business, like the code. However, there are other aspects that are no different than any other application you might make: for instance the compute the code runs on. By removing repetitive common tasks that don’t differentiate your business, like installing virtual machines, or storing backups, you can focus on what is strategically unique to your business and let AWS handle the tasks that are time consuming and don’t separate you from your competitors.\nSo where does AWS fit into all of this? Well AWS simply just provides cloud computing services. Those IT resources mentioned in the cloud computing definition are AWS services in this case. We’ll need to use these AWS services to architect a scalable, highly available, and cost effective infrastructure to host our corporate directory application. This way we can get our corporate directory app out into the world quickly, without having to manage any heavy-duty physical hardware. There are the six main advantages to running your workloads on AWS."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#the-six-benefits-of-cloud-computing",
    "href": "posts/2020-13-10-AWS-Copy1.html#the-six-benefits-of-cloud-computing",
    "title": "ThomasHSimm",
    "section": "The Six Benefits of Cloud Computing",
    "text": "The Six Benefits of Cloud Computing\n\nPay as you go. Instead of investing in data centers and hardware before you know how you are going to use them, you pay only when you use computing resources, and pay only for how much you use.\nBenefit from massive economies of scale. By using cloud computing, you can achieve a lower cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, AWS can achieve higher economies of scale, which translates into lower pay as-you-go prices.\nStop guessing capacity. Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes notice.\nIncrease speed and agility. IT resources are only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization since the cost and time it takes to experiment and develop is significantly lower.\nStop spending money running and maintaining data centers. Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your customers, rather than on the heavy lifting of racking, stacking, and powering physical infrastructure. This is often referred to as undifferentiated heavy lifting.\nGo global in minutes. Easily deploy your application in multiple Regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at a minimal cost.\n\n\nhttps://aws.amazon.com/what-is-cloud-computing/\nhttp://docs.aws.amazon.com/whitepapers/latest/aws-overview/types-of-cloud-computing.html\nhttps://aws.amazon.com/what-is-aws/\n\n#collapse-hide ## AWS Global Infrastructure\nInfrastructure, like data centers and networking connectivity, still exists as the foundation of every cloud application. In AWS, this physical infrastructure makes up the AWS Global Infrastructure, in the form of Availability Zones and Regions.\nRegions are geographic locations worldwide where AWS hosts its data centers. AWS Regions are named after the location where they reside. For example, in the United States, there is a Region in Northern Virginia called the Northern Virginia Region and a Region in Oregon called the Oregon Region. There are Regions in Asia Pacific, Canada, Europe, the Middle East, and South America, and AWS continues to expand to meet the needs of its customers.\nEach AWS Region is associated with a geographical name and a Region code.\nfor example, - us-east-1: This is the first Region created in the east of the US. The geographical name for this Region is N. Virginia. - ap-northeast-1: The first Region created in the northeast of Asia Pacific. The geographical name for this Region is Tokyo.\n\nChoose the Right AWS Region\nConsider four main aspects when deciding which AWS Region to host your applications and workloads: latency, price, service availability, and compliance.\n\nLatency. If your application is sensitive to latency, choose a Region that is close to your user base. This helps prevent long wait times for your customers. Synchronous applications such as gaming, telephony, WebSockets, and IoT are significantly affected by higher latency, but even asynchronous workloads, such as ecommerce applications, can suffer from an impact on user connectivity.\nPrice. Due to the local economy and the physical nature of operating data centers, prices may vary from one Region to another. The pricing in a Region can be impacted by internet connectivity, prices of imported pieces of equipment, customs, real estate, and more. Instead of charging a flat rate worldwide, AWS charges based on the financial factors specific to the location.\nService availability. Some services may not be available in some Regions. The AWS documentation provides a table containing the Regions and the available services within each one.\nData compliance. Enterprise companies often need to comply with regulations that require customer data to be stored in a specific geographic territory. If applicable, you should choose a Region that meets your compliance requirements."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#availability-zones",
    "href": "posts/2020-13-10-AWS-Copy1.html#availability-zones",
    "title": "ThomasHSimm",
    "section": "Availability Zones",
    "text": "Availability Zones\nInside every Region is a cluster of Availability Zones (AZ). An AZ consists of one or more data centers with redundant power, networking, and connectivity. These data centers operate in discrete facilities with undisclosed locations. They are connected using redundant high-speed and low-latency links.\n\nWhat is low latency link? Low latency describes a computer network that is optimized to process a very high volume of data messages with minimal delay (latency).\n\n\nWhat does redundant mean in routing? Failover or Redundant routing is a network arrangement with several links and paths between the person who places a call and the call recipient. Should at any time a path or link in the network, the other links will automatically route the incoming call to a predetermined number, device or location.\n\nAZs also have a code name. Since they’re located inside Regions, they can be addressed by appending a letter to the end of the Region code name. For example:\n\nus-east-1a: an AZ in us-east-1 (Northern Virginia Region)\nsa-east-1b: an AZ in sa-east-1 (São Paulo Region in South America)\n\nIf you see that a resource exists in us-east-1c, you know this resource is located in AZ c of the us-east-1 Region.\n\nScope AWS Services\nDepending on the AWS Service you use, your resources are either deployed at the AZ, Region, or Global level. Each service is different, so you need to understand how the scope of a service may affect your application architecture.\nWhen you operate a Region-scoped service, you only need to select the Region you want to use. If you are not asked to specify an individual AZ to deploy the service in, this is an indicator that the service operates on a Region-scope level. For region-scoped services, AWS automatically performs actions to increase data durability and availability.\nOn the other hand, some services ask you to specify an AZ. With these services, you are often responsible for increasing the data durability and high availability of these resources.\n\n\nMaintain Resiliency\n\nWhat is resiliency? The capability to recover when stressed by load (more requests for service), attacks (either accidental through a bug, or deliberate through intention), and failure of any component in the workload’s components.\n\nTo keep your application available, you need to maintain high availability and resiliency. A well-known best practice for cloud architecture is to use Region-scoped, managed services. These services come with availability and resiliency built in.\nWhen that is not possible, make sure the workload is replicated across multiple AZs. At a minimum, you should use two AZs. If one entire AZ fails, your application will have infrastructure up and running in at least a second AZ to take over the traffic.\n#collapse-hide ## Interacting with AWS\n\nAPI call: Application programming interfaces (APIs) are a way for one program to interact with another. API calls are the medium by which they interact. An API call, or API request, is a message sent to a server asking an API to provide a service or information.\n\nEvery action you make in AWS is an API call that is authenticated and authorized. In AWS, you can make API calls to services and resources through the AWS Management Console, the AWS Command Line Interface (CLI), or the AWS Software Development Kits (SDKs).\n\n\nThe AWS Management Console\nOne way to manage cloud resources is through the web-based console, where you log in and click on the desired service. This can be the easiest way to create and manage resources when you first begin working with the cloud. Below is a screenshot that shows the landing page when you first log into the AWS Management Console.\n\nThe services are placed in categories, such as compute, database, storage and security, identity and compliance.\nOn the upper right corner is the Region selector. If you click it and change the Region, you will make requests to the services in the chosen Region. The URL changes, too. Changing the Region directs the browser to make requests to a whole different AWS Region, represented by a different subdomain.\n\n\nThe AWS Command Line Interface (CLI)\nConsider the scenario where you run tens of servers on AWS for your application’s backend. You want to run a report to collect data from all of these servers. You need to do this programmatically every day because the server details may change. Instead of manually logging into the AWS Management Console and copying/pasting information, you can schedule an AWS Command Line Interface (CLI) script with an API call to pull this data for you.\nThe AWS CLI is a unified tool to manage AWS services. With just one tool to download and configure, you control multiple AWS services from the command line and automate them with scripts. The AWS CLI is open-source, and there are installers available for Windows, Linux, and Mac OS.\nHere is an example of running an API call against a service using the AWS CLI: aws ec2 describe-instances\nYou get this response:\n{     \"Reservations\": [         {             \"Groups\": [],             \"Instances\": [                 {                     \"AmiLaunchIndex\": 0,\nand so on.\n\n\nAWS Software Development Kits (SDKs)\nAPI calls to AWS can also be performed by executing code with programming languages. You can do this by using AWS Software Development Kits (SDKs). SDKs are open-source and maintained by AWS for the most popular programming languages, such as C++, Go, Java, JavaScript, .NET, Node.js, PHP, Python, and Ruby.\nDevelopers commonly use AWS SDKs to integrate their application source code with AWS services. Let’s say the backend of the application runs in Python and every time it receives a cat photo, it uploads that photo to a storage service. This action can be achieved from within the source code by using the AWS SDK for Python.\nHere is an example of code you can implement to work with AWS resources using the Python AWS SDK.\nimport boto3 ec2 = boto3.client('ec2') response = ec2.describe_instances() print(response)\n#collapse-hide ## Security and the AWS Shared Responsibility Model\nWhen you begin working with the AWS Cloud, managing security and compliance is a shared responsibility between AWS and you. To depict this shared responsibility, AWS created the shared responsibility model. This distinction of responsibility is commonly referred to as security of the cloud, versus security in the cloud.\n\n\n\nWhat Is AWS Responsible For?\nAWS is responsible for security of the cloud. This means AWS is required to protect and secure the infrastructure that runs all the services offered in the AWS Cloud. AWS is responsible for:\n\nProtecting and securing AWS Regions, Availability Zones, and data centers, down to the physical security of the buildings\nManaging the hardware, software, and networking components that run AWS services, such as the physical server, host operating systems, virtualization layers, and AWS networking components\n\nThe level of responsibility AWS has depends on the service. AWS classifies services into three different categories. The following table provides information about each, as well as the AWS responsibility.\n\n\n\n\n\n\n\n\nCategory\nExamples of AWS Services in the Category\nAWS Responsibility\n\n\n\n\nInfrastructure services\nCompute services, such as Amazon Elastic Compute Cloud (Amazon EC2)\nAWS manages the underlying infrastructure and foundation services.\n\n\nContainer services\nServices that require less management from the customer, such as Amazon Relational Database Service (Amazon RDS)\nAWS manages the underlying infrastructure and foundation services, operating system, and application platform.\n\n\nAbstracted services\nServices that require very little management from the customer, such as Amazon Simple Storage Service (Amazon S3)\nAWS operates the infrastructure layer, operating system, and platforms, as well as server-side encryption and data protection.\n\n\n\nNote Container services refer to AWS abstracting application containers behind the scenes, not Docker container services. This enables AWS to move the responsibility of managing that platform away from customers.\n\n\nWhat Is the Customer Responsible For?\nYou’re responsible for security in the cloud. When using any AWS service, you’re responsible for properly configuring the service and your applications, as well as ensuring your data is secure.\nThe level of responsibility you have depends on the AWS service. Some services require you to perform all the necessary security configuration and management tasks, while other more abstracted services require you to only manage the data and control access to your resources. Using the three categories of AWS services, you can determine your level of responsibility for each AWS service you use.\n\n\n\n\n\n\n\n\nCategory\nAWS Responsibility\nCustomer Responsibility\n\n\n\n\nInfrastructure services\nAWS manages the infrastructure and foundation services.\nYou control the operating system and application platform, as well as encrypting, protecting, and managing customer data.\n\n\nContainer services\nAWS manages the infrastructure and foundation services, operating system, and application platform.\nYou are responsible for customer data, encrypting that data, and protecting it through network firewalls and backups.\n\n\nAbstracted services\nAWS operates the infrastructure layer, operating system, and platforms, as well as server-side encryption and data protection.\nYou are responsible for managing customer data and protecting it through client-side encryption.\n\n\n\nDue to the varying level of effort, it’s important to consider which AWS service you use and review the level of responsibility required to secure the service. It’s also important to review how the shared security model aligns with the security standards in your IT environment, as well as any applicable laws and regulations.\nIt’s important to note that you maintain complete control of your data and are responsible for managing the security related to your content. Here are some examples of your responsibilities in context.\n\nChoosing a Region for AWS resources in accordance with data sovereignty regulations\nImplementing data protection mechanisms, such as encryption and managing backups\nUsing access control to limit who has access to your data and AWS resources"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#whats-the-big-deal-about-auth",
    "href": "posts/2020-13-10-AWS-Copy1.html#whats-the-big-deal-about-auth",
    "title": "ThomasHSimm",
    "section": "What’s the Big Deal About Auth?",
    "text": "What’s the Big Deal About Auth?\nWhen you’re configuring access to any account, two terms come up frequently: - authentication - and authorization.\nThough these terms may seem basic, you need to understand them to properly configure access management on AWS. It’s important to keep this in mind as you progress through the course. Let’s define both terms.\n\nUnderstand Authentication\nWhen you create your AWS account, you use a combination of an email address and a password to verify your identity. If the user types in the correct email and password, the system assumes the user is allowed to enter and grants them access. This is the process of authentication.\nAuthentication ensures that the user is who they say they are. Usernames and passwords are the most common types of authentication, but you may also work with other forms, such as token-based authentication or biometric data like a fingerprint. Authentication simply answers the question, “Are you who you say you are?”\n\n\nUnderstand Authorization\nOnce you’re inside your AWS account, you might be curious about what actions you can take. This is where authorization comes in. Authorization is the process of giving users permission to access AWS resources and services. Authorization determines whether the user can perform an action—whether it be to read, edit, delete, or create resources.\nAuthorization answers the question, “What actions can you perform?”\n\n\nWhat Is the AWS Root User?\nWhen you first create an AWS account, you begin with a single sign-in identity that has complete access to all AWS services and resources in the account. This identity is called the AWS root user and is accessed by signing in with the email address and password that you used to create the account.\n\n\nUnderstand the AWS Root User Credentials\nThe AWS root user has two sets of credentials associated with it. One set of credentials is the email address and password used to create the account. This allows you to access the AWS Management Console. The second set of credentials is called access keys, which allow you to make programmatic requests from the AWS Command Line Interface (AWS CLI) or AWS API.\nAccess keys consist of two parts:\n\nAn access key ID, for example, A2lAl5EXAMPLE\nA secret access key, for example, wJalrFE/KbEKxE\n\nSimilar to a username and password combination, you need both the access key ID and secret access key to authenticate your requests via the AWS CLI or AWS API. Access keys should be managed with the same security as an email address and password.\n\n\nFollow Best Practices When Working with the AWS Root User\nKeep in mind that the root user has complete access to all AWS services and resources in your account, as well as your billing and personal information. Due to this, securely lock away the credentials associated with the root user and do not use the root user for everyday tasks.\nTo ensure the safety of the root user:\n\nChoose a strong password for the root user.\nNever share your root user password or access keys with anyone.\nDisable or delete the access keys associated with the root user.\nDo not use the root user for administrative tasks or everyday tasks.\n\nWhen is it OK to use the AWS root user?\nThere are some tasks where it makes sense to use the AWS root user. Check out the links at the end of this section to read about them.\n\n\nDelete Your Keys to Stay Safe\nIf you don’t already have an access key for your AWS account root user, don’t create one unless you absolutely need to. If you do have an access key for your AWS account root user and want to delete the keys:\n\nGo to the My Security Credentials page in the AWS Management Console and sign in with the root user’s email address and password.\nOpen the Access keys section.\nUnder Actions, click Delete.\nClick Yes.\n\n\n\nThe Case for Multi-Factor Authentication\nWhen you create an AWS account and first log in to that account, you use single-factor authentication. Single-factor authentication is the simplest and most common form of authentication. It only requires one authentication method. In this case, you use a username and password to authenticate as the AWS root user. Other forms of single-factor authentication include a security pin or a security token.\nHowever, sometimes a user’s password is easy to guess. For example, your coworker Bob’s password, IloveCats222, might be easy for someone who knows Bob personally to guess, because it’s a combination of information that is easy to remember and describes certain things about Bob (1. Bob loves cats, and 2. Bob’s birthday is February 22).\nIf a bad actor guessed or cracked Bob’s password through social engineering, bots, or scripts, Bob might lose control of his account. Unfortunately, this is a common scenario that users of any website often face.\nThis is why using MFA has become so important in preventing unwanted account access. MFA requires two or more authentication methods to verify an identity, pulling from three different categories of information.\n\nSomething you know, such as a username and password, or pin number\nSomething you have, such as a one-time passcode from a hardware device or mobile app\nSomething you are, such as fingerprint or face scanning technology\n\nUsing a combination of this information enables systems to provide a layered approach to account access. Even though the first method of authentication, Bob’s password, was cracked by a malicious user, it’s very unlikely that a second method of authentication, such as a fingerprint, would also be cracked.\nThis extra layer of security is needed when protecting your most sacred accounts, which is why it’s important to enable MFA on your AWS root user.\n\n\nUse MFA on AWS\nIf you enable MFA on your root user, you are required to present a piece of identifying information from both the something you know category and the something you have category. The first piece of identifying information the user enters is an email and password combination. The second piece of information is a temporary numeric code provided by an MFA device.\nEnabling MFA adds an additional layer of security because it requires users to use a supported MFA mechanism in addition to their regular sign-in credentials. It’s best practice to enable MFA on the root user.\n\nReview Supported MFA Devices\nAWS supports a variety of MFA mechanisms, such as virtual MFA devices, hardware devices, and Universal 2nd Factor (U2F) security keys. For instructions on how to set up each method, check out the Resources section."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#understanding-servers",
    "href": "posts/2020-13-10-AWS-Copy1.html#understanding-servers",
    "title": "ThomasHSimm",
    "section": "Understanding Servers",
    "text": "Understanding Servers\nThe first building block you need to host an application is a server. Servers often times can handle Hypertext Transfer Protocol (HTTP) requests and send responses to clients following the client-server model, though any API based communication also falls under this model. A client being a person or computer that sends a request, and a server handling the requests is a computer, or collection of computers, connected to the internet serving websites to internet users.\nThese servers power your application by providing CPU, memory, and networking capacity to process users’ requests and transform them into responses. For context, common HTTP servers include:\n\nWindows options, such as Internet Information Services (IIS).\nLinux options, such as Apache HTTP Web Server, Nginx, and Apache Tomcat.\n\nTo run an HTTP server on AWS, you need to find a service that provides compute power in the AWS Management Console. You can log into the console and view the complete list of AWS compute services."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#choose-the-right-compute-option",
    "href": "posts/2020-13-10-AWS-Copy1.html#choose-the-right-compute-option",
    "title": "ThomasHSimm",
    "section": "Choose the Right Compute Option",
    "text": "Choose the Right Compute Option\nIf you’re responsible for setting up servers on AWS to run your infrastructure, you have many compute options. You need to know which service to use for which use case. At a fundamental level, there are three types of compute options: - virtual machines, e.g. EC2 - container services, - serverless.\nIf you’re coming to AWS with prior infrastructure knowledge, a virtual machine can often be the easiest compute option in AWS to understand. This is because a virtual machine emulates a physical server and allows you to install an HTTP server to run your applications. To run these virtual machines, you install a hypervisor on a host machine. This hypervisor provisions the resources to create and run your virtual machines.\n\nHow does AWS hypervisor work? A hypervisor is a piece of system software that provides virtual machines (VMs), on which users can run their OS and applications. The hypervisor provides isolation between VMs, which run independent of each other, and allows different VMs to run their own OS\n\nIn AWS, these virtual machines are called Amazon Elastic Compute Cloud or Amazon EC2. Behind the scenes, AWS operates and manages the host machines and the hypervisor layer. AWS also installs the virtual machine operating system, called the guest operating system.\nSome AWS compute services use Amazon EC2 or use virtualization concepts under the hood, therefore it is best to understand this service first before moving on to container services and serverless compute."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-amazon-ec2",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-amazon-ec2",
    "title": "ThomasHSimm",
    "section": "What Is Amazon EC2?",
    "text": "What Is Amazon EC2?\nAmazon EC2 is a web service that provides secure, resizable compute capacity in the cloud. It allows you to provision virtual servers called EC2 instances. Although AWS uses the phrase “web service” to describe it, it doesn’t mean that you are limited to running just web servers on your EC2 instances.\nYou can create and manage these instances through the AWS Management Console, the AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), or through automation tools and infrastructure orchestration services.\nIn order to create an EC2 instance, you need to define:\n\nHardware specifications, like CPU, memory, network, and storage.\nLogical configurations, like networking location, firewall rules, authentication, and the operating system of your choice.\n\nWhen launching an EC2 instance, the first setting you configure is which operating system you want by selecting an Amazon Machine Image (AMI).\n\nWhat Is an Amazon Machine Image (AMI)?\nIn the traditional infrastructure world, the process of spinning up a server consists of installing an operating system from installation disks, installation drives, or installation wizards over the network. In the AWS Cloud, this operating system installation is no longer your responsibility, and is instead built into the AMI that you choose.\nNot only does an AMI let you configure which operating system you want, you can also select storage mappings, the architecture type (such as 32-bit, 64-bit, or 64-bit ARM), and additional software installed.\n\n\nWhat Is the Relationship Between AMIs and EC2 Instances?\nEC2 instances are live instantiations of what is defined in an AMI, much like a cake is a live instantiation of a cake recipe. If you are familiar with software development, you can also see this kind of relationship between a Class and an Object.\nA Class is something you model and define, while an object is something you interact with. In this case, the AMI is how you model and define your instance, while the EC2 instance is the entity you interact with, where you can install your web server, and serve your content to users.\nWhen you launch a new instance, AWS allocates a virtual machine that runs on a hypervisor. Then the AMI you selected is copied to the root device volume, which contains the image used to boot the volume. In the end, you get a server you can connect to and install packages and any additional software. In this case, you install a web server along with the properly configured source code of your employee directory app.\n\nOne advantage of using AMIs is that they are reusable.\nYou might choose a Linux-based AMI and configure the HTTP server, application packages, and any additional software you may need to run your application.\nIf you wanted to create a second EC2 instance with the same configurations, how can you easily do that? One option is to go through the entire instance creation and configuration process and try to match your settings to the first instance. However, this is time consuming and leaves room for human error.\nThe second, better option, is to create an AMI from your running instance and use this AMI to start a new instance. This way, your new instance will have all the same configurations as your current instance, because the configurations set in the AMIs are the same.\n\n\nWhere Can You Find AMIs?\nYou can select an AMI from the following categories.\n\nQuick Start AMIs that are premade by AWS and allow you to get started quickly.\nAWS Marketplace AMIs that provide popular open source and commercial software from third-party vendors.\nMy AMIs that are created from your EC2 instances.\nCommunity AMIs that are provided by the AWS user community.\nBuild your own custom image with EC2 Image Builder.\n\nEach AMI in the AWS Management Console has an AMI ID, which is prefixed by “ami-”, followed by a random hash of numbers and letters. These IDs are unique to each AWS region."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#amazon-ec2-instance-lifecycle",
    "href": "posts/2020-13-10-AWS-Copy1.html#amazon-ec2-instance-lifecycle",
    "title": "ThomasHSimm",
    "section": "Amazon EC2 Instance Lifecycle",
    "text": "Amazon EC2 Instance Lifecycle\nNow that you know how to select an operating system for your EC2 instance, it’s time to choose other configurations to create your EC2 instance, such as the instance type, network, and storage.\nFor an application like the employee directory application, you need instances with enough capacity to run web servers and process incoming customer requests. Your instance sizing will depend on both the demands of your application and the anticipated size of your user base.\nForecasting server capacity for an on-premises application requires difficult decisions involving significant up-front capital spending, while changes to the allocation of your cloud-based services can be made with a simple API call.\nBecause of AWS’s pay-as-you-go model, you can match your infrastructure capacity to your application’s demand, instead of the other way around.\n\nWhat Makes Up an EC2 Instance?\nEC2 instances are a combination of virtual processors (vCPUs), memory, network, and in some cases, instance storage and graphics processing units (GPUs). When you create an EC2 instance, you need to choose how much you need of each of these components.\nAWS offers a variety of instances that differ based on performance. Some instances provide you with more capacity and others provide less. To get an overview of the capacity details for a particular instance, you should look at the instance type.\nInstance types consist of a prefix identifying the type of workloads they’re optimized for, followed by a size. For example, the instance type c5.large can be broken down into the following elements.\n\nc5 determines the instance family and generation number. Here, the instance belongs to the fifth generation of instances in an instance family that’s optimized for generic computation.\nlarge, which determines the amount of instance capacity.\n\n\n\nWhat Are Instance Families?\n\n\n\n\n\n\n\n\nInstance Family\nDescription\nUse Cases\n\n\n\n\nGeneral purpose\nProvides a balance of compute, memory, and networking resources, and can be used for a variety of workloads.\nScale-out workloads such as web servers, containerized microservices, caching fleets, distributed data stores, and development environments.\n\n\nCompute optimized\nIdeal for compute-bound applications that benefit from high-performance processors.\nHigh-performance web servers, scientific modeling, batch processing, distributed analytics, high-performance computing (HPC), machine/deep learning, ad serving, highly scalable multiplayer gaming.\n\n\nMemory optimized\nDesigned to deliver fast performance for workloads that process large data sets in memory.\nMemory-intensive applications such as high-performance databases, distributed web-scale in-memory caches, mid-size in-memory databases, real-time big-data analytics, and other enterprise applications.\n\n\nAccelerated computing\nUse hardware accelerators or co-processors to perform functions such as floating-point number calculations, graphics processing, or data pattern matching more efficiently than is possible with conventional CPUs.\n3D visualizations, graphics-intensive remote workstations, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.\n\n\nStorage optimized\nDesigned for workloads that require high, sequential read and write access to large data sets on local storage. They are optimized to deliver tens of thousands of low-latency random I/O operations per second (IOPS) to applications that replicate their data across different instances.\nNoSQL databases, such as Cassandra, MongoDB, and Redis, in-memory databases, scale-out transactional databases, data warehousing, Elasticsearch, and analytics.\n\n\n\n\nWhere Does Your EC2 Instance Live?\nBy default, your EC2 instances are placed in a network called the default Amazon Virtual Private Cloud (VPC). This network was created so that you can easily get started with Amazon EC2 without having to learn how to create and configure a VPC.\nAny resource you put inside the default VPC will be public and accessible by the internet, so you shouldn’t place any customer data or private information inside of it.\nOnce you get more comfortable with networking on AWS, you should change this default setting to choose your own custom VPCs and restrict access with additional routing and connectivity mechanisms.\n\n\nArchitect for High Availability\nInside this network, your instance resides in an Availability Zone of your choice. AWS services that are scoped at the Availability Zone level must be architected with high availability in mind.\nWhile EC2 instances are typically reliable, two is better than one, and three is better than two. Specifying the instance size gives you an advantage when designing your architecture because you can use more smaller instances instead of a few larger ones.\nIf your frontend only has a single instance and that instance fails, your application goes down. On the other hand, if your workload is distributed across 10 instances and one fails, you lose only 10 percent of your fleet and your application availability is hardly affected.\nWhen architecting any application for high availability, consider using at least two EC2 instances in two separate Availability Zones.\n\n\nExplore the EC2 Instance Lifecycle\nAn EC2 instance transitions between different states from the moment you create it all the way through to its termination.\n\n\nWhen you launch an instance, it enters the pending state (1). When the instance is pending, billing has not started. At this stage, the instance is preparing to enter the running state. Pending is where AWS performs all actions needed to set up an instance, such as copying the AMI content to the root device and allocating the necessary networking components.\nWhen your instance is running (2), it’s ready to use. This is also the stage where billing begins. As soon as an instance is running, you are then able to take other actions on the instance, such as reboot, terminate, stop, and stop-hibernate.\nWhen you reboot an instance (3), it’s different than performing a stop action and then a start action. Rebooting an instance is equivalent to rebooting an operating system. The instance remains on the same host computer and maintains its public and private IP address, and any data on its instance store.\nIt typically takes a few minutes for the reboot to complete. When you stop and start an instance (4), your instance may be placed on a new underlying physical server. Therefore, you lose any data on the instance store that were on the previous host computer. When you stop an instance, the instance gets a new public IP address but maintains the same private IP address.\nWhen you terminate an instance (5), the instance store are erased, and you lose both the public IP address and private IP address of the machine. Termination of an instance means you can no longer access the machine.\n\n\n\nWhat Is the Difference Between Stop and Stop-Hibernate?\nWhen you stop your instance, it enters the stopping state, and then the stopped state. AWS does not charge usage or data transfer fees for your instance after you stop it, but storage for any Amazon EBS volumes is still charged. While your instance is in the stopped state, you can modify some attributes, like the instance type. When you stop your instance, the data stored in memory (RAM) is lost.\nWhen you stop-hibernate your instance, AWS signals the operating system to perform hibernation (suspend-to-disk), which saves the contents from the instance memory (RAM) to the Amazon EBS root volume.\nConsider a scenario where you build a standard three tier application, where you have web servers, application servers and database servers. Turns out, the application you built becomes extremely popular. To relieve some stress on the database that supports your application, you want to implement a custom backend layer that caches database information in memory (RAM). You decide to run this custom backend caching solution on Amazon EC2.\nIn this scenario, the stop-hibernate feature would be instrumental in persisting storage. It would prevent you from having to manually create scripts to save this RAM data before shutting down the server.\n\n\n\nWhat Makes Up the Pricing?\nTo understand EC2 pricing, let’s decouple the instance price from other services attached to it, such as storage and networking costs. In this unit we refer to the instance cost as the cost associated with the instance in terms of specifications and not the total blended cost of running an instance.\nOnce an instance is launched in your AWS account, the billing usually accrues on a per-second basis. For simplicity of calculation, prices are stated per-hour. For example, if you have an instance running for 5 minutes and 38 seconds during a given month, you only pay for 338 seconds of utilization at the end of the month.\nOne exception to this pricing convention may be third-party AMIs purchased from the AWS Marketplace, which may have a minimum billing of 1 hour. For more details, check out the resources section of this unit.\n\nWhat Are the EC2 Pricing Options?\nOne of the ways to reduce costs with Amazon EC2 is to choose the right pricing option for the way your applications run. There are three main purchasing options for EC2 instances: - on-demand, - reserved, and - spot instances.\n\n\nPay As You Go with On-Demand Instances\nWith On-Demand instances, you pay for compute capacity with no long-term commitments. Billing begins whenever the instance is running, and billing stops when the instance is in a stopped or terminated state. The price per second for a running On-Demand instance is fixed.\nFor applications that require servers to be running all the time, you are less likely to benefit from the On-Demand pricing model, simply because there is no situation where you will need to turn servers off. For example, you might want the web server hosting the frontend of your corporate directory application to be running 24/7 so that users can access the website at any time. Even if there are no users connected to your website, you don’t want to shut down the servers supporting the site in case of potential user activity.\nIn the case when servers cannot be stopped, consider using a Reserved Instance to save on costs.\n\n\nReserve Capacity with Reserved Instances (RIs)\nRIs provide you with a significant discount compared to On-Demand instance pricing. RIs provide a discounted hourly rate and an optional capacity reservation for EC2 instances. You can choose between three payment options: - All Upfront, - Partial Upfront, or - No Upfront.\nYou can select for each of these options either a - 1-year or - 3-year term\nDepending on which option you choose, you are discounted differently.\n\nAll Upfront offers a higher discount than Partial Upfront instances.\nPartial Upfront instances offer a higher discount than No Upfront.\nNo Upfront offers a higher discount than On-Demand.\n\nOn-Demand and No Upfront are similar since both do not require any upfront payment. However, there is a major difference. When you choose an On-Demand instance, you stop paying for the instance when you stop or terminate the instance. When you stop an RI, you still pay for it because you committed to a 1-year or 3-year term.\nReserved Instances are associated with an instance type and an Availability Zone depending on how you reserve it. The discount applied by a Reserved Instance purchase is not directly associated with a specific instance ID, but with an instance type.\n\n\nSave on Costs with Spot Instances\nAnother way of paying for EC2 instances is by using Spot Instances. Amazon EC2 Spot Instances allow you to take advantage of unused EC2 capacity in the AWS Cloud. They are available at up to a 90% discount compared to On-Demand prices.\nWith Spot Instances, you set a limit on how much you would like to pay for the instance hour. This is compared against the current Spot price that AWS determines. If the amount you pay is more than the current Spot price and there is capacity, then you will receive an instance. While they are very promising from the billing perspective, there are some architectural considerations you will need to consider in order to use them effectively.\nOne consideration is that your spot instance may be interrupted. For example, if AWS determines that capacity is no longer available for a particular spot instance or if the Spot price exceeds how much you are willing to pay, AWS will give you a 2-minute warning before it interrupts your instance. That means any application or workload that runs on a Spot instance must be able to be interrupted.\nBecause of this unique consideration, inherently fault-tolerant workloads are typically good candidates to use with Spot instances.\nThese include - big data, - containerized workloads, - continuous integration/continuous delivery (CI/CD), - web servers, - high-performance computing (HPC), - image and media rendering, - or other test and development workloads."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-a-container",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-a-container",
    "title": "ThomasHSimm",
    "section": "What Is a Container?",
    "text": "What Is a Container?\n\nWhat is the container in AWS? Containers provide a standard way to package your application’s code, configurations, and dependencies into a single object. Containers share an operating system installed on the server and run as resource-isolated processes, ensuring quick, reliable, and consistent deployments, regardless of environment\n\nContainers can host a variety of different workloads, including - web applications, - lift and shift migrations, - distributed applications, and - streamlining of development, test, and production environments.\nWith the evolution of the open source software community, containers evolved. Today, containers are used as a solution to problems of traditional compute, including the issue of getting software to run reliably when it moves from one compute environment to another.\nA container is a standardized unit that packages up your code and all of its dependencies. This package is designed to run reliably on any platform, because the container creates its own independent environment. This makes it easy to carry workloads from one place to another, such as from development to production or from on-premises to the cloud."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-docker",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-docker",
    "title": "ThomasHSimm",
    "section": "What Is Docker?",
    "text": "What Is Docker?\nWhen you hear the word container, you may associate it with Docker. Docker is a popular container runtime that simplifies the management of the entire operating system stack needed for container isolation, including networking and storage. Docker makes it easy to create, package, deploy, and run containers.\n\nWhat Is the Difference Between Containers and VMs?\nContainers share the same operating system and kernel as the host they exist on, whereas virtual machines contain their operating system. Since each virtual machine has to maintain a copy of an operating system, there’s a degree of wasted space.\nA container is more lightweight. They spin up quicker, almost instantly. This difference in startup time becomes instrumental when designing applications that need to scale quickly during input/output (I/O) bursts.\nWhile containers can provide speed, virtual machines offer you the full strength of an operating system and offer more resources, like package installation, a dedicated kernel, and more.\n\n\n\nOrchestrate Containers\nIn AWS, containers run on EC2 instances. For example, you may have a large instance and run a few containers on that instance.\nWhile running one instance is easy to manage, it lacks high availability and scalability. Most companies and organizations run many containers on many EC2 instances across several Availability Zones.\nIf you’re trying to manage your compute at a large scale, you need to know:\n\nHow to place your containers on your instances.\nWhat happens if your container fails.\nWhat happens if your instance fails.\nHow to monitor deployments of your containers.\n\nThis coordination is handled by a container orchestration service. AWS offers two container orchestration services: Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).\n\n\nManage Containers with Amazon Elastic Container Service (Amazon ECS)\n\nAmazon ECS is an end-to-end container orchestration service that allows you to quickly spin up new containers and manage them across a cluster of EC2 instances.\nTo run and manage your containers, you need to install the Amazon ECS Container Agent on your EC2 instances. This agent is open source and responsible for communicating back to the Amazon ECS service about cluster management details. You can run this agent on both Linux and Windows AMIs. An instance with the container agent installed is often called a container instance.\n\nOnce the Amazon ECS container instances are up and running, you can perform actions that include, but are not limited to, - launching and stopping containers, - getting cluster state, - scaling in and out, - scheduling the placement of containers across your cluster, - assigning permissions, and - meeting availability requirements.\nTo prepare your application to run on Amazon ECS, you create a task definition. The task definition is a text file, in JSON format, that describes one or more containers. A task definition is similar to a blueprint that describes the resources you need to run that container, such as CPU, memory, ports, images, storage, and networking information.\nHere is a simple task definition that you can use for your corporate director application. In this example, the runs on the Nginx web server.\n{     \"family\": \"webserver\",     \"containerDefinitions\": [ {         \"name\": \"web\",         \"image\": \"nginx\",         \"memory\": \"100\",         \"cpu\": \"99\"     } ],     \"requiresCompatibilities\": [ \"FARGATE\" ],     \"networkMode\": \"awsvpc\",     \"memory\": \"512\",     \"cpu\": \"256\" }\n\n\nUse Kubernetes with Amazon Elastic Kubernetes Service (Amazon EKS)\nKubernetes is a portable, extensible, open source platform for managing containerized workloads and services. By bringing software development and operations together by design, Kubernetes created a rapidly growing ecosystem that is very popular and well established in the market.\nIf you already use Kubernetes, you can use Amazon EKS to orchestrate these workloads in the AWS Cloud.\nAmazon EKS is conceptually similar to Amazon ECS, but there are some differences.\n\nAn EC2 instance with the ECS Agent installed and configured is called a container instance.\n\nIn Amazon EKS, it is called a worker node.\n\nAn ECS Container is called a task.\n\nIn the Amazon EKS ecosystem, it is called a pod.\n\nWhile Amazon ECS runs on AWS native technology,\n\nAmazon EKS runs on top of Kubernetes.\n\n\nIf you have containers running on Kubernetes and want an advanced orchestration solution that can provide simplicity, high availability, and fine-grained control over your infrastructure, Amazon EKS is the tool for you."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-networking",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-networking",
    "title": "ThomasHSimm",
    "section": "What Is Networking?",
    "text": "What Is Networking?\nNetworking is how you connect computers around the world and allow them to communicate with one another. In this trail, you’ve already seen a few examples of networking. One is the AWS global infrastructure. AWS has created a network of resources using data centers, Availability Zones, and Regions.\n\nKnow the Networking Basics\nThink about sending a letter. When sending a letter, there are three pieces of information you need.\n\nThe payload or letter inside the envelope.\nThe address of the sender in the From section.\nThe address of the recipient in the To section.\n\nLet’s go further. Each address must contain information such as:\n\nName of sender and recipient\nStreet\nCity\nState or province\nZip, area, or postal code\nCountry\n\nYou need all parts of an address to ensure that your letter gets to its destination. Without the correct address, postal workers are not able to properly deliver the message. In the digital world, computers handle the delivery of messages in a similar way. This is called routing."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-are-ip-addresses",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-are-ip-addresses",
    "title": "ThomasHSimm",
    "section": "What Are IP Addresses?",
    "text": "What Are IP Addresses?\nIn order to properly route your messages to a location, you need an address. Just like each home has a mail address, each computer has an IP address. However, instead of using the combination of street, city, state, zip code, and country, the IP address uses a combination of bits, 0s and 1s.\nHere is an example of a 32-bit address in binary format:\n11000000 10101000 00000001 00011110\nIt’s called 32-bit because you have 32 digits. Feel free to count!\n\nWhat Is IPv4 Notation?\nTypically, you don’t see an IP address in this binary format. Instead, it’s converted into decimal format and noted as an Ipv4 address.\nIn the diagram below, the 32 bits are grouped into groups of 8 bits, also called octets. Each of these groups is converted into decimal format separated by a period.\n11000000 10101000 00000001 00011110\n192.168.1.30\nIn the end, this is what is called an Ipv4 address. This is important to know when trying to communicate to a single computer. But remember, you’re working with a network. This is where CIDR Notation comes in.\n\n\nUse CIDR Notation\n192.168.1.30 is a single IP address. If you wanted to express IP addresses between the range of 192.168.1.0 and 192.168.1.255, how can you do that?\nOne way is by using Classless Inter-Domain Routing (CIDR) notation. CIDR notation is a compressed way of specifying a range of IP addresses. Specifying a range determines how many IP addresses are available to you.\nCIDR notation looks like this:\n192.168.1.0/24\n\n192 is fixed\n168 is fixed\n1 is fixed\n0 is flexible\n\nIt begins with a starting IP address and is separated by a forward slash (the “/” character) followed by a number. The number at the end specifies how many of the bits of the IP address are fixed. In this example, the first 24 bits of the IP address are fixed. The rest are flexible.\n32 total bits subtracted by 24 fixed bits leaves 8 flexible bits. Each of these flexible bits can be either 0 or 1, because they are binary. That means you have two choices for each of the 8 bits, providing 256 IP addresses in that IP range.\nThe higher the number after the /, the smaller the number of IP addresses in your network. For example, a range of 192.168.1.0/24 is smaller than 192.168.1.0/16.\nWhen working with networks in the AWS Cloud, you choose your network size by using CIDR notation. In AWS, the smallest IP range you can have is /28, which provides you 16 IP addresses. The largest IP range you can have is a /16, which provides you with 65,536 IP addresses.\nStanford: Introduction to Computer Networking\nExternal Site: Ionos: CIDR: What is classless inter-domain routing?"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#the-main-route-table",
    "href": "posts/2020-13-10-AWS-Copy1.html#the-main-route-table",
    "title": "ThomasHSimm",
    "section": "The Main Route Table",
    "text": "The Main Route Table\nWhen you create a VPC, AWS creates a route table called the main route table. A route table contains a set of rules, called routes, that are used to determine where network traffic is directed. AWS assumes that when you create a new VPC with subnets, you want traffic to flow between them. Therefore, the default configuration of the main route table is to allow traffic between all subnets in the local network. Below is an example of a main route table:\n\n\n\nDestination\nTarget\nStatus\nPropagated\n\n\n\n\n10.2.0.0/16\nlocal\nactive\nno\n\n\n\nThere are two main parts to this route table.\n\nThe destination, which is a range of IP addresses where you want your traffic to go. In the example of sending a letter, you need a destination to route the letter to the appropriate place. The same is true for routing traffic. In this case, the destination is the IP range of our VPC network.\nThe target, which is the connection through which to send the traffic. In this case, the traffic is routed through the local VPC network.\n\n\nCustom Route Tables\nWhile the main route table controls the routing for your VPC, you may want to be more granular about how you route your traffic for specific subnets. For example, your application may consist of a frontend and a database. You can create separate subnets for these resources and provide different routes for each of them.\nIf you associate a custom route table with a subnet, the subnet will use it instead of the main route table. By default, each custom route table you create will have the local route already inside it, allowing communication to flow between all resources and subnets inside the VPC.\n\n\n\nSecure Your Subnets with Network ACLs\nThink of a network ACL as a firewall at the subnet level. A network ACL enables you to control what kind of traffic is allowed to enter or leave your subnet. You can configure this by setting up rules that define what you want to filter. Here’s an example.\n\nInbound\n\n\n\nRule #\nType\nProtocolPort Range\nSource\nAllow/Deny\n\n\n\n\n100\nAll IPv4 traffic\nAll\n0.0.0.0/0\nALLOW\n\n\n*\nAll IPv4 traffic\nAll\n0.0.0.0/0\nDENY\n\n\n\n\n\nOutbound\n\n\n\nRule #\nType\nProtocolPort Range\nSource\nAllow/Deny\n\n\n\n\n100\nAll IPv4 traffic\nAll\n0.0.0.0/0\nALLOW\n\n\n*\nAll IPv4 traffic\nAll\n0.0.0.0/0\nDENY\n\n\n\nThe default network ACL, shown in the table above, allows all traffic in and out of your subnet. To allow data to flow freely to your subnet, this is a good starting place.\nHowever, you may want to restrict data at the subnet level. For example, if you have a web application, you might restrict your network to allow HTTPS traffic and remote desktop protocol (RDP) traffic to your web servers.\n\n\nInbound\n\n\n\n\n\n\n\n\n\n\n\nRule #\nSource IP\nProtocol\nPort\nAllow/Deny\nComments\n\n\n\n\n100\nAll IPv4 traffic\nTCP\n443\nALLOW\nAllows inbound HTTPS traffic from anywhere\n\n\n130\n192.0.2.0/24\nTCP\n3389\nALLOW\nAllows inbound RDP traffic to the web servers from your home network’s public IP address range (over the internet gateway)\n\n\n*\nAll IPv4 traffic\nAll\nAll\nDENY\nDenies all inbound traffic not already handled by a preceding rule (not modifiable)\n\n\n\n\n\nOutbound\n\n\n\n\n\n\n\n\n\n\n\nRule #\nDestination IP\nProtocol\nPort\nAllow/Deny\nComments\n\n\n\n\n120\n0.0.0.0/0\nTCP\n1025-65535\nALLOW\nAllows outbound responses to clients on the internet (serving people visiting the web servers in the subnet)\n\n\n*\n0.0.0.0/0\nAll\nAll\nDENY\nDenies all outbound traffic not already handled by a preceding rule (not modifiable)\n\n\n\nNotice that in the network ACL example above, you allow inbound 443 and outbound range 1025-65535. That’s because HTTP uses port 443 to initiate a connection and will respond to an ephemeral port. Network ACL’s are considered stateless, so you need to include both the inbound and outbound ports used for the protocol. If you don’t include the outbound range, your server would respond but the traffic would never leave the subnet.\nSince network ACLs are configured by default to allow incoming and outgoing traffic, you don’t need to change their initial settings unless you need additional security layers.\n\n\n\nSecure Your EC2 Instances with Security Groups\nThe next layer of security is for your EC2 Instances. Here, you can create a firewall called a security group. The default configuration of a security group blocks all inbound traffic and allows all outbound traffic.\n\nYou might be wondering: “Wouldn’t this block all EC2 instances from receiving the response of any customer requests?” Well, security groups are stateful, meaning they will remember if a connection is originally initiated by the EC2 instance or from the outside and temporarily allow traffic to respond without having to modify the inbound rules.\nIf you want your EC2 instance to accept traffic from the internet, you’ll need to open up inbound ports. If you have a web server, you may need to accept HTTP and HTTPS requests to allow that type of traffic in through your security group. You can create an inbound rule that will allow port 80 (HTTP) and port 443 (HTTPS) as shown below.\n\n\n\nType\nProtocol\nPort Range\nSource\n\n\n\n\nHTTP (80)\nTCP (6)\n80\n0.0.0.0/0\n\n\nHTTP (80)\nTCP (6)\n80\n::/0\n\n\nHTTP (443)\nTCP (6)\n443\n0.0.0.0/0\n\n\nHTTP (443)\nTCP (6)\n443\n::/0\n\n\n\nYou learned in a previous unit that subnets can be used to segregate traffic between computers in your network. Security groups can be used to do the same thing. A common design pattern is organizing your resources into different groups and creating security groups for each to control network communication between them.\n\nThis example allows you to define three tiers and isolate each tier with the security group rules you define. In this case, you only allow internet traffic to the web tier over HTTPS, Web Tier to Application Tier over HTTP, and Application tier to Database tier over MySQL. This is different from traditional on-premises environments, in which you isolate groups of resources via VLAN configuration. In AWS, security groups allow you to achieve the same isolation without tying it to your network.\n\ns3\nec2\nvpc\nalb auto load balancer\nasg auto scaling group\nroute53\namazon cloud watch\nidentity and excess managwe first 7 chapet"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#aws-solutions-architect",
    "href": "posts/2020-13-10-AWS-Copy1.html#aws-solutions-architect",
    "title": "ThomasHSimm",
    "section": "AWS Solutions architect",
    "text": "AWS Solutions architect\n\nWhat is virtualizations?\nA virtualization architecture is a conceptual model specifying the arrangement and interrelationships of the particular components involved in delivering a virtual – rather than physical – version of something, such as an operating system (OS), a server, a storage device or network resources.\nAct like a their physical counterpart\n\nuses a hyperisor that allows a single computer to host many VMs\nVMs are software containers that run their own OS and act like standalone computers, despite using a fraction of teh underlying hardware\nhyperisor also assigns computing power to each VM as needed for efficiency\n\nThe image below illustrates the difference between traditional computing architecture and a virtualization architecture.\n\nhttps://www.techtarget.com/whatis/definition/virtualization-architecture\nTraditional - Application - OS -\nVirtual - windows and Linux - Every app can have a different OS - Virtualization layer -\nVirtualisation is used to replace physical files, servers, networks, … infracture with compuetr-generated versions hosted by a service provider\nProviders\nhttps://www.bigcommerce.com/articles/ecommerce/saas-vs-paas-vs-iaas/\n\nSaaS- Software as a Service\nSaaS platforms involve software that is available via third-party over the Internet.\nSoftware as a Service (SaaS) provides you with a completed product that is run and managed by the service provider. In most cases, people referring to Software as a Service are referring to end-user applications. With a SaaS offering you do not have to think about how the service is maintained or how the underlying infrastructure is managed; you only need to think about how you will use that particular piece of software. A common example of a SaaS application is web-based email which you can use to send and receive email without having to manage feature additions to the email product or maintain the servers and operating systems that the email program is running on.\nExamples of popular SaaS providers include:\n\nOffice365\nGoogle apps\n\n\n\n\nPaaS- Platform as a Service\nPaaS focuses primarily on hardware and software tools available over the internet.\nPlatform as a Service (PaaS) removes the need for your organization to manage the underlying infrastructure (usually hardware and operating systems) and allows you to focus on the deployment and management of your applications. This helps you be more efficient as you don’t need to worry about resource procurement, capacity planning, software maintenance, patching, or any of the other\nExamples of popular PaaS providers include:\n\nAWS Elastic Beanstalk.\nHeroku.\nWindows Azure (mainly used as PaaS).\nForce.com.\nGoogle App Engine.\n\n\n\nIaaS- Infrastructure as a Service\nIaaS works primarily with cloud-based and pay-as-you-go services such as storage, networking and virtualization.\nInfrastructure as a Service (IaaS) contains the basic building blocks for cloud IT and typically provides access to networking features, computers (virtual or on dedicated hardware), and data storage space. IaaS provides you with the highest level of flexibility and management control over your IT resources and is most similar to existing IT resources that many IT departments and developers are familiar with today.\nExamples of popular IaaS providers include:\nAWS EC2.\nRackspace.\nGoogle Compute Engine (GCE).\nDigital Ocean.\nMicrosoft Azure. \n\n\nCharacteristics of virtualization\n\nResource sharing\n\n\nvirtualization allows users to build many computing environments from a single host machine. Alllows users to manage the number of active servers, save power limit number of active servers\n\n\nIsolation\n\n\nSelf-contained VMs in virtualization provided an isolated online environment for guest users (people, apps, OSs). The separation keeps sensitive data safe while allowing guests to stay connected\n\n\nAvailability\n\n\nIncreased uptime, availability, fault tolerance, and help users avoid downtime, reduce productivity and poses security and safety risks\n\ni.e. Across different data centres, in case one goes down\n\nAggregation\n\n\nVirtualization allows various devices to share resources from a single machine, but it may also be used to integrate multiple devices into a single powerful host. Cluster management software is required for aggregation, which links a homogeneous set of computers or servers to create a unified resource centre\n\n\nReliability\n\n\nAutomated load balancing (ALB), which runs redundant servers on differnt host machines to prevent disruptions, ensures continual uptime for virtualisation platforms\n\nThree-tier architecture\n\nfirewall\nweb-server\nfirewall\napplication server\nfirewall\ndatabase server\n\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\n\n\n\nimage-3.png\n\n\n\n\n\nimage-4.png\n\n\n\n\n\nimage-5.png\n\n\n\n\n\nimage-6.png\n\n\n\n\n\nimage-7.png\n\n\nhttps://www.udemy.com/course/practice-exams-aws-certified-solutions-architect-associate/#instructor-2\nhttps://explore.skillbuilder.aws/learn/signin\nhttps://aws.amazon.com/certification/certified-solutions-architect-associate/\nhttps://823250371685.signin.aws.amazon.com 823250371685 user_4 Pa$$w0rd8944\nCloud computing an internet based computing platform connects large groups of servers for centralised storage and online access to computer service and resources\nOrganisation can use shared computing and storage resources insead of constructing and expanding infrastructure on their own when the use cloud computing\n\nOn-demand resources\nscaling up and down\naccessed securely over internet\npay as you go models, charge based on resources and utilisation\n\nThree types\n\nPublic cloud (AWS, etc\nPrivate Cloud (home/office also called data-centre)\nHybrid cloud (combined)\nAWS snowball like an external hard drive\nAWS import/export suitable for migration moving data centre\nDifferent sizes up to trucks"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#amazon-rds",
    "href": "posts/2020-13-10-AWS-Copy1.html#amazon-rds",
    "title": "ThomasHSimm",
    "section": "Amazon RDS",
    "text": "Amazon RDS\n\nRelational Database server- database engine similar to MySQL, Oracle etc\nAutomatically updates database software and handles backups according to users preference\n\nAthena to query S3 by sql??"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#storage-and-backups",
    "href": "posts/2020-13-10-AWS-Copy1.html#storage-and-backups",
    "title": "ThomasHSimm",
    "section": "Storage and Backups",
    "text": "Storage and Backups\n\nS3 (Simple Storage Service)\nStore data as an object inside buckets\nAs many as want read, write, remove"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#nas-and-san",
    "href": "posts/2020-13-10-AWS-Copy1.html#nas-and-san",
    "title": "ThomasHSimm",
    "section": "NAS and SAN",
    "text": "NAS and SAN\n\nIP based dedicated high performance file sharing and storage device\nShare fiels over IP network for NAS clients\n\nhttps://www.backblaze.com/blog/whats-the-diff-nas-vs-san/\nStorage Area Network\n  - Block storage -"
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#prefixes",
    "href": "posts/2020-13-10-AWS-Copy1.html#prefixes",
    "title": "ThomasHSimm",
    "section": "Prefixes",
    "text": "Prefixes\nCan be used to increase perfermoance on requests PUT/COPY/GET/HEAD ?????\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html\nYou can use prefixes to organize the data that you store in Amazon S3 buckets. A prefix is a string of characters at the beginning of the object key name. A prefix can be any length, subject to the maximum length of the object key name (1,024 bytes). You can think of prefixes as a way to organize your data in a similar way to directories. However, prefixes are not directories.\nSearching by prefix limits the results to only those keys that begin with the specified prefix. The delimiter causes a list operation to roll up all the keys that share a common prefix into a single summary list result.\nThe purpose of the prefix and delimiter parameters is to help you organize and then browse your keys hierarchically. To do this, first pick a delimiter for your bucket, such as slash (/), that doesn’t occur in any of your anticipated key names. You can use another character as a delimiter. There is nothing unique about the slash (/) character, but it is a very common prefix delimiter. Next, construct your key names by concatenating all containing levels of the hierarchy, separating each level with the delimiter.\nFor example, if you were storing information about cities, you might naturally organize them by continent, then by country, then by province or state. Because these names don’t usually contain punctuation, you might use slash (/) as the delimiter. The following examples use a slash (/) delimiter.\nEurope/France/Nouvelle-Aquitaine/Bordeaux\n\nNorth America/Canada/Quebec/Montreal\n\nNorth America/USA/Washington/Bellevue\n\nNorth America/USA/Washington/Seattle\nIf you stored data for every city in the world in this manner, it would become awkward to manage a flat key namespace. By using Prefix and Delimiter with the list operation, you can use the hierarchy that you’ve created to list your data. For example, to list all the states in USA, set Delimiter=‘/’ and Prefix=‘North America/USA/’. To list all the provinces in Canada for which you have data, set Delimiter=‘/’ and Prefix=‘North America/Canada/’.\n."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-amazon-s3",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-amazon-s3",
    "title": "ThomasHSimm",
    "section": "What Is Amazon S3?",
    "text": "What Is Amazon S3?\nUnlike Amazon EBS, Amazon S3 is a standalone storage solution that isn’t tied to compute. It enables you to retrieve your data from anywhere on the web. If you’ve ever used an online storage service to back up the data from your local machine, then you most likely have used a service similar to Amazon S3. The big difference between those online storage services and Amazon S3 is the storage type.\nAmazon S3 is an object storage service. Object storage stores data in a flat structure, using unique identifiers to look up objects when requested. An object is simply a file combined with metadata and that you can store as many of these objects as you’d like. All of these characteristics of object storage are also characteristics of Amazon S3. Understand Amazon S3 Concepts\nIn Amazon S3, you have to store your objects in containers called buckets. You can’t upload any object, not even a single photo, to S3 without creating a bucket first. When you create a bucket, you choose, at the very minimum, two things: the bucket name and the AWS Region you want the bucket to reside in.\nThe first part is choosing the Region you want the bucket to reside in. Typically, this will be a Region that you’ve used for other resources, such as your compute. When you choose a Region for your bucket, all objects you put inside that bucket are redundantly stored across multiple devices, across multiple Availability Zones. This level of redundancy is designed to provide Amazon S3 customers with 99.999999999% durability and 99.99% availability for objects over a given year.\nThe second part is choosing a bucket name which must be unique across all AWS accounts. AWS stops you from choosing a bucket name that has already been chosen by someone else in another AWS account. Once you choose a name, that name is yours and cannot be claimed by anyone else unless you delete that bucket, which then releases the name for others to use.\nAWS uses this name as part of the object identifier. In S3, each object is identified using a URL, which looks like this:\nAfter the http://, you see the bucket name. In this example, the bucket is named doc. Then, the identifier uses the service name, s3 and specifies the service provider amazonaws. After that, you have an implied folder inside the bucket called 2006-03-01 and the object inside the folder that is named AmazonS3.html. The object name is often referred to as the key name.\nNote, you can have folders inside of buckets to help you organize objects. However, remember that there’s no actual file hierarchy that supports this on the back end. It is instead a flat structure where all files and folders live at the same level. Using buckets and folders implies a hierarchy, which makes it easy to understand for the human eye. S3 Use Cases\nAmazon S3 is one of the most widely used storage services, with far more use cases than could fit on one screen. The following list summarizes some of the most common ways you can use Amazon S3.\nBackup and storage: S3 is a natural place to back up files because it is highly redundant. As mentioned in the last unit, AWS stores your EBS snapshots in S3 to take advantage of its high availability.\n\nMedia hosting: Because you can store unlimited objects, and each individual object can be up to 5 TBs, S3 is an ideal location to host video, photo, or music uploads.\n\nSoftware delivery: You can use S3 to host your software applications that customers can download.\n\nData lakes: S3 is an optimal foundation for a data lake because of its virtually unlimited scalability. You can increase storage from gigabytes to petabytes of content, paying only for what you use.\n\nStatic websites: You can configure your bucket to host a static website of HTML, CSS, and client-side scripts.\n\nStatic content: Because of the limitless scaling, the support for large files, and the fact that you access any object over the web at any time, S3 is the perfect place to store static content.\nChoose the Right Connectivity Option for Your Resources\nEverything in Amazon S3 is private by default. This means that all S3 resources, such as buckets, folders, and objects can only be viewed by the user or AWS account that created that resource. Amazon S3 resources are all private and protected to begin with.\nIf you decide that you want everyone on the internet to see your photos, you can choose to make your buckets, folders, and objects public. Keep in mind that a public resource means that everyone on the internet can see it. Most of the time, you don’t want your permissions to be all or nothing. Typically, you want to be more granular about the way you provide access to your resources.\nTo be more specific about who can do what with your S3 resources, Amazon S3 provides two main access management features: IAM policies and S3 bucket policies. Understand IAM Policies\nPreviously, you learned about creating and using IAM policies, and now you get to apply this to Amazon S3. When IAM policies are attached to IAM users, groups, and roles, the policies define which actions they can perform. IAM policies are not tied to any one AWS service and can be used to define access to nearly any AWS action. You should use IAM policies for private buckets when:\nYou have many buckets with different permission requirements. Instead of defining many different S3 bucket policies, you can use IAM policies instead.\n\nYou want all policies to be in a centralized location. Using IAM policies allows you to manage all policy information in one location.\nUnderstand S3 Bucket Policies\nS3 bucket policies are similar to IAM policies, in that they are both defined using the same policy language in a JSON format. The difference is IAM policies are attached to users, groups, and roles, whereas S3 bucket policies are only attached to buckets. S3 bucket policies specify what actions are allowed or denied on the bucket.\nFor example, if you have a bucket called employeebucket, you can attach an S3 bucket policy to it that allows another AWS account to put objects in that bucket.\nOr if you wanted to allow anonymous viewers to read the objects in employeebucket, then you can apply a policy to that bucket that allows anyone to read objects in the bucket using “Effect”:Allow on the “Action:[”s3:GetObject”]”.\nHere’s an example of what that S3 bucket policy might look like. { “Version”:“2012-10-17”, “Statement”:[{ “Sid”:“PublicRead”, “Effect”:“Allow”, “Principal”: “*“,”Action”:[“s3:GetObject”], “Resource”:[“arn:aws:s3:::employeebucket/*”] }] }\nS3 Bucket policies can only be placed on buckets, and cannot be used for folders or objects. However, the policy that is placed on the bucket applies to every object in that bucket.\nYou should use S3 bucket policies when:\nYou need a simple way to do cross-account access to S3, without using IAM roles.\n\nYour IAM policies bump up against the defined size limit. S3 bucket policies have a larger size limit.\nEncrypt S3\nAmazon S3 reinforces encryption in transit (as it travels to and from Amazon S3) and at rest. To protect data at rest, you can use:\nServer-side encryption: This allows Amazon S3 to encrypt your object before saving it on disks in its data centers and then decrypt it when you download the objects.\n\nClient-side encryption: Encrypt your data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and all related tools.\nTo encrypt in transit, you can use client-side encryption or Secure Sockets Layer (SSL). Use Versioning to Preserve Objects\nAs you know, Amazon S3 identifies objects in part by using the object name. For example, when you upload an employee photo to S3, you may name the object employee.jpg and store it in a folder called employees. If you don’t use Amazon S3 versioning, anytime you upload an object called employee.jpg to the employees folder, it overwrites the original file. This can be an issue for several reasons.\nemployee.jpg is a common name for an employee photo object. You or someone else who has access to that bucket might not have intended to overwrite it, and now that you have, you no longer have access to the original file.\n\nYou may want to preserve different versions of employee.jpg. Without versioning, if you wanted to create a new version of employee.jpg, you would need to upload the object and choose a different name for it. Having several objects all with slight differences in naming variations may cause confusion and clutter in your bucket.\nSo, what do you do? You use S3 versioning!\nVersioning enables you to keep multiple versions of a single object in the same bucket. This allows you to preserve old versions of an object without having to use different naming constructs, in case you need to recover from accidental deletions, accidental overwrites, or even application failures. Let’s see how this works.\nIf you enable versioning for a bucket, Amazon S3 automatically generates a unique version ID for the object being stored. In one bucket, for example, you can have two objects with the same key, but different version IDs, such as employeephoto.gif (version 111111) and employeephoto.gif (version 121212).\nVersioning-enabled buckets let you recover objects from accidental deletion or overwrite.\nDeleting an object does not remove the object permanently. Instead, Amazon S3 puts a marker on the object that shows you tried to delete it. If you want to restore the object, you can remove this marker and it reinstates the object.\n\nIf you overwrite an object, it results in a new object version in the bucket. You still have access to previous versions of the object.\nUnderstand Versioning States\nBuckets can be in one of three states.\nUnversioned (the default): No new or existing objects in the bucket have a version.\n\nVersioning-enabled: This enables versioning for all objects in the bucket.\n\nVersioning-suspended: This suspends versioning for new objects. All new objects in the bucket will not have a version. However, all existing objects keep their object versions.\nThe versioning state applies to all of the objects in that bucket. Keep in mind that storage costs are incurred for all objects in your bucket and all versions of those objects. To reduce your S3 bill, you may want to delete previous versions of your objects that are no longer in use.\nWhat Are Amazon S3 Storage Classes?\nWhen you upload an object to Amazon S3 and you don’t specify the storage class, you’re uploading it to the default storage class—often referred to as standard storage. When you learned about Amazon S3 in previous units, you were learning about the standard storage class without even knowing it!\nS3 storage classes let you change your storage tier as your data characteristics change. For example, if you are now accessing your old photos infrequently, you may want to change the storage class those photos are stored in to save on costs.\nThere are six S3 storage classes.\nAmazon S3 Standard: This is considered general purpose storage for cloud applications, dynamic websites, content distribution, mobile and gaming applications, and big data analytics.\n\nAmazon S3 Intelligent-Tiering: This tier is useful if your data has unknown or changing access patterns. S3 Intelligent-Tiering stores objects in two tiers, a frequent access tier and an infrequent access tier. Amazon S3 monitors access patterns of your data, and automatically moves your data to the most cost-effective storage tier based on frequency of access.\n\nAmazon S3 Standard-Infrequent Access (S3 Standard-IA): S3 Standard-IA is for data that is accessed less frequently, but requires rapid access when needed. S3 Standard-IA offers the high durability, high throughput, and low latency of S3 Standard, with a low per-GB storage price and per-GB retrieval fee. This storage tier is ideal if you want to store long-term backups, disaster recovery files, and so on.\n\nAmazon S3 One Zone-Infrequent Access (S3 One Zone-IA): Unlike other S3 storage classes which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It’s a good choice for storing secondary backup copies of on-premises data or easily re-creatable data.\n\nAmazon S3 Glacier: S3 Glacier is a secure, durable, and low-cost storage class for data archiving. You can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. To keep costs low yet suitable for varying needs, S3 Glacier provides three retrieval options that range from a few minutes to hours.\n\nAmazon S3 Glacier Deep Archive: S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year. It is designed for customers—particularly those in highly regulated industries, such as the Financial Services, Healthcare, and Public Sectors—that retain data sets for 7 to 10 years or longer to meet regulatory compliance requirements.\nAutomate Tier Transitions with Object Lifecycle Management\nIf you keep manually changing your objects, such as your employee photos, from storage tier to storage tier, you may want to look into automating this process using a lifecycle policy. When you define a lifecycle policy configuration for an object or group of objects, you can choose to automate two actions: transition and expiration actions.\nTransition actions are used to define when you should transition your objects to another storage class.\n\nExpiration actions define when objects expire and should be permanently deleted.\nFor example, you might choose to transition objects to S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them.\nThe following use cases are good candidates for lifecycle management.\nPeriodic logs: If you upload periodic logs to a bucket, your application might need them for a week or a month. After that, you might want to delete them.\n\nData that changes in access frequency: Some documents are frequently accessed for a limited period of time. After that, they are infrequently accessed. At some point, you might not need real-time access to them, but your organization or regulations might require you to archive them for a specific period. After that, you can delete them."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#elastic-compute-cloud-ec2-vm",
    "href": "posts/2020-13-10-AWS-Copy1.html#elastic-compute-cloud-ec2-vm",
    "title": "ThomasHSimm",
    "section": "Elastic Compute Cloud EC2 (VM)",
    "text": "Elastic Compute Cloud EC2 (VM)\n\n\n\nimage.png\n\n\nAmazon EC2 is a web service that provides secure, resizable compute capacity in the cloud. It allows you to provision virtual servers called EC2 instances. Although AWS uses the phrase “web service” to describe it, it doesn’t mean that you are limited to running just web servers on your EC2 instances.\nYou can create and manage these instances through the AWS Management Console, the AWS Command Line Interface (CLI), AWS Software Development Kits (SDKs), or through automation tools and infrastructure orchestration services. In order to create an EC2 instance, you need to define:\n\nHardware specifications, like CPU, memory, network, and storage.\nLogical configurations, like networking location, firewall rules, authentication, and the operating system of your choice.\n\nWhen launching an EC2 instance, the first setting you configure is which operating system you want by selecting an Amazon Machine Image (AMI)."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-an-ami",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-an-ami",
    "title": "ThomasHSimm",
    "section": "What Is an AMI?",
    "text": "What Is an AMI?\nIn the traditional infrastructure world, the process of spinning up a server consists of installing an operating system from installation disks, installation drives, or installation wizards over the network. In the AWS Cloud, this operating system installation is no longer your responsibility, and is instead built into the AMI that you choose.\nNot only does an AMI let you configure which operating system you want, you can also select storage mappings, the architecture type (such as 32-bit, 64-bit, or 64-bit ARM), and additional software installed."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#what-is-the-relationship-between-amis-and-ec2-instances-1",
    "href": "posts/2020-13-10-AWS-Copy1.html#what-is-the-relationship-between-amis-and-ec2-instances-1",
    "title": "ThomasHSimm",
    "section": "What Is the Relationship Between AMIs and EC2 Instances?",
    "text": "What Is the Relationship Between AMIs and EC2 Instances?\nEC2 instances are live instantiations of what is defined in an AMI, much like a cake is a live instantiation of a cake recipe. If you are familiar with software development, you can also see this kind of relationship between a Class and an Object. A Class is something you model and define, while an object is something you interact with. In this case, the AMI is how you model and define your instance, while the EC2 instance is the entity you interact with, where you can install your web server, and serve your content to users.\nWhen you launch a new instance, AWS allocates a virtual machine that runs on a hypervisor. Then the AMI you selected is copied to the root device volume, which contains the image used to boot the volume. In the end, you get a server you can connect to and install packages and any additional software. In this case, you install a web server along with the properly configured source code of your employee directory app.\n\nOne advantage of using AMIs is that they are reusable.\nYou might choose a Linux-based AMI and configure the HTTP server, application packages, and any additional software you may need to run your application.\nIf you wanted to create a second EC2 instance with the same configurations, how can you easily do that? One option is to go through the entire instance creation and configuration process and try to match your settings to the first instance. However, this is time consuming and leaves room for human error.\nThe second, better option, is to create an AMI from your running instance and use this AMI to start a new instance. This way, your new instance will have all the same configurations as your current instance, because the configurations set in the AMIs are the same."
  },
  {
    "objectID": "posts/2020-13-10-AWS-Copy1.html#where-can-you-find-amis-1",
    "href": "posts/2020-13-10-AWS-Copy1.html#where-can-you-find-amis-1",
    "title": "ThomasHSimm",
    "section": "Where Can You Find AMIs?",
    "text": "Where Can You Find AMIs?\nYou can select an AMI from the following categories.\nQuick Start AMIs that are premade by AWS and allow you to get started quickly.\n\nAWS Marketplace AMIs that provide popular open source and commercial software from third-party vendors.\n\nMy AMIs that are created from your EC2 instances.\n\nCommunity AMIs that are provided by the AWS user community.\n\nBuild your own custom image with EC2 Image Builder.\nEach AMI in the AWS Management Console has an AMI ID, which is prefixed by “ami-”, followed by a random hash of numbers and letters. These IDs are unique to each AWS region.\nResources\nExternal Site: AWS: Amazon EC2\n\nExternal Site: AWS: Amazon Machine Images (AMI)\n\nExternal Site: AWS: Creating an Amazon EBS-backed Linux AMI\n\nExternal Site: AWS: What Is EC2 Image Builder?"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#name-of-operating-system",
    "href": "posts/2021-10-04-OS.html#name-of-operating-system",
    "title": "ThomasHSimm",
    "section": "name of operating system",
    "text": "name of operating system\n\nprint('os.name',',',os.name,'\\n')\n\nos.name , nt"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#get-current-dir",
    "href": "posts/2021-10-04-OS.html#get-current-dir",
    "title": "ThomasHSimm",
    "section": "get current dir",
    "text": "get current dir\n\nprint('os.getcwd()',',',os.getcwd(),'\\n')\n\nos.getcwd() , C:\\Users\\44781\\pyproj\\_misc"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#list-files-in-dir",
    "href": "posts/2021-10-04-OS.html#list-files-in-dir",
    "title": "ThomasHSimm",
    "section": "list files in dir",
    "text": "list files in dir\n\nprint('os.listdir()',',',os.listdir(),'\\n')\n\nos.listdir() , ['.ipynb_checkpoints', 'adapic.jpg', 'awarhol.jpg', 'awarhol.webp', 'dog.jpg', 'draw.png', 'ebsd2.tif', 'ebsdmap.png', 'ebsdmap.tif', 'fastAI_C1_notes.ipynb', 'image_1000.jpg', 'image_5000(1).jpg', 'IndeedExtract-Copy1.ipynb', 'IndeedExtract-Copy2.ipynb', 'No_61_Mark_Rothko-thumbnail_webp-9999x9999.webp', 'os.ipynb', 'output', 'PF_500C R.png', 'PythonBook.ipynb', 're.ipynb', 'styleTransfer.ipynb', 'test2', 'Untitled.ipynb', 'vangogh.jpg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'water.webp']"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#make-a-directory",
    "href": "posts/2021-10-04-OS.html#make-a-directory",
    "title": "ThomasHSimm",
    "section": "make a directory",
    "text": "make a directory\n\nthis_dir=os.getcwd()\ndirectory='test'\n#this adds either / or \\ depending on os\npath = os.path.join(this_dir, directory)\n\ntry:\n    os.mkdir(path)\nexcept:\n    pass\n\n#or \ntry:\n    os.mkdir('test2')\nexcept:\n    pass"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#list-files-in-dir-1",
    "href": "posts/2021-10-04-OS.html#list-files-in-dir-1",
    "title": "ThomasHSimm",
    "section": "list files in dir",
    "text": "list files in dir\n\nprint('os.listdir()',',',os.listdir(),'\\n')\n\nos.listdir() , ['.ipynb_checkpoints', 'adapic.jpg', 'awarhol.jpg', 'awarhol.webp', 'dog.jpg', 'draw.png', 'ebsd2.tif', 'ebsdmap.png', 'ebsdmap.tif', 'fastAI_C1_notes.ipynb', 'image_1000.jpg', 'image_5000(1).jpg', 'IndeedExtract-Copy1.ipynb', 'IndeedExtract-Copy2.ipynb', 'No_61_Mark_Rothko-thumbnail_webp-9999x9999.webp', 'os.ipynb', 'output', 'PF_500C R.png', 'PythonBook.ipynb', 're.ipynb', 'styleTransfer.ipynb', 'test', 'test2', 'Untitled.ipynb', 'vangogh.jpg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'water.webp']"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#check-filedir-exists",
    "href": "posts/2021-10-04-OS.html#check-filedir-exists",
    "title": "ThomasHSimm",
    "section": "Check file/dir exists",
    "text": "Check file/dir exists\n\nprint(os.path.exists(\"test2\"),os.path.exists(\"test\"))\n\nTrue True"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#change-directory",
    "href": "posts/2021-10-04-OS.html#change-directory",
    "title": "ThomasHSimm",
    "section": "change directory",
    "text": "change directory\n\nos.chdir(directory)\nprint('os.getcwd()',',',os.getcwd(),'\\n')\n\nos.getcwd() , C:\\Users\\44781\\pyproj\\_misc\\test"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#create-and-rename-a-file",
    "href": "posts/2021-10-04-OS.html#create-and-rename-a-file",
    "title": "ThomasHSimm",
    "section": "Create and Rename a file",
    "text": "Create and Rename a file\n\n# create a file 'a' is append\nopen('Old.txt','a').close()\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\n# rename a file\nfd = \"Old.txt\"\nos.rename(fd,'New.txt')\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\nold= True . new= False\nold= False . new= True"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#copy-a-file-",
    "href": "posts/2021-10-04-OS.html#copy-a-file-",
    "title": "ThomasHSimm",
    "section": "Copy a file-",
    "text": "Copy a file-\n\ncan be done in os but easier in shutil\nhttps://stackabuse.com/how-to-copy-a-file-in-python/\n\nimport shutil\nshutil.copyfile('New.txt', 'Old.txt')\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\nold= True . new= True"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#remove-a-file",
    "href": "posts/2021-10-04-OS.html#remove-a-file",
    "title": "ThomasHSimm",
    "section": "Remove a file",
    "text": "Remove a file\n\n# remove a file\nos.remove(\"New.txt\")\n# os.remove(\"Old.txt\")\n\n# check file exists \nprint('old=',os.path.exists(\"Old.txt\"),'. new=',os.path.exists(\"New.txt\"))\n\nold= True . new= False"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#go-back-up-in-directory",
    "href": "posts/2021-10-04-OS.html#go-back-up-in-directory",
    "title": "ThomasHSimm",
    "section": "Go back up in directory",
    "text": "Go back up in directory\n\n\nos.path.dirname(os.path.dirname(   ))\n\n'C:\\\\Users\\\\44781\\\\pyproj'\n\n\n\n#remove directory\nos.rmdir(path)\n#list files in dir\nprint('os.listdir()',',',os.listdir(),'\\n')\n\nos.listdir() , ['.ipynb_checkpoints', 'adapic.jpg', 'awarhol.jpg', 'awarhol.webp', 'dog.jpg', 'draw.png', 'ebsd2.tif', 'ebsdmap.png', 'ebsdmap.tif', 'fastAI_C1_notes.ipynb', 'image_1000.jpg', 'image_5000(1).jpg', 'IndeedExtract-Copy1.ipynb', 'IndeedExtract-Copy2.ipynb', 'No_61_Mark_Rothko-thumbnail_webp-9999x9999.webp', 'os.ipynb', 'output', 'PF_500C R.png', 'PythonBook.ipynb', 're.ipynb', 'styleTransfer.ipynb', 'test2', 'Untitled.ipynb', 'vangogh.jpg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'water.webp']"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#create-new-files",
    "href": "posts/2021-10-04-OS.html#create-new-files",
    "title": "ThomasHSimm",
    "section": "Create new files",
    "text": "Create new files\n\n#create new file and edit\nnano file.txt\n#create file\ntouch file.txt\n\n\n!cd\n\nC:\\Users\\44781\\pyproj\\_misc\\test"
  },
  {
    "objectID": "posts/2021-10-04-OS.html#shell-commands",
    "href": "posts/2021-10-04-OS.html#shell-commands",
    "title": "ThomasHSimm",
    "section": "Shell Commands",
    "text": "Shell Commands\n\necho\n\necho HELLO print HELLO to screen\necho $string1 print variable string1\n\n\n\nmaths operations\n\necho $(( 10 + 5 )) add two numbers\n\n\n\ncat\n\ncat [file] command allows us to create single or multiple files, view the contents of a file, concatenate files, and redirect output in terminal or other files.\n\n\n\ngrep\nGrep command, which stands for “global regular expression print”, processes text line-by-line and prints any lines that match a specified pattern.\n\ngrep [pattern] [file-directory/location]\ne.g. grep \"jane\" list.txt find the occurances of “jane” in list.txt\n\nHere, [file-directory] is the path to the directory/folder where you want to perform a search operation. The grep command is also used to search text and match a string or pattern within a file.\n\n\ncut\n\ncut [options] [file] The cut command extracts a given number of characters or columns from a file. A delimiter is a character or set of characters that separate text strings.\nFor delimiter separated fields, the - d option is used. The -f option specifies the field, a set of fields, or a range of fields to be extracted. cut -d [delimiter] -f [field number]\n\n\n\ncat\n\ncat > [file]\nEach stream uses redirection commands. A single greater than sign (>) or a double greater than sign (>>) can be used to redirect standard output. If the target file doesn’t exist, a new file with the same name will be created.\ncat >> [file]\nCommands with a double greater than sign (>>) do not overwrite the existing file content, but it will append to it.\n> can be used to create a file\ne.g. > test.txt\ncreates the file test.txt\necho \"I am appending text to this test file\" >> test.txt\nto append to the same file\n\n\n\ntest\ntests an assertion can be replaced with []\n\n\nnano\nEdit a file / create a file and edit it\nfor a shell script - #!/bin/bash\nAnd for a python script - #!/usr/bin/env python3\n\n\nchmod\n\nchmod +x findJane.sh\n\n\n\nfor statement\n\nfor i in 1 2 3; do echo $i; done\nthe key elements to note are ; do and done\n\nExamples\ncat list.txt\n001 jane /data/jane_profile_07272018.doc\n002 kwood /data/kwood_profile_04022017.doc\n003 pchow /data/pchow_profile_05152019.doc\n004 janez /data/janez_profile_11042019.doc\n005 jane /data/jane_pic_07282018.jpg\n006 kwood /data/kwood_pic_04032017.jpg\n007 pchow /data/pchow_pic_05162019.jpg\n008 jane /data/jane_contact_07292018.csv\n009 kwood /data/kwood_contact_04042017.csv\n010 pchow /data/pchow_contact_05172019.csv\ncat list.txt | cut -d ' ' -f 2\njane\nkwood\npchow\njanez\njane\nkwood\npchow\njane\nkwood\npchow\n\nhere | is a pipe to connect commands\neach line is cut by delimiter space ’ ’ then the 2nd term is outputted. IF we put 1 instead we get 001, 002 etc\nor f 1,3 would get 1st and 3rd parts after split by space\n\nif test -e ~/data/jane_profile_07272018.doc; then echo \"File exists\"; else echo \"File doesn't exist\"; fi\n\nthe use of e tests if a file exists\n\n\n# For statement print numbers 1 to 99 in steps of 1\nfor i in {1..99..1}\ndo \n  echo $i\ndone\n\n\n# For and If statements with math operation\nfor i in {1..99..1}\ndo \n  if [ $(( i % 2 )) == 1 ]\n  then\n    echo $i\n  fi\ndone\n\n\n#!/bin/bash\n> oldFiles.txt\n\nfiles=\"$(grep \" jane \" ../data/list.txt | cut -d \" \" -f 3)\"\n\nfor file in $files;\n  do\n   if test -e \"..\"$file;\n   then echo $file >> oldFiles.txt;\n   else echo \"no\" $file;\n   fi\n\ndone\n\nBash Scripting Resources\nCheck out the following links for more information:\n\nhttps://ryanstutorials.net/bash-scripting-tutorial/\nhttps://linuxconfig.org/bash-scripting-tutorial-for-beginners\nhttps://www.shellscript.sh"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#some-maths",
    "href": "posts/2021-10-04-PythonBook.html#some-maths",
    "title": "ThomasHSimm",
    "section": "Some maths",
    "text": "Some maths\n\nimport math\nprint(math.pi)\nprint(math.sqrt(34))\n\n3.141592653589793\n5.830951894845301\n\n\n\nimport random\nprint(random.random())\n\nprint(random.choice([1,2,3,4]))\nprint(random.choice([1,2,3,4]))\n\n0.7617615023592539\n4\n2"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#indexing",
    "href": "posts/2021-10-04-PythonBook.html#indexing",
    "title": "ThomasHSimm",
    "section": "Indexing",
    "text": "Indexing\n\nS='Spam'\n\nprint(S[1:3])\nprint(S[:-1])\nprint(S[1:])\nprint(S[:])\nprint(S*3)\n\npa\nSpa\npam\nSpam\nSpamSpamSpam"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#immutability",
    "href": "posts/2021-10-04-PythonBook.html#immutability",
    "title": "ThomasHSimm",
    "section": "Immutability",
    "text": "Immutability\n\n\n# strings are not immutable\nS[0]='p' ##error\n\nTypeError: 'str' object does not support item assignment\n\n\n\n# but we can create a new string\nS = 'z' +S[1:]\nprint(S)\n#or use replaces\n\nzpam"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#string-specific-methods",
    "href": "posts/2021-10-04-PythonBook.html#string-specific-methods",
    "title": "ThomasHSimm",
    "section": "String specific methods",
    "text": "String specific methods\nhttps://docs.python.org/3/library/stdtypes.html#string-methods\n\nSplit\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then there is no limit on the number of splits (all possible splits are made).\n\nstra='xsxhu csjoaij jsaijaio j dijoi'\nstra1=stra.split()\nprint(stra1)\nstra1=stra.split('j',maxsplit=2)\nprint(stra1)\n\n['xsxhu', 'csjoaij', 'jsaijaio', 'j', 'dijoi']\n['xsxhu cs', 'oai', ' jsaijaio j dijoi']\n\n\n\nline='aaa,bbb,cccc,dd d\\n'\n\n#split based on something\nprint(line.split(','))\n#creates a list\nprint(type(line.split(',')))\n\n# strip out whitespace on rhs\nprint(line.rstrip())\n\n\n\nStrip\nReturn a copy of the string with the leading and trailing characters removed.\n\n'   spacious   '.strip()\n\n'spacious'\n\n\n\n\nCheck nature of string\nstr.isalnum()\nThis method checks if all the characters of a string are alphanumeric (a-z, A-Z and 0-9).\n\nstra='abcD1'\nprint(stra,stra.isalnum())\nstra='abcD1#'\nprint(stra,stra.isalnum())\n\nabcD1 True\nabcD1# False\n\n\nstr.isalpha()\nThis method checks if all the characters of a string are alphabetical (a-z and A-Z).\n\nstra='abcD1'\nprint(stra,stra.isalpha())\nstra='abcD'\nprint(stra,stra.isalpha())\n\nabcD1 False\nabcD True\n\n\nstr.isdigit()\nThis method checks if all the characters of a string are digits (0-9)\nstra=‘abcD1’ print(stra,stra.isdigit()) stra=‘190’ print(stra,stra.isdigit())\nstr.islower()\nThis method checks if all the characters of a string are lowercase characters (a-z).\n\nstra='abcD1'\nprint(stra,stra.islower())\nstra='190'\nprint(stra,stra.islower())\n\nabcD1 False\n190 False\n\n\nstr.lower or str.upper change whether upper or lower case\n\nstra='abcD1'\nprint(stra,stra.lower(),stra.upper())\n\nabcD1 abcd1 ABCD1\n\n\ncaptialize the first character\n\nprint(stra.capitalize())\n\nAbcd1\n\n\n\n\nFind\nFind the position of a substring within a string\nstring.find(stringIN) scan left to right\nstring.rfind(stringIN) scan right to left\n\nstra='ABCDCDC'\nstraa='BCD'\nstra.find('CD'),stra.rfind('CD')\n\n(2, 4)\n\n\n\n\nReplace\nstring.replace(sub_string,string) replace parts of a string\n\nS='oke doke karaoke'\n\n#replace parts of a string\nprint(S)\nprint(S.replace('karaoke','noke'))\n\n\noke doke karaoke\noke doke noke"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#formatting",
    "href": "posts/2021-10-04-PythonBook.html#formatting",
    "title": "ThomasHSimm",
    "section": "Formatting",
    "text": "Formatting\n\n\nprint('%s, eggs, and %s' % ('spam', 'SPAM!'))\n\nprint('{0}, eggs, and {1}'.format('spam', 'SPAM!'))"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#help",
    "href": "posts/2021-10-04-PythonBook.html#help",
    "title": "ThomasHSimm",
    "section": "Help",
    "text": "Help\nPut into help( ) to get help on it\n\nhelp(S.format)"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#lists",
    "href": "posts/2021-10-04-PythonBook.html#lists",
    "title": "ThomasHSimm",
    "section": "Lists",
    "text": "Lists\nhttps://docs.python.org/3/tutorial/datastructures.html?highlight=tuple\nThe Python list object is the most general sequence provided by the language. Lists are positionally ordered collections of arbitrarily typed objects, and they have no fixed size. They are also mutable—unlike strings, lists can be modified in-place by assignment to offsets as well as a variety of list method calls\n\nNew List\nCreate a list with list(XX)\n\na='1 2 3 4 5 6 7'\nlista = list(a)\nprint(lista)\n\n['1', ' ', '2', ' ', '3', ' ', '4', ' ', '5', ' ', '6', ' ', '7']\n\n\n\n\nCopy\nlist.copy\n\nlista =a.split(' ')\nlista=lista[0:3]\nprint('Original a=\\n',lista)\nlistb=lista\nlistc=lista.copy()\nlistd=lista[:]\n\nlistb[1]='po'\n\nprint('list b, where b=a and b[1] modified, b=\\n',listb,\n    '\\nJust using equals b=a after mods, a=\\n',lista,\n      '\\n Using a copy c=a.copy(), c=\\n',listc,\n      '\\n Using d=a[:] to create a copy, d=\\n',listd)\n\nOriginal a=\n ['1', '2', '3']\nlist b, where b=a and b[1] modified, b=\n ['1', 'po', '3'] \nJust using equals b=a after mods, a=\n ['1', 'po', '3'] \n Using a copy c=a.copy(), c=\n ['1', '2', '3'] \n Using d=a[:] to create a copy, d=\n ['1', '2', '3']\n\n\n\n\nAppend\nlist.append(x), add x to end of a list\n\nprint(lista)\nlista.append('ok')\nprint(lista)\n\n['1', 'po', '3']\n['1', 'po', '3', 'ok']\n\n\n\n\nInsert\nlista.insert(i,x) insert x at position i\n\nlista.insert(2,'two')\nprint(lista)\n\n['1', 'po', 'two', '3', 'ok']\n\n\n\n\nRemove\nlista.remove(x) Remove the first item from the list whose value is equal to x.\n\nlista.remove('two')\nprint(lista)\n\n['1', 'po', '3', 'ok']\n\n\n\n\nPop\nlista.pop([i]) Remove the item at the given position in the list, and return it\nlist.popleft at left\n\nprint(lista.pop(1))\n\npo\n\n\n\n\nRemove\nlist.clear() Remove all items from the list. Equivalent to del a[:].\n\nprint(lista.clear())\nprint(lista)\n\nNone\n[]\n\n\n\n\nIndex\nlist.index(x,i) Return position of x within list starting at position i\n\nlistc.append('1')\nprint(listc)\nprint(listc.index('1'),2)\n\n['1', '2', '3', '1']\n0 2\n\n\n\n\nCount\nlista.count(x) Return the number of times x appears in the list.\n\nprint(listc.count('1'))\n\n2\n\n\n\n\nSort\nlista.sort(*, key=None, reverse=False) Sort the items of the list in place (the arguments can be used for sort customization, see sorted() (https://docs.python.org/3/library/functions.html#sorted) for their explanation).\n\nlistc.sort()\nprint(listc)\n\n['1', '1', '2', '3']\n\n\n\n\nReverse\nlista.reverse() Reverse the elements of the list in place.\n\n\nDel\ndel lista[0] remove an item from a list given its index instead of its value\n\nprint(listc)\ndel listc[2]\nprint(listc)\n\n['1', '1', '2', '3']\n['1', '1', '3']\n\n\n\n\n#list of different types\nL =[123, 'spam',1.23]\nprint(L)\n\n#access\nprint(L[2])\n\n#append\nL.append('NI')\nprint(L)\n\n#get rid of one pop!\nL.pop(0)\nprint(L)\n\nM=['aa','jeji','boio','popo','gsss','zulu','ccc']\n#sort\nM.sort()\nprint(M)\nM.reverse()\nprint(M)\n\n[123, 'spam', 1.23]\n1.23\n[123, 'spam', 1.23, 'NI']\n['spam', 1.23, 'NI']\n['aa', 'boio', 'ccc', 'gsss', 'jeji', 'popo', 'zulu']\n['zulu', 'popo', 'jeji', 'gsss', 'ccc', 'boio', 'aa']"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#comprehensions",
    "href": "posts/2021-10-04-PythonBook.html#comprehensions",
    "title": "ThomasHSimm",
    "section": "Comprehensions",
    "text": "Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition.\n\nsquares=[]\nfor x in range(10):\n    squares.append(x**2)\nprint(squares)\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n\n# the comprehension version\n\nprint([x**2 for x in range(10)])\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\nA list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for or if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n\n[(x,y) for x in [1,2,3] for y in [3, 1, 4] if x!=y]\n\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\n\n\n\nvec = [[1,2,3], [4,5,6], [7,8,9]]\n[num for elem in vec for num in elem]\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nmatrix=[[1,2,3,4],\n       [5,6,7,8],\n       [9,19,11,12]]\n[[col[i] for col in matrix] for i in range(4)]\n\n[[1, 5, 9], [2, 6, 19], [3, 7, 11], [4, 8, 12]]\n\n\n\nList to string\nConvert a list to a string with \"\".join(lista)\n\nstra = \"\".join(listd)\nprint(stra,'-',stra[1:])\n\n123 - 23"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#dictionaries",
    "href": "posts/2021-10-04-PythonBook.html#dictionaries",
    "title": "ThomasHSimm",
    "section": "Dictionaries",
    "text": "Dictionaries\nPython dictionaries are something completely different (Monty Python reference intended)—they are not sequences at all, but are instead known as mappings. Mappings are also collections of other objects, but they store objects by key instead of by relative position. In fact, mappings don’t maintain any reliable left-to-right order; they simply map keys to associated values. Dictionaries, the only mapping type in Python’s core objects set, are also mutable: they may be changed in-place and can grow and shrink on demand, like lists.\n\n#create dict\n\nD = {'food':'Spam','quality':4, 'color':'pink'}\nprint(D)\n\n#or create by key assignment \nD={}\nD['food']='Spam'\nD['quality']=4\nD['color']='pink'\nprint(D)\n\n#index it\nprint(D['food'])\n\n\n# Nesting\n#what if the info is more complex? Nest\n\nrec = {'name':{'first':'Bob','last':'Smith'},\n        'job':['dev','mgr'],\n        'age':40.5}\n\n#index them\nprint(rec['name'])\n\nprint(rec['name']['last'])\n\nprint(rec['job'][0])\n\n#or add more NB job is a list\nrec['job'].append('janitor')\n\nprint(rec)\n\n#keys are 1st bit\nprint(rec.keys())"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#tuples",
    "href": "posts/2021-10-04-PythonBook.html#tuples",
    "title": "ThomasHSimm",
    "section": "Tuples",
    "text": "Tuples\nroughly like a list that cannot be changed—tuples are sequences, like lists, but they are immutable, like strings. Syntactically, they are coded in parentheses instead of square brackets, and they support arbitrary types, arbitrary nesting, and the usual sequence operations:\n\nT=(1,2,3,4)\nprint(len(T))\n\n#concatenation\nprint(T+(5,6))\n\n#indexing\nprint(T[0])\n\n## or\nT = ('spam', 3.0, [11, 22, 33])\nprint(T)"
  },
  {
    "objectID": "posts/2021-10-04-PythonBook.html#print",
    "href": "posts/2021-10-04-PythonBook.html#print",
    "title": "ThomasHSimm",
    "section": "Print",
    "text": "Print\n\n# to so many decimal places\n\nx=30.5557889\n\nprint('{:.5f}'.format(x))\n\n30.55579\n\n\n\n# add additional characters to string\n\nwidth = 20\nprint('HackerRank'.ljust(width,'-'))#or rjust\n\nHackerRank----------\n\n\n\nwidth = 20\nprint('HackerRank'.center(width,'-'))\n\n-----HackerRank-----\n\n\nhttps://docs.python.org/3/library/stdtypes.html#string-methods\nConversion……………………… Meaning\nd………………………………. Signed integer decimal.\ni………………………………. Signed integer decimal.\no………………………………. Signed octal value.\nu………………………………. Obsolete type – it is identical to ‘d’.\nx………………………………. Signed hexadecimal (lowercase).\nX………………………………. Signed hexadecimal (uppercase).\ne ………………………………. Floating point exponential format (lowercase).\nE………………………………. Floating point exponential format (uppercase).\nf………………………………. Floating point decimal format.\nF………………………………. Floating point decimal format.\ng………………………………. Floating point format. Uses lowercase exponential format if exponent is less than -4 or not less than precision, decimal format otherwise.\nG ………………………………. Floating point format. Uses uppercase exponential format if exponent is less than -4 or not less than precision, decimal format otherwise.\nc………………………………. Single character (accepts integer or single character string).\nr………………………………. String (converts any Python object using repr()).\ns………………………………. String (converts any Python object using str()).\na………………………………. String (converts any Python object using ascii()).\n%………………………………. No argument is converted, results in a ‘%’ character in the result."
  },
  {
    "objectID": "posts/2021-10-10-ImageClassifier.html#the-model-part",
    "href": "posts/2021-10-10-ImageClassifier.html#the-model-part",
    "title": "ThomasHSimm",
    "section": "1) The model Part",
    "text": "1) The model Part\nThe model was run on https://colab.research.google.com with a GPU\nNecessary to have a GPU for time\nSome imports and installs\n\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n\nGets Azure search key to use Bing search API\n\nkey = os.environ.get('AZURE_SEARCH_KEY', 'keygoeshere')\n\nI’m going to do a classifier for holiday types\n\ndestas={'beach':{'beach','tropical','sea','beach holidays'},\n        'snow':{'ski','snowboard','snow','ski holidays'},\n        'countryside':{'lakes mountains','countryside','forest','fields'},\n        'city':{'city','cities','bars','buildings'},\n        'safari':{'safari','safari holidays','safari park','safari africa'}}\n\nCreates a folder containing images for each type\nNeed to add to dir with different searches not delete and add new stuff each time\nFor eaach holiday type- go through the search topics and add the results together before downloading images to the holiday type folder\nThis gives 600 pics per holiday type\n\npath = Path('Destinations')\ntry:\n    path.mkdir()\nexcept:\n    pass\n\n\nfor o in destas:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True)\n    for ii,oo in enumerate(destas[o]): \n        # print(oo)\n        results = search_images_bing(key, f'{oo}')\n        if ii>0:\n            resultsALL = L(resultsALL,results).concat()\n        else:\n            resultsALL=results\n    print(o)\n    print(np.shape(resultsALL))\n    download_images(dest, urls=resultsALL.attrgot('contentUrl'))\n\nCreate a data block for fastai\n\nfns = get_image_files(path)\n\ndests = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\nget rid of failed images\n\nfailed = verify_images(fns)\nfailed.map(Path.unlink)\nfailed\n\nHave a look at the images\n\ndls = dests.dataloaders(path)\ndls.valid.show_batch(max_n=40, nrows=10)\n\n\ncreate a dls for the learner\n\nrandomresizedcrop\ndefault aug transforms\n\n\ndests = dests.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\ndls = dests.dataloaders(path)\n\nDo the learning over 4 epochs\n\nlearn = cnn_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n\nConfusion matrix\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\nSave the model (saves as export.pkl)\n\nlearn.export()"
  },
  {
    "objectID": "posts/2021-10-10-ImageClassifier.html#the-app-in-python",
    "href": "posts/2021-10-10-ImageClassifier.html#the-app-in-python",
    "title": "ThomasHSimm",
    "section": "2) The App in python",
    "text": "2) The App in python\nSome imports\n\n# Classifier App\n# THSimm\n\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nimport urllib.request\n\nCreate parts of the widget\n\nlearn_inf = load_learner('export.pkl')\nbtn_upload = widgets.FileUpload()\n\nout_pl = widgets.Output()\nout_pl.clear_output()\n\nlbl_pred = widgets.Label()\n\nFunction occurs on click upload\n\ndef on_click_classify(change):\n    img = PILImage.create(btn_upload.data[-1])\n    out_pl.clear_output()\n    with out_pl: display(img.to_thumb(500,500))\n    pred,pred_idx,probs = learn_inf.predict(img)\n    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n\n\nbtn_upload.observe(on_click_classify,names=['data'])\n\nWhat is displayed\n\n#hide_output\ntext ='Select your plane'\n\ndisplay(VBox([widgets.HTML(value = f\"<h1><font color='Black'>{text}</h1>\\\n                                     <ol text-align: center><font color='Black'>\\\n                                    <li>Beach</li>\\\n                                    <li>Snow</li>\\\n                                    <li>Countryside</li>\\\n                                    <li>City</li>\\\n                                    <li>Safari</li>\\\n                                    </ol>\"), \n      btn_upload,  out_pl, lbl_pred]) )"
  },
  {
    "objectID": "posts/2021-10-10-ImageClassifier.html#the-binder-part",
    "href": "posts/2021-10-10-ImageClassifier.html#the-binder-part",
    "title": "ThomasHSimm",
    "section": "3) The Binder Part",
    "text": "3) The Binder Part\n\nBinder\n\nmybinder.org is an online service for building and sharing reproducible and interactive computational environments from online repositories. Under the hood, it is a federation of BinderHub deployments that are maintained by the Binder community. It serves as both a public service and a demonstration of the BinderHub technology, though it is by no means the only BinderHub in existence. If you’re interested in deploying your own BinderHub for your own uses, please see the BinderHub documentation and don’t hesitate to reach out to the Binder community.\n\nhttps://mybinder.readthedocs.io/en/latest/introduction.html#preparing-a-repository-for-binder\nBasically allowing us to put code online\n\n\nVoila\nThe 2nd import part is Voila which allows us to hide the code and just display outputs\nhttps://voila.readthedocs.io/en/stable/using.html\n\nMethod:\n\n\nCreate repository on github that is public, containing the ipynb file and a requirements.txt file\n\n\nThen go to binder https://mybinder.org/\n\n\nFill in form as shown below\n\n\nIn requirements.txt:\nvoila fastai packaging ipywidgets"
  },
  {
    "objectID": "posts/2021-10-10-ImageClassifier.html#the-result",
    "href": "posts/2021-10-10-ImageClassifier.html#the-result",
    "title": "ThomasHSimm",
    "section": "The result",
    "text": "The result\nhttps://mybinder.org/v2/gh/ThomasHSimm/LocationsClassifier/HEAD?urlpath=%2Fvoila%2Frender%2FAppForDestClass.ipynb\nhttps://tinyurl.com/LocClassAppThomasHSimm"
  },
  {
    "objectID": "posts/2021-10-17-Regular-Expressions.html#regular-expressions-cheat-sheets",
    "href": "posts/2021-10-17-Regular-Expressions.html#regular-expressions-cheat-sheets",
    "title": "ThomasHSimm",
    "section": "Regular Expressions Cheat-Sheets",
    "text": "Regular Expressions Cheat-Sheets\nCheck out the following links for more information:\nhttps://docs.python.org/3/howto/regex.html\nhttps://docs.python.org/3/library/re.html\nhttps://docs.python.org/3/howto/regex.html#greedy-versus-non-greedy\nShout out to regex101.com, which will explain each stage of a regex."
  },
  {
    "objectID": "posts/2021-10-17-Regular-Expressions.html#summary",
    "href": "posts/2021-10-17-Regular-Expressions.html#summary",
    "title": "ThomasHSimm",
    "section": "Summary",
    "text": "Summary\n^ Beginning character\n$ End character\nPutting  before finds the special char\n\\w matches letters number and underscores\n\\d matches digits\n\\s for whitespace characters, space tab or newline\n\\b for word boundaries\n[a-z] is all lowercase letters\n[A-Z] is upercase letters\n[0-9] is numbers\n. is a joker button\n* means can have any length\n? zero or one occurence of the character before it\n^ NOT to all in the character class\n| Or statement\n[] within square brackets are or statements\n{n,m} numeric repetition qualifiers with brackets between n and m. Remove n or m can do less or more"
  },
  {
    "objectID": "posts/2021-10-17-Regular-Expressions.html#different-commands",
    "href": "posts/2021-10-17-Regular-Expressions.html#different-commands",
    "title": "ThomasHSimm",
    "section": "Different commands",
    "text": "Different commands\nre.search finds first instance\nre.findall finds all instances\nre.split split based on the expression\nre.sub substitute a part of the string\n\nprint('Using>> re.search(r\"ba\",\"babar\") gives:\\n',\\\n      re.search(r\"ba\",\"babar\"))\nprint('Using>> re.findall(r\"ba\",\"babar\") gives:\\n',\\\n      re.findall(r\"ba\",\"babar\"))\n\nUsing>> re.search(r\"ba\",\"babar\") gives:\n <re.Match object; span=(0, 2), match='ba'>\nUsing>> re.findall(r\"ba\",\"babar\") gives:\n ['ba', 'ba']\n\n\n\nprint(re.split(r\"[.?!]\",\"the dog! is here. whhere? oh I see.\"))\n\n['the dog', ' is here', ' whhere', ' oh I see', '']\n\n\n\nprint(re.sub(r\"dog\",\"cat\",\"the dog! is here. whhere? oh I see.\"))\n\nthe cat! is here. whhere? oh I see."
  },
  {
    "objectID": "posts/2021-10-17-Regular-Expressions.html#search-within-a-string",
    "href": "posts/2021-10-17-Regular-Expressions.html#search-within-a-string",
    "title": "ThomasHSimm",
    "section": "Search within a string",
    "text": "Search within a string\n\nprint('        Find a string within a string')\n\nresult = re.search(r\"aza\",\"bazaar\")\nprint(result)\nresult = re.search(r\"aza\",\"plaza\")\nprint(result)\n\nprint('\\n        At start of the string')\nresult=re.search(r\"^z\",\"zebra\")\nprint(result)\nresult = re.search(r\"^z\",\"plaza\")\nprint(result)\n\nprint('\\n        The joker .')\nresult = re.search(r\"x.n\",\"xenon\")\nprint(result)\nresult = re.search(r\"x..o\",\"xenon\")\nprint(result)\n\n        Find a string within a string\n<re.Match object; span=(1, 4), match='aza'>\n<re.Match object; span=(2, 5), match='aza'>\n\n        At start of the string\n<re.Match object; span=(0, 1), match='z'>\nNone\n\n        The joker .\n<re.Match object; span=(0, 3), match='xen'>\n<re.Match object; span=(0, 4), match='xeno'>\n\n\n\nCharacter classes\nThese are inside square brackets and are OR statements\n[a-z] is all lowercase letters [A-Z] is upercase letters [0-9] is numbers\n\nprint(re.search(r\"[Ppc]ython\",\"cython\"))\nprint(re.search(r\"[a-z]ython\",\"dython\"))\nprint(re.search(r\"[a-z]way\",\"My way\"))\nprint(re.search(r\"[a-z]way\",\"Myway\"))\n\n#find cloud with letter or number after it\nprint(re.search(r\"cloud[a-zA-Z0-9]\",\"cloud9\"))\nprint(re.search(r\"[a-zA-Z0-9]\",\"dy9thon\"))\n\n<re.Match object; span=(0, 6), match='cython'>\n<re.Match object; span=(0, 6), match='dython'>\nNone\n<re.Match object; span=(1, 5), match='yway'>\n<re.Match object; span=(0, 6), match='cloud9'>\n<re.Match object; span=(0, 1), match='d'>\n\n\n\n\napply a NOT to all in the character class\nThis uses the pipe class ^\n\n#this finds a space\nprint(re.search(r\"[^a-zA-Z0-9]\",\"dy9 thon\"))\n#this finds an underscore\nprint(re.search(r\"[^a-zA-Z0-9]\",\"dy9_thon\"))\n\n#this includes a not for spaces\nprint(re.search(r\"[^a-zA-Z0-9 ]\",\"dy9 thon-\"))\n\n<re.Match object; span=(3, 4), match=' '>\n<re.Match object; span=(3, 4), match='_'>\n<re.Match object; span=(8, 9), match='-'>\n\n\n\n\nfind a string OR another one\n\n\nprint(re.search(r\"cat|dog\",\"I ilke cats\"))\n\n<re.Match object; span=(7, 10), match='cat'>\n\n\n\n\nGreedy *\nExtension of .\n.* means can have any length\n\n#this finds something starting with p and ending with n\nprint(re.search(r\"p.*n\",\"python programming\"))\n\n#this finds something starting with py ending n but only a-z chars\nprint(re.search(r\"py[a-z]*n\",\"python programming\"))\n\n<re.Match object; span=(0, 17), match='python programmin'>\n<re.Match object; span=(0, 6), match='python'>\n\n\n\n\nmatch one or more occurence +\nSo o+l looks for ol\n\n#this works\nprint(re.search(r\"o+l\",\"olly\"))\n\n#this fails because there is an i inbetween\nprint(re.search(r\"o+l\",\"oilly\"))\n\n#this finds from 1st o to l\nprint(re.search(r\"o+l\",\"oolly\"))\n\n# here we can just remove the +\nprint(re.search(r\"ol\",\"oolly\"))\n\n<re.Match object; span=(0, 2), match='ol'>\nNone\n<re.Match object; span=(0, 3), match='ool'>\n<re.Match object; span=(1, 3), match='ol'>\n\n\n\n\nzero or one occurence of the character before it ?\n\n#\nprint(re.search(r\"p?each\",\"To each their own\"))\n\n#\nprint(re.search(r\"p?each\",\"To peach their own\"))\n\n#\nprint(re.search(r\"p?each\",\"Top each their own\"))\n\n<re.Match object; span=(3, 7), match='each'>\n<re.Match object; span=(3, 8), match='peach'>\n<re.Match object; span=(4, 8), match='each'>\n\n\n\n\nspecial characters \\\nPutting \\ before finds the special char\n\n# . here is anything so works here\nprint(re.search(r\".com\",\"internet.com\"))\n# but not here\nprint(re.search(r\".com\",\"welcome\"))\n# Add backslash we get it here \nprint(re.search(r\"\\.com\",\"internet.com\"))\n# and a negative here\nprint(re.search(r\"\\.com\",\"welcome\"))\n# find a (\nprint(re.search(r\"\\(\",\"welcome (no dont)\"))\n\n<re.Match object; span=(8, 12), match='.com'>\n<re.Match object; span=(2, 6), match='lcom'>\n<re.Match object; span=(8, 12), match='.com'>\nNone\n<re.Match object; span=(8, 9), match='('>\n\n\n\n\nMore special chars\n\\w matches letters number and underscores\n\\d matches digits\n\\s for whitespace characters, space tab or newline\n^ Beginning character\n$ End character\n\nprint('       so get here internet (stops at dot)')\nprint(re.search(r\"\\w*\",\"internet.com\"))\n\nprint(\"\\n     and here the whole string\")\nprint(re.search(r\"\\w*\",\"internet99_com\"))\n\n\nprint(\"\\n     find country start and end in 'a'\")\n\nprint(\"this works>>\\n\",re.search(r\"A.*a\",\"Australia\"))\nprint(\"this doesn't end in a>>\\n\",re.search(r\"A.*a\",\"Azerbaijan\"))\n\nprint(\"\\n     add the begin and end chars- works correct for both\")\nprint(re.search(r\"^A.*a$\",\"Australia\"))\nprint(re.search(r\"^A.*a$\",\"Azerbaijan\"))\n\n       so get here internet (stops at dot)\n<re.Match object; span=(0, 8), match='internet'>\n\n     and here the whole string\n<re.Match object; span=(0, 14), match='internet99_com'>\n\n     find country start and end in 'a'\nthis works>>\n <re.Match object; span=(0, 9), match='Australia'>\nthis doesn't end in a>>\n <re.Match object; span=(0, 9), match='Azerbaija'>\n\n     add the begin and end chars- works correct for both\n<re.Match object; span=(0, 9), match='Australia'>\nNone\n\n\n\n\nWord boundaries \\b\nFor word boundaries the \\b needs to be placed on both sides of the word to find\n\nprint(\"           Find the word hello\")\nprint(re.search(r\"\\bhello\\b\",\"hello darkness my old friend\"))\nprint(\"\\n           Find the substring hell\")\nprint(\"works without \\b>>\\n\",re.search(r\"hell\",\"hello darkness my old friend\"))\nprint(\"but not a full word so doesn't work with \\b>>\\n\",re.search(r\"\\bhell\\b\",\"hello darkness my old friend\"))\n\n           Find the word hello\n<re.Match object; span=(0, 5), match='hello'>\n\n           Find the substring hell\nworks without \b>>\n <re.Match object; span=(0, 4), match='hell'>\nbut not a full word so doesn't work with \b>>\n None\n\n\n\n\nCombine a few\nThis is for valid variable names\n\n# ^[a-zA-Z_] startswith letters or underscore\n# [a-zA-Z0-9_] then letters, numbers or undercore\n# *$ end with above\npattern=r\"^[a-zA-Z_][a-zA-Z0-9_]*$\"\n\nprint(re.search(pattern,\"LLnananj_9\"))\n\nprint(re.search(pattern,\"LLnananj_9\"))\nprint(re.search(pattern,\"9LLnananj_9\"))\n\n<re.Match object; span=(0, 10), match='LLnananj_9'>\n<re.Match object; span=(0, 10), match='LLnananj_9'>\nNone\n\n\n\n\nnumeric repetition qualifiers {m,n}\n[a-z]{n} for a repetition of lower case chars n time\n[a-z]{n,m} repetition between n and m\n[a-z]{n,} repetition of n or more\n[a-z]{,n} repetitions of n or less\n\nprint(re.search(r\"[a-zA-Z]{5}\",\"a ghost\"))\n\n# a number but we only get the first\nprint(re.search(r\"[a-zA-Z]{5}\",\"a scary super ghost\"))\n\n<re.Match object; span=(2, 7), match='ghost'>\n<re.Match object; span=(2, 7), match='scary'>\n\n\n\nprint(re.findall(r\"[a-zA-Z]{5}\",\"a scary super ghost\"))\n\n# but if we give a longer word?\nprint(re.findall(r\"[a-zA-Z]{5}\",\"a scary superior ghost\"))\n\n# we get part of the superior word\n\n# to get just the words we want of 5 long can use \\b\nprint(re.findall(r\"\\b[a-zA-Z]{5}\\b\",\"a scary superior ghost\"))\n\n['scary', 'super', 'ghost']\n['scary', 'super', 'ghost']\n['scary', 'ghost']\n\n\n\n#between 2 and 4 exactly  full word\nprint(re.search(r\"\\b[a-zA-Z]{2,4}\\b\",\"a ab abc abcd abcde abcdef\"))\n\nprint(re.findall(r\"\\b[a-zA-Z]{2,4}\\b\",\"a ab abc abcd abcde abcdef\"))\n\n#NB \\b needed otherwise see below\nprint(re.findall(r\"[a-zA-Z]{2,4}\",\"a ab abc abcd abcde abcdef\"))\n\n# 2 and above full word\nprint(re.findall(r\"\\b[a-zA-Z]{2,}\\b\",\"a ab abc abcd abcde abcdef\"))\n\n# {,3} up to this many reps\nprint(re.findall(r\"\\b[a-zA-Z]{,3}\\b\",\"a ab abc abcd abcde abcdef\"))\n\n<re.Match object; span=(2, 4), match='ab'>\n['ab', 'abc', 'abcd']\n['ab', 'abc', 'abcd', 'abcd', 'abcd', 'ef']\n['ab', 'abc', 'abcd', 'abcde', 'abcdef']\n['a', '', 'ab', '', 'abc', '', '', '', '', '', '', '']"
  },
  {
    "objectID": "posts/2021-10-17-Regular-Expressions.html#capturing-groups",
    "href": "posts/2021-10-17-Regular-Expressions.html#capturing-groups",
    "title": "ThomasHSimm",
    "section": "Capturing groups",
    "text": "Capturing groups\n\n# start with letters number and underscores  \n# then comma and space\n# ends with letters number and underscores\n\ndef dogroups(regExpr,string):\n\n    result = re.search(regExpr,string)\n    \n    print(\"String is >> {},\\n regExpr is >> {},\\n result is >> {}\\n\".format(string, regExpr,result))\n\n    print(\"groups\",result.groups())\n    try:\n        print(\"result[0]\",result[0])\n    except:\n        print(\"no result 0\")\n    try:\n        print(\"result[1]\",result[1])\n    except:\n        print(\"no result 1\")\n    try:\n        print(\"result[2]\",result[2])\n    except:\n        print(\"no result 2\")\n             \n\n\nMatch normally, just get one result\n\ndogroups(r\"^\\w*, \\w*$\",\"Lovelace, Ada\") \n\nString is >> Lovelace, Ada,\n regExpr is >> ^\\w*, \\w*$,\n result is >> <re.Match object; span=(0, 13), match='Lovelace, Ada'>\n\ngroups ()\nresult[0] Lovelace, Ada\nno result 1\nno result 2\n\n\n\n\nUse brackets () to match multiple results\n\ndogroups(r\"(^\\w*), (\\w*$)\",\"Lovelace, Ada\") \n\nString is >> Lovelace, Ada,\n regExpr is >> (^\\w*), (\\w*$),\n result is >> <re.Match object; span=(0, 13), match='Lovelace, Ada'>\n\ngroups ('Lovelace', 'Ada')\nresult[0] Lovelace, Ada\nresult[1] Lovelace\nresult[2] Ada\n\n\n\nlog = \"July 31 07:51:48 mycomputer bad_process[12345]: ERROR Performing package upgrade\"\n# has [ followed by digits at least 1 followed by ]\nregex= r\"\\[(\\d+)\\]\"\nresult= re.search(regex,log)\nprint(\"result[0]= {}, result[1]={}\".format(result[0],result[1]))\nprint(\"result.group= {}, result.groups= {}\".format(result.group(),result.groups()))\n\n\nresult[0]= [12345], result[1]=12345\nresult.group= [12345], result.groups= ('12345',)\n\n\n\ndef extract_pid(log_line):\n    regex= r\"\\[(\\d+)\\]\"\n    result=re.search(regex,log_line)\n    if result is None:\n        return \"None\"\n    return result[1]\n\nprint(extract_pid(log))\nprint(extract_pid(\"[cat]  sass\"))\n\n12345\nNone\n\n\n\n\nre.sub\nthe general format is:\nre.sub(regular_expression_looking_for, what_to_replace_with,the_input_string)\n\n# (char num _) at least one + folowed by @ with char dot or dash at least one +\n\nprint(re.sub(r\"[\\w.%+-]+@[\\w.-]+\",\"[REDACTED]\",\"Received an email for go_nuts95@my.examle.com\"))\n\nReceived an email for [REDACTED]\n\n\n\nCombining with groups\nIf the regular expression has split the answer into groups (using ()) then can specify those parts using \\1 for first term \\2 for second term etc in the what to replace with part\nre.sub(regexp,r\"\\1 and \\2\",string)\nthe output is just the 1st and 2nd parts with “and” in the middle\n\ntexta = \"Lovelace, Ada\"\npatt = r\"^([\\w]*), ([\\w]*$)\"\nres=re.search(patt, texta)\nprint(res[0],res[1],res[2])\n\n     #this says sub with: result2 space result 1\nre.sub(patt, r\"\\2 \\1\",texta)\n\nLovelace, Ada Lovelace Ada\n\n\n'Ada Lovelace'"
  },
  {
    "objectID": "posts/2021-10-17-Regular-Expressions.html#some-examples",
    "href": "posts/2021-10-17-Regular-Expressions.html#some-examples",
    "title": "ThomasHSimm",
    "section": "Some Examples",
    "text": "Some Examples\n\nimport re\ndef repeating_letter_a(text):\n    #here we go A or a - followed by a-z or space- followed by a or A  \n    result = re.search(r\"(a|A)[a-z ]*(a|A)\", text)\n\n    return result != None\n\nprint(repeating_letter_a(\"banana\")) # True\nprint(repeating_letter_a(\"pineapple\")) # False\nprint(repeating_letter_a(\"Animal Kingdom\")) # True\nprint(repeating_letter_a(\"A is for apple\")) # True\n\n\n# Fill in the code to check if the text\n# passed has at least 2 groups of alphanumeric characters \n# (including letters, numbers, and underscores)\n# separated by one or more whitespace characters.\nimport re\ndef check_character_groups(text):\n  result = re.search(r\"\\w\\s\\w\", text)\n  return result != None\n\nprint(check_character_groups(\"One\")) # False\nprint(check_character_groups(\"123  Ready Set GO\")) # True\nprint(check_character_groups(\"username user_01\")) # True\nprint(check_character_groups(\"shopping_list: milk, bread, eggs.\")) # False\n\n\nimport re\ndef check_web_address(text):\n\n# starts with letters,numbers,underscores\n# followed by a dot then ends with letters,numbers,underscores\n    pattern = r\"\\w\\.\\w*$\"\n    result = re.search(pattern, text)\n    return result != None\n\nprint(check_web_address(\"gmail.com\")) # True\nprint(check_web_address(\"www@google\")) # False\nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False\nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\nimport re\ndef rearrange_name(name):\n    result = re.search(r\"^([\\w \\.-]*), ([\\w \\.-]*)$\", name)\n    if result == None:\n        \n        return name\n        \n    return \"{} {}\".format(result[2], result[1])\n\nname=rearrange_name(\"Kennedy, John F.\")\nprint(name)\n\nname=rearrange_name(\"Kennedy, John Franklin\")\nprint(name)\n\nJohn F. Kennedy\nJohn Franklin Kennedy\n\n\n\n#words of at least 7 chars\nimport re\ndef long_words(text):\n    #this says full words (\\b) with chars [A-Za-z] repeated 7 times or more {7,}\n    pattern = r\"\\b[A-Za-z]{7,}\\b\"\n    result = re.findall(pattern, text)\n    return result\n\nprint(long_words(\"I like to drink coffee in the morning.\")) # ['morning']\nprint(long_words(\"I also have a taste for hot chocolate in the afternoon.\")) # ['chocolate', 'afternoon']\nprint(long_words(\"I never drink tea late at night.\")) # []\n\n\n\n['morning']\n['chocolate', 'afternoon']\n[]\n\n\n\n# Add to the regular expression used in the extract_pid function, \n# to return the uppercase message in parenthesis, after the process id.\n\nimport re\ndef extract_pid(log_line):\n    regex = r\"\\[([0-9]*)\\]\"  #\n    result = re.search(regex, log_line)\n    if result is None:\n        return None\n    print(result)\n    return result[1]#\"{} ({})\".format(result[1],result[2])\n\nprint(extract_pid(\"July 31 07:51:48 mycomputer bad_process[12345]: ERROR Performing package upgrade\")) # 12345 (ERROR)\nprint(extract_pid(\"99 elephants in a [cage]\")) # None\nprint(extract_pid(\"A string that also has numbers [34567] but no uppercase message\")) # None\nprint(extract_pid(\"July 31 08:08:08 mycomputer new_process[67890]: RUNNING Performing backup\")) # 67890 (RUNNING)\n\n<re.Match object; span=(39, 46), match='[12345]'>\n12345\nNone\n<re.Match object; span=(31, 38), match='[34567]'>\n34567\n<re.Match object; span=(39, 46), match='[67890]'>\n67890\n\n\n\n# We want to split a piece of text by either the word \"a\" or \"the\", \n# as implemented in the following code. \n# What is the resulting split list?\n\nre.split(r\"the|a\", \"One sentence. Another one? And the last one!\")\n\n['One sentence. Ano', 'r one? And ', ' l', 'st one!']\n\n\n\nimport re\ndef transform_record(record):\n    pat = r\"(\\b[A-Za-z ]{2,}\\b),([0-9-]{2,}),(\\b[A-Za-z ]{2,}\\b)\"\n    new_record = re.sub(pat,r\"\\1,\\3 (+1-\\2)\",record)\n    \n    return new_record\n\n# Change the order to Name, Job, (Phone No.)\n\nprint(transform_record(\"Sabrina Green,802-867-5309,System Administrator\")) \n\nprint(transform_record(\"Eli Jones,684-3481127,IT specialist\")) \n\nprint(transform_record(\"Melody Daniels,846-687-7436,Programmer\")) \n\nprint(transform_record(\"Charlie Rivera,698-746-3357,Web Developer\")) \n\nSabrina Green,System Administrator (+1-802-867-5309)\nEli Jones,IT specialist (+1-684-3481127)\nMelody Daniels,Programmer (+1-846-687-7436)\nCharlie Rivera,Web Developer (+1-698-746-3357)\n\n\n\nimport re\ndef multi_vowel_words(text):\n  pattern = r\"[A-Za-z]*[aeiou]{3,}[a-z]*\"\n  result = re.findall(pattern, text)\n  return result\n\nprint(multi_vowel_words(\"Life is beautiful\")) \n# ['beautiful']\n\nprint(multi_vowel_words(\"Obviously, the queen is courageous and gracious.\")) \n# ['Obviously', 'queen', 'courageous', 'gracious']\n\nprint(multi_vowel_words(\"The rambunctious children had to sit quietly and await their delicious dinner.\")) \n# ['rambunctious', 'quietly', 'delicious']\n\nprint(multi_vowel_words(\"The order of a data queue is First In First Out (FIFO)\")) \n# ['queue']\n\nprint(multi_vowel_words(\"Hello world!\")) \n# []\n\n['beautiful']\n['Obviously', 'queen', 'courageous', 'gracious']\n['rambunctious', 'quietly', 'delicious']\n['queue']\n[]\n\n\n\nimport re\ndef transform_comments(line_of_code):\n    patt=r\"#{1,}\"\n    result = re.sub(patt,\"//\",line_of_code)\n    return result\n\nprint(transform_comments(\"### Start of program\")) \n# Should be \"// Start of program\"\nprint(transform_comments(\"  number = 0   ## Initialize the variable\")) \n# Should be \"  number = 0   // Initialize the variable\"\nprint(transform_comments(\"  number += 1   # Increment the variable\")) \n# Should be \"  number += 1   // Increment the variable\"\nprint(transform_comments(\"  return(number)\")) \n# Should be \"  return(number)\"\n\n// Start of program\n  number = 0   // Initialize the variable\n  number += 1   // Increment the variable\n  return(number)\n\n\n\nstring = \"My number is 21-345-9999.\"\n\npatt = r\"([0-9]{2}-)\"\nresa=re.findall(patt,phone)\n# result = re.sub(patt,r\"({0}),{1},{2}\".format(resa[0],resa[1],resa[2]),phone)\n\n\n# result\n\n\nimport re\ndef convert_phone_number(phone):\n  patt = r\"\\s([0-9]{1,})[-\\s]([0-9]{1,})[-]([0-9]{1,})\"\n    \n  result = re.sub(patt,r\" (\\1) \\2-\\3\",phone)\n  return result\n\nprint(convert_phone_number(\"My number is 212-345-9999.\")) # My number is (212) 345-9999.\nprint(convert_phone_number(\"Please call 888-555-1234\")) # Please call (888) 555-1234\nprint(convert_phone_number(\"123-123-12345\")) # 123-123-12345\nprint(convert_phone_number(\"Phone number of Buckingham Palace is +44 303 123 7300\")) # Phone number of Buckingham Palace is +44 303 123 7300\n\nMy number is (212) 345-9999.\nPlease call (888) 555-1234\n123-123-12345\nPhone number of Buckingham Palace is +44 303 123 7300"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#introduction-to-git-and-github",
    "href": "posts/2021-10-18-Git-and-Github.html#introduction-to-git-and-github",
    "title": "ThomasHSimm",
    "section": "Introduction to Git and GitHub",
    "text": "Introduction to Git and GitHub\nFrom the Coursera course within Google IT Automation with Python Professional Certificate https://www.coursera.org/learn/introduction-git-github/home/welcome"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#check-out-the-following-links-for-more-information",
    "href": "posts/2021-10-18-Git-and-Github.html#check-out-the-following-links-for-more-information",
    "title": "ThomasHSimm",
    "section": "Check out the following links for more information:",
    "text": "Check out the following links for more information:\nhttps://git-scm.com/doc\nhttps://en.wikipedia.org/wiki/Version_control\nThe Linux kernel documentation itself (https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/process/submitting-patches.rst?id=HEAD), as well as impassioned opinions from other developers. (http://stopwritingramblingcommitmessages.com/ https://robots.thoughtbot.com/5-useful-tips-for-a-better-commit-message)\nYou can check out “Setting your email in Git” (https://help.github.com/articles/setting-your-email-in-git/) and “Keeping your email address private” on the GitHub help site for how to do this. (https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-user-account/managing-email-preferences/setting-your-commit-email-address)\nRun in github bash\nGit is a distributed version control system.\nDistributed means that each developer has a copy of the whole repository on their local machine."
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#diff-find-the-difference-between-two-files",
    "href": "posts/2021-10-18-Git-and-Github.html#diff-find-the-difference-between-two-files",
    "title": "ThomasHSimm",
    "section": "diff find the difference between two files",
    "text": "diff find the difference between two files\ndiff\nhttps://man7.org/linux/man-pages/man1/diff.1.html\ndiff is used to find differences between two files. On its own, it’s a bit hard to use; instead, use it with diff -u to find lines which differ in two files: diff -u\ndiff -u is used to compare two files, line by line, and have the differing lines compared side-by-side in the same output. See below:\n\n>>diff test.py test2.py\n\n\noutput\n\n3c3\n< c=a**b\n---\n> c=a**b+a\n4a5\n> d=c**c\n\n3c3\nline in file 1 - c=change - line in file 2 a=added\n\n>>diff -u test.py test2.py\n\n#output\n\n--- test.py     2021-10-17 11:14:24.880950400 +0100\n+++ test2.py    2021-10-17 11:14:21.155278200 +0100\n@@ -1,4 +1,5 @@\n a=3\n b=2\n-c=a**b\n+c=a**b+a\n print(c)\n+d=c**c\n\nadding -u gives extra context to changes"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#applying-changes",
    "href": "posts/2021-10-18-Git-and-Github.html#applying-changes",
    "title": "ThomasHSimm",
    "section": "applying changes",
    "text": "applying changes\n\nCreate a file with the changes in\n\n>>diff -u test.py test2.py >change.diff\n\n\n\npatch\nhttp://man7.org/linux/man-pages/man1/patch.1.html\n\n>>patch test-Copy1.py < change.diff\n\nthis applies changes in change.diff to test-Copy1.diff"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#vcs-version-control-system",
    "href": "posts/2021-10-18-Git-and-Github.html#vcs-version-control-system",
    "title": "ThomasHSimm",
    "section": "VCS version control system",
    "text": "VCS version control system\nBy keeping track of the changes that we make to our files, a VCS lets us know when a file changed, who changed it, and also lets us easily roll back those changes."
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#git-config",
    "href": "posts/2021-10-18-Git-and-Github.html#git-config",
    "title": "ThomasHSimm",
    "section": "git config",
    "text": "git config\n\n>>git config --global user.email \"me@example.com\" \n>>git config --global user.name \"My name\" \n\nset email and name\n–global means for all repositories\n\n# Find details of configuration\n>>git config -l"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#create-a-new-repository",
    "href": "posts/2021-10-18-Git-and-Github.html#create-a-new-repository",
    "title": "ThomasHSimm",
    "section": "create a new repository",
    "text": "create a new repository\n\n>>mkdir testa\n>>cd testa\n>>git init \n\ndetals of the created directory\n\n>>ls -l .git\n\n#output->>\n-rw-r--r-- 1 44781 197609  23 Oct 17 12:06 HEAD\n-rw-r--r-- 1 44781 197609 130 Oct 17 12:06 config\n-rw-r--r-- 1 44781 197609  73 Oct 17 12:06 description\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 hooks/\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 info/\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 objects/\ndrwxr-xr-x 1 44781 197609   0 Oct 17 12:06 refs/\n\nThe git directory acts as a database for all the changes tracked in Git and the working tree acts as a sandbox where we can edit the current versions of the files."
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#add-a-file-to-the-directory-and-get-it-tracked",
    "href": "posts/2021-10-18-Git-and-Github.html#add-a-file-to-the-directory-and-get-it-tracked",
    "title": "ThomasHSimm",
    "section": "add a file to the directory and get it tracked",
    "text": "add a file to the directory and get it tracked\n\n>>cp ../test.py . \n#note the dot at end to say copy to this directory\n>>git add test.py\n\nThe file is now in the staging area or index\ncontains all info about what files and changes are in the next commit\n\n>>git add -p\n\nthis would all tracked and shows differences and asks if want to make the add"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#get-the-status",
    "href": "posts/2021-10-18-Git-and-Github.html#get-the-status",
    "title": "ThomasHSimm",
    "section": "get the status",
    "text": "get the status\n\n>>git status\n\nOn branch master\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached <file>...\" to unstage)\n        new file:   test.py\n\ntest.py ready to be committed"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#make-a-commit",
    "href": "posts/2021-10-18-Git-and-Github.html#make-a-commit",
    "title": "ThomasHSimm",
    "section": "Make a commit",
    "text": "Make a commit\n\n>>git commit\n\n# Please enter the commit message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n#\n# On branch master\n#\n# Initial commit\n#\n# Changes to be committed:\n#       new file:   test.py\n#\n~\n~\n~\n~\n~\n~\n~\n~\n~\n~\n~\n\nthis opens up an editor with text as shown\nEnter details of the commit\nTo exit and save: Type the description at the very top, press esc to exit insert mode, then type :x! (now the cursor is at the bottom) and hit enter to save and exit\nAlternatively add -m command with details of commit\ngit commit -m ‘Changed print to include some text’\n\nTracked files\n\nModified\n\nmade changes but not committed yet\n\nStaged\n\nin staging area\ngit add\n\nCommitted\n\nin git directory\ngit commit\n\n\n\n\nCommit messages\nBrief description\nMore indepth details\nMore indepth\n(remember to add new lines)"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#git-log",
    "href": "posts/2021-10-18-Git-and-Github.html#git-log",
    "title": "ThomasHSimm",
    "section": "Git log",
    "text": "Git log\n\n>>git log\ncommit 05958854b7ad68f8b1a178f260dccd844aec0e16 (HEAD -> master)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 13:04:10 2021 +0100\n\n    added python start line\n\ncommit 917a027f6282ce1c2c01e00a48bb72995e3984a6\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 12:56:41 2021 +0100\n\n    Changed print to include some text\n\ncommit 7e32e328db17594fd0a507b4a23f489b68c09543\nAuthor: thomashsimm <thomas  @gmail.com>\nDate:   Sun Oct 17 12:38:02 2021 +0100\n\n    Add new file test.py"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#skipping-the-staging-area",
    "href": "posts/2021-10-18-Git-and-Github.html#skipping-the-staging-area",
    "title": "ThomasHSimm",
    "section": "Skipping the Staging Area",
    "text": "Skipping the Staging Area\n\n>>git commit -a\n\nor\n>>git commit -a -m \"Added a new output\"\n\na shortcut to stage any changes to tracked files and commit them in one step"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#getting-more-information-about-our-changes",
    "href": "posts/2021-10-18-Git-and-Github.html#getting-more-information-about-our-changes",
    "title": "ThomasHSimm",
    "section": "Getting more information about our changes",
    "text": "Getting more information about our changes\n\n>>git log -p\n\nEquivalent to diff -u (describe above)\nto get more info on a particular commit\n\n>>git show 7e32e328db17594fd0a507b4a23f489b68c09543\n\nSome stats of repo\n\n>>git log --stat\n\nchanges in file, relative to repo/staging area\n\n>>git diff"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#deleting-and-renaming-files",
    "href": "posts/2021-10-18-Git-and-Github.html#deleting-and-renaming-files",
    "title": "ThomasHSimm",
    "section": "Deleting and Renaming Files",
    "text": "Deleting and Renaming Files\n\n>>git rm test.py\n\nremoves the file test.py\n\n>>git commit -m \"Deleted test.py\"\n\ncommit the change/deletion of the file\n\n>>git mv test2.py test.py \n\nrename a file\nN.B. git mv can also be used for moving files\n\n>>echo .DS_STORE > .gitignore\n#create .gitignore file to ignore .DS_STORE files (OS sys)\n>>ls -la\n#view hidden files\n>>git add .gitignore\n#add file\n>>git commit -m \"added a gitignore file\"\n#commit changes"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#gitignore-files",
    "href": "posts/2021-10-18-Git-and-Github.html#gitignore-files",
    "title": "ThomasHSimm",
    "section": ".gitignore files",
    "text": ".gitignore files\n.gitignore files are used to tell the git tool to intentionally ignore some files in a given Git repository. For example, this can be useful for configuration files or metadata files that a user may not want to check into the master branch. Check out more at: https://git-scm.com/docs/gitignore.\nA few common examples of file patterns to exclude can be found here https://gist.github.com/octocat/9257657."
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#undoing-changes",
    "href": "posts/2021-10-18-Git-and-Github.html#undoing-changes",
    "title": "ThomasHSimm",
    "section": "Undoing changes",
    "text": "Undoing changes\n\nUndoing unstaged changes\n\n>>git restore test.py\n\n“git restore …” to discard changes in working directory\nThis comes up as an option to do when go git status\nSame as git checkout\nThis takes the file from the directory and changes the one in the working tree to match this\n\n\nUndoing staged changes\nSay we’ve added all files in a directory\ngit add *\nWhen we run git status we reaslise it includes a file we don’t want to add\nTo remove the add we do:\n\n>>git restore --staged newfile.txt\n\nor\n>>git reset HEAD newfile.txt"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#amending-commits",
    "href": "posts/2021-10-18-Git-and-Github.html#amending-commits",
    "title": "ThomasHSimm",
    "section": "Amending commits",
    "text": "Amending commits\n\n>git commit --amend\n\nThis allows us to ammend the last commit\nSo for example we could add some more files to it and then modify the comments on the commit\nThen overwrites the previous commit\n\nOnly use for: local changes\n\n\nAmend Commits are not for commits that have been made public"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#rollbacks",
    "href": "posts/2021-10-18-Git-and-Github.html#rollbacks",
    "title": "ThomasHSimm",
    "section": "Rollbacks",
    "text": "Rollbacks\nRevert to an earlier commit\nWith git revert, a new commit is created with inverse changes. This cancels previous changes instead of making it as though the original commit never happened.\n\n>>git revert HEAD\n\nAdd description of why doing rollback\nRecall press esc to exit insert mode, then type :x! (now the cursor is at the bottom) and hit enter to save and exit"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#identifying-a-commit",
    "href": "posts/2021-10-18-Git-and-Github.html#identifying-a-commit",
    "title": "ThomasHSimm",
    "section": "Identifying a commit",
    "text": "Identifying a commit\nSHA1 hash numbers that Git uses to identify commits - They provide the consistency that is critical for distributed systems such as Git.\n\nThey are created using the commit message, date, author, and the snapshot taken of the working tree.\nThey are composed of 40 characters.\n\n\n>>git show\n\n# pick one of the commits\n\n>>git show 34051fe65ab25ae011b0473fd1707e6e84f89b71\n\n# And if we wanted to revert to this\n\n>>git revert 34051fe65ab25ae011b0473fd1707e6e84f89b71\n\n# this would also work if id is unique in repo\n>> git revert 34051f"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#git-revert-cheat-sheet",
    "href": "posts/2021-10-18-Git-and-Github.html#git-revert-cheat-sheet",
    "title": "ThomasHSimm",
    "section": "Git Revert Cheat Sheet",
    "text": "Git Revert Cheat Sheet\n\ngit checkout is effectively used to switch branches. https://git-scm.com/docs/git-checkout\ngit reset basically resets the repo, throwing away some changes. It’s somewhat difficult to understand, so reading the examples in the documentation may be a bit more useful. https://git-scm.com/docs/git-reset#_examples\nThere are some other useful articles online, which discuss more aggressive approaches to resetting the repo. https://jwiegley.github.io/git-from-the-bottom-up/3-Reset/4-doing-a-hard-reset.html\ngit commit –amend is used to make changes to commits after-the-fact, which can be useful for making notes about a given commit. https://git-scm.com/docs/git-commit#Documentation/git-commit.txt—amend\ngit revert makes a new commit which effectively rolls back a previous commit. It’s a bit like an undo command. https://git-scm.com/docs/git-revert\nThere are a few ways you can rollback commits in Git. https://git-scm.com/book/en/v2/Git-Basics-Undoing-Things\nThere are some interesting considerations about how git object data is stored, such as the usage of sha-1.\n\nFeel free to read more here:\n\nhttps://en.wikipedia.org/wiki/SHA-1\nhttps://github.blog/2017-03-20-sha-1-collision-detection-on-github-com/"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#git-branch",
    "href": "posts/2021-10-18-Git-and-Github.html#git-branch",
    "title": "ThomasHSimm",
    "section": "Git Branch",
    "text": "Git Branch\n\na pointer to a particular commit\nit represents an independent line of development in a project\nthe default branch that git creates for you when initialised is called master (sometimes main)\nTo do something new or experimenting try adding a new branch\nNew branches enable changes to be worked on without disrupting the most current working state\n\n\nList all branches in a repo\n\n>>git branch\n* master\n\njust the one at the moment the master\n\n\nAdd a new branch\n\n>>git branch tryThis\n>>git branch\n* master\n  tryThis\n\nthe * indicates the branch we are in\n\n\nSwitch to different branch\nwe use git checkout to check out the latest snapshot for both files and for branches.\n\n>>git checkout tryThis\nSwitched to branch 'tryThis'\n>>git branch\n  master\n* tryThis\n\n\n\nAdd and switch branches\n\n>>git checkout -b orThis\nSwitched to a new branch 'orThis'\n>>git branch\n  master\n* orThis\n  tryThis\n\n\n# look at last two commits\n>> git log -2\ncommit 9204f0f890143d81c8fc3fa5db839be5f65e63e9 (HEAD -> orThis)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 18:25:06 2021 +0100\n\n    add an empty file\n\ncommit 34051fe65ab25ae011b0473fd1707e6e84f89b71 (tryThis, master)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 15:36:19 2021 +0100\n\n    Revert \"Revert \"added a gitignore file\"\"\n\n    This reverts commit dc28347e0177c298e9b527ab8140973fb3a567ba.\n\nWe see the last two commits in this branch. Notice how next to the latest commit ID, git shows that this is where head is pointing to and that the branch is called orThis.\nNext to the previous commit,git shows that both the master and the trThis branches are pointing to that snapshot of the project.\nIn this way, we can see that the orThis branch is ahead of the master branch.\n\n>>nano gogo2.py\n#creates file gogo2.py\n>>git add *\n>>git commit -m \"gogo2.py file added to orThis\"\n>>ls -l\ntotal 2\n-rw-r--r-- 1 44781 197609  9 Oct 17 18:56 gogo2.py\n-rw-r--r-- 1 44781 197609 38 Oct 17 14:51 test.py\n\n#go back to master\n>>git checkout master\ntotal 3\n-rw-r--r-- 1 44781 197609  7 Oct 17 18:59 go.py\n-rw-r--r-- 1 44781 197609 16 Oct 17 18:59 gogo.py\n-rw-r--r-- 1 44781 197609 38 Oct 17 14:51 test.py\n\n#gogo2.py is not here!\n\n\n\nDelete branch\n\n>>git branch -d tryThis\nerror: The branch 'tryThis' is not fully merged.\nIf you are sure you want to delete it, run 'git branch -D tryThis'.\n\n>>git branch -D tryThis\nDeleted branch tryThis (was 59ec266).\n\n>>git branch\n* master\n  orThis"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#merging-branches",
    "href": "posts/2021-10-18-Git-and-Github.html#merging-branches",
    "title": "ThomasHSimm",
    "section": "Merging branches",
    "text": "Merging branches\nMerging is the term that Git uses for combining branch data and history together.\n\n#make sure in master\n>>git branch\n* master\n  orThis\n#then merge orThis\n>>git merge orThis\nUpdating da04c1c..4eb59cb\nFast-forward\n go2.py | 4 ++++\n 1 file changed, 4 insertions(+)\n create mode 100644 go2.py\n\n\n>>git log\ncommit 4eb59cb2dca6a09fb59477fcdf4595551ff9f85f (HEAD -> master, branch2)\nAuthor: thomashsimm <thomas @gmail.com>\nDate:   Sun Oct 17 19:17:28 2021 +0100\n\nBoth branches are pointed at the same commit -> (HEAD -> master, branch2)\n\nMerge conflict\nFrom time to time, we might find that both the branches we’re trying to merge have edits to the same part of the same file.\nThis will result in something called a merge conflict.\nNormally, Git can automatically merge files for us. But when we have a merge conflict, it will need a little help to figure out what to do.\n\n#amend same file in master and a new branch- branch2\n>>git merge branch2\nAuto-merging go.py\nCONFLICT (content): Merge conflict in go.py\nAutomatic merge failed; fix conflicts and then commit the result.\n\n#error message produced\n\n\n>>git status\nOn branch master\nYou have unmerged paths.\n  (fix conflicts and run \"git commit\")\n  (use \"git merge --abort\" to abort the merge)\n\nUnmerged paths:\n  (use \"git add <file>...\" to mark resolution)\n        both modified:   go.py\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n        .gogo.py.swp\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nTo try to resolve this we open up the file in editor\n\n>>nano go.py\n\n####in editor>>\n\nb=3\n<<<<<<< HEAD\n#hello\n\n=======\n#comment here too\n>>>>>>> branch2\n\n\n####which we change to this to keep both mods>>\n\nb=3\n#hello\n#comment here too\n\n\nThen add the file and check the status\n\n>>git add go.py\n>>git status\nOn branch master\nAll conflicts fixed but you are still merging.\n  (use \"git commit\" to conclude merge)\n\nChanges to be committed:\n        modified:   go.py\n>>git commit \n[master b7e6929] Merge branch 'branch2' Kept both features\n\nSyntaxError: invalid syntax (<ipython-input-2-5de9e5fcd226>, line 1)\n\n\nConflicts now gone\nAnd committed\n–graph –oneline ==>> helps us visualise the merge\n\n>>git log --graph --oneline\n\n\n\nAbort merge\n\n>>git merge --abort"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#git-branches-and-merging-cheat-sheet",
    "href": "posts/2021-10-18-Git-and-Github.html#git-branches-and-merging-cheat-sheet",
    "title": "ThomasHSimm",
    "section": "Git Branches and Merging Cheat Sheet",
    "text": "Git Branches and Merging Cheat Sheet\ngit branch Used to manage branches https://git-scm.com/docs/git-branch\ngit branch [branchname]  Creates the branch https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging\ngit branch -d [branchname] Deletes the branch https://git-scm.com/docs/git-branch#Documentation/git-branch.txt–D\ngit branch -D [branchname]  Forcibly deletes the branch https://git-scm.com/docs/git-branch#Documentation/git-branch.txt–D\ngit checkout [branchname]  Switches to a branch. https://git-scm.com/docs/git-checkout\ngit checkout -b [branchname] Creates a new branch and switches to it. https://git-scm.com/docs/git-checkout#Documentation/git-checkout.txt–bltnewbranchgt\ngit merge [branchname]  Merge joins branches together. https://git-scm.com/docs/git-merge\ngit merge –abort If there are merge conflicts (meaning files are incompatible), –abort can be used to abort the merge action.\ngit log –graph –onelineThis shows a summarized view of the commit history for a repo. https://git-scm.com/book/en/v2/Git-Basics-Viewing-the-Commit-History"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#working-with-remotes",
    "href": "posts/2021-10-18-Git-and-Github.html#working-with-remotes",
    "title": "ThomasHSimm",
    "section": "Working with remotes",
    "text": "Working with remotes\nGitHub is a web-based Git repository hosting service.\nOn top of the version control functionality of Git, GitHub includes extra features like bug tracking, wikis, and task management.\nGitHub lets us share and access repositories on the web and copy or clone them to our local computer, so we can work on them.\nGitHub is a popular choice with a robust feature set, but it’s not the only one. Other services that provide similar functionality are BitBucket, and GitLab.\n\n\n\nhtpps://github.com\n\n\nGitHub provides free access to a Git server for public and private repositories.\nIt limits the number of contributors for the free private repositories, and offers an unlimited private repository service for a monthly fee. We’ll be using a free repository for our examples, which is fine for educational use, small personal projects, or open source development.\n\nClone a directory\nThis is to create a local copy of a repository from the github website\n\nGo to the repo\nClick code and copy the clone URL HTTPS\n\n\nother options are availabe too\n\n\n\nIn Git bash run\n\ngit clone https://github.com/ThomasHSimm/SwanseaProperty.git\nFill in any passwords if required\n\n# Make changes to files\n\n#Then add and commit the changes\n>>git commit -a -m \"Modified the readme\"\n[main c9307f7] modified read me\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#git-push",
    "href": "posts/2021-10-18-Git-and-Github.html#git-push",
    "title": "ThomasHSimm",
    "section": "Git Push",
    "text": "Git Push\nSend the changes to the remote repository\n\n>>git push\nEnumerating objects: 5, done.\nCounting objects: 100% (5/5), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 309 bytes | 309.00 KiB/s, done.\nTotal 3 (delta 2), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/ThomasHSimm/SwanseaProperty.git\n   08aa0a2..c9307f7  main -> main"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#basic-interaction-with-github-cheat-sheet",
    "href": "posts/2021-10-18-Git-and-Github.html#basic-interaction-with-github-cheat-sheet",
    "title": "ThomasHSimm",
    "section": "Basic Interaction with GitHub Cheat-Sheet",
    "text": "Basic Interaction with GitHub Cheat-Sheet\nThere are various remote repository hosting sites:\n- GitHub\n\n- BitBucket\n\n- Gitlab.\nFollow the workflow at https://github.com/join to set up a free account, username, and password. After that, these steps (https://help.github.com/articles/create-a-repo/) will help you create a brand new repository on GitHub.\nSome useful commands for getting started:\n\ngit clone URL\nGit clone is used to clone a remote repository into a local workspace https://git-scm.com/docs/git-clone\n\n\ngit push\nGit push is used to push commits from your local repo to a remote repo https://git-scm.com/docs/git-push\n\n\ngit pull\nGit pull is used to fetch the newest updates from a remote repository https://git-scm.com/docs/git-pull\n\n\nThese can be useful for keeping your local workspace up to date.\n\nhttps://help.github.com/en/articles/caching-your-github-password-in-git\nhttps://help.github.com/en/articles/generating-an-ssh-key"
  },
  {
    "objectID": "posts/2021-10-18-Git-and-Github.html#fetching-new-changes",
    "href": "posts/2021-10-18-Git-and-Github.html#fetching-new-changes",
    "title": "ThomasHSimm",
    "section": "Fetching new changes",
    "text": "Fetching new changes\n\n>>git fetch\n\nThis copies changes done in remote repo to local repo\nBut unlike git pull doesn’t instantly merge changes\n\ngit pull = fetch and merge\ngit fetch = just fetches\n\nCan merge like this\n\n>>git merge orgin/master\n\nOr just do both with pull\nAs long as there are no conflicts, Git will move the current branch tip up to the target branch tip and combine histories of both commits. Using a fast-forward merge\n\n>>git pull\n\nTo create a local branch for a remote branch we don’t have yet run git checkout BRANCH_NAME\ngit remote update will fetch the contents of all remote branches and allow us to merge the contents ourselves."
  },
  {
    "objectID": "posts/2021-10-24-Data-Viz.html",
    "href": "posts/2021-10-24-Data-Viz.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "Data Viz\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: Thomas H. Simm\ncategories: [data viz, posters, data science, Thomas Simm]\n\n\nSome data visualizations from my work in metallurgy. Most of my work was line plots so tried to keep these to a minimum here.\n\nEBSD\n\nElectron backscatter diffraction (EBSD) is a scanning electron microscope–based microstructural-crystallographic characterization technique commonly used in the study of crystalline or polycrystalline materials.[1][2] The technique can provide information about the structure,[3] crystal orientation ,[3]phase,[3] or strain[4] in the material.\n[1] Randle, Valerie; Engler, Olaf (2000). Introduction to texture analysis: macrotexture, microtexture and orientation mapping (Digital printing 2003 ed.). Boca Raton: CRC Press. ISBN 978-9056992248.\n[2] Schwartz, A. J.; Kumar, M.; Adams, B. L.; Field, D. P. (2000). Electron backscatter diffraction in materials science. New York: Kluwer Academic.\n[3] Electron backscatter diffraction in materials science (2nd ed.). Springer Science+Business Media. 2009. p. 1. ISBN 978-0-387-88135-5.\n[4] Wright, Stuart I.; Matthew, M. Nowell; David, P. Field. (2011). “A review of strain analysis using electron backscatter diffraction”. Microscopy and Microanalysis. 17. 17 (3): 316–329. Bibcode:2011MiMic..17..316W. doi:10.1017/S1431927611000055. PMID 21418731.\nFrom: https://en.wikipedia.org/wiki/Electron_backscatter_diffraction\n\nA matenistic steel showing prior austenite grains. The top image has undergone an additional rolling regime resulting in smaller grain size.\nThis is your classic EBSD orientation map with a twist in that the orientations are predicted. The colours represent different orientations given by the legend on the left- they are a vector [phi1,Phi,phi2] (MTEX) with each spatial point having it’s own vector. The colours are reconstructed using ARPGE to give a prediction on what the grains would be prior to cooling, based on the rotation matrix between adjacent elements. There are two problems here, defining the orientation relationships (or rotations) between neighbours and reconstructing grains. In the next case we can ignore the first.\n Paper: The Influence of Lath, Block and Prior Austenite Grain (PAG) Size on the Tensile, Creep and Fatigue Properties of Novel Maraging Steel \n An austenitic stainless steel that transforms to martensite under load. This is similar to the above example, but easier to solve as we only need to look at the rotation across one boundary at a time. In the top figure the coloured regions represent a different phase (martensite) with austenite grains and the particular colour what the orientation relationship (OR) is. The lines show the slip systems and the maximum Schmid factor. Basically, some OR are preferred, the direction of the martensite relates to the particular OR and the Schmid factors.\n Paper: In situ observation of strain and phase transformation in plastically deformed 301 austenitic stainless steel \n The change in various EBSD maps of an austenitic stainless steel (see above) before and after being pulled to 10% strain. See also the image below. Each set of maps (on horizontal axis and below) give a different measure of plastic deformation. But if we look closely we can see some areas with high values of one parameter can have low values of another. Even if we average over a grain it can be difficult to predict behaviour. These observations illustrate aspects of plastic deformation such as the chaotic nature and the none unique definition of plastic deformation.\n Paper: The τ-plot, a multicomponent 1-D pole figure plot, to quantify the heterogeneity of plastic deformation \n This is a localised strain map of the sample shown above but a slightly bigger region. This is produced by digital image correlation (DIC) by comparing two surface images. The data is then combined with the EBSD data allowing us to visualise the grain boundaries (black lines).\n So how do we take account of orientation differences in grains (they matter) AND the chaotic nature of deformation and differences in parameters?  \n We do some averageing \n This is a classic plot in metallurgy called the inverse pole figure (IPF) plot. Simply put each point on the triangle represents a different group of orientations. We are averageing based on an orientation criteria. In the top figures are two models that relate to plastic deformation (Schmid factor left and Taylor model right) plotted on to this IPF plot. The bottom two figures represent experimental data of a ‘Damage parameter’ (number of un-indexed points on boundary) of grains after creep deformation of an austenitic stainless steel. Clearly (hopefully), we can see a transition from type with increasing stress and overall plastic deformation. {Some adjustments could be done on the algorithm to create the plots but the main points remain}\n\nIn a similar manner we can average details of a sample based on orientation in a different manner, as shown here. The reason for this averaging is so we can combine EBSD with powder diffraction (X-ray and neutron). Powder diffraction provides useful insights on some parameters connected to EBSD such as texture, plastic deformation and phases. Furthermore, the information can be from larger volumes of the sample (and not just the surface) than EBSD. However, the way it is measured means we have to modify how we combine the data.\nIn the figure crystal plasticity models are compared with experimental data for EBSD and powder diffraction on the same axis.\n Paper: The τ-plot, a multicomponent 1-D pole figure plot, to quantify the heterogeneity of plastic deformation \n\nAPT\n\nThe atom probe was introduced at the 14th Field Emission Symposium in 1967 by Erwin Wilhelm Müller and J. A. Panitz. It combined a field ion microscope with a mass spectrometer having a single particle detection capability and, for the first time, an instrument could “… determine the nature of one single atom seen on a metal surface and selected from neighboring atoms at the discretion of the observer”.[1]\nhttps://en.wikipedia.org/wiki/Atom_probe\n The image is an APT tip (a 3D cylinder type shape) showing iso-surfaces for two different elements (i.e. inside these surfaces the composition of an element {Ni and Mo here} is higher than a set value). This image is typical of APT analysis and produced from a designated software package.\n This transforms data similar to shown above, first the APT data was cut into slices- this makes it easier to visualize the density and details and compares better with other techniques such as TEM. Secondly, I adjusted colours and contrast to improve the visual feel.\n The above maps are pretty but very qualitative. Some extra details can be found by extracting details from the data as shown here.\n\nPosters"
  },
  {
    "objectID": "posts/2021-10-28-Data-Science.html#general-data-science",
    "href": "posts/2021-10-28-Data-Science.html#general-data-science",
    "title": "ThomasHSimm",
    "section": "General Data Science",
    "text": "General Data Science\n\n IBM Data Science Professional Certificate\n Google Data Analytics Professional Certificate\n Google IT Automation with Python Professional Certificate\n Learn SQL Basics for Data Science Specialization\n learnpython.org Python Development Course\n Excel/VBA for Creative Problem Solving\nAWS Cloud Technical Essentials"
  },
  {
    "objectID": "posts/2021-10-28-Data-Science.html#machine-learning",
    "href": "posts/2021-10-28-Data-Science.html#machine-learning",
    "title": "ThomasHSimm",
    "section": "Machine Learning",
    "text": "Machine Learning\n\n Fast AI\nIBM AI Engineering Professional Certificate\n Machine Learning Stanford\n Deep Learning Specialization\n TensorFlow Developer Professional Certificate\n TensorFlow: Advanced Techniques Specialization\n TensorFlow 2 for Deep Learning Specialization\n\n\nGeneral Data Science\n\n\nIBM Data Science Professional Certificate\n\nhttps://www.coursera.org/professional-certificates/ibm-data-science\n\nAbout this Professional Certificate\n590,718 recent views\nData science is one of the hottest professions of the decade, and the demand for data scientists who can analyze data and communicate results to inform data driven decisions has never been greater. This Professional Certificate from IBM will help anyone interested in pursuing a career in data science or machine learning develop career-relevant skills and experience.\nIt’s a myth that to become a data scientist you need a Ph.D. Anyone with a passion for learning can take this Professional Certificate – no prior knowledge of computer science or programming languages required – and develop the skills, tools, and portfolio to have a competitive edge in the job market as an entry level data scientist.\nThe program consists of 9 online courses that will provide you with the latest job-ready tools and skills, including open source tools and libraries, Python, databases, SQL, data visualization, data analysis, statistical analysis, predictive modeling, and machine learning algorithms. You’ll learn data science through hands-on practice in the IBM Cloud using real data science tools and real-world data sets.\nUpon successfully completing these courses, you will have built a portfolio of data science projects to provide you with the confidence to plunge into an exciting profession in data science.\nIn addition to earning a Professional Certificate from Coursera, you’ll also receive a digital badge from IBM recognizing your proficiency in data science.\n\n\nApplied Learning Project\nThis Professional Certificate has a strong emphasis on applied learning. Except for the first course, all other courses include a series of hands-on labs in the IBM Cloud that will give you practical skills with applicability to real jobs, including:\nTools: Jupyter / JupyterLab, GitHub, R Studio, and Watson Studio\nLibraries: Pandas, NumPy, Matplotlib, Seaborn, Folium, ipython-sql, Scikit-learn, ScipPy, etc.\nProjects: random album generator, predict housing prices, best classifier model, Predicting successful rocket landing, dashboa rd and interactive map \n\nimport pandas as pd\nimport numpy as np\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)']\n#IBMds = pd.DataFrame(columns=columns)\n\ndat = [['What is Data Science?',9,6],\n    ['Tools for Data Science',17,6],\n    ['Data Science Methodology',8,6],\n    ['Python for Data Science, AI & Development',17,6],\n    ['Python Project for Data Science',6,6],\n    ['Databases and SQL for Data Science with Python',18,6],\n    ['Data Analysis with Python',20,6],\n    ['Data Visualization with Python',13,6],\n    ['Machine Learning with Python',21,6],\n    ['Applied Data Science Capstone',47,6]]\n\nss = pd.DataFrame(data = dat,columns=columns)\n\nssTot=pd.DataFrame(data = [['IBM Data- Overview',ss['Expected Time (h)'].sum(),ss['Rating (0-10)'].mean()]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(12)\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n    \n  \n  \n    \n      0\n      IBM Data- Overview\n      176\n      6.0\n    \n    \n      1\n      What is Data Science?\n      9\n      6.0\n    \n    \n      2\n      Tools for Data Science\n      17\n      6.0\n    \n    \n      3\n      Data Science Methodology\n      8\n      6.0\n    \n    \n      4\n      Python for Data Science, AI & Development\n      17\n      6.0\n    \n    \n      5\n      Python Project for Data Science\n      6\n      6.0\n    \n    \n      6\n      Databases and SQL for Data Science with Python\n      18\n      6.0\n    \n    \n      7\n      Data Analysis with Python\n      20\n      6.0\n    \n    \n      8\n      Data Visualization with Python\n      13\n      6.0\n    \n    \n      9\n      Machine Learning with Python\n      21\n      6.0\n    \n    \n      10\n      Applied Data Science Capstone\n      47\n      6.0\n    \n  \n\n\n\n\n\nGoogle Data Analytics Professional Certificate\n\nhttps://www.coursera.org/professional-certificates/google-data-analytics\n\n\nAbout this Professional Certificate\n2,827,984 recent views\nPrepare for a new career in the high-growth field of data analytics, no experience or degree required. Get professional training designed by Google and have the opportunity to connect with top employers. There are 380,000 U.S. job openings in data analytics with a $74,000 median entry-level salary.¹\nData analytics is the collection, transformation, and organization of data in order to draw conclusions, make predictions, and drive informed decision making.\nOver 8 courses, gain in-demand skills that prepare you for an entry-level job. You’ll learn from Google employees whose foundations in data analytics served as launchpads for their own careers. At under 10 hours per week, you can complete the certificate in less than 6 months.\nYou’ll prepare yourself for jobs that include junior or associate data analyst, database administrator, and more. Upon completion of the certificate, you can directly apply for jobs with Google and over 150 U.S. employers, including Walmart, Best Buy, Astreya.\n75% of Google Career Certificate Graduates in the United States report an improvement in their career trajectory (e.g. new job or career, promotion or raise) within 6 months of certificate completion²\n¹US Burning Glass Labor Insight Report salary data (median with 0-5 years experience) and job opening data. Data for job roles relevant to featured programs (4/01/2021 - 3/31/22).\n²Based on program graduate survey responses, United States 2021\n\n\nApplied Learning Project\nThis program includes over 180 hours of instruction and hundreds of practice-based assessments, which will help you simulate real-world data analytics scenarios that are critical for success in the workplace. The content is highly interactive and exclusively developed by Google employees with decades of experience in data analytics. Through a mix of videos, assessments, and hands-on labs, you’ll get introduced to analysis tools and platforms and key analytical skills required for an entry-level job.\nSkills you’ll gain will include: Data cleaning, problem solving, critical thinking, data ethics, and data visualization\nPlatforms and tools you will learn include: Presentations, Spreadsheets, SQL, Tableau and R Programming\nIn addition to expert training and hands-on projects, you’ll complete a case study that you can share with potential employers to showcase your new skill set. Learn concrete skills that top employers are hiring for right now.\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)']\nGoogleds = pd.DataFrame(columns=columns)\n\ndat = [['Foundations: Data, Data, Everywhere',20,3],\n    ['Ask Questions to Make Data-Driven Decisions',18,3],\n    ['Prepare Data for Exploration',22,3],\n    ['Process Data from Dirty to Clean',22,3],\n    ['Analyze Data to Answer Questions',25,3],\n    ['Share Data Through the Art of Visualization', 23,3],\n    [ 'Data Analysis with R Programming',38,3],\n    [ 'Google Data Analytics Capstone: Complete a Case Study',10,3] ]\nss = pd.DataFrame(data = dat,columns=columns)\n\nssTot=pd.DataFrame(data = [['Google Data- Overview',ss['Expected Time (h)'].sum(),ss['Rating (0-10)'].mean()]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n    \n  \n  \n    \n      0\n      Google Data- Overview\n      178\n      3.0\n    \n    \n      1\n      Foundations: Data, Data, Everywhere\n      20\n      3.0\n    \n    \n      2\n      Ask Questions to Make Data-Driven Decisions\n      18\n      3.0\n    \n    \n      3\n      Prepare Data for Exploration\n      22\n      3.0\n    \n    \n      4\n      Process Data from Dirty to Clean\n      22\n      3.0\n    \n    \n      5\n      Analyze Data to Answer Questions\n      25\n      3.0\n    \n    \n      6\n      Share Data Through the Art of Visualization\n      23\n      3.0\n    \n    \n      7\n      Data Analysis with R Programming\n      38\n      3.0\n    \n    \n      8\n      Google Data Analytics Capstone: Complete a Cas...\n      10\n      3.0\n    \n  \n\n\n\n\n\nGoogle IT Automation with Python Professional Certificate\n\nhttps://www.coursera.org/professional-certificates/google-it-automation\n\n\nAbout this Professional Certificate\n838,400 recent views\nThis beginner-level, six-course certificate, developed by Google, is designed to provide IT professionals with in-demand skills – including Python, Git, and IT automation – that can help you advance your career.\nKnowing how to write code to solve problems and automate solutions is a crucial skill for anybody in IT. Python, in particular, is now the most in-demand programming language by employers.\nThis program builds on your IT foundations to help you take your career to the next level. It’s designed to teach you how to program with Python and how to use Python to automate common system administration tasks. You’ll also learn to use Git and GitHub, troubleshoot and debug complex problems, and apply automation at scale by using configuration management and the Cloud.\nThis certificate can be completed in about 6 months and is designed to prepare you for a variety of roles in IT, like more advanced IT Support Specialist or Junior Systems Administrator positions. Upon completion, you can share your information with potential employers, like Walmart, Sprint, Hulu, Bank of America, Google (of course!), and more.\nWe recommend that you have Python installed on your machine. For some courses, you’ll need a computer where you can install Git or ask your administrator to install it for you.\n\n\nApplied Learning Project\nLearn how to program with Python with no previous knowledge of coding required and you’ll use Python to automate common system administration tasks\nLearn to use Git and GitHub, to troubleshoot and debug complex problems\nApply automation at scale by using configuration management and the Cloud\nPractice your technical skills with hands-on projects including a capstone project where you’ll use your new knowledge to solve a real-world IT problem\n \n\n\nimport pandas as pd\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\nIBMds = pd.DataFrame(columns=columns)\n\ndat=[['Crash Course on Python',32,8,100],\n['Using Python to Interact with the Operating System',31,6,100],\n['Introduction to Git and GitHub',19,8,100],\n['Troubleshooting and Debugging Technique',19, np.NaN  ,0],\n['Configuration Management and the Cloud',18, np.NaN,0],\n['Automating Real-World Tasks with Python',13, np.NaN ,0]]\nlendat=np.shape(dat)[0]\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['Google Python- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      Google Python- Overview\n      132\n      7.333333\n      62\n    \n    \n      1\n      Crash Course on Python\n      32\n      8.000000\n      100\n    \n    \n      2\n      Using Python to Interact with the Operating Sy...\n      31\n      6.000000\n      100\n    \n    \n      3\n      Introduction to Git and GitHub\n      19\n      8.000000\n      100\n    \n    \n      4\n      Troubleshooting and Debugging Technique\n      19\n      NaN\n      0\n    \n    \n      5\n      Configuration Management and the Cloud\n      18\n      NaN\n      0\n    \n    \n      6\n      Automating Real-World Tasks with Python\n      13\n      NaN\n      0\n    \n  \n\n\n\n\n\nLearn SQL Basics for Data Science Specialization\n\nhttps://www.coursera.org/specializations/learn-sql-basics-data-science\n\n\nAbout this Specialization\n159,302 recent views\nThis Specialization is intended for a learner with no previous coding experience seeking to develop SQL query fluency. Through four progressively more difficult SQL projects with data science applications, you will cover topics such as SQL basics, data wrangling, SQL analysis, AB testing, distributed computing using Apache Spark, Delta Lake and more. These topics will prepare you to apply SQL creatively to analyze and explore data; demonstrate efficiency in writing queries; create data analysis datasets; conduct feature engineering, use SQL with other data analysis and machine learning toolsets; and use SQL with unstructured data sets.\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\nIBMds = pd.DataFrame(columns=columns)\n\ndat=[['SQL for Data Science',14,8,100],\n['Data Wrangling, Analysis and AB Testing with SQL',16,8,100],\n['Distributed Computing with Spark SQL',14,8,100],\n['SQL for Data Science Capstone Project',35, 8  ,100]]\nlendat=np.shape(dat)[0]\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['SQL Course- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      SQL Course- Overview\n      79\n      8.0\n      100\n    \n    \n      1\n      SQL for Data Science\n      14\n      8.0\n      100\n    \n    \n      2\n      Data Wrangling, Analysis and AB Testing with SQL\n      16\n      8.0\n      100\n    \n    \n      3\n      Distributed Computing with Spark SQL\n      14\n      8.0\n      100\n    \n    \n      4\n      SQL for Data Science Capstone Project\n      35\n      8.0\n      100\n    \n  \n\n\n\n\n\nlearnpython.org Python Development Course\n\nhttps://learnpython.org/\n\n\ncolumns=['Course Title','Rating (0-10)']\n\ndat=[['Variables and Types',7],\n['Lists',7],\n['Basic Operators',7],\n['Strings',7],\n['Conditions',7],\n['Loops',7],\n['Functions',7],\n['Classes and Objects',7],\n['Dictionaries',7],\n['Modules and Packages',7],\n['List Comprehensions',7],\n['Regular Expressions',7],\n['Exception Handling',7],\n['Sets',7]]\n\nlendat=np.shape(dat)[0]\n\nss = pd.DataFrame(data = dat,columns=columns)\nss.head(lendat)\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Rating (0-10)\n    \n  \n  \n    \n      0\n      Variables and Types\n      7\n    \n    \n      1\n      Lists\n      7\n    \n    \n      2\n      Basic Operators\n      7\n    \n    \n      3\n      Strings\n      7\n    \n    \n      4\n      Conditions\n      7\n    \n    \n      5\n      Loops\n      7\n    \n    \n      6\n      Functions\n      7\n    \n    \n      7\n      Classes and Objects\n      7\n    \n    \n      8\n      Dictionaries\n      7\n    \n    \n      9\n      Modules and Packages\n      7\n    \n    \n      10\n      List Comprehensions\n      7\n    \n    \n      11\n      Regular Expressions\n      7\n    \n    \n      12\n      Exception Handling\n      7\n    \n    \n      13\n      Sets\n      7\n    \n  \n\n\n\n\n\nExcel/VBA for Creative Problem Solving\n\nhttps://www.coursera.org/specializations/excel-vba-creative-problem-solving\n\nAbout this Specialization\n13,746 recent views\nThis Specialization is for learners wishing to dramatically change the way that they use Excel spreadsheets by unleashing the power to automate and optimize spreadsheets using Visual Basic for Applications (VBA). The first two courses will teach learners the basics of VBA through the use of dozens of educational screencasts and a series of quizzes and in-application programming assignments. Finally, in Part 3 of the course, learners will complete 3 “real world” and somewhat open ended projects, which are graded through peer review.\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\nIBMds = pd.DataFrame(columns=columns)\n\ndat=[['Part 1',18,7,100],\n['Part 2',20,7,100],\n['Part 3',16,np.NaN,0]]\nlendat=np.shape(dat)[0]\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['Excel/VBA Course- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      Excel/VBA Course- Overview\n      54\n      7.0\n      70\n    \n    \n      1\n      Part 1\n      18\n      7.0\n      100\n    \n    \n      2\n      Part 2\n      20\n      7.0\n      100\n    \n    \n      3\n      Part 3\n      16\n      NaN\n      0\n    \n  \n\n\n\n\n\nAWS Cloud Technical Essentials\n\n\n\n\nAbout this course\nAre you in a technical role and want to learn the fundamentals of AWS? Do you aspire to have a job or career as a cloud developer, architect, or in an operations role? If so, AWS Cloud Technical Essentials is an ideal way to start. This course was designed for those at the beginning of their cloud-learning journey - no prior knowledge of cloud computing or AWS products and services required!\nThroughout the course, students will build highly available, scalable, and cost effective application step-by-step. Upon course completion, you will be able to make an informed decision about when and how to apply core AWS services for compute, storage, and database to different use cases. You’ll also learn about cloud security with a review of AWS’ shared responsibility model and an introduction to AWS Identity and Access Management (IAM). And, you’ll know how AWS services can be used to monitor and optimize infrastructure in the cloud.\nAWS Cloud Technical Essentials is a fundamental-level course and will build your competence, confidence, and credibility with practical cloud skills that help you innovate and advance your professional future. Enroll in AWS Cloud Technical Essentials and start learning the technical fundamentals of AWS today!\nNote: This course was designed for learners with a technical background. If you are new to the cloud or come from a business background, we recommend completing AWS Cloud Practitioner Essentials (https://www.coursera.org/learn/aws-cloud-practitioner-essentials) before enrolling in this course.\n\nMachine Learning\n\n\nFast AI\n\nhttps://www.fast.ai/\n\n\nPractical Deep Learning\nA free course designed for people with some coding experience, who want to learn how to apply deep learning and machine learning to practical problems.\nThis free course is designed for people (and bunnies!) with some coding experience who want to learn how to apply deep learning and machine learning to practical problems.\nDeep learning can do all kinds of amazing things. For instance, all illustrations throughout this website are made with deep learning, using DALL-E 2.\nPractical Deep Learning for Coders 2022, recorded at the University of Queensland, covers topics such as how to:\n\nBuild and train deep learning models for computer vision, natural language processing, tabular analysis, and collaborative filtering problems\nCreate random forests and regression models\nDeploy models\nUse PyTorch, the world’s fastest growing deep learning software, plus popular libraries like fastai and Hugging Face\n\nThere are 9 lessons, and each lesson is around 90 minutes long. The course is based on our 5-star rated book, which is freely available online.\nYou don’t need any special hardware or software — we’ll show you how to use free resources for both building and deploying models. You don’t need any university math either — we’ll teach you the calculus and linear algebra you need during the course.\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\n\ndat=[['Week 1',12,9,100],\n['Week 2',12,9,100],\n['Week 3',12,9,100],\n['Week 4',12,9,100],\n['Week 5',12,9,100],\n['Week 6',12,9,100],\n['Week 7',12,9,100],\n['Week 8',12,9,100],\n['Week 9',12,9,100],\n['Week 10',12,9,100],\n['Week 11',12,9,100]]\n\n\nlendat=np.shape(dat)[0]\n\n\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['Fast AI- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(lendat)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      Fast AI- Overview\n      132\n      9.0\n      100\n    \n    \n      1\n      Week 1\n      12\n      9.0\n      100\n    \n    \n      2\n      Week 2\n      12\n      9.0\n      100\n    \n    \n      3\n      Week 3\n      12\n      9.0\n      100\n    \n    \n      4\n      Week 4\n      12\n      9.0\n      100\n    \n    \n      5\n      Week 5\n      12\n      9.0\n      100\n    \n    \n      6\n      Week 6\n      12\n      9.0\n      100\n    \n    \n      7\n      Week 7\n      12\n      9.0\n      100\n    \n    \n      8\n      Week 8\n      12\n      9.0\n      100\n    \n    \n      9\n      Week 9\n      12\n      9.0\n      100\n    \n    \n      10\n      Week 10\n      12\n      9.0\n      100\n    \n  \n\n\n\n\n\nIBM AI Engineering Professional Certificate\n\nhttps://www.coursera.org/professional-certificates/ai-engineer\n\n\nAbout this Professional Certificate\n43,794 recent views\nArtificial intelligence (AI) is revolutionizing entire industries, changing the way companies across sectors leverage data to make decisions. To stay competitive, organizations need qualified AI engineers who use cutting-edge methods like machine learning algorithms and deep learning neural networks to provide data driven actionable intelligence for their businesses. This 6-course Professional Certificate is designed to equip you with the tools you need to succeed in your career as an AI or ML engineer.\nYou’ll master fundamental concepts of machine learning and deep learning, including supervised and unsupervised learning, using programming languages like Python. You’ll apply popular machine learning and deep learning libraries such as SciPy, ScikitLearn, Keras, PyTorch, and Tensorflow to industry problems involving object recognition, computer vision, image and video processing, text analytics, natural language processing (NLP), recommender systems, and other types of classifiers.\nThrough hands-on projects, you’ll gain essential data science skills scaling machine learning algorithms on big data using Apache Spark. You’ll build, train, and deploy different types of deep architectures, including convolutional neural networks, recurrent networks, and autoencoders.\nIn addition to earning a Professional Certificate from Coursera, you will also receive a digital badge from IBM recognizing your proficiency in AI engineering.\n\n\nApplied Learning Project\nThroughout the program, you will build a portfolio of projects demonstrating your mastery of course topics. The hands-on projects will give you a practical working knowledge of Machine Learning libraries and Deep Learning frameworks such as SciPy, ScikitLearn, Keras, PyTorch, and Tensorflow. You will also complete an in-depth Capstone Project, where you’ll apply your AI and Neural Network skills to a real-world challenge and demonstrate your ability to communicate project outcomes.\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)']\nIBMds = pd.DataFrame(columns=columns)\n\ndat = [['Machine Learning with Python',21,6],\n    ['Introduction to Deep Learning & Neural Networks with Keras',8,6],\n    ['Introduction to Computer Vision and Image Processing',21,6],\n    ['Deep Neural Networks with PyTorch',31,6],\n    ['Building Deep Learning Models with TensorFlow',13,6],\n    ['AI Capstone Project with Deep Learning', 16,6]]\nss = pd.DataFrame(data = dat,columns=columns)\nssTot=pd.DataFrame(data = [['IBM AI Engineering- Overview',ss['Expected Time (h)'].sum(),ss['Rating (0-10)'].mean()]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n    \n  \n  \n    \n      0\n      IBM AI Engineering- Overview\n      110\n      6.0\n    \n    \n      1\n      Machine Learning with Python\n      21\n      6.0\n    \n    \n      2\n      Introduction to Deep Learning & Neural Network...\n      8\n      6.0\n    \n    \n      3\n      Introduction to Computer Vision and Image Proc...\n      21\n      6.0\n    \n    \n      4\n      Deep Neural Networks with PyTorch\n      31\n      6.0\n    \n    \n      5\n      Building Deep Learning Models with TensorFlow\n      13\n      6.0\n    \n    \n      6\n      AI Capstone Project with Deep Learning\n      16\n      6.0\n    \n  \n\n\n\n\n\nMachine Learning Stanford\n\nhttps://www.coursera.org/specializations/machine-learning-introduction\n\n\nAbout this Specialization\n574,468 recent views\nThe Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. This beginner-friendly program will teach you the fundamentals of machine learning and how to use these techniques to build real-world AI applications.\nThis Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.\nThis 3-course Specialization is an updated version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012.\nIt provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)\nBy the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.\n\n\nApplied Learning Project\nBy the end of this Specialization, you will be ready to:\n• Build machine learning models in Python using popular machine learning libraries NumPy and scikit-learn.\n• Build and train supervised machine learning models for prediction and binary classification tasks, including linear regression and logistic regression.\n• Build and train a neural network with TensorFlow to perform multi-class classification.\n• Apply best practices for machine learning development so that your models generalize to data and tasks in the real world.\n• Build and use decision trees and tree ensemble methods, including random forests and boosted trees.\n• Use unsupervised learning techniques for unsupervised learning: including clustering and anomaly detection.\n• Build recommender systems with a collaborative filtering approach and a content-based deep learning method.\n• Build a deep reinforcement learning model.\n\n\nDeep Learning Specialization\n\nhttps://www.coursera.org/specializations/deep-learning\n\n\nAbout this Specialization\n379,682 recent views\nThe Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology.\nIn this Specialization, you will build and train neural network architectures such as Convolutional Neural Networks, Recurrent Neural Networks, LSTMs, Transformers, and learn how to make them better with strategies such as Dropout, BatchNorm, Xavier/He initialization, and more. Get ready to master theoretical concepts and their industry applications using Python and TensorFlow and tackle real-world cases such as speech recognition, music synthesis, chatbots, machine translation, natural language processing, and more.\nAI is transforming many industries. The Deep Learning Specialization provides a pathway for you to take the definitive step in the world of AI by helping you gain the knowledge and skills to level up your career. Along the way, you will also get career advice from deep learning experts from industry and academia. Applied Learning Project\nBy the end you’ll be able to\n• Build and train deep neural networks, implement vectorized neural networks, identify architecture parameters, and apply DL to your applications\n• Use best practices to train and develop test sets and analyze bias/variance for building DL applications, use standard NN techniques, apply optimization algorithms, and implement a neural network in TensorFlow\n• Use strategies for reducing errors in ML systems, understand complex ML settings, and apply end-to-end, transfer, and multi-task learning\n• Build a Convolutional Neural Network, apply it to visual detection and recognition tasks, use neural style transfer to generate art, and apply these algorithms to image, video, and other 2D/3D data\n• Build and train Recurrent Neural Networks and its variants (GRUs, LSTMs), apply RNNs to character-level language modeling, work with NLP and Word Embeddings, and use HuggingFace tokenizers and transformers to perform Named Entity Recognition and Question Answering\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\n\n\ndat=[['Neural Networks and Deep Learning',23,8,100],\n['Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization',22,8,100],\n['Structuring Machine Learning Projects',6,8,100],\n['Convolutional Neural Networks',35, 8  ,100],\n['Sequence Models',36, 8,20]]\nlendat=np.shape(dat)[0]\n\n\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['Deep Learning- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      Deep Learning- Overview\n      122\n      8.0\n      76\n    \n    \n      1\n      Neural Networks and Deep Learning\n      23\n      8.0\n      100\n    \n    \n      2\n      Improving Deep Neural Networks: Hyperparameter...\n      22\n      8.0\n      100\n    \n    \n      3\n      Structuring Machine Learning Projects\n      6\n      8.0\n      100\n    \n    \n      4\n      Convolutional Neural Networks\n      35\n      8.0\n      100\n    \n    \n      5\n      Sequence Models\n      36\n      8.0\n      20\n    \n  \n\n\n\n\n\nTensorFlow Developer Professional Certificate\n\nhttps://www.coursera.org/professional-certificates/tensorflow-in-practice\n\n\nAbout this Specialization\nTensorFlow is one of the most in-demand and popular open-source deep learning frameworks available today. The DeepLearning.AI TensorFlow Developer Professional Certificate program teaches you applied machine learning skills with TensorFlow so you can build and train powerful models.\nIn this hands-on, four-course Professional Certificate program, you’ll learn the necessary tools to build scalable AI-powered applications with TensorFlow. After finishing this program, you’ll be able to apply your new TensorFlow skills to a wide range of problems and projects. This program can help you prepare for the Google TensorFlow Certificate exam and bring you one step closer to achieving the Google TensorFlow Certificate.\nReady to deploy your models to the world? Learn how to go live with your models with the TensorFlow: Data and Deployment Specialization.\nLooking to customize and build powerful real-world models for complex scenarios? Check out the TensorFlow: Advanced Techniques Specialization.\n\n\nApplied Learning Project\nIn the DeepLearning.AI TensorFlow Developer Professional Certificate program, you’ll get hands-on experience through 16 Python programming assignments. By the end of this program, you will be ready to:\n\nBuild and train neural networks using TensorFlow\nImprove your network’s performance using convolutions as you train it to identify real-world images\nTeach machines to understand, analyze, and respond to human speech with natural language processing systems\nProcess text, represent sentences as vectors, and train a model to create original poetry!\n\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\n\n\ndat=[['Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning',18,9,100],\n['Convolutional Neural Networks in TensorFlow',18,9,100],\n['Natural Language Processing in TensorFlow',25,8,100],\n['Sequences, Time Series and Prediction',24, 8  ,100]]\nlendat=np.shape(dat)[0]\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['Tensorflow Developer- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      Tensorflow Developer- Overview\n      85\n      8.5\n      100\n    \n    \n      1\n      Introduction to TensorFlow for Artificial Inte...\n      18\n      9.0\n      100\n    \n    \n      2\n      Convolutional Neural Networks in TensorFlow\n      18\n      9.0\n      100\n    \n    \n      3\n      Natural Language Processing in TensorFlow\n      25\n      8.0\n      100\n    \n    \n      4\n      Sequences, Time Series and Prediction\n      24\n      8.0\n      100\n    \n  \n\n\n\n\n\nTensorFlow: Advanced Techniques Specialization\n\nhttps://www.coursera.org/professional-certificates/tensorflow-in-practice\n\n\nAbout this Specialization\nExpand your knowledge of the Functional API and build exotic non-sequential model types. Learn how to optimize training in different environments with multiple processors and chip types and get introduced to advanced computer vision scenarios such as object detection, image segmentation, and interpreting convolutions. Explore generative deep learning including the ways AIs can create new content from Style Transfer to Auto Encoding, VAEs, and GANs.\n\n\nApplied Learning Project\nIn this Specialization, you will gain practical knowledge of and hands-on training in advanced TensorFlow techniques such as style transfer, object detection, and generative machine learning.\nCourse 1: Understand the underlying basis of the Functional API and build exotic non-sequential model types, custom loss functions, and layers.\nCourse 2: Learn how optimization works and how to use GradientTape and Autograph. Optimize training in different environments with multiple processors and chip types.\nCourse 3: Practice object detection, image segmentation, and visual interpretation of convolutions.\nCourse 4: Explore generative deep learning and how AIs can create new content, from Style Transfer through Auto Encoding and VAEs to Generative Adversarial Networks.\n \n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\n\n\ndat=[['Custom Models, Layers, and Loss Functions with TensorFlow',37,9,100],\n['Custom and Distributed Training with TensorFlow',29,9,100],\n['Advanced Computer Vision with TensorFlow',29, 8,25],\n['Generative Deep Learning with TensorFlow',27, 0  ,0]]\nlendat=np.shape(dat)[0]\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['TensorFlow: Advanced Techniques Specialization- Overview',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      TensorFlow: Advanced Techniques Specialization...\n      122\n      6.5\n      60\n    \n    \n      1\n      Custom Models, Layers, and Loss Functions with...\n      37\n      9.0\n      100\n    \n    \n      2\n      Custom and Distributed Training with TensorFlow\n      29\n      9.0\n      100\n    \n    \n      3\n      Advanced Computer Vision with TensorFlow\n      29\n      8.0\n      25\n    \n    \n      4\n      Generative Deep Learning with TensorFlow\n      27\n      0.0\n      0\n    \n  \n\n\n\n\n\nTensorFlow 2 for Deep Learning Specialization\n\nhttps://www.coursera.org/specializations/tensorflow2-deeplearning\n\n\nAbout this Specialization\nThis Specialization is intended for machine learning researchers and practitioners who are seeking to develop practical skills in the popular deep learning framework TensorFlow.\nThe first course of this Specialization will guide you through the fundamental concepts required to successfully build, train, evaluate and make predictions from deep learning models, validating your models and including regularisation, implementing callbacks, and saving and loading models.\nThe second course will deepen your knowledge and skills with TensorFlow, in order to develop fully customised deep learning models and workflows for any application. You will use lower level APIs in TensorFlow to develop complex model architectures, fully customised layers, and a flexible data workflow. You will also expand your knowledge of the TensorFlow APIs to include sequence models.\nThe final course specialises in the increasingly important probabilistic approach to deep learning. You will learn how to develop probabilistic models with TensorFlow, making particular use of the TensorFlow Probability library, which is designed to make it easy to combine probabilistic models with deep learning. As such, this course can also be viewed as an introduction to the TensorFlow Probability library.\nPrerequisite knowledge for this Specialization is python 3, general machine learning and deep learning concepts, and a solid foundation in probability and statistics (especially for course 3)..\n\n\nApplied Learning Project\nWithin the Capstone projects and programming assignments of this Specialization, you will acquire practical skills in developing deep learning models for a range of applications such as image classification, language translation, and text and image generation.\n\n\ncolumns=['Course Title','Expected Time (h)','Rating (0-10)','Percentage completed']\n\n\ndat=[['Getting started with TensorFlow 2',26,8,100],\n['Customising your models with TensorFlow 2',27,7,75],\n['Probabilistic Deep Learning with TensorFlow 2',53, 0,0]]\nlendat=np.shape(dat)[0]\n\n\nss = pd.DataFrame(data = dat,columns=columns)\n\npctot=int(np.sum(ss['Percentage completed'] * ss['Expected Time (h)']/(ss['Expected Time (h)'].sum())))\n\nssTot=pd.DataFrame(data = [['TensorFlow 2 for Deep Learning Specialization',ss['Expected Time (h)'].sum(),(ss['Rating (0-10)'].mean(skipna=True)),pctot]],columns=columns)\nss=ssTot.append(ss)\nss.reset_index(inplace=True,drop=True)\nss.head(10)\n\n\n\n\n\n  \n    \n      \n      Course Title\n      Expected Time (h)\n      Rating (0-10)\n      Percentage completed\n    \n  \n  \n    \n      0\n      TensorFlow 2 for Deep Learning Specialization\n      106\n      5.0\n      43\n    \n    \n      1\n      Getting started with TensorFlow 2\n      26\n      8.0\n      100\n    \n    \n      2\n      Customising your models with TensorFlow 2\n      27\n      7.0\n      75\n    \n    \n      3\n      Probabilistic Deep Learning with TensorFlow 2\n      53\n      0.0\n      0"
  },
  {
    "objectID": "posts/2021-10-29-Imbedding-Python-Web.html#ipywidgets",
    "href": "posts/2021-10-29-Imbedding-Python-Web.html#ipywidgets",
    "title": "ThomasHSimm",
    "section": "Ipywidgets",
    "text": "Ipywidgets\nhttps://ipywidgets.readthedocs.io/en/latest/\n\nipywidgets, also known as jupyter-widgets or simply widgets, are interactive HTML widgets for Jupyter notebooks and the IPython kernel.\nNotebooks come alive when interactive widgets are used. Users gain control of their data and can visualize changes in the data.\nLearning becomes an immersive, fun experience. Researchers can easily see how changing inputs to a model impact the results.\n\nImport\n\nimport ipywidgets as widgets\n\nA slider\n\nwidgets.IntSlider()\n\n\n\n\nChange the details of the slider\n\nwidgets.IntSlider(\n    value=7,\n    min=0,\n    max=10,\n    step=1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='d'\n)\n\n\n\n\nGet the value\n\nx=widgets.IntSlider()\nprint('The value is {}'.format(str(x.value)))\nx\n\nThe value is 0\n\n\n\n\n\nA different way with interact\n\n#import the interact part\nfrom ipywidgets import interact\n\n#some function we want to call\ndef square(x):\n    return x * x *2\n\n#the new widget slider\ninteract(square, x=(0, 100, 10));\n\n\n\n\nA text box\n\nwidgets.Text(value='Hello World!', disabled=True)\n\n\n\n\nA toggle button\n\nwidgets.ToggleButton(\n    value=False,\n    description='Click me',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    tooltip='Description',\n    icon='check' # (FontAwesome names without the `fa-` prefix)\n)\n\n\n\n\nA dropdown menu\n\nwidgets.Dropdown(\n    options=['1', '2', '3'],\n    value='2',\n    description='Number:',\n    disabled=False,\n)\n\n\n\n\nA radiobutton with a label in a box\n\nwidgets.Box(\n    [\n        widgets.Label(value='Pizza topping with a very long label:'),\n        widgets.RadioButtons(\n            options=[\n                'pepperoni',\n                'pineapple',\n                'anchovies',\n                'and the long name that will fit fine and the long name that will fit fine and the long name that will fit fine '\n            ],\n            layout={'width': 'max-content'}\n        )\n    ]\n)\n\n\n\n\nSome html\n\nwidgets.HTMLMath(\n    value=r\"Some math and <i>HTML</i>: \\(x^2\\) and $$\\frac{x+1}{x-1}$$\",\n    placeholder='Some HTML',\n    description='Some HTML',\n)\n\n\n\n\nAccordion, with slider and textbox\n\naccordion = widgets.Accordion(children=[widgets.IntSlider(), widgets.Text()], titles=('Slider', 'Text'))\naccordion\n\n\n\n\nmultiple sliders\n\na = widgets.IntSlider(description='a')\nb = widgets.IntSlider(description='b')\nc = widgets.IntSlider(description='c')\ndef f(a, b, c):\n    print('{}*{}*{}={}'.format(a, b, c, a*b*c))\n\nout = widgets.interactive_output(f, {'a': a, 'b': b, 'c': c})\n\nwidgets.HBox([widgets.VBox([a, b, c]), out])"
  },
  {
    "objectID": "posts/2021-10-29-Imbedding-Python-Web.html#inserting-into-a-website",
    "href": "posts/2021-10-29-Imbedding-Python-Web.html#inserting-into-a-website",
    "title": "ThomasHSimm",
    "section": "Inserting into a website",
    "text": "Inserting into a website\nAfter installing nbinteract a html file of a python notebook can be created\n\nnbinteract Quick_ipyWidget.ipynb -s thomashsimm/TestWdgets/main"
  },
  {
    "objectID": "posts/2021-11-16-ChicagoBikes.html#introduction",
    "href": "posts/2021-11-16-ChicagoBikes.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nSome quick analysis on Cycle bike-share data from Chicago\nWelcome to the Cyclistic bike-share analysis case study! In this case study, you will perform many real-world tasks of a junior data analyst. You will work for a fictional company, Cyclistic, and meet different characters and team members. In order to answer the key business questions, you will follow the steps of the data analysis process: ask, prepare, process, analyze, share, and act. Along the way, the Case Study Roadmap tables — including guiding questions and key tasks — will help you stay on the right path. By the end of this lesson, you will have a portfolio-ready case study. Download the packet and reference the details of this case study anytime. Then, when you begin your job hunt, your case study will be a tangible way to demonstrate your knowledge and skills to potential employers.\n\nSome imports\n\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport numpy as np\nimport requests\n# from datetime import datetime, timezone\nimport os\nimport geopandas as gpd\n\n#get the current working directory\nowd=os.getcwd()"
  },
  {
    "objectID": "posts/2021-11-16-ChicagoBikes.html#a-function-to-extract-web-zip-files-and-save-to-dat-folder",
    "href": "posts/2021-11-16-ChicagoBikes.html#a-function-to-extract-web-zip-files-and-save-to-dat-folder",
    "title": "ThomasHSimm",
    "section": "A function to extract web zip files and save to /dat folder",
    "text": "A function to extract web zip files and save to /dat folder\n\nWe’ll just look at Q1 for 2020 data\nThe data for 2020 is split into Q1 and the rest is for each month. So we need to download and convert each to a data frame and then combine them together\n\ndef extractStuff(url):\n    import requests, zipfile, io\n    import os\n    owd=os.getcwd()\n    r = requests.get(url)\n    z = zipfile.ZipFile(io.BytesIO(r.content))\n    z.extractall(owd+\"/dat/\")\nURL=\"https://divvy-tripdata.s3.amazonaws.com/\"\nnoma =[['202004-divvy-tripdata'],\n['202005-divvy-tripdata'],\n['202006-divvy-tripdata'],\n['202007-divvy-tripdata'],\n['202008-divvy-tripdata'],\n['202009-divvy-tripdata'],\n['202010-divvy-tripdata'],\n['202011-divvy-tripdata'],\n['202012-divvy-tripdata']]\n    \n\n\nfor nom in noma:\n    extractStuff(URL+ nom[0]+\".zip\")\n\n\n\nLoad files, put in pandas data frame and have a look\n\nLets load each csv and combine them\n\nfor i,nom in enumerate(noma):\n    if i>0:\n        df=pd.read_csv(owd+\"/dat/\"+nom[0]+'.csv')\n        dfAll=pd.concat([df,dfAll])    \n        print('1 ',nom[0])\n    else:\n        dfAll=pd.read_csv(owd+\"/dat/\"+nom[0]+'.csv')\n        print('2',nom[0])\n\n2 202004-divvy-tripdata\n1  202005-divvy-tripdata\n1  202006-divvy-tripdata\n1  202007-divvy-tripdata\n1  202008-divvy-tripdata\n1  202009-divvy-tripdata\n1  202010-divvy-tripdata\n1  202011-divvy-tripdata\n1  202012-divvy-tripdata\n\n\n\n\n\nHow many NaN stations?\n\nprint('The percentage start stations NaN = {}'.format(100*np.shape(dfAll[dfAll['start_station_id'].isna()])[0] / np.shape(dfAll)[0]) )#95 282 3 114 796\n\nprint('The percentage end stations NaN = {}'.format(100*np.shape(dfAll[dfAll['end_station_id'].isna()])[0] / np.shape(dfAll)[0]) )#95 282 3 114 796\n\nbothNa=dfAll[dfAll['start_station_id'].isna() | dfAll['end_station_id'].isna()] \nprint('The percentage start stations NaN = {}'.format(100*np.shape(bothNa)[0] / np.shape(dfAll)[0]) )#95 282 3 114 796\n\nThe percentage start stations NaN = 3.059012532441932\nThe percentage end stations NaN = 3.5745840177013197\nThe percentage start stations NaN = 4.889597906251324\n\n\n\nimport copy\ndfUse=copy.copy(dfAll[dfAll['start_station_id'].notnull() & dfAll['end_station_id'].notnull()])\ndfUse.describe(include='all')\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      count\n      2962495\n      2962495\n      2962495\n      2962495\n      2962495\n      2962495.0\n      2962495\n      2962495.0\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2962495\n    \n    \n      unique\n      2962287\n      3\n      2568216\n      2556286\n      689\n      1301.0\n      690\n      1304.0\n      NaN\n      NaN\n      NaN\n      NaN\n      2\n    \n    \n      top\n      0A2B0949201A9D0C\n      docked_bike\n      2020-09-07 15:19:26\n      2020-10-14 07:23:00\n      Streeter Dr & Grand Ave\n      35.0\n      Streeter Dr & Grand Ave\n      35.0\n      NaN\n      NaN\n      NaN\n      NaN\n      member\n    \n    \n      freq\n      2\n      2535257\n      12\n      13\n      32629\n      32192.0\n      34905\n      34467.0\n      NaN\n      NaN\n      NaN\n      NaN\n      1710201\n    \n    \n      mean\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.190534e+01\n      -8.764452e+01\n      4.190559e+01\n      -8.764481e+01\n      NaN\n    \n    \n      std\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.157203e-02\n      2.446731e-02\n      4.169299e-02\n      2.460637e-02\n      NaN\n    \n    \n      min\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.164850e+01\n      -8.777470e+01\n      4.164850e+01\n      -8.777470e+01\n      NaN\n    \n    \n      25%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.188316e+01\n      -8.765840e+01\n      4.188338e+01\n      -8.765862e+01\n      NaN\n    \n    \n      50%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.190096e+01\n      -8.764117e+01\n      4.190096e+01\n      -8.764182e+01\n      NaN\n    \n    \n      75%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.193120e+01\n      -8.762773e+01\n      4.193125e+01\n      -8.762775e+01\n      NaN\n    \n    \n      max\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.206490e+01\n      -8.752823e+01\n      4.206501e+01\n      -8.752823e+01\n      NaN\n    \n  \n\n\n\n\n\n\nNow we need to convert the dates from object (i.e. string) to date format\n\nnext add a new column as time for hire in hours\n\ndfUse.loc[:,'started_at']=pd.to_datetime(dfUse['started_at'],infer_datetime_format=True)\ndfUse.loc[:,'ended_at']=pd.to_datetime(dfUse['ended_at'],infer_datetime_format=True)\n\ndelta=dfUse.iloc[:,3]-dfUse.iloc[:,2]\ndd=delta.dt.total_seconds()/(60*60)\ndfUse.insert(2,\"hire_time_h\",dd)\ndfUse.head()\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      hire_time_h\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      70B6A9A437D4C30D\n      classic_bike\n      0.176944\n      2020-12-27 12:44:29\n      2020-12-27 12:55:06\n      Aberdeen St & Jackson Blvd\n      13157\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      39\n      15F369FDAED4E8E3\n      electric_bike\n      0.130556\n      2020-12-18 13:53:56\n      2020-12-18 14:01:46\n      Larrabee St & Armitage Ave\n      TA1309000006\n      Wells St & Walton St\n      TA1306000011\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      50\n      0CFD61DFE00E6043\n      electric_bike\n      0.030000\n      2020-12-28 17:10:25\n      2020-12-28 17:12:13\n      Kingsbury St & Kinzie St\n      KA1503000043\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      87\n      244CB936487039B7\n      docked_bike\n      1.013056\n      2020-12-10 13:36:16\n      2020-12-10 14:37:03\n      Clark St & Leland Ave\n      TA1309000014\n      Clark St & Leland Ave\n      TA1309000014\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      88\n      B7AD5038F79637F9\n      classic_bike\n      0.101111\n      2020-12-20 13:09:04\n      2020-12-20 13:15:08\n      Dearborn St & Monroe St\n      TA1305000006\n      Kingsbury St & Kinzie St\n      KA1503000043\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\nMaybe we want the day of the week?\nThe day of the week with Monday=0, Sunday=6.\n\ndfUse.insert(3,'day_week',dfUse.loc[:,'started_at'].dt.dayofweek)\ndfUse.head()\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      hire_time_h\n      day_week\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      70B6A9A437D4C30D\n      classic_bike\n      0.176944\n      6\n      2020-12-27 12:44:29\n      2020-12-27 12:55:06\n      Aberdeen St & Jackson Blvd\n      13157\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.877726\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      39\n      15F369FDAED4E8E3\n      electric_bike\n      0.130556\n      4\n      2020-12-18 13:53:56\n      2020-12-18 14:01:46\n      Larrabee St & Armitage Ave\n      TA1309000006\n      Wells St & Walton St\n      TA1306000011\n      41.918112\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      50\n      0CFD61DFE00E6043\n      electric_bike\n      0.030000\n      0\n      2020-12-28 17:10:25\n      2020-12-28 17:12:13\n      Kingsbury St & Kinzie St\n      KA1503000043\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.889193\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      87\n      244CB936487039B7\n      docked_bike\n      1.013056\n      3\n      2020-12-10 13:36:16\n      2020-12-10 14:37:03\n      Clark St & Leland Ave\n      TA1309000014\n      Clark St & Leland Ave\n      TA1309000014\n      41.967096\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      88\n      B7AD5038F79637F9\n      classic_bike\n      0.101111\n      6\n      2020-12-20 13:09:04\n      2020-12-20 13:15:08\n      Dearborn St & Monroe St\n      TA1305000006\n      Kingsbury St & Kinzie St\n      KA1503000043\n      41.881320\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\n\nLets also get the time on its own\n\ndfUse.insert(4,'time_day',dfUse.loc[:,'started_at'].dt.hour + dfUse.loc[:,'started_at'].dt.minute/60)\ndfUse.head()\n\n\n\n\n\n  \n    \n      \n      ride_id\n      rideable_type\n      hire_time_h\n      day_week\n      time_day\n      started_at\n      ended_at\n      start_station_name\n      start_station_id\n      end_station_name\n      end_station_id\n      start_lat\n      distance\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      70B6A9A437D4C30D\n      classic_bike\n      0.176944\n      6\n      12.733333\n      2020-12-27 12:44:29\n      2020-12-27 12:55:06\n      Aberdeen St & Jackson Blvd\n      13157\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.877726\n      1.491984\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      39\n      15F369FDAED4E8E3\n      electric_bike\n      0.130556\n      4\n      13.883333\n      2020-12-18 13:53:56\n      2020-12-18 14:01:46\n      Larrabee St & Armitage Ave\n      TA1309000006\n      Wells St & Walton St\n      TA1306000011\n      41.918112\n      2.144117\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      50\n      0CFD61DFE00E6043\n      electric_bike\n      0.030000\n      0\n      17.166667\n      2020-12-28 17:10:25\n      2020-12-28 17:12:13\n      Kingsbury St & Kinzie St\n      KA1503000043\n      Desplaines St & Kinzie St\n      TA1306000003\n      41.889193\n      0.323238\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      87\n      244CB936487039B7\n      docked_bike\n      1.013056\n      3\n      13.600000\n      2020-12-10 13:36:16\n      2020-12-10 14:37:03\n      Clark St & Leland Ave\n      TA1309000014\n      Clark St & Leland Ave\n      TA1309000014\n      41.967096\n      0.000000\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      88\n      B7AD5038F79637F9\n      classic_bike\n      0.101111\n      6\n      13.150000\n      2020-12-20 13:09:04\n      2020-12-20 13:15:08\n      Dearborn St & Monroe St\n      TA1305000006\n      Kingsbury St & Kinzie St\n      KA1503000043\n      41.881320\n      1.147392\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\nAnd the distance travelled\n\ndef distanceLatLong(lat1,lon1,lat2,lon2):\n    \n    import numpy as np\n\n    def deg2rad(deg):\n        return deg * np.pi/180\n\n    R = 6371; # Radius of the earth in km\n    dLat = deg2rad(lat2-lat1)  # deg2rad below\n    dLon = deg2rad(lon2-lon1)\n    a = np.sin(dLat/2) * np.sin(dLat/2) + \\\n    np.cos(deg2rad(lat1)) * np.cos(deg2rad(lat2)) * \\\n    np.sin(dLon/2) * np.sin(dLon/2)\n\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    d = R * c ## Distance in km\n \n    return d\n\n\nd=distanceLatLong(dfUse[\"start_lat\"].values,dfUse[\"start_lng\"].values,dfUse[\"end_lat\"].values,dfUse[\"end_lng\"].values)\ndfUse.insert(11,'distance',d)\ndfUse.describe()\n\n\n\n\n\n  \n    \n      \n      hire_time_h\n      day_week\n      start_lat\n      distance\n      start_lng\n      end_lat\n      end_lng\n    \n  \n  \n    \n      count\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n      2.962495e+06\n    \n    \n      mean\n      4.291666e-01\n      3.262215e+00\n      4.190534e+01\n      2.240406e+00\n      -8.764452e+01\n      4.190559e+01\n      -8.764481e+01\n    \n    \n      std\n      6.640800e+00\n      1.973614e+00\n      4.157203e-02\n      2.029178e+00\n      2.446731e-02\n      4.169299e-02\n      2.460637e-02\n    \n    \n      min\n      -4.841661e+02\n      0.000000e+00\n      4.164850e+01\n      0.000000e+00\n      -8.777470e+01\n      4.164850e+01\n      -8.777470e+01\n    \n    \n      25%\n      1.377778e-01\n      2.000000e+00\n      4.188316e+01\n      8.598642e-01\n      -8.765840e+01\n      4.188338e+01\n      -8.765862e+01\n    \n    \n      50%\n      2.525000e-01\n      3.000000e+00\n      4.190096e+01\n      1.713410e+00\n      -8.764117e+01\n      4.190096e+01\n      -8.764182e+01\n    \n    \n      75%\n      4.577778e-01\n      5.000000e+00\n      4.193120e+01\n      3.098683e+00\n      -8.762773e+01\n      4.193125e+01\n      -8.762775e+01\n    \n    \n      max\n      9.786672e+02\n      6.000000e+00\n      4.206490e+01\n      4.837080e+01\n      -8.752823e+01\n      4.206501e+01\n      -8.752823e+01\n    \n  \n\n\n\n\n\n\nSome issues arose above\n\nhire_time_h max and min values\n\nLooks like the error is there from the start, so lets delete them\ndo the same for long times\n\ndfUse=dfUse[dfUse.hire_time_h>=0]\n\ndfUse=dfUse[dfUse.hire_time_h<24]\n\n\n\nLets drop some columns for space\n\ndfUse.drop(columns=[\"ride_id\", \"started_at\",\"ended_at\",\"start_station_name\",\"end_station_name\"],inplace=True)\n#,\"start_station_id\",\"end_station_id\"]\n\n\n\nsave\n\ndfUse.to_csv('/data/df_2020.csv')\ndf=copy.copy(dfUse)\n\n\ndf = pd.read_csv('/data/df_2020.csv')\ndf\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      rideable_type\n      hire_time_h\n      day_week\n      time_day\n      start_station_id\n      end_station_id\n      start_lat\n      distance\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      0\n      classic_bike\n      0.176944\n      6\n      12.733333\n      13157\n      TA1306000003\n      41.877726\n      1.491984\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      1\n      39\n      electric_bike\n      0.130556\n      4\n      13.883333\n      TA1309000006\n      TA1306000011\n      41.918112\n      2.144117\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      2\n      50\n      electric_bike\n      0.030000\n      0\n      17.166667\n      KA1503000043\n      TA1306000003\n      41.889193\n      0.323238\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      3\n      87\n      docked_bike\n      1.013056\n      3\n      13.600000\n      TA1309000014\n      TA1309000014\n      41.967096\n      0.000000\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      4\n      88\n      classic_bike\n      0.101111\n      6\n      13.150000\n      TA1305000006\n      KA1503000043\n      41.881320\n      1.147392\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2949984\n      84771\n      docked_bike\n      0.215278\n      3\n      16.166667\n      140.0\n      140.0\n      41.899000\n      0.000000\n      -87.629900\n      41.899000\n      -87.629900\n      member\n    \n    \n      2949985\n      84772\n      docked_bike\n      0.319167\n      3\n      17.933333\n      322.0\n      351.0\n      41.799600\n      1.056377\n      -87.594700\n      41.803000\n      -87.606600\n      casual\n    \n    \n      2949986\n      84773\n      docked_bike\n      1.886111\n      4\n      19.950000\n      236.0\n      182.0\n      41.907600\n      0.604983\n      -87.638600\n      41.903200\n      -87.634300\n      casual\n    \n    \n      2949987\n      84774\n      docked_bike\n      0.708611\n      3\n      17.983333\n      310.0\n      310.0\n      41.920100\n      0.000000\n      -87.677900\n      41.920100\n      -87.677900\n      casual\n    \n    \n      2949988\n      84775\n      docked_bike\n      0.100000\n      5\n      1.516667\n      138.0\n      138.0\n      41.904600\n      0.000000\n      -87.640600\n      41.904600\n      -87.640600\n      casual\n    \n  \n\n2949989 rows × 13 columns\n\n\n\n\n\nPut frequency location onto a map\n\nimport folium\nfrom folium import plugins\nfrom folium.plugins import HeatMap\n\nlat=df['start_lat'].values\nlon=df['start_lng'].values\nlatlon = [lat, lon]\n\nmaps = folium.Map(location=[lat[0],lon[0]],\n                    zoom_start = 11)\n\nlatlon=np.transpose(latlon)\n\n# Plot it on the map\nHeatMap(latlon).add_to(maps)\n\n# Display the map\nmaps\n\n\nBit of a mess, grouping by region may be better"
  },
  {
    "objectID": "posts/2021-11-16-ChicagoBikes.html#plot-some-choroplots",
    "href": "posts/2021-11-16-ChicagoBikes.html#plot-some-choroplots",
    "title": "ThomasHSimm",
    "section": "Plot some choroplots",
    "text": "Plot some choroplots\nopen and modify the geojson file- seems to make life easier later\n\nimport geopandas as gpd\nfname='Chicago.geojson'\nchicago = gpd.read_file(fname)\n\n# neighborhoods aren't unique so lets use the index and call it ID\nchicago.reset_index(inplace=True)\nchicago.rename(columns={'index':'ID'},inplace=True)\n\nchicago.drop(columns=['sec_neigh','shape_area','shape_len'],inplace=True)\nchicago.to_file(\"Chi_.json\", driver=\"GeoJSON\")\nchicago.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      pri_neigh\n      geometry\n    \n  \n  \n    \n      0\n      0\n      Grand Boulevard\n      MULTIPOLYGON (((-87.60671 41.81681, -87.60670 ...\n    \n    \n      1\n      1\n      Printers Row\n      MULTIPOLYGON (((-87.62761 41.87437, -87.62760 ...\n    \n    \n      2\n      2\n      United Center\n      MULTIPOLYGON (((-87.66707 41.88885, -87.66707 ...\n    \n    \n      3\n      3\n      Sheffield & DePaul\n      MULTIPOLYGON (((-87.65833 41.92166, -87.65835 ...\n    \n    \n      4\n      4\n      Humboldt Park\n      MULTIPOLYGON (((-87.74060 41.88782, -87.74060 ...\n    \n  \n\n\n\n\n\nNow we want to convert each station to a region within the json file\n\nFirst let’s create a variable for each station, with location and station_id\n\n#use mean here just in case some slight differences- big ones lets hope not!\ndfStat=df.groupby(by=['start_station_id']).mean()\n\ndfStat=dfStat.drop(columns=['Unnamed: 0','hire_time_h','day_week','time_day','distance','end_lat','end_lng'])\ndfStat.reset_index(inplace=True)\ndfStat\n\n\n\n\n\n  \n    \n      \n      start_station_id\n      start_lat\n      start_lng\n    \n  \n  \n    \n      0\n      2.0\n      41.876505\n      -87.620535\n    \n    \n      1\n      3.0\n      41.867228\n      -87.615357\n    \n    \n      2\n      4.0\n      41.856268\n      -87.613345\n    \n    \n      3\n      5.0\n      41.874050\n      -87.627709\n    \n    \n      4\n      6.0\n      41.886974\n      -87.612813\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1877\n      TA1309000066\n      41.969101\n      -87.674234\n    \n    \n      1878\n      TA1309000067\n      41.803034\n      -87.606613\n    \n    \n      1879\n      WL-008\n      41.867122\n      -87.641071\n    \n    \n      1880\n      WL-011\n      41.880395\n      -87.642727\n    \n    \n      1881\n      WL-012\n      41.883364\n      -87.641203\n    \n  \n\n1882 rows × 3 columns\n\n\n\n\n\nNow for each station we want a JSON-area code\nThis is slightly convoluted - scroll through each station - for each station find if it’s inside a Chigao_JSON region - if not we assign if a value 1000 - for those with no region find the nearest station that has a JSON-region (done in tab after this)\nwhatChoro = json ID whatwhat = station ID\n\nfrom shapely.geometry import shape, Point\n\n\nwhatChoro=[]\nwhatwhat=[]\n# check each polygon to see if it contains the point\ni=0\n# scroll through each station\nfor istat in range(np.shape(dfStat)[0]):\n    i=0\n    #create a point for the station\n    point=Point(dfStat.loc[istat,'start_lng'],dfStat.loc[istat,'start_lat'])\n    \n    #scroll through each geometery\n    for feature in chicago.ID:\n        polygon = shape(chicago.loc[i,'geometry'])\n        if polygon.contains(point):\n            #this gives the json region ID\n            whatChoro.append(chicago.loc[i,'ID'])\n            #this give the station id\n            whatwhat.append(dfStat.loc[istat,'start_station_id'])\n            break \n        \n        #if we don't get a match!!\n        if feature==chicago['ID'].iloc[-1]:\n            \n            import copy\n            # find distances lat2/lng2 this location\n            # lat1/lng1 all locations\n            lat1_=copy.copy(dfStat['start_lat'])\n            lon1_=copy.copy(dfStat['start_lng'])\n            lat2_=dfStat.loc[istat,'start_lat']\n            lon2_=dfStat.loc[istat,'start_lng']\n\n            \n            #this gives the json region ID\n            whatChoro.append(1000)\n            #this give the station id\n            whatwhat.append(dfStat.loc[istat,'start_station_id'])\n            \n            \n        i=i+1\n\n\n\nThis does the cleaning up if they don’t have a json id\nThis will handle when we don’t get a match—> a reuse of the distance function with slight mods\n\ndef distanceLatLong_v2(lat1_,lon1_,lat2_,lon2_):\n    \n    import numpy as np\n    import math\n    def deg2rad(deg):\n        return deg * np.pi/180\n    def inner(lat1,lon1,lat2,lon2):\n        R = 6371; # Radius of the earth in km\n        dLat = deg2rad(lat2-lat1)  # deg2rad below\n        dLon = deg2rad(lon2-lon1)\n        a = np.sin(dLat/2) * np.sin(dLat/2) + \\\n        np.cos(deg2rad(lat1)) * np.cos(deg2rad(lat2)) * \\\n        np.sin(dLon/2) * np.sin(dLon/2)\n\n        c = 2 * math.atan2(np.sqrt(a), np.sqrt(1-a))\n        d = R * c ## Distance in km\n        if d==0:\n            d=1000\n        return d\n    if np.shape(lat1_)[0]>1:\n        d=[]\n        for i in range(np.shape(lat1_)[0]):\n            d.append(inner(lat1_[i],lon1_[i],lat2_,lon2_))\n        \n    else:\n        d=inner(lat1_,lon1_,lat2_,lon2_)   \n    \n    return d\n\nthis scrolls through ones we didn’t match and finds nearest JSON-id we did match\n\nfor i in range(np.shape(dfStat)[0]):\n    if whatChoro[i]==1000:\n             \n        #find distances lat2/lng2 this location\n        # lat1/lng1 all locations\n        lat1_=copy.copy(dfStat['start_lat'])\n        lon1_=copy.copy(dfStat['start_lng'])\n        lat2_=dfStat.loc[i,'start_lat']\n        lon2_=dfStat.loc[i,'start_lng']\n        ind=[idx for idx, element in enumerate(whatChoro) if element==1000]\n        lat1_[ind]=0\n        lon1_[ind]=0\n        d=distanceLatLong_v2(lat1_,lon1_,lat2_,lon2_)\n        indamin=d.index(min(d))\n#         whatwhat[i]=whatwhat[indamin]\n        whatChoro[i]=whatChoro[indamin]\n        \n        print(i,indamin,whatChoro[i],whatChoro[indamin],min(d))\n\n554 474 48 48 3.218616605981318\n555 474 48 48 1.5436541433245226\n556 474 48 48 0.7244340745224377\n557 554 48 48 1.618989106320433\n558 557 48 48 0.9589393666816851\n559 558 48 48 1.703490590200107\n560 559 48 48 1.0394756465095663\n561 554 48 48 0.5321339843549502\n562 561 48 48 0.8611490298165934\n563 561 48 48 0.4535879672825213\n570 554 48 48 0.7620712283526319\n603 562 48 48 0.7657516801324228\n604 1355 55 55 0.9398603094768803\n605 559 48 48 1.3757808765327746\n1441 554 48 48 0.0009191040374285816\n1442 1441 48 48 0.003706303019684898\n1443 555 48 48 0.006456249041029345\n1444 556 48 48 4.9908562509422157e-05\n1445 1444 48 48 0.002230404415936471\n1446 557 48 48 0.0012372240336437155\n1447 1446 48 48 0.003412919018808641\n1450 558 48 48 0.005285184511373336\n1451 1450 48 48 0.011408782497315317\n1452 559 48 48 0.027327480291422585\n1453 560 48 48 0.0012042612006966005\n1454 561 48 48 0.0010429138707679156\n1455 562 48 48 0.0017205826064828574\n1456 1455 48 48 0.0034819520850311483\n1457 563 48 48 0.0025804458419044335\n1458 563 48 48 0.009202498604403178\n1470 570 48 48 0.004764480272445732\n1513 603 48 48 0.0008354495738933785\n1514 603 48 48 0.0011940325501674988\n1515 604 55 55 0.006060872681823562\n1516 1515 55 55 0.012603279140811706\n1517 605 48 48 0.009833621616663023\n1582 555 48 48 0.0011726503764087032\n1583 559 48 48 0.0038048094986119284\n1584 1453 48 48 0.0005568291527966493\n1585 561 48 48 0.0005786222457187065\n1586 1447 48 48 0.5069880704727254\n1587 605 48 48 0.0032438412454957833\n\n\n\n\n\nNow we can insert a new column in df with the json ID\n\nchicID=[]\nfor stat in df['start_station_id']:\n#     chicID.append(stat)\n    ind=[idx for idx, element in enumerate(whatwhat) if element==stat]\n    try:\n        chicID.append(whatChoro[ind[0]])\n    except:\n        continue\n\n\ndf.insert(0,'ID',chicID)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Unnamed: 0\n      rideable_type\n      hire_time_h\n      day_week\n      time_day\n      start_station_id\n      end_station_id\n      start_lat\n      distance\n      start_lng\n      end_lat\n      end_lng\n      member_casual\n    \n  \n  \n    \n      0\n      40\n      0\n      classic_bike\n      0.176944\n      6\n      12.733333\n      13157\n      TA1306000003\n      41.877726\n      1.491984\n      -87.654787\n      41.888716\n      -87.644448\n      member\n    \n    \n      1\n      92\n      39\n      electric_bike\n      0.130556\n      4\n      13.883333\n      TA1309000006\n      TA1306000011\n      41.918112\n      2.144117\n      -87.643799\n      41.900129\n      -87.634448\n      member\n    \n    \n      2\n      97\n      50\n      electric_bike\n      0.030000\n      0\n      17.166667\n      KA1503000043\n      TA1306000003\n      41.889193\n      0.323238\n      -87.638576\n      41.889099\n      -87.642479\n      member\n    \n    \n      3\n      56\n      87\n      docked_bike\n      1.013056\n      3\n      13.600000\n      TA1309000014\n      TA1309000014\n      41.967096\n      0.000000\n      -87.667429\n      41.967096\n      -87.667429\n      casual\n    \n    \n      4\n      26\n      88\n      classic_bike\n      0.101111\n      6\n      13.150000\n      TA1305000006\n      KA1503000043\n      41.881320\n      1.147392\n      -87.629521\n      41.889177\n      -87.638506\n      member\n    \n  \n\n\n\n\n\n\nAnd represent each JSON region by how many times they’re used\nWe’ll take the count and divide it by the total- and because of the distribution we’ll also take the log- basically hires are highly focussed on a few regions with many having low %\n\ndfG=df.groupby('ID').count()\ndfG.reset_index(inplace=True)\ndfG=dfG[['ID','rideable_type']]\ndfG.rename(columns={'rideable_type':'Frequency'})\ndfG.rideable_type=np.log(dfG.rideable_type/sum(dfG.rideable_type))\ndfG.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      rideable_type\n    \n  \n  \n    \n      0\n      0\n      -5.835124\n    \n    \n      1\n      1\n      -5.124845\n    \n    \n      2\n      2\n      -6.001956\n    \n    \n      3\n      3\n      -3.718336\n    \n    \n      4\n      4\n      -4.965188\n    \n  \n\n\n\n\n\ndf.to_csv('/data/dfChoro_2020.csv')\n\n\ndf = pd.read_csv('/data/dfChoro_2020.csv')\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\n\n\n\nNow the plotting\nWe first read in the json file, add the df with our frequency values to it then we can plot the data\n\n\nLets put this in a function to look at differences\n\ndef bigChoro(dfIN,colname,choi):\n    import folium \n    \n    LEGNOM=colname\n    if choi=='count':\n        dfG=dfIN.groupby('ID').count()\n        dfG[colname]=dfG[colname]/(100*274/7)\n        myscale = (dfG[colname].quantile((0,0.25,0.5,0.75,0.9,0.95,.97,1))).tolist()\n#         np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n        LEGNOM='Number of journeys 100s per week'\n    elif choi=='mean':\n        dfG=dfIN.groupby('ID').mean()\n        myscale = np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n    elif choi=='sum':\n        dfG=dfIN.groupby('ID').sum()\n        myscale = np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n    elif choi=='dayofweek':\n        dfIN=dfIN[['ID',colname]]\n        dfG=dfIN.groupby(['ID']).agg(lambda x:x.value_counts().index[0])\n        dfG[dfG[colname]>4]=5-dfG[dfG[colname]>4]\n        myscale = np.array([-2.,0.,1.,2.,3.,4.])\n        LEGNOM='Day of week (-2 to -1 weekend, 0-4 Monday to Friday)'\n    elif choi=='mode':\n        dfIN=dfIN[['ID',colname]]\n        dfIN[colname].astype('int32')\n        dfG=dfIN.groupby(['ID']).agg(lambda x:x.value_counts().index[0])\n        myscale = np.linspace(dfG[colname].min(),dfG[colname].max(),10)\n        \n    dfG.reset_index(inplace=True)\n    dfG=dfG[['ID',colname]]\n\n\n    nil=gpd.read_file(\"Chi_.json\")\n    nil=nil[['ID','geometry']]\n\n    # merge data frames\n    nilpop=nil.merge(dfG,on=\"ID\")\n\n    #initial map\n    m = folium.Map(location=[41.884,-87.6247], zoom_start=10,\\\n       control_scale=True,tiles=\"Stamen Toner\")#,tiles = t_list[1])\n\n    folium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n\n   \n    # (dfG['rideable_type'].quantile((0,.02,0.1,.25,0.5,0.75,0.9,0.95,0.98,1))).tolist()\n    choropleth =folium.Choropleth(\n        geo_data=\"Chi_.json\", \n        data=nilpop,\n        threshold_scale=myscale,\n        columns=['ID',colname],\n        name='choropleth',\n        fill_color='BuPu',#PuBuGn YlGn PuBuGn YlGnBu RdYlBu\n        key_on= \"feature.properties.ID\",\n        fill_opacity=0.7,\n        line_opacity=0.2,\n        nan_fill_color='gray',\n        legend_name=LEGNOM, \n        nan_fill_opacity =.5,\n        ).add_to(m)\n    folium.LayerControl().add_to(m)\n    choropleth.geojson.add_child(\n        folium.features.GeoJsonTooltip(['pri_neigh'],labels=False)\n        )\n    return m\n\n\ndfIN.columns\n\nIndex(['ID', 'Unnamed: 0', 'rideable_type', 'hire_time_h', 'day_week',\n       'time_day', 'start_station_id', 'end_station_id', 'start_lat',\n       'distance', 'start_lng', 'end_lat', 'end_lng', 'member_casual'],\n      dtype='object')\n\n\n\ncolname='distance'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'mean')\nm\n\n\n\ncolname='day_week'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'dayofweek')\nm\n\n\n\ncolname='time_day'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'mode')\nm\n\n\n\ncolname='time_day'#end_station_id\ndfIN= df[df.member_casual=='member']\nm=bigChoro(dfIN,colname,'count')\nm\n\n\n\ncolname='time_day'#end_station_id\ndfIN= df[df.member_casual=='casual']\nm=bigChoro(dfIN,colname,'count')\nm\n\n\n\nnp.linspace(-2,4,7)\nnp.array([-2.,0.,1.,2.,3.,4.])\n\narray([-2.,  0.,  1.,  2.,  3.,  4.])\n\n\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n\nsns.set_theme(style=\"ticks\")\n\nf, ax = plt.subplots(figsize=(7, 5))\nsns.despine(f)\n\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(df,hue=\"member_casual\", x=\"time_day\",\n            multiple=\"stack\",\n            palette=\"dark:b_r\",\n            edgecolor=\".3\",\n            linewidth=.5,)\nsns.despine(offset=10, trim=True)\n\n\n\n\n\nfrom matplotlib.ticker import PercentFormatter\ndf_=df[df.hire_time_h<5]\ndf_=df_[df_.hire_time_h>0]\nsns.set_theme(style=\"ticks\")\n\nbinwidth = 5\n\nf, ax1 = plt.subplots(figsize=(10, 7))\nsns.despine(f)\ndf2_=df_[df_.member_casual=='member']\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(df2_, x=\"hire_time_h\",\n            multiple=\"stack\",\n            palette=\"light:m_r\",\n            edgecolor=\".3\",\n            linewidth=.5,\n            stat='probability',\n            log_scale=True,\n            ax=ax1,\n            label='member')\n\nax2=ax1.twinx()\n\ndf2_=df_[df_.member_casual=='casual']\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(df2_, x=\"hire_time_h\",\n             element=\"step\",fill=False,\n             color='red',\n            linewidth=.8,\n            stat='probability',\n            log_scale=True,\n            ax=ax2,\n            label='casual')\n\nax1.legend(loc='upper left')\nax2.legend(loc='upper right')\nsns.despine(offset=10, trim=True)\n# ax.legend('Member','Casual')\n\n\n\n\n\nsns.set_theme(style=\"ticks\")\n\nf, ax = plt.subplots(figsize=(10, 8))\nsns.despine(f)\ndf_=df[ df[\"distance\"]>0.1 ]\ndf_= df_[df_[\"distance\"]<20]\ndf_=df_[df_.member_casual=='member']\n# Draw a nested boxplot to show bills by day and time\nsns.histplot(data=df_, x=\"distance\",\n            edgecolor=\".3\",\n            linewidth=.5,\n            stat='probability',\n             label='member')\nsns.despine(offset=10, trim=True)\ndf_=df[df[\"distance\"]>0.1]\ndf_= df_[df_[\"distance\"]<20]\ndf_=df_[df_.member_casual=='casual']\nsns.histplot(data=df_, x=\"distance\",\n            linewidth=.8,\n            color='r',\n            stat='probability',\n             label='casual',\n            fill=False,\n            element='step')\n\nax.legend(loc='upper right')\n\n<matplotlib.legend.Legend at 0x2f212cc0be0>\n\n\n\n\n\n\n# f, ax = plt.subplots(figsize=(7, 5))\nsns.set_theme(style=\"whitegrid\")\n\n# Draw a nested boxplot to show bills by day and time\nax=sns.histplot(df,hue=\"member_casual\", \n             x=\"day_week\",palette=\"dark:b_r\",\n             multiple=\"dodge\",\n             bins=[0 ,1 ,2 ,3, 4, 5, 6,7],\n             shrink=.9\n            )\nsns.despine(offset=20, trim=True)\naa=np.array([0,1,2,3,4,5,6])+.5\nax.set_xticks(aa)\nax.set_xlim([0, 7.5])\nlab=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\nax.set_xticklabels(lab,rotation='vertical')\nax.set_xlabel('Day of the week')\n\nText(0.5, 0, 'Day of the week')\n\n\n\n\n\n\n\nSo after a quick look at the data (*maybe some plots need mods) some clear trends:\n\nCasuals use bikes more on weekends, members more on weekdays\nMembers tend to use bikes in commuting times 7-9 am and 4-7 pm. Whereas casuals more spread but focussed later\nCasuals tend to use the bikes for longer and travel further from initial location"
  },
  {
    "objectID": "posts/2021-11-17-StyleTransfer.html#introduction",
    "href": "posts/2021-11-17-StyleTransfer.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nUse two images a content image and style image to create a new image of the content image in the style of the style image.\nSource used, Deep Learning Specialization Week 4 https://www.coursera.org/lecture/convolutional-neural-networks/what-is-neural-style-transfer-SA5H8\n\nyoutube: https://youtu.be/R39tWYYKNcI\n\nFrom original NST paper published by the Visual Geometry Group at University of Oxford in 2014"
  },
  {
    "objectID": "posts/2021-11-17-StyleTransfer.html#code",
    "href": "posts/2021-11-17-StyleTransfer.html#code",
    "title": "ThomasHSimm",
    "section": "Code",
    "text": "Code\nSome imports\n\nimport os\nimport sys\nimport scipy.io\nimport scipy.misc\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework.ops import EagerTensor\nimport pprint\n%matplotlib inline\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\nSet the style image\n\nstyle_image = np.array(Image.open(\"/content/drive/MyDrive/Colab Notebooks/Tiles.jpg\"))\n\nimshow(style_image)\n\n\nAnd the content image\n\n\ncontent_image = np.array(Image.open(\"/content/drive/MyDrive/Colab Notebooks/boat.jpg\"))\n\nprint(np.shape(content_image))\nimshow(content_image)   \n\n\nResize the images\n\n#gonna reduce to a square image of size in pixels of\nimg_size = 1100\n\n# get image as array, then resize\ncontent_image = Image.fromarray(content_image)\ncontent_image =np.array(content_image.resize((img_size, img_size)))\n\n# create content image as tf tensor\ncontent_image = tf.constant(np.reshape(content_image, ((1,) + content_image.shape)))\n\n\n\n# same for style image\n\nstyle_image = Image.fromarray(style_image)\nstyle_image = np.array(style_image.resize((img_size, img_size)))\n\nstyle_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n\n\nLoad parameters from the VGG model. A pretrained model for image classification\nhttps://www.robots.ox.ac.uk/~vgg/research/very_deep/\nhttps://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md\n\ntf.random.set_seed(272)\npp = pprint.PrettyPrinter(indent=4)\n\n\nvgg = tf.keras.applications.VGG19(include_top=False,\n                                  input_shape=(img_size, img_size, 3),\n                                  weights='/content/drive/MyDrive/Colab Notebooks/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\nvgg.trainable = False\npp.pprint(vgg)\n\n<keras.engine.functional.Functional object at 0x7f84e154af90>\n\n\nNow choose layers to represent the style of the image and assign style costs: Lower number more basic features\n\nSTYLE_LAYERS = [\n    ('block1_conv1', .2),\n    ('block2_conv1', .2),\n    ('block3_conv1', .2),\n    ('block4_conv1', .2),\n    ('block5_conv1', .2)]\n\nCompute the “content cost” using TensorFlow.\n\ndef compute_content_cost(content_output, generated_output):\n    \"\"\"\n    Computes the content cost\n    \n    Arguments:\n    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n    \n    Returns: \n    J_content -- scalar that you compute using equation 1 above.\n    \"\"\"\n    a_C = content_output[-1]\n    a_G = generated_output[-1]\n       \n    \n    # Retrieve dimensions from a_G \n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n    \n    # Reshape a_C and a_G \n    a_C_unrolled = tf.reshape(a_C, shape=[m, n_H * n_W, n_C])\n    a_G_unrolled = tf.reshape(a_G, shape=[m, n_H * n_W, n_C])\n    \n    # compute the cost with tensorflow \n    J_content =  (1/(4*n_H*n_W*n_C) )*tf.reduce_sum(tf.square( tf.subtract(a_C_unrolled, a_G_unrolled ) ))\n    \n    \n    \n    return J_content\n\nthe gram matrix of A is 𝐺𝐴=𝐴𝐴𝑇.\n\ndef gram_matrix(A):\n    \"\"\"\n    Argument:\n    A -- matrix of shape (n_C, n_H*n_W)\n    \n    Returns:\n    GA -- Gram matrix of A, of shape (n_C, n_C)\n    \"\"\"  \n    \n    \n    GA = tf.linalg.matmul(\n    A, A, transpose_b=True)\n    \n\n    return GA\n\nCompute the style cost for a single layer.\n\ndef compute_layer_style_cost(a_S, a_G):\n    \"\"\"\n    Arguments:\n    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n    \n    Returns: \n    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n    \"\"\"\n\n    \n    # Retrieve dimensions from a_G \n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n    \n    # Reshape the images from (n_H * n_W, n_C) to have them of shape (n_C, n_H * n_W) \n    a_S = tf.transpose(a_S)\n    a_S=tf.reshape(a_S, shape=[n_C, n_H * n_W])\n    a_G = tf.transpose(a_G)#, shape=[n_C, n_H * n_W])\n    a_G=tf.reshape(a_G, shape=[n_C, n_H * n_W])\n    \n    print(np.shape(a_S))\n    \n    # Computing gram_matrices for both images S and G \n    GS = gram_matrix(a_S)\n    GG = gram_matrix(a_G)\n    \n    # Computing the loss (≈1 line)\n    J_style_layer = J_content =  (1/(4*(n_H*n_W)**2*n_C**2) )*tf.reduce_sum(tf.square( tf.subtract(GS, GG ) ))\n    \n    \n    \n    return J_style_layer\n\nCompute style cost function, Calls individual layers cost funcxtion and applies a weight based on variable STYLE_LAYERS\n\ndef compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):\n    \"\"\"\n    Computes the overall style cost from several chosen layers\n    \n    Arguments:\n    style_image_output -- our tensorflow model\n    generated_image_output --\n    STYLE_LAYERS -- A python list containing:\n                        - the names of the layers we would like to extract style from\n                        - a coefficient for each of them\n    \n    Returns: \n    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n    \"\"\"\n    \n    # initialize the overall style cost\n    J_style = 0\n\n    # Set a_S to be the hidden layer activation from the layer we have selected.\n    # The last element of the array contains the content layer image, which must not to be used.\n    a_S = style_image_output[:-1]\n\n    # Set a_G to be the output of the choosen hidden layers.\n    # The last element of the array contains the content layer image, which must not to be used.\n    a_G = generated_image_output[:-1]\n    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  \n        # Compute style_cost for the current layer\n        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])\n\n        # Add weight * J_style_layer of this layer to overall style cost\n        J_style += weight[1] * J_style_layer\n\n    return J_style\n\nA total cost function including both style and content costs\n\n@tf.function()\ndef total_cost(J_content, J_style, alpha = 10, beta = 40):\n    \"\"\"\n    Computes the total cost function\n    \n    Arguments:\n    J_content -- content cost coded above\n    J_style -- style cost coded above\n    alpha -- hyperparameter weighting the importance of the content cost\n    beta -- hyperparameter weighting the importance of the style cost\n    \n    Returns:\n    J -- total cost as defined by the formula above.\n    \"\"\"\n    \n    J = alpha*J_content +beta*J_style\n    \n    \n    return J\n\n ### 5.3 Randomly Initialize the Image to be Generated Now, you get to initialize the “generated” image as a noisy image created from the content_image.\n\nThe generated image is slightly correlated with the content image.\nBy initializing the pixels of the generated image to be mostly noise but slightly correlated with the content image, this will help the content of the “generated” image more rapidly match the content of the “content” image.\n\n\ngenerated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n# noise = tf.random.uniform(tf.shape(generated_image), 0, 0.5)\n# generated_image = tf.add(generated_image, noise)\ngenerated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)\n\ndefine a function which loads the VGG19 model and returns a list of the outputs for the middle layers.\n\ndef get_layer_outputs(vgg, layer_names):\n    \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n    outputs = [vgg.get_layer(layer[0]).output for layer in layer_names]\n\n    model = tf.keras.Model([vgg.input], outputs)\n    return model\n\nNow, define the content layer and build the model.\n\ncontent_layer = [('block5_conv4', 1)]\n\nvgg_model_outputs = get_layer_outputs(vgg, STYLE_LAYERS + content_layer)\n\nSave the outputs for the content and style layers in separate variables.\n\ncontent_target = vgg_model_outputs(content_image)  # Content encoder\nstyle_targets = vgg_model_outputs(style_image)     # Style enconder\n\n\n# Assign the content image to be the input of the VGG model.  \n# Set a_C to be the hidden layer activation from the layer we have selected\npreprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\na_C = vgg_model_outputs(preprocessed_content)\n\n# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input.\na_G = vgg_model_outputs(generated_image)\n\n# Compute the content cost\nJ_content = compute_content_cost(a_C, a_G)\n\nprint(J_content)\n\ntf.Tensor(0.0, shape=(), dtype=float32)\n\n\nsets a_S to be the tensor giving the hidden layer activation for STYLE_LAYERS.\n\n# Assign the input of the model to be the \"style\" image \npreprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\na_S = vgg_model_outputs(preprocessed_style)\n\n# Compute the style cost\nJ_style = compute_style_cost(a_S, a_G)\nprint(J_style)\n\n(64, 1210000)\n(128, 302500)\n(256, 75625)\n(512, 18769)\n(512, 4624)\ntf.Tensor(2067.7974, shape=(), dtype=float32)\n\n\nUtils that you will need to display the images generated by the style transfer model.\n\ndef clip_0_1(image):\n    \"\"\"\n    Truncate all the pixels in the tensor to be between 0 and 1\n    \n    Arguments:\n    image -- Tensor\n    J_style -- style cost coded above\n\n    Returns:\n    Tensor\n    \"\"\"\n    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n\ndef tensor_to_image(tensor):\n    \"\"\"\n    Converts the given tensor into a PIL image\n    \n    Arguments:\n    tensor -- Tensor\n    \n    Returns:\n    Image: A PIL image\n    \"\"\"\n    tensor = tensor * 255\n    tensor = np.array(tensor, dtype=np.uint8)\n    if np.ndim(tensor) > 3:\n        assert tensor.shape[0] == 1\n        tensor = tensor[0]\n    return Image.fromarray(tensor)\n\n\nTrain a step\nlearning rate lower slower\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.03)\n\n@tf.function()\ndef train_step(generated_image):\n    with tf.GradientTape() as tape:\n        # In this function you must use the precomputed encoded images a_S and a_C\n        # Compute a_G as the vgg_model_outputs for the current generated image\n        \n\n        a_G = vgg_model_outputs(generated_image)\n        # Compute the style cost\n     \n        J_style = compute_style_cost(a_S, a_G)\n\n        \n        # Compute the content cost\n        J_content = compute_content_cost(a_C, a_G)\n        # Compute the total cost\n        J = total_cost(J_content, J_style, alpha = 10, beta = 40)  \n        \n        \n        \n    grad = tape.gradient(J, generated_image)\n\n    optimizer.apply_gradients([(grad, generated_image)])\n    generated_image.assign(clip_0_1(generated_image))\n  \n    return J\n\n\n\n\nTrain the Model\n\n# Show the generated image at some epochs\n# Uncoment to reset the style transfer process. You will need to compile the train_step function again \ngenerated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\nepochs = 5001\nfor i in range(epochs):\n    train_step(generated_image)\n    if i % 100 == 0:\n        print(f\"Epoch {i} \")\n    if i % 100 == 0:\n        image = tensor_to_image(generated_image)\n        imshow(image)\n        image.save(f\"image_{i}.jpg\")"
  },
  {
    "objectID": "posts/2021-11-17-StyleTransfer.html#some-examples",
    "href": "posts/2021-11-17-StyleTransfer.html#some-examples",
    "title": "ThomasHSimm",
    "section": "Some Examples",
    "text": "Some Examples"
  },
  {
    "objectID": "posts/2021-11-18-WebScraping.html#overview",
    "href": "posts/2021-11-18-WebScraping.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n Photo by Ilya Pavlov on Unsplash\n“Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites.” from https://en.wikipedia.org/wiki/Web_scraping\n\nThere are legal issues around web scraping, so be careful “The legality of web scraping varies across the world. In general, web scraping may be against the terms of use of some websites, but the enforceability of these terms is unclear.”\n\nThe first step is to go to a website and add /robots.txt onto the end of the web address to see what they allow. Most will disallow most areas.\nI am only doing this for research and learning purposes and the information is all available freely."
  },
  {
    "objectID": "posts/2021-11-18-WebScraping.html#indeed-beautifulsoup-and-pandas",
    "href": "posts/2021-11-18-WebScraping.html#indeed-beautifulsoup-and-pandas",
    "title": "ThomasHSimm",
    "section": "Indeed, BeautifulSoup and Pandas",
    "text": "Indeed, BeautifulSoup and Pandas\n\nPhoto by Clem Onojeghuo on Unsplash\nIndeed has a wealth of job information across the UK and beyond for virtually every job. So whether you are looking for work or examining economic activity, it is a good resource. But how do you get the data from the website into a form you can work with?\n            By web scraping Indeed \n\nExamine the website\nThe first step in web scraping is to examine the website. Here I’ll use Google Chrome, but the same capabilities are in most browsers. Let’s open indeed and do a search for jobs in an area. The output is below\n\nWhen searching for “electrician mate” in the location Swansea we get the url https://uk.indeed.com/jobs?q=electrician+mate&l=Swansea%2C+Swansea.\nHence, in Python we can specify the url as follows, this allows us to change for job type and location later if we want:\n\nlocation=\"Swansea%2C+Swansea\"\njobtype=\"electrician+mate\"\n\nURL=\"https://uk.indeed.com/jobs?q=\"+jobtype+\"&l=\"+location\nURL\n\n'https://uk.indeed.com/jobs?q=electrician+mate&l=Swansea%2C+Swansea'\n\n\nNext open developer tools on Chrome (Ctrl+Shift+I or More Tools-> developer tools)\n\nThen click on the icon circled in the image below to examine the website. Placing the cursor over the website reveals the html structure. When this is done on one of the job blocks we can see that it is identified as:\n\n<div class=\"job_seen_beacon\">\nOR\n<a id=\"..........>\n\nExamining other blocks shows this is repeated for them all. So we can get the job blocks!\nWe’ll return to this later…\n\n\nBeautifulSoup\nBeautiful soup (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python library for pulling data out of HTML and XML files. Something similar can be done with pandas, but for this situation I’ll use the soup.\n\n#import the libraries\nimport requests\nimport bs4\nfrom bs4 import BeautifulSoup\n\nTo use: the libraries are loaded, then get get the page, then pass to Beautiful soup.\nSoup can be viewed. But it is still a mess so we’ll now use what we learned about the job tabs and extract these.\n\n#collapse-output\n#Using beautiful soup-get page\npage = requests.get(URL)\n#get soup\nsoup = BeautifulSoup(page.text, \"html.parser\")\nsoup\n\n<!DOCTYPE html>\n<html><head><meta content=\"website\" property=\"og:type\"/><meta content=\"Matmatch\" name=\"apple-mobile-web-app-title\"/><meta content=\"Matmatch\" name=\"application-name\"/><link href=\"/static/images/favicon/favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/><link href=\"/static/images/favicon/favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/><link href=\"/static/images/favicon/apple-touch-icon.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/><link href=\"/static/images/favicon/manifest.json\" rel=\"manifest\"/><link color=\"#526294}\" href=\"/static/images/favicon/safari-pinned-tab.svg\" rel=\"mask-icon\"/><link href=\"/static/images/favicon/favicon.ico?v2=pgrv6keokB\" rel=\"shortcut icon\"/><script src=\"https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js\"></script><script>WebFont.load({custom: {families: [\"Open Sans\"],urls: [\"/static/fonts/fonts.css\"]}});</script><script type=\"application/ld+json\">{\n              \"@context\": \"http://schema.org\",\n              \"@type\": \"Corporation\",\n              \"name\": \"Matmatch\",\n              \"url\": \"https://matmatch.com\",\n              \"logo\": \"https://matmatch.com/blog/wp-content/uploads/2019/01/matmatch_logo_stacked_large.png\",\n              \"contactPoint\": {\n              \"@type\": \"ContactPoint\",\n              \"telephone\": \"+49089262075200\",\n              \"contactType\": \"customer service\",\n              \"availableLanguage\": [\"English\",\"Spanish\",\"German\"]\n            },\n              \"sameAs\": [\n              \"https://www.facebook.com/MatmatchGmbH/\",\n              \"https://twitter.com/matmatchgmbh\",\n              \"https://www.youtube.com/channel/UCUaSuhkac7eIGDt_oslErqg\",\n              \"https://www.linkedin.com/company/matmatch/\"\n              ]\n            }</script><meta charset=\"utf-8\"/><meta content=\"initial-scale=1.0, width=device-width\" name=\"viewport\"/><meta content=\"/static/images/og-homepage.png\" property=\"og:image\"/><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n          new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n        })(window,document,'script','dataLayer','GTM-PV6RPFJ');</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n            ga('create', 'UA-85033665-5', { 'cookieName': '_ga', 'cookieExpires': 0, storeGac: false });\n            ga('require', 'GTM-KQK3NFF');\n            ga('set', 'anonymizeIp', true);\n          </script><title>Advanced Search - Matmatch</title><meta content=\"6\" name=\"next-head-count\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-5cd94c89d3acac5f.js\"></script><script defer=\"\" src=\"/_next/static/chunks/webpack-7f7ce7d3b611b805.js\"></script><script defer=\"\" src=\"/_next/static/chunks/framework-00d20ba7ea4a049e.js\"></script><script defer=\"\" src=\"/_next/static/chunks/main-e7e93353c7fa0f3d.js\"></script><script defer=\"\" src=\"/_next/static/chunks/pages/_app-d283c11d990f5118.js\"></script><script defer=\"\" src=\"/_next/static/chunks/4287-f7e14c54c16c4711.js\"></script><script defer=\"\" src=\"/_next/static/chunks/8423-5df76c682adf5f31.js\"></script><script defer=\"\" src=\"/_next/static/chunks/5345-398cd87d7cf78279.js\"></script><script defer=\"\" src=\"/_next/static/chunks/3789-912517a4e13b4a43.js\"></script><script defer=\"\" src=\"/_next/static/chunks/pages/advanced-search-2c198b26c959d4ab.js\"></script><script defer=\"\" src=\"/_next/static/d4287122/_buildManifest.js\"></script><script defer=\"\" src=\"/_next/static/d4287122/_ssgManifest.js\"></script><script defer=\"\" src=\"/_next/static/d4287122/_middlewareManifest.js\"></script><style data-styled=\"\" data-styled-version=\"5.3.3\">html{line-height:1.15;-webkit-text-size-adjust:100%;}/*!sc*/\nbody{margin:0;}/*!sc*/\nmain{display:block;}/*!sc*/\nh1{font-size:2em;margin:0.67em 0;}/*!sc*/\nhr{box-sizing:content-box;height:0;overflow:visible;}/*!sc*/\npre{font-family:monospace,monospace;font-size:1em;}/*!sc*/\na{background-color:transparent;}/*!sc*/\nabbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;}/*!sc*/\nb,strong{font-weight:bolder;}/*!sc*/\ncode,kbd,samp{font-family:monospace,monospace;font-size:1em;}/*!sc*/\nsmall{font-size:80%;}/*!sc*/\nsub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline;}/*!sc*/\nsub{bottom:-0.25em;}/*!sc*/\nsup{top:-0.5em;}/*!sc*/\nimg{border-style:none;}/*!sc*/\nbutton,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0;}/*!sc*/\nbutton,input{overflow:visible;}/*!sc*/\nbutton,select{text-transform:none;}/*!sc*/\nbutton,[type=\"button\"],[type=\"reset\"],[type=\"submit\"]{-webkit-appearance:button;}/*!sc*/\nbutton::-moz-focus-inner,[type=\"button\"]::-moz-focus-inner,[type=\"reset\"]::-moz-focus-inner,[type=\"submit\"]::-moz-focus-inner{border-style:none;padding:0;}/*!sc*/\nbutton:-moz-focusring,[type=\"button\"]:-moz-focusring,[type=\"reset\"]:-moz-focusring,[type=\"submit\"]:-moz-focusring{outline:1px dotted ButtonText;}/*!sc*/\nfieldset{padding:0.35em 0.75em 0.625em;}/*!sc*/\nlegend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;}/*!sc*/\nprogress{vertical-align:baseline;}/*!sc*/\ntextarea{overflow:auto;}/*!sc*/\n[type=\"checkbox\"],[type=\"radio\"]{box-sizing:border-box;padding:0;}/*!sc*/\n[type=\"number\"]::-webkit-inner-spin-button,[type=\"number\"]::-webkit-outer-spin-button{height:auto;}/*!sc*/\n[type=\"search\"]{-webkit-appearance:textfield;outline-offset:-2px;}/*!sc*/\n[type=\"search\"]::-webkit-search-decoration{-webkit-appearance:none;}/*!sc*/\n::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;}/*!sc*/\ndetails{display:block;}/*!sc*/\nsummary{display:list-item;}/*!sc*/\ntemplate{display:none;}/*!sc*/\n[hidden]{display:none;}/*!sc*/\ndata-styled.g1[id=\"sc-global-ecVvVt1\"]{content:\"sc-global-ecVvVt1,\"}/*!sc*/\n.uluvW{margin:0;overflow:hidden;list-type:none;padding:0;}/*!sc*/\ndata-styled.g7[id=\"list__List-sc-7ainlj-0\"]{content:\"uluvW,\"}/*!sc*/\n.RbSSA{color :#fff;text-align:left;}/*!sc*/\n.bzfZbQ{color :#fff;}/*!sc*/\n.bzfZbQ:not(:last-child){margin-bottom:6px;}/*!sc*/\n.cJazBI{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color :#fff;}/*!sc*/\n.cJazBI:not(:last-child){margin-bottom:6px;}/*!sc*/\n.gJZFKn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color :#fff;}/*!sc*/\ndata-styled.g8[id=\"list__ListItem-sc-7ainlj-1\"]{content:\"RbSSA,bzfZbQ,cJazBI,gJZFKn,\"}/*!sc*/\n.ghQHoL{max-width:100%;margin:0;font-size :28px;font-weight :600;color:#3a4056;}/*!sc*/\n.fEFHaQ{max-width:100%;margin:0;font-size :15px;color:#3a4056;margin-bottom:36px;}/*!sc*/\n.fcGhiO{max-width:100%;margin:0;font-size :15px;color :#3880E5;display :inline-block;cursor :pointer;-webkit-text-decoration:underline;text-decoration:underline;margin-left:24px;}/*!sc*/\n.hJBnMN{max-width:100%;margin:0;font-size :16px;color :#ffffff;cursor :pointer;-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.hJBnMN:hover{color:#e0e0e0;}/*!sc*/\n.kFbVgZ{max-width:100%;margin:0;font-size :15px;font-weight :600;color :white;margin:3.5999999999999996px;}/*!sc*/\n.wmqFD{max-width:100%;margin:0;font-size :16px;font-weight :600;color :#526193;margin-bottom:12px;}/*!sc*/\n.cJojhb{max-width:100%;margin:0;font-size :12px;color:#3a4056;text-align :center;margin-top:6px;}/*!sc*/\n.dzDHxo{max-width:100%;margin:0;font-size :15px;color:#3a4056;}/*!sc*/\n.dSdjdP{max-width:100%;margin:0;font-size :15px;color :#526193;}/*!sc*/\n.ehJUxb{max-width:100%;margin:0;font-size :16px;color :#4f4f4f;white-space:nowrap;margin-right:12px;}/*!sc*/\n.jLqxex{max-width:100%;margin:0;font-size :15px;font-weight :600;color :#526193;text-transform:uppercase;}/*!sc*/\n.cgTHVD{max-width:100%;margin:0;font-size :13px;color :#333333;}/*!sc*/\n.hjLFxX{max-width:100%;margin:0;font-size :13px;color:#3a4056;display :inline-block;margin-left:6px;}/*!sc*/\n.ldWNpx{max-width:100%;margin:0;font-size :13px;font-weight :600;color :#3880E5;cursor :pointer;}/*!sc*/\n.LLywI{max-width:100%;margin:0;font-size :13px;color :#333333;margin-bottom:6px;}/*!sc*/\n.hjtwVq{max-width:100%;margin:0;font-size :16px;color :#333333;}/*!sc*/\n.hLVIHw{max-width:100%;margin:0;font-size :15px;font-weight :600;color :#526193;margin-bottom:12px;}/*!sc*/\n.KmEHA{max-width:100%;margin:0;font-size :13px;color :#333333;margin-left:6px;}/*!sc*/\n.fWynpt{max-width:100%;margin:0;font-size :13px;color :#333333;display :inline-block;}/*!sc*/\n.eUTBqM{max-width:100%;margin:0;font-size :16px;color :#ff8200;}/*!sc*/\n.hMWWGw{max-width:100%;margin:0;font-size :16px;color :#828282;}/*!sc*/\n.iidREl{max-width:100%;margin:0;font-size :13px;color :#828282;}/*!sc*/\n.lolWkU{max-width:100%;margin:0;font-size :13px;color:#3a4056;display :inline-block;margin-right:6px;}/*!sc*/\n.tenyk{max-width:100%;margin:0;font-size :20px;font-weight :600;color :#526193;}/*!sc*/\n.GTisG{max-width:100%;margin:0;font-size :16px;color :#333333;display :inline-block;margin-left:12px;}/*!sc*/\ndata-styled.g10[id=\"text__Text-sc-f4nboj-0\"]{content:\"ghQHoL,fEFHaQ,fcGhiO,hJBnMN,kFbVgZ,wmqFD,cJojhb,dzDHxo,dSdjdP,ehJUxb,jLqxex,cgTHVD,hjLFxX,ldWNpx,LLywI,hjtwVq,hLVIHw,KmEHA,fWynpt,eUTBqM,hMWWGw,iidREl,lolWkU,tenyk,GTisG,\"}/*!sc*/\n.ipttFt{cursor:pointer;color:#03c7a7;display:block;margin:0 auto;}/*!sc*/\n.ipttFt:hover{color:#02a187;-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.eYFpTR{cursor:pointer;color:#03c7a7;}/*!sc*/\n.eYFpTR:hover{-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.eePTOF{cursor:pointer;color:#03c7a7;display:block;}/*!sc*/\n.eePTOF:hover{color:#02a187;-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.fpFFKD{cursor:pointer;color:#03c7a7;}/*!sc*/\n.fpFFKD:hover{color:#02a187;-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.QbWNQ{cursor:pointer;color:#3880E5;display:block;font-weight:600;}/*!sc*/\n.QbWNQ:hover{-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.dhcylR{cursor:pointer;color:#333333;font-size:13px;font-weight:600;}/*!sc*/\n.dhcylR:hover{-webkit-undefined;-ms-flex-undefined;undefined;}/*!sc*/\n.kdVFv{cursor:pointer;color:#333333;}/*!sc*/\n.kdVFv:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\ndata-styled.g18[id=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0\"]{content:\"ipttFt,eYFpTR,eePTOF,fpFFKD,QbWNQ,dhcylR,kdVFv,\"}/*!sc*/\n.jkkDbK{background-position:center;background-repeat:no-repeat;background-color:transparent;background-image:url('/static/images/inlined/logo_inverted.svg');width:167px;height:37px;}/*!sc*/\n.dOZIXC{background-position:center;background-repeat:no-repeat;background-color:transparent;background-image:url('/static/images/inlined/logo_inverted.svg');width:95px;height:22px;}/*!sc*/\ndata-styled.g20[id=\"styled-link-styles__ImageLinkStyles-sc-l1ctuc-2\"]{content:\"jkkDbK,dOZIXC,\"}/*!sc*/\n.lhTnpm{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;padding:14.399999999999999px 18px;font-size:16px;font-weight:600;}/*!sc*/\n.MSVaf{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;}/*!sc*/\n.kPiOHq{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;width:100%;padding:18px 24px;font-size:20px;font-weight:600;}/*!sc*/\n.NWGvI{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;width:100%;}/*!sc*/\n.eGHzTm{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;opacity:0.7;pointer-events:none;background-repeat:no-repeat;background-size:12px;background-image:url(\"/static/images/icons/2.0/white/arrow-back.svg\");padding:14.399999999999999px 18px;background-position:center;margin-right:24px;}/*!sc*/\n.ljvJNw{cursor:pointer;text-align:center;display:inline-block;padding:6px 12px;-webkit-transition:background-color 0.15s;transition:background-color 0.15s;border-radius:4px;background-repeat:no-repeat;background-size:12px;background-image:url(\"/static/images/icons/2.0/white/arrow-forward.svg\");padding:14.399999999999999px 18px;background-position:center;margin-left:24px;}/*!sc*/\ndata-styled.g29[id=\"button__BaseButton-sc-ekfcy0-0\"]{content:\"lhTnpm,MSVaf,kPiOHq,NWGvI,eGHzTm,ljvJNw,\"}/*!sc*/\n.nqeas{color:#ffffff;background-color:#3880E5;border:1px solid #4c8de8;}/*!sc*/\ndata-styled.g30[id=\"button__ButtonPrimary-sc-ekfcy0-1\"]{content:\"nqeas,\"}/*!sc*/\n.kTlrHY{color:#ffffff;border:1px solid #bdbdbd;background-color:#828282;}/*!sc*/\ndata-styled.g31[id=\"button__ButtonDefault-sc-ekfcy0-2\"]{content:\"kTlrHY,\"}/*!sc*/\n.juQzaQ{color:#ffffff;border:1px solid #ffd8af;background-color:#ff8200;}/*!sc*/\n.juQzaQ:hover{background-color:#cc6900;}/*!sc*/\ndata-styled.g33[id=\"button__ButtonSpecial-sc-ekfcy0-4\"]{content:\"juQzaQ,\"}/*!sc*/\n.gKwwSj{color:#ffffff;border:1px solid #7cd16d;background-color:#67ac5b;}/*!sc*/\n.gKwwSj:hover{background-color:#48A43F;}/*!sc*/\ndata-styled.g34[id=\"button__ButtonSuccess-sc-ekfcy0-5\"]{content:\"gKwwSj,\"}/*!sc*/\n.jUHcrU{display:inline-block;cursor:pointer;}/*!sc*/\n.hrfsee{margin-bottom:24px;}/*!sc*/\n.hrfsee:after{content:\" \";display:block;height:0;clear:both;}/*!sc*/\n.cdlmON:after{content:\" \";display:block;height:0;clear:both;}/*!sc*/\n.zDQjJ{margin-bottom:24px;}/*!sc*/\n.kneKJ{text-align:center;}/*!sc*/\n.kTmWRN{margin-left:24px;}/*!sc*/\n.kqTmue{width :438px;}/*!sc*/\n.UxvCa{margin-top:6px;margin-bottom:6px;}/*!sc*/\n.bcLXBB{margin-bottom:6px;}/*!sc*/\n.bRaHnE{margin-bottom:12px;}/*!sc*/\n.dTGKOg{margin-left:12px;}/*!sc*/\n.kXMRZj{max-width :1170px;margin :0 auto;}/*!sc*/\n.eHEnyb{max-width :1200px;margin :0 auto;}/*!sc*/\ndata-styled.g38[id=\"wrappers__Wrapper-sc-14fw43j-0\"]{content:\"cJNByu,jUHcrU,hrfsee,cdlmON,zDQjJ,kneKJ,kTmWRN,kqTmue,UxvCa,bcLXBB,bRaHnE,dTGKOg,kXMRZj,eHEnyb,\"}/*!sc*/\n.hFcCJB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\n.gFqwTB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content :space-between;-ms-flex-pack:justify;justify-content :space-between;}/*!sc*/\n.dMXLyl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n.cwHZQB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content :space-between;-ms-flex-pack:justify;justify-content :space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n.cdLigN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content :space-between;-ms-flex-pack:justify;justify-content :space-between;}/*!sc*/\ndata-styled.g41[id=\"wrappers__WrapperFlex-sc-14fw43j-3\"]{content:\"hFcCJB,gFqwTB,dMXLyl,cwHZQB,cdLigN,\"}/*!sc*/\n.hzZiwD{max-width:1400px;margin:0 auto;padding:36px;}/*!sc*/\n@media (max-width:991.98px){.hzZiwD{width:100%;}}/*!sc*/\n@media (max-width:767.98px){.hzZiwD{width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:0px;}}/*!sc*/\n@media (max-width:575.98px){.hzZiwD{padding:0px;min-height:0px;}}/*!sc*/\ndata-styled.g42[id=\"wrappers__WrapperStaticContent-sc-14fw43j-4\"]{content:\"hzZiwD,\"}/*!sc*/\n.flfCwz{overflow:hidden;max-width:1400px;margin:0 auto;padding:36px;}/*!sc*/\n@media (max-width:991.98px){.flfCwz{width:100%;}}/*!sc*/\n@media (max-width:767.98px){.flfCwz{width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:0px;}}/*!sc*/\n@media (max-width:575.98px){.flfCwz{padding:0px;min-height:0px;}}/*!sc*/\ndata-styled.g43[id=\"wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5\"]{content:\"flfCwz,\"}/*!sc*/\n.prlvG{width:calc((100% - 42px) * 0.7);margin-right:0px;margin-left:42px;float:left;}/*!sc*/\n@media (max-width:991.98px){.prlvG{margin-top:24px;margin-left:0;margin-right:0;width:100%;}}/*!sc*/\ndata-styled.g47[id=\"wrappers__WrapperMainContent-sc-14fw43j-9\"]{content:\"prlvG,\"}/*!sc*/\n.fUzxei{width:calc((100% - 42px) * 0.4);float:left;-webkit-transition:width 0.5s;transition:width 0.5s;}/*!sc*/\n@media (max-width:991.98px){.fUzxei{width:100%;}}/*!sc*/\ndata-styled.g48[id=\"wrappers__WrapperSidebar-sc-14fw43j-10\"]{content:\"fUzxei,\"}/*!sc*/\n.ftzCdl{max-height:0px;overflow:hidden;-webkit-transition:max-height .2s;transition:max-height .2s;}/*!sc*/\ndata-styled.g50[id=\"wrappers__CollapseContentWrapper-sc-14fw43j-12\"]{content:\"ftzCdl,\"}/*!sc*/\n.ejKxFX{color:#ffffff;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:#ff8200;width:36px;height:18px;border-radius:12px;-webkit-text-decoration:none;text-decoration:none;font-size:12px;margin-left:3px;}/*!sc*/\ndata-styled.g52[id=\"badge__LinkBadge-sc-1kc0y45-0\"]{content:\"ejKxFX,\"}/*!sc*/\n.iIAlRS{width:25%;}/*!sc*/\n@media (max-width:767.98px){.iIAlRS{float:left;width:50%;margin-top:24px;}}/*!sc*/\ndata-styled.g53[id=\"footer-list__FooterListWrapper-sc-17tjnty-0\"]{content:\"iIAlRS,\"}/*!sc*/\n.gFyZtw{margin-bottom:12px;}/*!sc*/\ndata-styled.g54[id=\"footer-list__FooterListHeading-sc-17tjnty-1\"]{content:\"gFyZtw,\"}/*!sc*/\n@media (max-width:767.98px){.jHUSlK{display:block;}}/*!sc*/\ndata-styled.g69[id=\"footer-copyright__FooterCopyrightWrapper-sc-p1jkef-0\"]{content:\"jHUSlK,\"}/*!sc*/\n.EMFJO{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:24px;width:24px;background-image:url(\"/static/images/icons/white/search.svg\");}/*!sc*/\n.gpNPvA{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:24px;width:24px;background-image:url(\"/static/images/icons/2.0/white/ios-world-outline.svg\");}/*!sc*/\n.bZBKhy{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/default/arrow-up.svg\");}/*!sc*/\n.cXnjPW{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:24px;width:30px;background-image:url(\"/static/images/icons/2.0/white/ios-search-strong.svg\");}/*!sc*/\n.eyhBpa{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:22px;width:22px;background-image:url(\"/static/images/icons/2.0/white/android-menu.svg\");}/*!sc*/\n.kbRKml{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:14px;width:14px;background-image:url(\"/static/images/icons/2.0/primary/ios-arrow-down.svg\");margin-left:6px;}/*!sc*/\n.iNazJp{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:12px;width:12px;background-image:url(\"/static/images/icons/2.0/primary/ios-arrow-down.svg\");margin-left:6px;}/*!sc*/\n.eiXgPa{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:10px;width:10px;background-image:url(\"/static/images/icons/2.0/white/plus.svg\");margin-left:6px;}/*!sc*/\n.kXkjMs{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:12px;width:12px;background-image:url(\"/static/images/icons/2.0/default/close.svg\");margin-right:12px;}/*!sc*/\n.kTando{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:unset;height:20px;width:20px;margin-right:12px;background-image:url(\"/static/images/icons/2.0/multicolor/default.svg\");}/*!sc*/\n.duJtpp{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/footer/social-linkedin.svg\");}/*!sc*/\n.UGQFe{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/footer/social-twitter.svg\");}/*!sc*/\n.bfOfuL{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:pointer;height:30px;width:30px;background-image:url(\"/static/images/icons/2.0/footer/social-facebook.svg\");}/*!sc*/\n.cnxXUV{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:default;height:16px;width:16px;background-image:url(\"/static/images/icons/2.0/footer/ios-telephone.svg\");}/*!sc*/\n.jLgsnQ{background-size:contain;background-repeat:no-repeat;background-position:center;display:inline-block;cursor:default;height:16px;width:16px;background-image:url(\"/static/images/icons/2.0/footer/ios-location.svg\");}/*!sc*/\ndata-styled.g70[id=\"icon__Icon-sc-1230ehg-0\"]{content:\"EMFJO,gpNPvA,bZBKhy,cXnjPW,eyhBpa,kbRKml,iNazJp,eiXgPa,kXkjMs,kTando,duJtpp,UGQFe,bfOfuL,cnxXUV,jLgsnQ,\"}/*!sc*/\n.caVxgD{width:20px;height:20px;fill:#3880E5;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;}/*!sc*/\n.jWARuS{width:20px;height:20px;fill:#526193;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;}/*!sc*/\n.fXOOJz{width:32px;height:32px;fill:#3880e5;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;}/*!sc*/\n.haqEoE{width:14px;height:14px;fill:#333333;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;}/*!sc*/\n.hrGMmp{width:12px;height:12px;fill:#4496ec;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;}/*!sc*/\n.enTUov{width:28px;height:22px;fill:#4496ec;stroke:none;stroke-linecap:round;stroke-linejoin:round;stroke-width:default;cursor:pointer;margin-left:9px;}/*!sc*/\ndata-styled.g71[id=\"icon__Svg-sc-1230ehg-1\"]{content:\"caVxgD,jWARuS,fXOOJz,haqEoE,hrGMmp,enTUov,\"}/*!sc*/\n@media (max-width:991.98px){.hwyVjw{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;margin-top:48px;}}/*!sc*/\n@media (max-width:767.98px){.hwyVjw{width:100%;display:inline-block;margin-top:24px;}}/*!sc*/\ndata-styled.g76[id=\"footer-social-links__SocialLinksList-sc-1hjdthk-0\"]{content:\"hwyVjw,\"}/*!sc*/\n.jkNDpJ{display:inline-block;}/*!sc*/\n.jkNDpJ:not(:first-child){margin-left:42px;}/*!sc*/\n@media{.jkNDpJ:not(:first-child){margin-left:30px;}}/*!sc*/\ndata-styled.g77[id=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1\"]{content:\"jkNDpJ,\"}/*!sc*/\n.lcDCgL{width:25%;}/*!sc*/\n@media (max-width:767.98px){.lcDCgL{width:100%;}}/*!sc*/\ndata-styled.g78[id=\"footer-matmatch-logo-and-gdpr__NameAndDescriptionWrapper-sc-1mbx1ll-0\"]{content:\"lcDCgL,\"}/*!sc*/\n.dLmbUA{border:none;height:1px;margin-top:24px;margin-bottom:24px;margin-top:12px;margin-bottom:12px;}/*!sc*/\n.cVgbLf{border:none;height:1px;margin-top:24px;margin-bottom:24px;margin-top:12px;margin-left:36px;margin-right:36px;margin-bottom:12px;}/*!sc*/\ndata-styled.g79[id=\"separation-line__SeparationLine-sc-1gtqai2-0\"]{content:\"dLmbUA,cVgbLf,\"}/*!sc*/\n.kwnPiJ{color:#bdbdbd;background-color:#bdbdbd;}/*!sc*/\ndata-styled.g80[id=\"separation-line__SeparationLineDefault-sc-1gtqai2-1\"]{content:\"kwnPiJ,\"}/*!sc*/\n.fGzocz{width:100%;padding:0 12px;margin:0;}/*!sc*/\n@media (min-width:768px){.fGzocz{padding-left:24px;padding-right:24px;}}/*!sc*/\n@media (min-width:1170px){.fGzocz{max-width:1170px;margin-left:auto;margin-right:auto;}}/*!sc*/\ndata-styled.g84[id=\"static-page-wrappers__StaticPageContentWrapper-sc-fz58vx-1\"]{content:\"fGzocz,\"}/*!sc*/\n.kUuTvA{padding:96px 0;background-color:#fcfcfd;}/*!sc*/\n@media (max-width:767.98px){.kUuTvA{padding:36px 0;}}/*!sc*/\ndata-styled.g89[id=\"footer-container__FooterContainer-sc-16jfcf3-0\"]{content:\"kUuTvA,\"}/*!sc*/\nhtml{-webkit-tap-highlight-color:transparent;}/*!sc*/\nbody{background-color:#fcfcfd;color:#3a4056;font-family:'Open Sans',sans-serif;font-size:15px;line-height:1.6;}/*!sc*/\n*,:after,:before{box-sizing:border-box;margin:0;}/*!sc*/\nimg{max-height:100%;max-width:100%;}/*!sc*/\na{color:#3880e5;-webkit-text-decoration:none;text-decoration:none;border:none;background:none;padding:0;}/*!sc*/\nbody.body-noscroll{overflow:hidden;}/*!sc*/\nbutton{cursor:pointer;-webkit-appearance:button;outline:none;}/*!sc*/\ndiv.DraftEditor-root{padding:12px;border:1px solid #3a4056;color:#3a4056;}/*!sc*/\ndiv.about-google-map{height:100%;}/*!sc*/\n.description ul{list-style-type:none;padding-left:24px;}/*!sc*/\n@media (max-width:767.98px){.description ul{padding-left:12px;}}/*!sc*/\n.description ol{padding-left:40px;}/*!sc*/\n@media (max-width:767.98px){.description ol{padding-left:28px;}}/*!sc*/\n.description ul li{position:relative;padding-left:16px;}/*!sc*/\n.description ul li:before{width:8px;height:8px;border-radius:4px;background-color:#03c7a7;content:'';margin-top:9px;position:absolute;left:0;}/*!sc*/\n.write-message div.DraftEditor-root,.render-message div.DraftEditor-root{border:none;height:80%;overflow-y:auto;}/*!sc*/\n.write-message div.DraftEditor-editorContainer,.render-message div.DraftEditor-editorContainer{height:100%;}/*!sc*/\n.write-message div.public-DraftEditor-content,.render-message div.public-DraftEditor-content{height:100%;}/*!sc*/\n.write-message-retargeting div.DraftEditor-root{border:none;height:100%;overflow-y:auto;}/*!sc*/\n.write-message-retargeting div.DraftEditor-editorContainer{height:100%;}/*!sc*/\n.write-message-retargeting div.public-DraftEditor-content{height:100%;}/*!sc*/\n.grecaptcha-badge{visibility:hidden;}/*!sc*/\n.hiddenBlockQuote{display:none;}/*!sc*/\n.particle-table{width:100%;text-align:left;margin:24px 0;}/*!sc*/\ndata-styled.g90[id=\"sc-global-hpWtfi1\"]{content:\"sc-global-hpWtfi1,\"}/*!sc*/\n.OhGlj{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;margin-right:6px;}/*!sc*/\n.bBVMlc{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;margin-left:6px;}/*!sc*/\n.kurrkX{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;}/*!sc*/\ndata-styled.g156[id=\"check-box__CheckBoxDesign-sc-1ptpc08-0\"]{content:\"OhGlj,bBVMlc,kurrkX,\"}/*!sc*/\n.dsaEue{cursor:pointer;border-radius:2px;vertical-align:top;display:inline-block;background-color:#ffffff;width:18px;height:18px;min-width:18px;border:1px solid #828282;background-size:contain;background-repeat:no-repeat;background-color:#3880E5;background-image:url(\"/static/images/icons/2.0/white/minus.svg\");margin-left:6px;}/*!sc*/\ndata-styled.g157[id=\"check-box__MinusCheckboxDesign-sc-1ptpc08-1\"]{content:\"dsaEue,\"}/*!sc*/\n.eajQMm{color:#ffffff;font-size:13px;margin-left:12px;border-radius:12px;padding:0 6px;background-color:#333333;}/*!sc*/\ndata-styled.g168[id=\"advanced-search-count-number__CountNumber-sc-8hlubs-0\"]{content:\"eajQMm,\"}/*!sc*/\n.bhkHlB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:6px 0px;padding-left:0px;}/*!sc*/\ndata-styled.g169[id=\"tree-item__TreeItem-sc-1ndoqn1-0\"]{content:\"bhkHlB,\"}/*!sc*/\n.djLvdn{list-style-type:none;padding-inline-start:0px;}/*!sc*/\ndata-styled.g170[id=\"tree-renderer__TreeWrapper-sc-wdfwzn-0\"]{content:\"djLvdn,\"}/*!sc*/\n.gslBUi{display:inline-block;cursor:pointer;width:45px;height:20px;border-radius:10px;-webkit-animation:cpCHCi 0.5s linear;animation:cpCHCi 0.5s linear;background:#67ac5b;border:1px solid #67ac5b;}/*!sc*/\ndata-styled.g178[id=\"toggle__ToggleWrapper-sc-th0yzv-0\"]{content:\"gslBUi,\"}/*!sc*/\n.hbpQfU{display:inline-block;position:relative;left:5px;width:14px;height:18px;background-size:contain;background-repeat:no-repeat;background-position:center;background-image:url(\"/static/images/icons/2.0/white/checkmark.svg\");opacity:1;-webkit-transition:opacity 0.5s;transition:opacity 0.5s;}/*!sc*/\ndata-styled.g179[id=\"toggle__ToggleCheckmark-sc-th0yzv-1\"]{content:\"hbpQfU,\"}/*!sc*/\n.fArqYf{display:inline-block;position:relative;width:18px;height:18px;border-radius:9px;background-color:#ffffff;left:11px;-webkit-transition:left 0.5s;transition:left 0.5s;}/*!sc*/\ndata-styled.g180[id=\"toggle__ToggleToggle-sc-th0yzv-2\"]{content:\"fArqYf,\"}/*!sc*/\n.eipfdL{width:100%;border-left:1px solid #828db1;margin-top:12px;will-change:max-height;max-height:0px;}/*!sc*/\ndata-styled.g189[id=\"mobile-profile-menu__HeaderProfileMenuList-sc-c6el3s-0\"]{content:\"eipfdL,\"}/*!sc*/\n.eidcBU{color:#333333;padding:0 24px;margin:12px 0;list-style-type:none;border-right:1px solid transparent;font-weight:400;}/*!sc*/\ndata-styled.g190[id=\"mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1\"]{content:\"eidcBU,\"}/*!sc*/\n.elfMjy{font-size:13px;cursor:pointer;color:#333333;display:inline-block;}/*!sc*/\n.elfMjy:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.hKoOWf{font-size:13px;cursor:pointer;color:#333333;display:inline-block;font-weight:600;}/*!sc*/\n.hKoOWf:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.fIeyGw{font-size:13px;cursor:pointer;color:#333333;display:inline-block;font-weight:600;margin-bottom:24px;}/*!sc*/\n.fIeyGw:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\ndata-styled.g191[id=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0\"]{content:\"elfMjy,hKoOWf,fIeyGw,\"}/*!sc*/\n.dlnRUd{margin-left:24px;}/*!sc*/\ndata-styled.g192[id=\"mobile-header-dynamic-categories-connected__MobileHeaderDropdownSecondLevelLinksWrapper-sc-rlj3br-0\"]{content:\"dlnRUd,\"}/*!sc*/\n.eSAgkB{margin-left:24px;}/*!sc*/\ndata-styled.g194[id=\"mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0\"]{content:\"eSAgkB,\"}/*!sc*/\n.hHsZTR{margin-bottom:24px;}/*!sc*/\ndata-styled.g195[id=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1\"]{content:\"hHsZTR,\"}/*!sc*/\n.gAQIST{left:0;right:0;z-index:100;cursor:auto;max-height:0px;overflow:hidden;position:absolute;-webkit-transition:max-height .4s;transition:max-height .4s;background-color:transparent;box-shadow:0 5px 6px 0 #B0B3BB;}/*!sc*/\ndata-styled.g197[id=\"common__DesktopHeaderDropdownWrapper-sc-170boom-0\"]{content:\"gAQIST,\"}/*!sc*/\n.cTBSVf{width:50%;float:left;}/*!sc*/\n.cTBSVf:not(:last-child){padding-right:12px;}/*!sc*/\ndata-styled.g198[id=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1\"]{content:\"cTBSVf,\"}/*!sc*/\n.fWKIzC{font-size:13px;cursor:pointer;color:#333333;display:inline-block;font-weight:600;margin-bottom:3px;}/*!sc*/\n.fWKIzC:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n.kUjwEN{font-size:13px;cursor:pointer;color:#333333;display:inline-block;}/*!sc*/\n.kUjwEN:hover{-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\ndata-styled.g199[id=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2\"]{content:\"fWKIzC,kUjwEN,\"}/*!sc*/\n.cdqTz{margin-top:18px;background-color:#fcfcfd;}/*!sc*/\ndata-styled.g200[id=\"desktop-header-dropdown__DesktopHeaderDropdownInnerWrapper-sc-y1g0lx-0\"]{content:\"cdqTz,\"}/*!sc*/\n.dvhoXp:not(:last-child){margin-bottom:24px;}/*!sc*/\n.dvhoXp a{line-height:0;}/*!sc*/\ndata-styled.g201[id=\"header-action-link__CtaWrapper-sc-1yhrwj5-0\"]{content:\"dvhoXp,\"}/*!sc*/\n.hHnCBT{float:left;width:calc((100% / 3) - 0.1px);}/*!sc*/\n.hHnCBT:not(:last-child){padding-right:12px;}/*!sc*/\ndata-styled.g202[id=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0\"]{content:\"hHnCBT,\"}/*!sc*/\n.edSpfo:not(:last-child){margin-bottom:24px;}/*!sc*/\ndata-styled.g203[id=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1\"]{content:\"edSpfo,\"}/*!sc*/\n.czLQLd{float:left;width:calc((100% / 3) - 0.1px);}/*!sc*/\n.czLQLd:not(:last-child){padding-right:12px;}/*!sc*/\ndata-styled.g204[id=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0\"]{content:\"czLQLd,\"}/*!sc*/\n.CVmbS{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\ndata-styled.g208[id=\"bubble__BubbleWrapper-sc-i30r9c-0\"]{content:\"CVmbS,\"}/*!sc*/\n.hWwxLn{height:112px;}/*!sc*/\n@media (max-width:991.98px){.hWwxLn{display:none;}}/*!sc*/\ndata-styled.g211[id=\"main-content-spacer__MainContentSpacer-sc-1g5s1bz-0\"]{content:\"hWwxLn,\"}/*!sc*/\n.greBxI{padding:24px 0;}/*!sc*/\n@media (max-width:767.98px){.greBxI{padding:12px 0;}}/*!sc*/\ndata-styled.g218[id=\"footer__FooterWrapper-sc-1vgte7v-0\"]{content:\"greBxI,\"}/*!sc*/\n@media (max-width:767.98px){.hZBBnE{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}/*!sc*/\ndata-styled.g219[id=\"footer__FooterMiddleWrapper-sc-1vgte7v-1\"]{content:\"hZBBnE,\"}/*!sc*/\n.jdQCEK{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 auto;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;max-width:1170px;}/*!sc*/\n@media (max-width:767.98px){.jdQCEK{display:block;overflow:hidden;}}/*!sc*/\ndata-styled.g220[id=\"footer__FooterResponsiveWrapper-sc-1vgte7v-2\"]{content:\"jdQCEK,\"}/*!sc*/\n.hutcBS{position:fixed;background-color:#ffffff;padding:24px;max-width:660px;z-index:100;bottom:12px;box-shadow:0px 2px 5px #b0b3bb;border-radius:4px;left:calc(-50vw + 50%);right:calc(-50vw + 50%);margin-left:auto;margin-right:auto;}/*!sc*/\ndata-styled.g221[id=\"cookie-banner__CookieBannerWrapper-sc-1n3o3md-0\"]{content:\"hutcBS,\"}/*!sc*/\n.drTDou{background-color:#6a77a2;z-index:10;}/*!sc*/\ndata-styled.g253[id=\"desktop-header-search-bar__SearchButton-sc-n2cbkq-1\"]{content:\"drTDou,\"}/*!sc*/\n.iAiHqb{background-color:#ffffff;border-radius:4px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:38px;}/*!sc*/\ndata-styled.g255[id=\"desktop-header-search-bar__DesktopHeaderSearchBarInputBlockWrapper-sc-n2cbkq-3\"]{content:\"iAiHqb,\"}/*!sc*/\n.cQdUuW{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:relative;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/\ndata-styled.g256[id=\"desktop-header-search-bar__DesktopHeaderSearchInputWrapper-sc-n2cbkq-4\"]{content:\"cQdUuW,\"}/*!sc*/\n.ioBjKD{border:none;margin-left:12px;width:100%;}/*!sc*/\n.ioBjKD::-webkit-input-placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD::-moz-placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD:-ms-input-placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD::placeholder{color:#bdbdbd;opacity:1;}/*!sc*/\n.ioBjKD::-ms-clear{display:none;}/*!sc*/\n.ioBjKD:focus{outline:none;}/*!sc*/\ndata-styled.g257[id=\"desktop-header-search-bar__DesktopHeaderSearchInputField-sc-n2cbkq-5\"]{content:\"ioBjKD,\"}/*!sc*/\n.fuuwzT{position:relative;}/*!sc*/\ndata-styled.g258[id=\"desktop-header-search-bar__DesktopHeaderAutoSuggestionsWrapper-sc-n2cbkq-6\"]{content:\"fuuwzT,\"}/*!sc*/\n.hvBjgr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;}/*!sc*/\ndata-styled.g263[id=\"mobile-header-user-not-signed-in__MobileHeaderUserNotSignedInWrapper-sc-195838o-0\"]{content:\"hvBjgr,\"}/*!sc*/\n.lpgqvm{color:#ff8200;background-color:#fcfcfd;border:2px solid #ff8200;max-width:303px;}/*!sc*/\ndata-styled.g264[id=\"mobile-header-user-not-signed-in__MobileHeaderUserSignUpButton-sc-195838o-1\"]{content:\"lpgqvm,\"}/*!sc*/\n.bTObyH{color:#67ac5b;margin-bottom:12px;background-color:#fcfcfd;border:2px solid #67ac5b;max-width:303px;}/*!sc*/\ndata-styled.g265[id=\"mobile-header-user-not-signed-in__MobileHeaderUserSignInButton-sc-195838o-2\"]{content:\"bTObyH,\"}/*!sc*/\n.evPxyJ{list-style:none;overflow-y:auto;padding:0 36px;}/*!sc*/\ndata-styled.g266[id=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBar-sc-ssinjx-0\"]{content:\"evPxyJ,\"}/*!sc*/\n.bxYrpi{cursor:auto;max-height:0;overflow:hidden;background-color:#fcfcfd;}/*!sc*/\ndata-styled.g267[id=\"mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1\"]{content:\"bxYrpi,\"}/*!sc*/\n.bjzJUu{-webkit-flex:1;-ms-flex:1;flex:1;color:#526193;will-change:font-weight;font-weight:400;}/*!sc*/\ndata-styled.g268[id=\"mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2\"]{content:\"bjzJUu,\"}/*!sc*/\n.ghkwNZ{border-left:1px #526193 solid;}/*!sc*/\ndata-styled.g270[id=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4\"]{content:\"ghkwNZ,\"}/*!sc*/\n.lgzuuz{font-size:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;padding:3px 6px 18px 0;}/*!sc*/\n.kYgdAl{font-size:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;padding:3px 6px 18px 0;}/*!sc*/\n.kYgdAl:nth-last-child(2):not(:only-child),.kYgdAl:last-child:not(:only-child){padding-bottom:0px;}/*!sc*/\ndata-styled.g271[id=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5\"]{content:\"lgzuuz,kYgdAl,\"}/*!sc*/\n.kDpNZQ{background-color:#fcfcfd;}/*!sc*/\ndata-styled.g272[id=\"mobile-header__MobileHeaderWrapper-sc-dvud91-0\"]{content:\"kDpNZQ,\"}/*!sc*/\n.iiDvup{background-color:#526193;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;color:#ffffff;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:12px;height:62px;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\n@media screen and (max-width:575.98px){.iiDvup{height:45px;-webkit-box-pack:unset;-webkit-justify-content:unset;-ms-flex-pack:unset;justify-content:unset;}}/*!sc*/\ndata-styled.g273[id=\"mobile-header__MobileHeaderStaticBar-sc-dvud91-1\"]{content:\"iiDvup,\"}/*!sc*/\n.cmjpNo{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:auto;padding:0 12px;}/*!sc*/\n@media screen and (max-width:767.98px){.cmjpNo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/\ndata-styled.g274[id=\"mobile-header__MobileHeaderStaticBarSearchIconWrapper-sc-dvud91-2\"]{content:\"cmjpNo,\"}/*!sc*/\n.hpPhjx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:24px 0;position:relative;height:calc(100vh - 62px - 72px);}/*!sc*/\n@media screen and (max-width:575.98px){.hpPhjx{height:calc(100vh - 45px - 72px);}}/*!sc*/\ndata-styled.g275[id=\"mobile-header__MobileHeaderMenuList-sc-dvud91-3\"]{content:\"hpPhjx,\"}/*!sc*/\n.tMWkf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 36px;list-style:none;}/*!sc*/\ndata-styled.g276[id=\"mobile-header__MobileHeaderMenuListItem-sc-dvud91-4\"]{content:\"tMWkf,\"}/*!sc*/\n.CjJpx{position:relative;height:calc(100vh - 62px);-webkit-transition:margin-top 0.3s ease-out;transition:margin-top 0.3s ease-out;margin-top:-100vh;}/*!sc*/\n@media screen and (max-width:575.98px){.CjJpx{height:calc(100vh - 45px);}}/*!sc*/\ndata-styled.g277[id=\"mobile-header__MobileHeaderSlideDownHeader-sc-dvud91-5\"]{content:\"CjJpx,\"}/*!sc*/\n.cwmMhq{overflow:hidden;}/*!sc*/\ndata-styled.g278[id=\"mobile-header__MobileHeaderSlideDownWrapper-sc-dvud91-6\"]{content:\"cwmMhq,\"}/*!sc*/\n.igiZBr{background-color:#526193;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\ndata-styled.g279[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBar-sc-vppewv-0\"]{content:\"igiZBr,\"}/*!sc*/\n.hPDTUs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;max-width:654px;}/*!sc*/\ndata-styled.g280[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItems-sc-vppewv-1\"]{content:\"hPDTUs,\"}/*!sc*/\n.goozRc{color:#ffffff;border-bottom:1px solid rgba(255,255,255,0);}/*!sc*/\n.goozRc:hover{border-bottom:1px solid rgba(255,255,255,9);}/*!sc*/\ndata-styled.g281[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2\"]{content:\"goozRc,\"}/*!sc*/\n.gbNQTp{text-align:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g282[id=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemStyledButton-sc-vppewv-3\"]{content:\"gbNQTp,\"}/*!sc*/\n.bKWUBi{color:white;display:block;font-size:15px;border-bottom:1px solid rgba(255,255,255,0);}/*!sc*/\n.bKWUBi:after{content:'';width:10px;height:10px;display:inline-block;background-size:contain;background-position:center;background-repeat:no-repeat;margin-left:6px;background-image:url(\"/static/images/icons/2.0/white/arrow-down.svg\");}/*!sc*/\n.bKWUBi:hover{border-bottom:1px solid rgba(255,255,255,9);}/*!sc*/\ndata-styled.g283[id=\"desktop-header-navigation-links__DesktopHeaderNavigationDropdownText-sc-vppewv-4\"]{content:\"bKWUBi,\"}/*!sc*/\n.bPjIbr{float:left;}/*!sc*/\n@media (max-width:991.98px){.bPjIbr{width:130px;}}/*!sc*/\ndata-styled.g289[id=\"desktop-header-static-bar__HeaderLogoImage-sc-1aton5n-0\"]{content:\"bPjIbr,\"}/*!sc*/\n.KFXRI{position:fixed;left:0;right:0;top:0;z-index:3;background-color:#526193;}/*!sc*/\ndata-styled.g291[id=\"desktop-header-static-bar__DesktopHeaderStaticBar-sc-1aton5n-2\"]{content:\"KFXRI,\"}/*!sc*/\n.kHEXRD{padding-top:3px;padding-bottom:18px;}/*!sc*/\ndata-styled.g292[id=\"desktop-header-static-bar__DesktopHeadersLinksWrapper-sc-1aton5n-3\"]{content:\"kHEXRD,\"}/*!sc*/\n.cVRwqg{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/\ndata-styled.g293[id=\"desktop-header-static-bar__DesktopHeaderLogoSection-sc-1aton5n-4\"]{content:\"cVRwqg,\"}/*!sc*/\n.gigTJA{max-width:554px;-webkit-flex:3;-ms-flex:3;flex:3;margin:0 60px;}/*!sc*/\n@media (max-width:991.98px){.gigTJA{margin:0 12px;}}/*!sc*/\ndata-styled.g294[id=\"desktop-header-static-bar__DesktopHeaderSearchBarSection-sc-1aton5n-5\"]{content:\"gigTJA,\"}/*!sc*/\n.IRYso{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;min-width:282px;}/*!sc*/\ndata-styled.g295[id=\"desktop-header-static-bar__DesktopHeaderControlIconsSection-sc-1aton5n-6\"]{content:\"IRYso,\"}/*!sc*/\n.gWelzZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g296[id=\"desktop-header-static-bar__DesktopHeaderLanguagePanelWrapper-sc-1aton5n-7\"]{content:\"gWelzZ,\"}/*!sc*/\n.gBSUqi{cursor:pointer;margin-right:6px;}/*!sc*/\ndata-styled.g297[id=\"desktop-header-static-bar__DesktopHeaderCurrentLanguage-sc-1aton5n-8\"]{content:\"gBSUqi,\"}/*!sc*/\n.hMfFLt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:24px;}/*!sc*/\n@media (max-width:991.98px){.hMfFLt{margin-left:12px;}}/*!sc*/\ndata-styled.g298[id=\"desktop-header-static-bar__DesktopHeaderAuthControls-sc-1aton5n-9\"]{content:\"hMfFLt,\"}/*!sc*/\n.bga-dBn{width:100%;height:66px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 auto;color:#ffffff;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:0 12px;}/*!sc*/\n@media (min-width:768px){.bga-dBn{padding-left:24px;padding-right:24px;}}/*!sc*/\n@media (min-width:1170px){.bga-dBn{max-width:1440px;margin-left:auto;margin-right:auto;}}/*!sc*/\ndata-styled.g299[id=\"desktop-header-static-bar__DesktopHeaderStaticBarInner-sc-1aton5n-10\"]{content:\"bga-dBn,\"}/*!sc*/\n.lpaaHC{margin-right:24px;}/*!sc*/\n@media (max-width:991.98px){.lpaaHC{margin-right:12px;}}/*!sc*/\ndata-styled.g301[id=\"desktop-header-static-bar__SignInText-sc-1aton5n-12\"]{content:\"lpaaHC,\"}/*!sc*/\n.ihiZJY{position:relative;}/*!sc*/\ndata-styled.g302[id=\"header__HeaderWrapper-sc-vi2mkw-0\"]{content:\"ihiZJY,\"}/*!sc*/\n@media (max-width:767.98px){.iOXrTY{display:none;}}/*!sc*/\n@media (max-width:991.98px){.iOXrTY{display:none;}}/*!sc*/\ndata-styled.g303[id=\"header__DesktopHeaderWrapper-sc-vi2mkw-1\"]{content:\"iOXrTY,\"}/*!sc*/\n.eWjGyj{width:100%;z-index:4;display:none;}/*!sc*/\n@media (max-width:991.98px){.eWjGyj{display:block;}}/*!sc*/\n@media (max-width:767.98px){.eWjGyj{display:block;}}/*!sc*/\ndata-styled.g304[id=\"header__MobileHeaderWrapper-sc-vi2mkw-2\"]{content:\"eWjGyj,\"}/*!sc*/\n.ewHqQp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;height:90px;}/*!sc*/\n@media (max-width:575.98px){.ewHqQp{height:44px;}}/*!sc*/\ndata-styled.g305[id=\"campaigns__CampaignBannerWrapper-sc-a2pwr6-0\"]{content:\"ewHqQp,\"}/*!sc*/\n.dcaIxI{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\ndata-styled.g344[id=\"adbutler__CampaignBannerWrapper-sc-1snm6gk-0\"]{content:\"dcaIxI,\"}/*!sc*/\n.fgLnFQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 auto;overflow:hidden;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:728px;height:90px;}/*!sc*/\n.fgLnFQ .adbutler-banner-wrapper:not(:empty) ~ *{display:none;}/*!sc*/\n.fgLnFQ img{width:auto;height:auto;}/*!sc*/\n@media (max-width:575.98px){.fgLnFQ{height:61px;}}/*!sc*/\ndata-styled.g345[id=\"adbutler__CampaignBannerInnerWrapper-sc-1snm6gk-1\"]{content:\"fgLnFQ,\"}/*!sc*/\n.hucmjH{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:16px;height:16px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:8px;border:1px solid #3880E5;}/*!sc*/\ndata-styled.g583[id=\"radio-button__RadioButtonOuter-sc-mwb92w-0\"]{content:\"hucmjH,\"}/*!sc*/\n.jXbQYq{width:10px;height:10px;border-radius:5px;background-color:#3880E5;}/*!sc*/\ndata-styled.g584[id=\"radio-button__RadioButtonInner-sc-mwb92w-1\"]{content:\"jXbQYq,\"}/*!sc*/\n.dDcZzF{color:#fcfcfd;margin:36px 0;}/*!sc*/\ndata-styled.g585[id=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0\"]{content:\"dDcZzF,\"}/*!sc*/\n.hXYfhe{color:#ffffff;font-size:16px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;border-radius:2px;-webkit-flex:1;-ms-flex:1;flex:1;margin-right:24px;border:1px solid #48A43F;background-color:#67ac5b;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:6px;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/\n.hXYfhe:hover{background-color:#48A43F;}/*!sc*/\ndata-styled.g586[id=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0\"]{content:\"hXYfhe,\"}/*!sc*/\n.cwhWGZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin-top:24px;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\ndata-styled.g587[id=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0\"]{content:\"cwhWGZ,\"}/*!sc*/\n.hVhMIm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;opacity:.7;pointer-events:none;}/*!sc*/\ndata-styled.g588[id=\"advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1\"]{content:\"hVhMIm,\"}/*!sc*/\n.iPlPmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g589[id=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0\"]{content:\"iPlPmm,\"}/*!sc*/\n.XbfDr{overflow-y:auto;-webkit-transition:margin-top .25s,max-height .15s;transition:margin-top .25s,max-height .15s;margin-top:24px;max-height:0px;margin-top:0;}/*!sc*/\ndata-styled.g590[id=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0\"]{content:\"XbfDr,\"}/*!sc*/\n.fdCHWk{position:relative;width:16px;height:16px;}/*!sc*/\n.fdCHWk:before,.fdCHWk:after{content:\"\";position:absolute;background-color:white;-webkit-transition:-webkit-transform 0.25s ease-out;-webkit-transition:transform 0.25s ease-out;transition:transform 0.25s ease-out;background-color:#3880e5;}/*!sc*/\n.fdCHWk:before{top:0;left:50%;width:4px;height:100%;margin-left:-2px;}/*!sc*/\n.fdCHWk:after{top:50%;left:0;width:100%;height:4px;margin-top:-2px;}/*!sc*/\ndata-styled.g591[id=\"plus-icon__PlusIcon-sc-13w6ro8-0\"]{content:\"fdCHWk,\"}/*!sc*/\n.gNwTRO{margin:4px 12px;-webkit-flex:1;-ms-flex:1;flex:1;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;}/*!sc*/\ndata-styled.g592[id=\"advanced-search-category-specific-settings-dropdown__FieldText-sc-113hj4-0\"]{content:\"gNwTRO,\"}/*!sc*/\n.epQYxF{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:12px;background:#ffffff;border:1px solid #bdbdbd;box-sizing:border-box;border-radius:4px;}/*!sc*/\ndata-styled.g593[id=\"advanced-search-category-specific-settings-dropdown__FieldWrapper-sc-113hj4-1\"]{content:\"epQYxF,\"}/*!sc*/\n.kRDCWz{position:relative;}/*!sc*/\ndata-styled.g594[id=\"advanced-search-category-specific-settings-dropdown__DropDownContainer-sc-113hj4-2\"]{content:\"kRDCWz,\"}/*!sc*/\n.huFKrQ{position:absolute;top:100%;z-index:2;width:100%;margin-top:-12px;padding:12px;padding-bottom:0;max-height:236px;overflow-y:auto;-webkit-transition:all .5s;transition:all .5s;opacity:0;visibility:hidden;background-color:#ffffff;border:1px solid #bdbdbd;box-sizing:border-box;box-shadow:0px 2px 5px #b0b3bb;border-radius:4px;}/*!sc*/\ndata-styled.g595[id=\"advanced-search-category-specific-settings-dropdown__DropDownItemsWrapper-sc-113hj4-3\"]{content:\"huFKrQ,\"}/*!sc*/\n.zzdEX{margin-right:12px;}/*!sc*/\ndata-styled.g599[id=\"advanced-search-category-specific-settings-dropdown__PlusIconContainer-sc-113hj4-7\"]{content:\"zzdEX,\"}/*!sc*/\n.cFpniu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g603[id=\"advanced-search-sidebar-suppliers__ItemHeaderWrapper-sc-12new5k-0\"]{content:\"cFpniu,\"}/*!sc*/\n.gdlobs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:12px 0;margin-bottom:12px;}/*!sc*/\n@media (max-width:991.98px){.gdlobs{display:none;}}/*!sc*/\ndata-styled.g616[id=\"collapse-toggle__CollapseToggleWrapper-sc-vxcac6-0\"]{content:\"gdlobs,\"}/*!sc*/\n.gFfIFF{display:block;}/*!sc*/\ndata-styled.g617[id=\"collapse-toggle__CollapseToggleOptionsIcon-sc-vxcac6-1\"]{content:\"gFfIFF,\"}/*!sc*/\n.iTeGNl{color:#526193;margin:0 6px;-webkit-flex:1;-ms-flex:1;flex:1;font-weight:600;display:block;}/*!sc*/\ndata-styled.g618[id=\"collapse-toggle__CollapseToggleTitle-sc-vxcac6-2\"]{content:\"iTeGNl,\"}/*!sc*/\n.cgzKyT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:white;border:1px solid #bdbdbd;border-radius:50%;width:40px;height:40px;cursor:pointer;-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg);}/*!sc*/\ndata-styled.g619[id=\"collapse-toggle__CollapseToggleArrowCircle-sc-vxcac6-3\"]{content:\"cgzKyT,\"}/*!sc*/\n.gyajYF{width:438px;padding:24px;border-radius:4px;background-color:#f2f2f2;}/*!sc*/\n@media (max-width:991.98px){.gyajYF{width:100%;}}/*!sc*/\n@media (max-width:767.98px){.gyajYF{display:none;display:none;}}/*!sc*/\n@media (max-width:575.98px){.gyajYF{padding:12px;}}/*!sc*/\ndata-styled.g620[id=\"sidebar__AdvancedSearchSidebarWrapper-sc-1v590t3-0\"]{content:\"gyajYF,\"}/*!sc*/\n.jnuTJQ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-radius:4px;background-color:#f2f2f2;max-width:1400px;margin:0 auto 24px auto;padding:12px 12px 0 12px;}/*!sc*/\n@media (max-width:991.98px){.jnuTJQ{overflow-x:auto;}}/*!sc*/\n@media (max-width:767.98px){.jnuTJQ{margin:12px 0 0 0;}}/*!sc*/\ndata-styled.g622[id=\"contextual-tags__ContextualTagsWrapper-sc-dg6jub-0\"]{content:\"jnuTJQ,\"}/*!sc*/\n.fsqjse{border-radius:4px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;margin-right:12px;margin-bottom:12px;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;background-color:#fcfcfd;border:1px solid #3880E5;padding:6px 12px;}/*!sc*/\ndata-styled.g623[id=\"contextual-tags__ContextualTagWrapper-sc-dg6jub-1\"]{content:\"fsqjse,\"}/*!sc*/\n@media (max-width:991.98px){.cSROfV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/\ndata-styled.g624[id=\"contextual-tags__ContextualTagsItemsWrapper-sc-dg6jub-2\"]{content:\"cSROfV,\"}/*!sc*/\n.fLLraV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:24px;}/*!sc*/\ndata-styled.g625[id=\"pagination__PaginationWrapper-sc-1s1bcvk-0\"]{content:\"fLLraV,\"}/*!sc*/\n.TXmbf{display:inline-block;}/*!sc*/\n@media (max-width:991.98px){.TXmbf{display:none;}}/*!sc*/\ndata-styled.g626[id=\"pagination__PaginationPagesText-sc-1s1bcvk-1\"]{content:\"TXmbf,\"}/*!sc*/\n.fLuqrw{position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\ndata-styled.g627[id=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0\"]{content:\"fLuqrw,\"}/*!sc*/\n.hxQNhN{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;border:1px solid #e0e0e0;margin-right:6px;}/*!sc*/\ndata-styled.g628[id=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1\"]{content:\"hxQNhN,\"}/*!sc*/\n.grBuVO{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;height:36px;line-height:36px;background:#ffffff;cursor:pointer;border:1px solid #e0e0e0;}/*!sc*/\ndata-styled.g629[id=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2\"]{content:\"grBuVO,\"}/*!sc*/\n.cqRtVo{position:absolute;display:block;top:100%;left:0;right:0;border:1px solid #e0e0e0;border-top:0;background:#fff;-webkit-transition:all 0.5s;transition:all 0.5s;opacity:0;visibility:hidden;z-index:2;box-shadow:0 2px 5px 0 #bdbdbd;}/*!sc*/\ndata-styled.g630[id=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3\"]{content:\"cqRtVo,\"}/*!sc*/\n.hwiCoG{position:relative;display:block;padding:0 12px 0 12px;line-height:36px;cursor:pointer;-webkit-transition:all 0.5s;transition:all 0.5s;font-size:12px;white-space:nowrap;text-overflow:ellipsis;overflow:hidden;}/*!sc*/\n.hwiCoG:hover{cursor:pointer;background-color:#e0e0e0;}/*!sc*/\ndata-styled.g631[id=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4\"]{content:\"hwiCoG,\"}/*!sc*/\n.kaSqTa{color:#4496ec;position:relative;display:block;padding:12px;cursor:pointer;-webkit-transition:all 0.5s;transition:all 0.5s;font-size:12px;}/*!sc*/\ndata-styled.g632[id=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5\"]{content:\"kaSqTa,\"}/*!sc*/\n.dUfhYU{max-width:228px;}/*!sc*/\n.dUfhYU:hover{cursor:pointer;background-color:transparent;}/*!sc*/\ndata-styled.g633[id=\"custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6\"]{content:\"dUfhYU,\"}/*!sc*/\n.cwaUxH{color:#bdbdbd;}/*!sc*/\ndata-styled.g634[id=\"custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7\"]{content:\"cwaUxH,\"}/*!sc*/\n.kOKDxB{position:relative;height:10px;width:10px;margin-right:6px;}/*!sc*/\n.kOKDxB::before{content:\"\";position:absolute;bottom:0;width:2px;height:100%;left:-3px;-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);background-color:#4496ec;}/*!sc*/\n.kOKDxB::after{content:\"\";position:absolute;bottom:0;width:2px;height:100%;left:3px;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);background-color:#4496ec;}/*!sc*/\ndata-styled.g635[id=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8\"]{content:\"kOKDxB,\"}/*!sc*/\n.emgOuh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:solid 1px #e0e0e0;border-radius:2px;margin-bottom:6px;padding:12px 24px;background-color:#fcfcfd;}/*!sc*/\n@media (max-width:767.98px){.emgOuh{display:none;}}/*!sc*/\ndata-styled.g637[id=\"header-properties-dropdown__PropertiesDropdownWrapper-sc-jye0ar-0\"]{content:\"emgOuh,\"}/*!sc*/\n.cVjyqt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;background-color:#ffffff;border:solid 1px #e0e0e0;margin-bottom:6px;box-shadow:0 2px 5px 0 #bdbdbd;padding:12px 24px;}/*!sc*/\n@media (max-width:767.98px){.cVjyqt{padding:12px;}}/*!sc*/\n.dSEUZx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;background-color:#ffffff;border:solid 1px #e0e0e0;margin-bottom:6px;box-shadow:0 2px 5px 0 #bdbdbd;padding:12px 24px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}/*!sc*/\n@media (max-width:767.98px){.dSEUZx{padding:12px;}}/*!sc*/\ndata-styled.g641[id=\"materials-list__MaterialsListItem-sc-1ickte1-0\"]{content:\"cVjyqt,dSEUZx,\"}/*!sc*/\n.dtZnEZ{width:32%;overflow:hidden;}/*!sc*/\n@media (max-width:767.98px){.dtZnEZ{width:90%;}}/*!sc*/\ndata-styled.g642[id=\"materials-list__MaterialDataWrapper-sc-1ickte1-1\"]{content:\"dtZnEZ,\"}/*!sc*/\n.hTQFno{width:63%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:12px;}/*!sc*/\n@media (max-width:767.98px){.hTQFno{display:none;}}/*!sc*/\ndata-styled.g643[id=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2\"]{content:\"hTQFno,\"}/*!sc*/\n.bDcoHI{width:5%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;padding-left:12px;}/*!sc*/\n@media (max-width:767.98px){.bDcoHI{width:10%;}}/*!sc*/\ndata-styled.g644[id=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3\"]{content:\"bDcoHI,\"}/*!sc*/\n.fHnuKk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin:24px auto;}/*!sc*/\n@media (max-width:991.98px){.fHnuKk{display:none;}}/*!sc*/\ndata-styled.g650[id=\"navigation-component__AdvancedSearchNavigationComponentWrapper-sc-1j05mwq-0\"]{content:\"fHnuKk,\"}/*!sc*/\n.fmDqYN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;min-width:50%;position:relative;padding:12px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-top:1px solid #bdbdbd;border-left:1px solid #bdbdbd;border-bottom:1px solid #bdbdbd;box-shadow:0px 2px 2px rgba(0,0,0,0.25);background-color:#F1F4F1;}/*!sc*/\n.fmDqYN::after{content:\"\";width:16px;height:16px;bottom:-8px;display:block;position:absolute;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);border-right:1px solid #bdbdbd;background:#F1F4F1;border-bottom:1px solid #bdbdbd;}/*!sc*/\n.fmDqYN:last-child{border-right:1px solid #bdbdbd;border-radius:0px 8px 8px 0px;}/*!sc*/\n.fmDqYN:first-child{border-radius:8px 0px 0px 8px;}/*!sc*/\n.hmFsem{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;cursor:pointer;min-width:50%;position:relative;padding:12px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-top:1px solid #bdbdbd;border-left:1px solid #bdbdbd;border-bottom:1px solid #bdbdbd;box-shadow:inset 0px 1px 1px rgba(0,0,0,0.25);background-color:#F0F5F5;}/*!sc*/\n.hmFsem:last-child{border-right:1px solid #bdbdbd;border-radius:0px 8px 8px 0px;}/*!sc*/\n.hmFsem:first-child{border-radius:8px 0px 0px 8px;}/*!sc*/\ndata-styled.g651[id=\"navigation-component__AdvancedSearchNavigationItemWrapper-sc-1j05mwq-1\"]{content:\"fmDqYN,hmFsem,\"}/*!sc*/\n.bwwYIA{width:26px;height:26px;font-size:16px;color:#ffffff;text-align:center;border-radius:13px;margin-right:12px;background:#ff8200;}/*!sc*/\n.fgAGgQ{width:26px;height:26px;font-size:16px;color:#ffffff;text-align:center;border-radius:13px;margin-right:12px;background:#828282;}/*!sc*/\ndata-styled.g652[id=\"navigation-component__NavigationItemNumber-sc-1j05mwq-2\"]{content:\"bwwYIA,fgAGgQ,\"}/*!sc*/\n.jleRfd{margin-bottom:12px;}/*!sc*/\n@media (max-width:767.98px){.jleRfd{padding-left:12px;padding-right:12px;}}/*!sc*/\ndata-styled.g653[id=\"results-list-view__TopPositionBannerWrapper-sc-d70l4k-0\"]{content:\"jleRfd,\"}/*!sc*/\n.ifaaZC{position:relative;}/*!sc*/\n@media (max-width:767.98px){.ifaaZC{margin-top:12px;}}/*!sc*/\ndata-styled.g654[id=\"results-list-view__AdvancedSearchMainContentWrapper-sc-d70l4k-1\"]{content:\"ifaaZC,\"}/*!sc*/\n@media (max-width:575.98px){.dgFZRr{padding:0px 12px;}}/*!sc*/\ndata-styled.g655[id=\"results-list-view__AdvancedSearchAllertsWrapper-sc-d70l4k-2\"]{content:\"dgFZRr,\"}/*!sc*/\n@media (max-width:991.98px){.ixACSA{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}/*!sc*/\ndata-styled.g658[id=\"advanced-search__AdvancedSearchMainSectionWrapper-sc-1eqc1e8-1\"]{content:\"ixACSA,\"}/*!sc*/\n@-webkit-keyframes cpCHCi{from{background-color:#828282;border-color:#828282;}to{background-color:#67ac5b;border-color:#67ac5b;}}/*!sc*/\n@keyframes cpCHCi{from{background-color:#828282;border-color:#828282;}to{background-color:#67ac5b;border-color:#67ac5b;}}/*!sc*/\ndata-styled.g660[id=\"sc-keyframes-cpCHCi\"]{content:\"cpCHCi,\"}/*!sc*/\n</style></head><body><div id=\"__next\"><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"cookie-banner__CookieBannerWrapper-sc-1n3o3md-0 hutcBS\" data-test-item=\"cookie-banner\"><p class=\"text__Text-sc-f4nboj-0 ghQHoL\" size=\"28\">OUR COOKIE DISCLAIMER</p><hr class=\"separation-line__SeparationLine-sc-1gtqai2-0 separation-line__SeparationLineDefault-sc-1gtqai2-1 dLmbUA kwnPiJ\"/><p class=\"text__Text-sc-f4nboj-0 fEFHaQ\" size=\"15\">Matmatch uses cookies and similar technologies to improve your experience and measure your interactions with our website. We also use them to provide you more relevant information and improve our platform and search tools. If that’s okay, click “Accept all.” To change your preferences, click “Open cookie settings.” You will find more information about cookies on our <a href=\"/imprint#privacy-policy\" style=\"text-decoration:underline;\">privacy policy page<a></a>.</a></p><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonSuccess-sc-ekfcy0-5 lhTnpm gKwwSj\">Accept all</button><p class=\"text__Text-sc-f4nboj-0 fcGhiO\" color=\"#3880E5\" cursor=\"pointer\" size=\"15\">Open cookie settings</p></div></div><div class=\"header-container__HeaderContainer-sc-fi6wlh-0 bOrpEs\" data-app-header=\"true\"><div class=\"header__HeaderWrapper-sc-vi2mkw-0 ihiZJY\"><div class=\"header__DesktopHeaderWrapper-sc-vi2mkw-1 iOXrTY\"><div class=\"desktop-header-static-bar__DesktopHeaderStaticBar-sc-1aton5n-2 KFXRI\"><div class=\"desktop-header-static-bar__DesktopHeaderStaticBarInner-sc-1aton5n-10 bga-dBn\"><div class=\"desktop-header-static-bar__DesktopHeaderLogoSection-sc-1aton5n-4 cVRwqg\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 styled-link-styles__ImageLinkStyles-sc-l1ctuc-2 ipttFt jkkDbK desktop-header-static-bar__HeaderLogoImage-sc-1aton5n-0 bPjIbr\" height=\"37\" href=\"/\" src=\"/static/images/inlined/logo_inverted.svg\" width=\"167\"></a></div><div class=\"desktop-header-static-bar__DesktopHeaderSearchBarSection-sc-1aton5n-5 gigTJA\"><div class=\"desktop-header-search-bar__DesktopHeaderSearchBarWrapper-sc-n2cbkq-2 doqVZA\"><div class=\"desktop-header-search-bar__DesktopHeaderSearchBarInputBlockWrapper-sc-n2cbkq-3 iAiHqb\"><div class=\"desktop-header-search-bar__DesktopHeaderSearchInputWrapper-sc-n2cbkq-4 cQdUuW\"><input class=\"desktop-header-search-bar__DesktopHeaderSearchInputField-sc-n2cbkq-5 ioBjKD\" placeholder=\"e.g. Aluminium\" type=\"text\" value=\"\"/></div><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonDefault-sc-ekfcy0-2 desktop-header-search-bar__SearchButton-sc-n2cbkq-1 MSVaf kTlrHY drTDou\"><span class=\"icon__Icon-sc-1230ehg-0 EMFJO\" color=\"white\" size=\"24\" type=\"search\"></span></button></div><div class=\"desktop-header-search-bar__DesktopHeaderAutoSuggestionsWrapper-sc-n2cbkq-6 fuuwzT\"></div></div></div><div class=\"desktop-header-static-bar__DesktopHeaderControlIconsSection-sc-1aton5n-6 IRYso\"><div class=\"desktop-header-static-bar__DesktopHeaderLanguagePanelWrapper-sc-1aton5n-7 gWelzZ\"><div class=\"desktop-header-static-bar__DesktopHeaderCurrentLanguage-sc-1aton5n-8 gBSUqi\"></div><div class=\"bubble__BubbleWrapper-sc-i30r9c-0 CVmbS\"><span class=\"icon__Icon-sc-1230ehg-0 desktop-header-static-bar__GlobeIcon-sc-1aton5n-11 gpNPvA language-picker-globe-icon\" color=\"2.0/white\" size=\"24\" type=\"ios-world-outline\"></span></div></div><div class=\"desktop-header-static-bar__DesktopHeaderAuthControls-sc-1aton5n-9 hMfFLt\"><div class=\"bubble__BubbleWrapper-sc-i30r9c-0 CVmbS\"><p class=\"text__Text-sc-f4nboj-0 desktop-header-static-bar__SignInText-sc-1aton5n-12 hJBnMN lpaaHC\" color=\"#ffffff\" cursor=\"pointer\" data-test-item=\"sign-in-button\" size=\"16\">Sign in</p><a data-test-item=\"sign-up-link\" href=\"/sign-up\" rel=\"noreferrer\" target=\"_blank\"><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonSpecial-sc-ekfcy0-4 MSVaf juQzaQ login-interaction-elem\"><p class=\"text__Text-sc-f4nboj-0 kFbVgZ\" color=\"white\">Register</p></button></a></div></div></div></div><div class=\"desktop-header-static-bar__DesktopHeadersLinksWrapper-sc-1aton5n-3 kHEXRD\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBar-sc-vppewv-0 igiZBr\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItems-sc-vppewv-1 hPDTUs\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 jUHcrU\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemStyledButton-sc-vppewv-3 gbNQTp\"><p class=\"desktop-header-navigation-links__DesktopHeaderNavigationDropdownText-sc-vppewv-4 bKWUBi\" color=\"#ffffff\">Materials</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"common__DesktopHeaderDropdownWrapper-sc-170boom-0 gAQIST\"><div class=\"desktop-header-dropdown__DesktopHeaderDropdownInnerWrapper-sc-y1g0lx-0 cdqTz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5 cJNByu flfCwz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 hrfsee\"><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Categories</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cdlmON\"><div class=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0 hHnCBT\"><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=biological-material&amp;view=result-list\">Biological Material</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=wood&amp;view=result-list\">Wood</a></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=ceramic&amp;view=result-list\">Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=carbon&amp;view=result-list\">Carbon</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=engineering-ceramic&amp;view=result-list\">Engineering Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=natural-ceramic&amp;view=result-list\">Natural Ceramic</a></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=composite&amp;view=result-list\">Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=ceramic-matrix-composite&amp;view=result-list\">Ceramic Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=metal-matrix-composite&amp;view=result-list\">Metal Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=polymer-matrix-composite&amp;view=result-list\">Polymer Matrix Composite</a></div></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0 hHnCBT\"><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=glass&amp;view=result-list\">Glass</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=glass-ceramic&amp;view=result-list\">Glass Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=lead-glass&amp;view=result-list\">Lead Glass</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=silicate-glass&amp;view=result-list\">Silicate Glass</a></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=polymer&amp;view=result-list\">Polymer</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=elastomer&amp;view=result-list\">Elastomer</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=thermoplastic&amp;view=result-list\">Thermoplastic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=thermosetting&amp;view=result-list\">Thermosetting</a></div></div></div><div class=\"desktop-header-dropdown-material-categories__CategoriesColumn-sc-1ousnfb-0 hHnCBT\"><div class=\"desktop-header-dropdown-material-categories__CategoriesBloackWrapper-sc-1ousnfb-1 edSpfo\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/advanced-search?categories=metal&amp;view=result-list\">Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=aluminium&amp;view=result-list\">Aluminium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=clad---bimetal&amp;view=result-list\">Clad / Bimetal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=cobalt&amp;view=result-list\">Cobalt</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=copper&amp;view=result-list\">Copper</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=iron&amp;view=result-list\">Iron</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=magnesium&amp;view=result-list\">Magnesium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=manganese&amp;view=result-list\">Manganese</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=nickel&amp;view=result-list\">Nickel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=noble-metal&amp;view=result-list\">Noble Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=other-metal&amp;view=result-list\">Other Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=refractory-metal&amp;view=result-list\">Refractory Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=steel&amp;view=result-list\">Steel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search?categories=titanium&amp;view=result-list\">Titanium</a></div></div></div></div></div><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 zDQjJ\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Tools</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/tools/unit-converter\">Unit Converter</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/tools/hardness-converter\">Hardness Converter</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/advanced-search\">Advanced Search</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/application\">Application Search</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"https://go.matmatch.com/sncurves\">Fatigue Data</a></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 zDQjJ\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Guides</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 kUjwEN\" href=\"/guide/sustainable-materials-selection\">Sustainable Materials Selection</a></div></div></div><div class=\"common__DesktopHeaderDropdownWrapperInner-sc-170boom-1 cTBSVf\"><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/advanced-search\"><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonSpecial-sc-ekfcy0-4 kPiOHq juQzaQ\">Advanced Search</button></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/blog/learn-with-matmatch/\"><img alt=\"Learn with Matmatch\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/05/learn-with-matmatch-menu.png\" style=\"min-width:100%\"/></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/guide/sustainable-materials-selection\"><img alt=\"Learn about sustainable materials selection\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/12/sustainable-materials-selection-menu.jpg\" style=\"min-width:100%\"/></a></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 kneKJ\"><span class=\"icon__Icon-sc-1230ehg-0 bZBKhy\" color=\"2.0/default\" size=\"30\" type=\"arrow-up\"></span></div></div></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 jUHcrU\"><div class=\"desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemStyledButton-sc-vppewv-3 gbNQTp\"><p class=\"desktop-header-navigation-links__DesktopHeaderNavigationDropdownText-sc-vppewv-4 bKWUBi\" color=\"#ffffff\">For Suppliers</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"common__DesktopHeaderDropdownWrapper-sc-170boom-0 gAQIST\"><div class=\"desktop-header-dropdown__DesktopHeaderDropdownInnerWrapper-sc-y1g0lx-0 cdqTz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5 cJNByu flfCwz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 hrfsee\"><div class=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0 czLQLd\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Matmatch Suppliers</p><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/supplier\">List Your Materials</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/partners\">Matmatch Partners</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"/supplier-resources\">Resources</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/advertise\">Advertise</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/advertising-media-kit\">Media Kit (Advertising)</a></div></div></div><div class=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0 czLQLd\"><p class=\"text__Text-sc-f4nboj-0 wmqFD\" color=\"#526193\" size=\"16\">Case Studies</p><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/ampco-metal\">AMPCO METAL</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/dew\">Deutsche Edelstahlwerke</a></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/phon-tech\">Phon Tech</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div><div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"common__DesktopHeaderDropdownLinkStyles-sc-170boom-2 fWKIzC\" href=\"https://go.matmatch.com/case-study/ceratizit\">CERATIZIT</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div></div><div class=\"desktop-header-suppliers-dropdown__Column-sc-1gypbt4-0 czLQLd\"><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/supplier\"><img alt=\"Grow with Matmatch\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/10/grow-with-matmatch-cta.jpg\" style=\"max-width:60%\"/></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"https://go.matmatch.com/advertise?headerImage\"><img alt=\"Advertise\" src=\"https://matmatch.com/blog/wp-content/uploads/2021/02/media-cta.jpg\" style=\"max-width:60%\"/></a></div><div class=\"header-action-link__CtaWrapper-sc-1yhrwj5-0 dvhoXp\"><a href=\"/supplier-resources\"><img alt=\"Resources\" src=\"https://matmatch.com/blog/wp-content/uploads/2020/10/marketing-resources-cta.jpg\" style=\"max-width:60%\"/></a></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 kneKJ\"><span class=\"icon__Icon-sc-1230ehg-0 bZBKhy\" color=\"2.0/default\" size=\"30\" type=\"arrow-up\"></span></div></div></div></div></div></div><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 eYFpTR desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2 goozRc\" href=\"/resources\">Resources</a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 eYFpTR desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2 goozRc\" href=\"/about\">About us</a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 eYFpTR desktop-header-navigation-links__DesktopHeaderNavigationLinksBarItemLink-sc-vppewv-2 goozRc\" href=\"/services/get-connected\">Get Connected</a></div></div></div></div></div><div class=\"header__MobileHeaderWrapper-sc-vi2mkw-2 eWjGyj\"><div class=\"mobile-header__MobileHeaderWrapper-sc-dvud91-0 kDpNZQ\"><div class=\"mobile-header__MobileHeaderStaticBar-sc-dvud91-1 iiDvup\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 styled-link-styles__ImageLinkStyles-sc-l1ctuc-2 eePTOF dOZIXC\" height=\"22\" href=\"/\" src=\"/static/images/inlined/logo_inverted.svg\" width=\"95\"></a><div class=\"mobile-header__MobileHeaderStaticBarSearchIconWrapper-sc-dvud91-2 cmjpNo\"><span class=\"icon__Icon-sc-1230ehg-0 cXnjPW\" color=\"2.0/white\" type=\"ios-search-strong\"></span></div><span class=\"icon__Icon-sc-1230ehg-0 eyhBpa\" color=\"2.0/white\" size=\"22\" type=\"android-menu\"></span></div><div class=\"mobile-header__MobileHeaderSlideDownWrapper-sc-dvud91-6 cwmMhq\"><div class=\"mobile-header__MobileHeaderSlideDownHeader-sc-dvud91-5 CjJpx\"><ul class=\"mobile-header__MobileHeaderMenuList-sc-dvud91-3 hpPhjx\"><li class=\"mobile-header__MobileHeaderMenuListItem-sc-dvud91-4 tMWkf\"><div class=\"mobile-header-user-not-signed-in__MobileHeaderUserNotSignedInWrapper-sc-195838o-0 hvBjgr\"><button class=\"button__BaseButton-sc-ekfcy0-0 mobile-header-user-not-signed-in__MobileHeaderUserSignInButton-sc-195838o-2 NWGvI bTObyH\">Sign in</button><button class=\"button__BaseButton-sc-ekfcy0-0 mobile-header-user-not-signed-in__MobileHeaderUserSignUpButton-sc-195838o-1 NWGvI lpgqvm\">Register</button><p class=\"text__Text-sc-f4nboj-0 cJojhb\">You are not signed in</p></div></li><li class=\"mobile-header__MobileHeaderMenuListItem-sc-dvud91-4 tMWkf\"><ul class=\"list__List-sc-7ainlj-0 mobile-profile-menu__HeaderProfileMenuList-sc-c6el3s-0 uluvW eipfdL\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/messages\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Messages</li></a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/account\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Profile</li></a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/account/settings\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Settings</li></a><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"/advanced-search?categories=steel&amp;tags=form%3Abar#\"><li class=\"list__ListItem-sc-7ainlj-1 mobile-profile-menu__HeaderProfileMenuItem-sc-c6el3s-1 RbSSA eidcBU\">Sign out</li></a></ul></li><hr class=\"separation-line__SeparationLine-sc-1gtqai2-0 separation-line__SeparationLineDefault-sc-1gtqai2-1 cVgbLf kwnPiJ\"/><li class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBar-sc-ssinjx-0 evPxyJ\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Categories</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-categories-connected__MobileHeaderDropdownSecondLevelLinksWrapper-sc-rlj3br-0 cJNByu dlnRUd\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=biological-material\">Biological Material</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=wood\">Wood</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=ceramic\">Ceramic</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=carbon\">Carbon</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=engineering-ceramic\">Engineering Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=natural-ceramic\">Natural Ceramic</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=composite\">Composite</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=ceramic-matrix-composite\">Ceramic Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=metal-matrix-composite\">Metal Matrix Composite</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=polymer-matrix-composite\">Polymer Matrix Composite</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=glass\">Glass</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=glass-ceramic\">Glass Ceramic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=lead-glass\">Lead Glass</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=silicate-glass\">Silicate Glass</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=polymer\">Polymer</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=elastomer\">Elastomer</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=thermoplastic\">Thermoplastic</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=thermosetting\">Thermosetting</a></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 kYgdAl\"><div style=\"flex:1\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 elfMjy\" href=\"/advanced-search?categories=metal\">Metal</a></div></div><span class=\"icon__Icon-sc-1230ehg-0 iNazJp\" color=\"2.0/primary\" size=\"12\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 kTmWRN bxYrpi\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=aluminium\">Aluminium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=clad---bimetal\">Clad / Bimetal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=cobalt\">Cobalt</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=copper\">Copper</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=iron\">Iron</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=magnesium\">Magnesium</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=manganese\">Manganese</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=nickel\">Nickel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=noble-metal\">Noble Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=other-metal\">Other Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=refractory-metal\">Refractory Metal</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 fIeyGw\" href=\"/advanced-search?categories=steel\">Steel</a></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search?categories=titanium\">Titanium</a></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Matmatch Suppliers</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/supplier\">List Your Materials</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/partners\">Matmatch Partners</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/supplier-resources\">Resources</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/advertise\">Advertise</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/advertising-media-kit\">Media Kit (Advertising)</a></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Case Studies</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/ampco-metal\">AMPCO METAL</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/dew\">Deutsche Edelstahlwerke</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/phon-tech\">Phon Tech</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/case-study/ceratizit\">CERATIZIT</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Tools</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/tools/unit-converter\">Unit Converter</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/tools/hardness-converter\">Hardness Converter</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/advanced-search\">Advanced Search</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/application\">Application Search</a></div></div><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"https://go.matmatch.com/sncurves\">Fatigue Data</a></div></div></div></div></div><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 mobile-header-dynamic-menu__MobileHeaderDropdownFirstLevelCategoryText-sc-ssinjx-2 dzDHxo bjzJUu\">Guides</p><span class=\"icon__Icon-sc-1230ehg-0 kbRKml\" color=\"2.0/primary\" size=\"14\" type=\"ios-arrow-down\"></span></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderDropdownWrapper-sc-ssinjx-1 cJNByu bxYrpi\"><div class=\"mobile-header-dynamic-menu__MobileHeaderDropdownItemsWrapper-sc-ssinjx-4 ghkwNZ\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-navigation__MobileHeaderDropdownSecondLevelLinksWrapper-sc-h9xaov-0 cJNByu eSAgkB\"><div class=\"mobile-header-dynamic-navigation__CategoriesBlockWrapper-sc-h9xaov-1 hHsZTR\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><a class=\"mobile-header-dropdown-link__MobileHeaderDropdownLinkStyles-sc-1ifsvtl-0 hKoOWf\" href=\"/guide/sustainable-materials-selection\">Sustainable Materials Selection</a></div></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarWrapper-sc-ssinjx-3 cJNByu\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 dSdjdP\" color=\"#526193\">Resources</p></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarWrapper-sc-ssinjx-3 cJNByu\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 dSdjdP\" color=\"#526193\">About us</p></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarWrapper-sc-ssinjx-3 cJNByu\"><div class=\"mobile-header-dynamic-menu__MobileHeaderNavigationLinksBarItemstyledButton-sc-ssinjx-5 lgzuuz\"><p class=\"text__Text-sc-f4nboj-0 dSdjdP\" color=\"#526193\">Get Connected</p></div></div></li></ul></div></div></div></div></div></div><div class=\"main-content-spacer__MainContentSpacer-sc-1g5s1bz-0 hWwxLn\"></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperStaticContentNoFlex-sc-14fw43j-5 cJNByu flfCwz\" style=\"padding-bottom:0\"><div class=\"contextual-tags__ContextualTagsWrapper-sc-dg6jub-0 jnuTJQ\"><div class=\"contextual-tags__ContextualTagsItemsWrapper-sc-dg6jub-2 cSROfV\"><div class=\"contextual-tags__ContextualTagWrapper-sc-dg6jub-1 fsqjse\"><p class=\"text__Text-sc-f4nboj-0 ehJUxb\" color=\"#4f4f4f\" size=\"16\">Bar</p><svg class=\"icon__Svg-sc-1230ehg-1 caVxgD\" cursor=\"pointer\" fill=\"#3880E5\" height=\"20\" viewbox=\"0 0 30 30\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#close-71610fd5--sprite\"></use></svg></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 wrappers__WrapperStaticContent-sc-14fw43j-4 advanced-search__AdvancedSearchMainSectionWrapper-sc-1eqc1e8-1 cJNByu hFcCJB hzZiwD ixACSA\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperSidebar-sc-14fw43j-10 sidebar__AdvancedSearchSidebarWrapper-sc-1v590t3-0 kqTmue fUzxei gyajYF\" width=\"438\"><div class=\"collapse-toggle__CollapseToggleWrapper-sc-vxcac6-0 gdlobs\"><svg class=\"icon__Svg-sc-1230ehg-1 jWARuS collapse-toggle__CollapseToggleOptionsIcon-sc-vxcac6-1 gFfIFF\" fill=\"#526193\" height=\"20\" viewbox=\"0 0 30 30\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#options-4de2f7a5--sprite\"></use></svg><div class=\"collapse-toggle__CollapseToggleTitle-sc-vxcac6-2 iTeGNl\">FILTERS</div><div class=\"collapse-toggle__CollapseToggleArrowCircle-sc-vxcac6-3 cgzKyT\"><svg class=\"icon__Svg-sc-1230ehg-1 fXOOJz\" fill=\"#3880e5\" height=\"32\" viewbox=\"0 0 30 30\" width=\"32\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#arrow-dropright-circle-d7d58289--sprite\"></use></svg></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Categories </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 UxvCa dMXLyl\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 cgTHVD\" color=\"#333333\" size=\"13\">All</p></div><ul class=\"tree-renderer__TreeWrapper-sc-wdfwzn-0 djLvdn\"><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Biological Material</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Ceramic</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Composite</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Glass</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div checked=\"\" class=\"check-box__MinusCheckboxDesign-sc-1ptpc08-1 dsaEue\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Metal</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">2214</span></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div><li class=\"tree-item__TreeItem-sc-1ndoqn1-0 bhkHlB de-collapsed-tree-item\"><svg class=\"icon__Svg-sc-1230ehg-1 hrGMmp\" cursor=\"pointer\" fill=\"#4496ec\" height=\"12\" viewbox=\"0 0 30 30\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#plus-open-47001aa9--sprite\"></use></svg><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 bBVMlc\"></div><svg class=\"icon__Svg-sc-1230ehg-1 enTUov\" cursor=\"pointer\" fill=\"#4496ec\" height=\"22\" viewbox=\"0 0 30 30\" width=\"28\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#folder-344ee9af--sprite\"></use></svg><p class=\"text__Text-sc-f4nboj-0 hjLFxX\" size=\"13\">Polymer</p></li><div class=\"wrappers__CollapseContentWrapper-sc-14fw43j-12 ftzCdl\"></div></ul></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Material properties </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div></div></div><div class=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0 cwhWGZ\"><button class=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0 hXYfhe\">Add a material property<span class=\"icon__Icon-sc-1230ehg-0 eiXgPa\" color=\"2.0/white\" size=\"10\" type=\"plus\"></span></button><p class=\"text__Text-sc-f4nboj-0 advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1 ldWNpx hVhMIm\" color=\"#3880E5\" cursor=\"pointer\" disabled=\"\" size=\"13\">Clear all</p></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Metal Filters</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div class=\"guided-tour-step-category-specific-settings\"><p class=\"text__Text-sc-f4nboj-0 LLywI\" color=\"#333333\" size=\"13\">Shape / Form</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"advanced-search-category-specific-settings-dropdown__FieldWrapper-sc-113hj4-1 epQYxF\"><p class=\"text__Text-sc-f4nboj-0 advanced-search-category-specific-settings-dropdown__FieldText-sc-113hj4-0 hjtwVq gNwTRO\" color=\"#333333\" size=\"16\">Bar</p><span><span style=\"cursor:help;display:block;flex-direction:column;z-index:100\"><span class=\"icon__Icon-sc-1230ehg-0 kXkjMs\" color=\"2.0/default\" size=\"12\" type=\"close\"></span></span></span><span><span style=\"cursor:help;display:block;flex-direction:column;z-index:100\"><div class=\"advanced-search-category-specific-settings-dropdown__PlusIconContainer-sc-113hj4-7 zzdEX\"><div class=\"plus-icon__PlusIcon-sc-13w6ro8-0 fdCHWk\" size=\"16\"></div></div></span></span></div><div class=\"advanced-search-category-specific-settings-dropdown__DropDownContainer-sc-113hj4-2 kRDCWz\"><div class=\"advanced-search-category-specific-settings-dropdown__DropDownItemsWrapper-sc-113hj4-3 huFKrQ\"></div></div></div></div></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><p class=\"text__Text-sc-f4nboj-0 hLVIHw\" color=\"#526193\">SYSTEM MEASUREMENTS</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bcLXBB dMXLyl\"><div class=\"radio-button__RadioButtonOuter-sc-mwb92w-0 hucmjH\"><div class=\"radio-button__RadioButtonInner-sc-mwb92w-1 jXbQYq\"></div></div><p class=\"text__Text-sc-f4nboj-0 KmEHA\" color=\"#333333\" size=\"13\">Metric</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE dMXLyl\"><div class=\"radio-button__RadioButtonOuter-sc-mwb92w-0 hucmjH\"></div><p class=\"text__Text-sc-f4nboj-0 KmEHA\" color=\"#333333\" size=\"13\">Imperial</p></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Suppliers </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 zDQjJ cwHZQB\"><div class=\"advanced-search-sidebar-suppliers__ItemHeaderWrapper-sc-12new5k-0 cFpniu\"><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Include materials without suppliers</p><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 dTGKOg hFcCJB\"><div checked=\"\" class=\"toggle__ToggleWrapper-sc-th0yzv-0 gslBUi\"><div checked=\"\" class=\"toggle__ToggleCheckmark-sc-th0yzv-1 hbpQfU\"></div><div checked=\"\" class=\"toggle__ToggleToggle-sc-th0yzv-2 fArqYf\"></div></div></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Deutsche Edelstahlwerke (DEW)</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">93</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Ugitech</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">50</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Sverdrup Steel AS</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">20</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Salomon's Metalen</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">16</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Hempel Special Metals</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">4</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">VDM Metals</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">1</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Dongguan songshun mould steel Co., Ltd.</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">13</span></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 bRaHnE cwHZQB\"><div class=\"advanced-search-sidebar-item-header__ItemHeaderWrapper-sc-1n7d7as-0 iPlPmm\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 OhGlj\"></div><p class=\"text__Text-sc-f4nboj-0 fWynpt\" color=\"#333333\" size=\"13\">Ambica Steels Limited</p><span class=\"advanced-search-count-number__CountNumber-sc-8hlubs-0 eajQMm\">10</span></div></div></div><div class=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0 cwhWGZ\"><button class=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0 hXYfhe\">See all suppliers</button><p class=\"text__Text-sc-f4nboj-0 advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1 ldWNpx hVhMIm\" color=\"#3880E5\" cursor=\"pointer\" disabled=\"\" size=\"13\">Clear all</p></div><hr class=\"advanced-search-sidebar-separator__AdvancedSearchSidebarSeparator-sc-1rstb9s-0 dDcZzF\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu gFqwTB\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><p class=\"text__Text-sc-f4nboj-0 jLqxex\" color=\"#526193\">Applications </p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 cJNByu dMXLyl\"><svg class=\"icon__Svg-sc-1230ehg-1 haqEoE\" cursor=\"pointer\" fill=\"#333333\" height=\"14\" viewbox=\"0 0 30 30\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><use href=\"#ios-arrow-down-cc61b5f7--sprite\"></use></svg></div></div><div class=\"advanced-search-sidebar-collapsible-filters-wrapper__ASSidebarCollapsibleFiltersWrapper-sc-1m5vrop-0 XbfDr categories-tree-wrapper\"></div><div class=\"advanced-search-sidebar-actions__ActionsWrapper-sc-qhfbni-0 cwhWGZ\"><button class=\"advanced-search-sidebar-action-button__ActionButton-sc-15cfzym-0 hXYfhe\">Add an application<span class=\"icon__Icon-sc-1230ehg-0 eiXgPa\" color=\"2.0/white\" size=\"10\" type=\"plus\"></span></button><p class=\"text__Text-sc-f4nboj-0 advanced-search-sidebar-actions__ActionsText-sc-qhfbni-1 ldWNpx hVhMIm\" color=\"#3880E5\" cursor=\"pointer\" disabled=\"\" size=\"13\">Clear all</p></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperMainContent-sc-14fw43j-9 results-list-view__AdvancedSearchMainContentWrapper-sc-d70l4k-1 cJNByu prlvG ifaaZC\"><div class=\"results-list-view__TopPositionBannerWrapper-sc-d70l4k-0 jleRfd\"><div class=\"campaigns__CampaignBannerWrapper-sc-a2pwr6-0 ewHqQp\" height=\"90\"></div></div><div class=\"results-list-view__AdvancedSearchAllertsWrapper-sc-d70l4k-2 dgFZRr\"></div><div class=\"navigation-component__AdvancedSearchNavigationComponentWrapper-sc-1j05mwq-0 fHnuKk\"><div class=\"navigation-component__AdvancedSearchNavigationItemWrapper-sc-1j05mwq-1 fmDqYN\"><div class=\"navigation-component__NavigationItemNumber-sc-1j05mwq-2 bwwYIA\">1</div><p class=\"text__Text-sc-f4nboj-0 eUTBqM\" color=\"#ff8200\" size=\"16\">RESULT LIST</p></div><div class=\"navigation-component__AdvancedSearchNavigationItemWrapper-sc-1j05mwq-1 hmFsem\"><div class=\"navigation-component__NavigationItemNumber-sc-1j05mwq-2 fgAGgQ\">2</div><p class=\"text__Text-sc-f4nboj-0 hMWWGw\" color=\"#828282\" size=\"16\">VISUALISE IN ASHBY</p></div></div><div class=\"header-properties-dropdown__PropertiesDropdownWrapper-sc-jye0ar-0 emgOuh\"><div style=\"width:32%\">Material</div><div style=\"flex:1\"><div class=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0 fLuqrw\"><div class=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1 hxQNhN\"><div class=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2 grBuVO\"><span class=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4 custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6 custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7 hwiCoG dUfhYU cwaUxH\">- Property</span><div class=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8 kOKDxB\"></div></div><div class=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3 cqRtVo\"><span class=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5 kaSqTa\">No items</span></div></div><span class=\"icon__Icon-sc-1230ehg-0 custom-dropdown__SortingIcon-sc-1r4pk0f-9 kTando\" color=\"2.0/multicolor\" cursor=\"unset\" size=\"20\" type=\"default\"></span></div></div><div style=\"flex:1\"><div class=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0 fLuqrw\"><div class=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1 hxQNhN\"><div class=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2 grBuVO\"><span class=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4 custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6 custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7 hwiCoG dUfhYU cwaUxH\">- Property</span><div class=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8 kOKDxB\"></div></div><div class=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3 cqRtVo\"><span class=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5 kaSqTa\">No items</span></div></div><span class=\"icon__Icon-sc-1230ehg-0 custom-dropdown__SortingIcon-sc-1r4pk0f-9 kTando\" color=\"2.0/multicolor\" cursor=\"unset\" size=\"20\" type=\"default\"></span></div></div><div style=\"flex:1\"><div class=\"custom-dropdown__CustomDropdownWrapper-sc-1r4pk0f-0 fLuqrw\"><div class=\"custom-dropdown__CustomDropdown-sc-1r4pk0f-1 hxQNhN\"><div class=\"custom-dropdown__CustomDropdownTrigger-sc-1r4pk0f-2 grBuVO\"><span class=\"custom-dropdown__CustomDropdownOption-sc-1r4pk0f-4 custom-dropdown__CustomDropdownOptionCurrent-sc-1r4pk0f-6 custom-dropdown__CustomDropdownOptionPlaceholder-sc-1r4pk0f-7 hwiCoG dUfhYU cwaUxH\">- Property</span><div class=\"custom-dropdown__CustomDropdownArrow-sc-1r4pk0f-8 kOKDxB\"></div></div><div class=\"custom-dropdown__CustomDropdownOptions-sc-1r4pk0f-3 cqRtVo\"><span class=\"custom-dropdown__CustomDropdownInfo-sc-1r4pk0f-5 kaSqTa\">No items</span></div></div><span class=\"icon__Icon-sc-1230ehg-0 custom-dropdown__SortingIcon-sc-1r4pk0f-9 kTando\" color=\"2.0/multicolor\" cursor=\"unset\" size=\"20\" type=\"default\"></span></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Superaustenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/destb19-acidur-4529\" target=\"_blank\">Acidur 4529</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests11-acidur-4401-at-\" target=\"_blank\">Acidur 4401 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests12-acidur-4435-at-\" target=\"_blank\">Acidur 4435 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests13-acidur-4541-at-\" target=\"_blank\">Acidur 4541 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests14-acidur-4571-at-\" target=\"_blank\">Acidur 4571 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 dSEUZx\"><div class=\"adbutler__CampaignBannerWrapper-sc-1snm6gk-0 dcaIxI\"><div class=\"adbutler__CampaignBannerInnerWrapper-sc-1snm6gk-1 fgLnFQ\" height=\"90\" id=\"advanced_search_slot\"><a href=\"https://go.matmatch.com/advertise\"><img src=\"/static/images/lorem-ipsum.png\"/></a></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests11a-acidur-4404-at-\" target=\"_blank\">Acidur 4404 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests9-acidur-4301-at-\" target=\"_blank\">Acidur 4301 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests9a-acidur-4307-at-\" target=\"_blank\">Acidur 4307 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Austenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests10-acidur-4305-at-\" target=\"_blank\">Acidur 4305 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Superaustenitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/vdmm023-vdm-alloy-926\" target=\"_blank\">VDM® Alloy 926</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/vdmm-vdm-metals\" size=\"13\" target=\"_blank\">VDM Metals</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests7-acidur-4418-qt900-\" target=\"_blank\">Acidur 4418 QT900 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Duplex Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests15-acidur-4462-at-\" target=\"_blank\">Acidur 4462 +AT </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests7a-acidur-4418-qt760-\" target=\"_blank\">Acidur 4418 QT760 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Duplex Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/ugit0076-ugima-4460-cold-finished\" target=\"_blank\">UGIMA® 4460 Cold Finished</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/ugit-ugitech\" size=\"13\" target=\"_blank\">Ugitech</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Duplex Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/ugit0077-ugima-4460-cold-finished-and-drawn\" target=\"_blank\">UGIMA® 4460 Cold Finished and Drawn</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/ugit-ugitech\" size=\"13\" target=\"_blank\">Ugitech</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Precipitation Hardening Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/ugit0129-ugi-4545-air-h1025\" target=\"_blank\">UGI® 4545 AIR H1025</a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/ugit-ugitech\" size=\"13\" target=\"_blank\">Ugitech</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests1-corrodur-4021-qt800-\" target=\"_blank\">Corrodur 4021 QT800 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests3-corrodur-4034-annealed-\" target=\"_blank\">Corrodur 4034 Annealed </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Martensitic Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests4-acidur-4057-qt800-\" target=\"_blank\">Acidur 4057 QT800 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"materials-list__MaterialsListItem-sc-1ickte1-0 cVjyqt\"><div class=\"materials-list__MaterialDataWrapper-sc-1ickte1-1 dtZnEZ\"><p class=\"text__Text-sc-f4nboj-0 iidREl\" color=\"#828282\" size=\"13\">Precipitation Hardening Stainless Steel</p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 QbWNQ\" color=\"#3880E5\" href=\"/materials/dests8-acidur-4542-p800-\" target=\"_blank\">Acidur 4542 P800 </a><p class=\"text__Text-sc-f4nboj-0 lolWkU\" size=\"13\">Supplied by: </p><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 dhcylR\" color=\"#333333\" href=\"/suppliers/dest-deutsche-edelstahlwerke-dew-\" size=\"13\" target=\"_blank\">Deutsche Edelstahlwerke (DEW)</a></div><div class=\"materials-list__MaterialPropsWrapper-sc-1ickte1-2 hTQFno\"></div><div class=\"materials-list__MaterialCompareWrapper-sc-1ickte1-3 bDcoHI\"><div class=\"check-box__CheckBoxDesign-sc-1ptpc08-0 kurrkX\"></div></div></div><div class=\"pagination__PaginationWrapper-sc-1s1bcvk-0 fLLraV\"><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonPrimary-sc-ekfcy0-1 eGHzTm nqeas\" data-test-item=\"prev-page\" disabled=\"\"></button><div class=\"pagination__PaginationPagesText-sc-1s1bcvk-1 TXmbf\">Page 1 of 111</div><button class=\"button__BaseButton-sc-ekfcy0-0 button__ButtonPrimary-sc-ekfcy0-1 ljvJNw nqeas\" data-test-item=\"next-page\"></button></div></div></div><div class=\"footer-container__FooterContainer-sc-16jfcf3-0 kUuTvA\"><div class=\"static-page-wrappers__StaticPageContentWrapper-sc-fz58vx-1 fGzocz\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer__FooterWrapper-sc-1vgte7v-0 cJNByu greBxI\"><div class=\"footer__FooterResponsiveWrapper-sc-1vgte7v-2 jdQCEK\"><div class=\"footer-matmatch-logo-and-gdpr__NameAndDescriptionWrapper-sc-1mbx1ll-0 lcDCgL\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">MATMATCH</p></div><p class=\"text__Text-sc-f4nboj-0 hjtwVq\" color=\"#333333\" size=\"16\">We connect engineers, product designers and procurement teams with the best materials and suppliers for their job.</p></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListWrapper-sc-17tjnty-0 cJNByu iIAlRS\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">COMPANY</p></div><ul class=\"list__List-sc-7ainlj-0 uluvW\"><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/about\">About us</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"https://matmatch-gmbh.jobs.personio.de/\">Career</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/resources\">Resources</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/supplier\">For suppliers</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"https://go.matmatch.com/advertise\">Advertise</a><span class=\"badge__LinkBadge-sc-1kc0y45-0 ejKxFX\">new</span></li></ul></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListWrapper-sc-17tjnty-0 cJNByu iIAlRS\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">GENERAL</p></div><ul class=\"list__List-sc-7ainlj-0 uluvW\"><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/imprint\">Legal</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/imprint#privacy-policy\">Privacy</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"/imprint#tnc-buyers\">Terms &amp; Conditions</a></li><li class=\"list__ListItem-sc-7ainlj-1 bzfZbQ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 kdVFv\" color=\"#333333\" href=\"https://www.plansee.com/en/about-us/whistleblower-system.html\">Whistleblower System</a></li></ul></div><ul class=\"list__List-sc-7ainlj-0 footer-social-links__SocialLinksList-sc-1hjdthk-0 uluvW hwyVjw\"><li class=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1 jkNDpJ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"https://www.linkedin.com/company/matmatch\"><span class=\"icon__Icon-sc-1230ehg-0 duJtpp\" color=\"2.0/footer\" fill=\"#526193\" size=\"30\" type=\"social-linkedin\"></span></a></li><li class=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1 jkNDpJ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"https://twitter.com/MatmatchGmbH\"><span class=\"icon__Icon-sc-1230ehg-0 UGQFe\" color=\"2.0/footer\" fill=\"#526193\" size=\"30\" type=\"social-twitter\"></span></a></li><li class=\"footer-social-links__SocialLinksListItem-sc-1hjdthk-1 jkNDpJ\"><a class=\"styled-link-styles__StyledLinkStyles-sc-l1ctuc-0 fpFFKD\" href=\"https://www.facebook.com/MatmatchGmbH/\"><span class=\"icon__Icon-sc-1230ehg-0 bfOfuL\" color=\"2.0/footer\" fill=\"#526193\" size=\"30\" type=\"social-facebook\"></span></a></li></ul></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer__FooterWrapper-sc-1vgte7v-0 cJNByu greBxI\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 footer__FooterMiddleWrapper-sc-1vgte7v-1 kXMRZj cdLigN hZBBnE\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 cJNByu\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer-list__FooterListHeading-sc-17tjnty-1 cJNByu gFyZtw\"><p class=\"text__Text-sc-f4nboj-0 tenyk\" color=\"#526193\" size=\"20\">CONTACT US</p></div><ul class=\"list__List-sc-7ainlj-0 uluvW\"><li class=\"list__ListItem-sc-7ainlj-1 cJazBI\"><span class=\"icon__Icon-sc-1230ehg-0 cnxXUV\" color=\"2.0/footer\" cursor=\"default\" size=\"16\" type=\"ios-telephone\"></span><p class=\"text__Text-sc-f4nboj-0 GTisG\" color=\"#333333\" size=\"16\">+49 89 262075200</p></li><li class=\"list__ListItem-sc-7ainlj-1 gJZFKn\"><span class=\"icon__Icon-sc-1230ehg-0 jLgsnQ\" color=\"2.0/footer\" cursor=\"default\" size=\"16\" type=\"ios-location\"></span><p class=\"text__Text-sc-f4nboj-0 GTisG\" color=\"#333333\" size=\"16\">Leopoldstraße 250 A, 80807 Munich</p></li></ul></div></div></div><div class=\"wrappers__Wrapper-sc-14fw43j-0 footer__FooterWrapper-sc-1vgte7v-0 cJNByu greBxI\"><div class=\"wrappers__Wrapper-sc-14fw43j-0 kXMRZj\"><hr class=\"separation-line__SeparationLine-sc-1gtqai2-0 separation-line__SeparationLineDefault-sc-1gtqai2-1 dLmbUA kwnPiJ\"/><div class=\"wrappers__Wrapper-sc-14fw43j-0 wrappers__WrapperFlex-sc-14fw43j-3 footer-copyright__FooterCopyrightWrapper-sc-p1jkef-0 eHEnyb cdLigN jHUSlK\"><p class=\"text__Text-sc-f4nboj-0 cgTHVD\" color=\"#333333\" size=\"13\">© <!-- -->2021<!-- --> Matmatch GmbH, All rights reserved.</p><p class=\"text__Text-sc-f4nboj-0 cgTHVD\" color=\"#333333\" size=\"13\">Made with ♥ in Munich!</p></div></div></div></div></div></div></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"initialProps\":{\"initialI18nStore\":{\"en\":{\"account\":{\"forgot-password\":\"Forgot password?\",\"forgot-password-description\":\"In case you forgot your password you can request to reset it here.\",\"forgot-password-cta\":\"Request reset link\",\"delete-account-error\":\"Some problems were occurred while deleting your account.\",\"next-step\":{\"title\":\"Almost Done!\",\"description\":\"An email has been sent to you with the link to reset you password.\",\"cta\":\"Back to sign in\",\"title-second\":\"Now check your inbox\",\"description-second\":\"Please check your inbox, an email with the password reset link has been sent to {{email}}!\"},\"settings\":{\"title\":\"Settings\",\"reset-password-description\":\"If you would like to change your password, please click the button below. We will e-mail you a link you can use to set a new password.\",\"reset-password-cta\":\"Reset Password\",\"delete-account\":\"Delete Account\"},\"my-saved-materials\":\"My saved materials\",\"all-saved-materials\":\"See all saved materials\",\"search-and-save-materials\":\"Search and save material data sheets\",\"my-saved-searches\":\"My saved searches\",\"all-saved-searches\":\"See all saved searches\",\"latest-articles\":\"Latest articles\",\"my-matmatch-account\":\"My Matmatch Account\",\"my-supplier-network\":\"My Supplier Network\",\"info-box-message\":\"Do you need help with your project or choosing the right material?\",\"industry-leads-in-country\":\"Industry leaders in {{country}} you may know\",\"industry-leads\":\"Industry leaders you may know\",\"see-all-suppliers\":\"See all our Suppliers\",\"title\":\"My Account\",\"edit-profile\":{\"title\":\"Edit Profile\"}},\"common\":{\"register\":\"Register\",\"property\":\"Property\",\"welcome-back\":\"Welcome back\",\"property-name\":\"Property Name\",\"interaction\":\"Interaction\",\"event-date\":\"Event Date\",\"material-name\":\"Material Name\",\"contact\":\"Contact\",\"finish\":\"Finish\",\"system-measurements\":\"System Measurements\",\"metric\":\"Metric\",\"imperial\":\"Imperial\",\"audience\":\"Audience\",\"or\":\"or\",\"eg\":\"e.g.\",\"and\":\"and\",\"next\":\"Next\",\"privacy\":\"Privacy\",\"removed\":\"Removed\",\"undo\":\"Undo\",\"value\":\"Value\",\"biography\":\"Biography\",\"type\":\"Type\",\"near-me\":\"Near me\",\"legal\":\"Legal\",\"career\":\"Career\",\"back-to-results\":\"Back to results\",\"save-changes\":\"Save changes\",\"show\":\"Show\",\"materials\":\"Materials\",\"searches\":\"Searches\",\"send\":\"Send\",\"unit\":\"Unit\",\"code\":\"Code\",\"result\":\"Result\",\"name\":\"Name\",\"locations\":\"Locations\",\"save\":\"Save\",\"more\":\"More\",\"read\":\"Read\",\"properties\":\"Properties\",\"industries\":\"Industries\",\"add\":\"Add\",\"less\":\"Less\",\"blog\":\"Blog\",\"resources\":\"Resources\",\"see-all\":\"See all\",\"blog-articles\":\"Blog Articles\",\"further-reading\":\"Further reading\",\"learn\":\"Learn with Matmatch\",\"clear\":\"Clear\",\"general\":\"General\",\"applications\":\"Applications\",\"grades-title\":\"Grades provided by the supplier\",\"additionally\":\"Additionally\",\"message\":\"Message\",\"headquarters\":\"Headquarters\",\"website\":\"Website\",\"revenue\":\"Revenue\",\"close\":\"Close\",\"new\":\"New\",\"select\":\"Select\",\"select-all\":\"Select all\",\"search\":\"Search\",\"language\":\"Language\",\"units\":\"Units\",\"forgot\":\"Forgot\",\"forgot-password\":\"Did you forget your password?\",\"converted-value\":\"Converted value\",\"phone\":\"Phone\",\"phone-call\":\"Phone call\",\"phone-contact\":\"Phone contact\",\"claim-profile\":\"Claim this profile\",\"delete\":\"Delete\",\"status\":\"Status\",\"subject\":\"Subject\",\"subject-edit-if-needed\":\"Subject (edit if needed)\",\"account\":\"Account\",\"add-new\":\"Add New\",\"settings\":\"Settings\",\"dashboard\":\"Dashboard\",\"profile\":\"Profile\",\"edit-profile\":\"Edit profile\",\"about-us\":\"About us\",\"partners\":\"Partners\",\"sign-in\":\"Sign in\",\"ask-now\":\"Ask now\",\"sign-up\":\"Sign up\",\"sign-out\":\"Sign out\",\"subscribe\":\"Subscribe\",\"publish\":\"Publish\",\"unpublish\":\"Unpublish\",\"report\":\"Report\",\"published\":\"Published\",\"companies\":\"Companies\",\"unpublished\":\"Unpublished\",\"first-name\":\"First Name\",\"last-name\":\"Last Name\",\"full-name\":\"Full Name\",\"company\":\"Company\",\"suppliers\":\"Suppliers\",\"required\":\"Required\",\"should-be-number\":\"Should be a number\",\"email\":\"Email\",\"job-title\":\"Job Title\",\"for-suppliers\":\"For suppliers\",\"please-select\":\"Please select\",\"internal\":\"Internal\",\"country\":\"Country\",\"industry\":\"Industry\",\"categories\":\"Categories\",\"phone-number\":\"Phone number\",\"manage-companies\":\"Manage companies\",\"messages-admin\":\"Manage messages\",\"telephone\":\"Telephone\",\"email-address\":\"Email address\",\"country-code\":\"Country code\",\"phone-code\":\"Code\",\"terms-and-conditions\":\"Terms \\u0026 Conditions\",\"whistleblower-system\":\"Whistleblower System\",\"nothing-found\":\"Nothing found\",\"employees\":\"Employees\",\"from\":\"from \",\"here\":\"here\",\"download\":\"Download\",\"advanced-search\":\"Advanced Search\",\"revenue-yearly\":\"Revenue (yearly)\",\"contact-us\":\"Contact us\",\"contact-me\":\"Contact me\",\"book-meeting\":\"Book a meeting\",\"material-page-data-set-description\":\"Chemical composition and material properties of {{materialName}}.\",\"material-page-data-set-description-sources\":\"Chemical composition and material properties of {{materialName}}. Also available for download in XLSX and PDF. Data provided by {{sources}}\",\"contact-suppliers\":\"Contact suppliers\",\"wizard-tabs-headline\":\"Customize your search with filters\",\"wizard-tabs-headline-2\":\"Select a {{text, lowercase}} as a search filter\",\"wizard-tabs-headline-3\":\"Define property values\",\"cookies-policy\":\"In order to understand how our website is used and to be able to present you with an interest-related offer, we use cookies and other technologies. You will find more information about cookies on the privacy policy page.\",\"back\":\"Back\",\"cancel\":\"Cancel\",\"consultation-times\":\"Consultation times: Mon-Fri 9am - 5pm CET\",\"follow\":\"Follow\",\"following\":\"Following\",\"follow-suppliers\":\"Follow suppliers!\",\"collapse-menu\":\"Collapse menu\",\"footer-description\":\"We connect engineers, product designers and procurement teams with the best materials and suppliers for their job.\",\"information-and-services\":\"Information and services\",\"no-dropdown-items\":\"No items\",\"advertise\":\"Advertise\",\"media-kit\":\"Media Kit (Advertising)\",\"filters\":\"Filters\",\"material-review\":{\"title\":\"Material review\",\"unpublished-count\":\"{{count}} unpublished materials\",\"publish-cta\":\"Publish {{count}}\",\"publish-selected\":\"Publish {{count}} Selected\",\"publish-all\":\"Publish All Materials\",\"last-update\":\"Last update\",\"report-message-placeholder\":\"Please describe what data needs to be changed, added or removed\",\"report-sent\":\"Report sent\",\"report-sent-message\":\"Thank you for your report. We will review it as quickly as possible.\",\"no-unpublished-materials-message\":\"Nothing to do here. We will notify you if there are actions to be taken!\",\"show-published-text\":\"Show published materials\",\"no-published-materials-message\":\"No published materials available.\",\"publish-all-triggered\":\"You have successfully triggered publishing of all materials. The process may take several minutes!\",\"publish-all-triggered-title\":\"Publishing...\"},\"countries\":{\"china\":\"China\",\"america\":\"America\",\"germany\":\"Germany\",\"india\":\"India\",\"other\":\"Other regions\"},\"discover-materials\":{\"title\":\"Discover, compare and evaluate over \\u003cspan\\u003e{{count}}\\u003c/span\\u003e materials\"},\"supplier-materials\":{\"action-label\":\"See all materials by this supplier\"},\"book-form\":{\"success-message\":{\"processing-request\":\"Processing request\",\"title\":\"Your request has been processed\",\"message-one\":\"Thanks for booking a consultation with us, you will receive an email with the instructions within the next two days\",\"message-two\":\"Did you know that by creating a Matmatch account your request process is easier and takes less time, you also will be able to save your materials and access or new developed tools.\"}},\"contact-form\":{\"meta-title\":\"Contact Form\",\"important\":\"Important\",\"automatic-account-creation-warning\":\"By entering your information here, you will automatically create Matmatch account, needed to contact our suppliers.\",\"headline\":\"Get in touch with Matmatch\",\"company-headline\":\"Contact {{company}}\",\"company-subject\":\"I'm interested in {{material}} and would like to get in touch with you.\",\"supplier-page-subject\":\"I'm interested in your products and would like to get in touch with you.\",\"first-name-placeholder\":\"Enter Your first name\",\"full-name-placeholder\":\"Enter Your full name\",\"last-name-placeholder\":\"Enter Your last name\",\"company-placeholder\":\"What company do you work for?\",\"job-title-placeholder\":\"What is your job title?\",\"phone-placeholder\":\"Your phone number\",\"email-placeholder\":\"Your email address\",\"company-message-placeholder\":\"I'm interested in {{material}} and would like to get in touch with you.\",\"terms-and-conditions\":\"In addition to the \\u003ca href='/imprint#privacy-policy' target='_blank'\\u003eTerms and Conditions\\u003c/a\\u003e I consent to share the content provided on this form with third parties (Suppliers) to provide Quotes and additional material information to me. This site is protected by reCAPTCHA and the Google  \\u003ca href='https://policies.google.com/privacy'\\u003ePrivacy Policy\\u003c/a\\u003e and \\u003ca href='https://policies.google.com/terms'\\u003eTerms of Service\\u003c/a\\u003e apply.\",\"noCompanySubject1\":\"I have questions about this material\",\"noCompanySubject2\":\"I'm searching for a material\",\"noCompanySubject3\":\"I'm searching for a supplier\",\"message-placeholder\":\"Please include all important information for your request, for example:\",\"message-placeholder-advice1\":\"- Material type\",\"message-placeholder-advice2\":\"- Purpose of application\",\"message-placeholder-advice3\":\"- Mandatory material properties\",\"message-placeholder-advice4\":\"- Shape and dimension\",\"success-title\":\"Message sent\",\"send-failed-title\":\"Message send failed!\",\"fill-the-form-below\":\"Fill the form below\",\"success-message\":\"We will get back to you as quickly as possible.\",\"success-company-message\":\"Thank you for your message, {{contact}} will be in touch shortly\",\"success-contact-form-sign-up-message\":\"Your request was sent to Matmatch Supplier. Please follow the link sent to your e-mail to confirm your request and join the Matmatch network.\",\"success-contact-form-message-board-intro\":\"You can keep track of all your messages from your Matmatch account:\",\"success-contact-form-message-board-link\":\"Message Board\",\"send-failed-company-message\":\"Sorry, but your message has not been sent. Some technical error or backend failure. We're fixing it.\",\"supplier-indicator-title\":\"Fill the form to connect with our suppliers for this material\",\"tell-us-what-you-want\":\"Hi, how can we help?\",\"technical-question\":\"I have a technical question.\",\"quotes-question\":\"I would like a quote.\",\"quotes-form-header-text\":\"Our suppliers are more likely to reply with more specific information. So, please be as detailed as possible and we will ensure you a quick response\",\"form-message-placeholder\":\"Write your request here. Provide us as much information as possible.\",\"company-email-placeholder\":\"Write (desirably) company email here.\",\"personal-information\":\"Personal information\",\"technical-requirements\":\"Technical requirements\",\"location-details\":\"Location\",\"attach-file-or-specs\":\"Attach file or specs \",\"feature-is-unavailable\":\"We are sorry. This feature is coming soon\",\"next-step\":\"Next\",\"optional\":\"Optional\",\"requested-material\":\"Requested material\",\"intended-application-or-usage\":\"Intended application/use\",\"material-form\":\"Form\",\"material-dimensions\":\"Dimensions\",\"material-quantity\":\"Quantity\",\"shipping-country\":\"Shipping country\",\"first-name\":\"First name\",\"last-name\":\"Last name\",\"phone\":\"Phone\",\"country-code\":\"Country code\",\"phone-code\":\"Code\",\"company\":\"Company\",\"company-email\":\"Company email\",\"job-title\":\"Job title\",\"message\":\"Add a comment or additional technical requirement\",\"private-email-warning\":\"Suppliers are more likely to reply if you provide a company email address\",\"additional-request-information\":\"Additional request information\",\"material-color\":\"Material color\",\"material-length\":\"Length\",\"material-width\":\"Width\",\"material-thickness\":\"Thickness\",\"material-diameter\":\"Diameter\",\"particle-size\":\"Particle size\",\"describe-your-material\":\"Short description of the material\",\"material-general-description\":\"Add a comment or additional technical requirement\",\"create-account\":\"Would you like to send requests more quickly in the future and access additional Matmatch features? Then create your Matmatch account now - it just takes a click.\",\"material-shapes-info\":\"You see only supported material shapes in dropdown menu above. If you want other shape, please choose 'Other' and describe desired shape in corresponding fields. If you don't see 'Other' option, supplier doesn't produce custom material shapes for selected material.\",\"describe-custom-form\":\"Describe custom form here\",\"contact-user\":\"Contact user\",\"contact-users\":\"Contact {{ number }} users\",\"one-more-step-popup-header\":\"One more step\",\"one-more-step-popup-message\":\"Please \\u003cb\\u003echeck your email mailbox\\u003c/b\\u003e and verify your account for your request to reach the supplier and for you to receive replies.\",\"type-or-select-shipping-location\":\"Type or select a shipping location\",\"company-website\":\"Company website\",\"company-website-placeholder\":\"Your company website\",\"form-section-name-suppliers\":\"{{sectionNumber}}. Suppliers ({{count}})\",\"form-section-technical-information\":\"{{sectionNumber}}. Technical information\",\"form-section-personal-information\":\"{{sectionNumber}}. Personal information\",\"send-request\":\"Send request\",\"send-message\":\"Send message\",\"material-request-form-title\":\"Material request\",\"alert-error-fill-required-fields-title\":\"Fill all required fields\",\"alert-error-fill-required-fields-text\":\"Please fill all the required fields in order to send the request to our supplier!\",\"view-request-for\":\"View request for {{materialName}}\",\"request-more-details\":\"Request more details\",\"quotation-request-form-title\":\"Request a quotation\",\"technical-question-form-title\":\"Ask a technical question\",\"your-question\":\"Your question (please provide as much detail as possible)\",\"your-message\":\"Your message (please provide as much detail as possible)\",\"supplier-profile-contact-form-title\":\"Contact {{companyName}}\"},\"contact-forms-items\":{\"granule\":\"Granule\",\"powder\":\"Powder\",\"pellet\":\"Pellet\",\"film\":\"Film\",\"sheet\":\"Sheet\",\"filament\":\"Filament\",\"other\":\"Other\"},\"contact-box\":{\"supplied-by\":\"Material Supplied by\",\"any-questions\":\"Do you have any questions?\",\"contact-mat-sci\":\"Contact our Material Scientists\",\"contact-supplier\":\"Contact Supplier\",\"contact-specific-supplier\":\"Contact {{name}} now\",\"contact-specific-supplier-promo\":\"Do you have a question about this material?\",\"contact-suppliers\":\"Contact Suppliers ({{num}})\",\"contact-partner\":\"Contact {{type}}\",\"send-us-question\":\"Send us a message\",\"more-details\":\"More Details\",\"send-a-question-to\":\"Send a question to\",\"any-doubt\":\"Any doubt?\",\"send-a-question-for-free\":\"Any questions?\",\"send-a-message\":\"Send a message\",\"write-your-message-here\":\"Write your message here\",\"request-quotation\":\"Request a quotation\",\"ask-supplier-technical-question\":\"Ask the supplier a technical question\",\"ask-a-technical-question\":\"Ask a technical question\"},\"supplier-indicator-contact-box\":{\"title\":\"Find a supplier\",\"contact\":\"Send your requirements\",\"info\":\"We can help you find a supplier of {{materialName}}\",\"note\":\"We will evaluate your request and get back to you soon.\"},\"show-more\":{\"show-all\":\"Show all\",\"show-less\":\"Show less\"},\"pagination\":{\"previous\":\"Previous\",\"next\":\"Next\",\"pages-info\":\"Page {{num}} of {{total}}\"},\"saved-materials\":{\"see-list\":\"See list\",\"saved-items\":\"Saved items\",\"saved-materials\":\"Saved Materials\",\"new-material-saved\":\"New material saved\",\"not-registered-yet\":\"Not registered yet?\",\"auth-box-heading\":\"Save your materials and searches permanently!\",\"auth-box-text\":\"Sign in or sign up for a free account to permanently save materials and searches.\",\"saved-materials-mobile-text\":\"Save materials by pressing the star icon that you can find on search results list.\"},\"saved-searches\":{\"save-search\":\"Save search\",\"popup\":{\"title\":\"Name you search\",\"description\":\"Give a name to your search before saving it\",\"input-placeholder\":\"Search name\"}},\"saved-items\":{\"box-title\":\"My saved items\",\"saved-items\":\"Saved items\",\"new-item-saved\":\"New item saved\"},\"accept-terms-and-newsletter\":{\"title\":\"Privacy \\u0026 terms\",\"heading\":\"Please agree to our terms\",\"terms\":\"To continue you need to agree with our \\u003ca href='/imprint#tnc-buyers'\\u003eTerms and Conditions\\u003c/a\\u003e and our \\u003ca href='imprint#privacy-policy'\\u003ePrivacy Policy\\u003c/a\\u003e\",\"newsletter\":\"I would like to receive the Matmatch newsletter\",\"accept\":\"Accept and continue\"},\"comparison\":{\"compare\":\"Compare\",\"text\":\"{{count}} materials selected for comparison.\",\"disabled\":\"Please select two or more materials for comparison\",\"search-results\":\"Search results\",\"section-standards\":\"Standards\",\"section-equivalent-standards\":\"Equivalent standards\",\"section-chemical-composition\":\"Chemical composition\"},\"supported-languages\":{\"english\":\"English\",\"german\":\"German\",\"spanish\":\"Spanish\"},\"account-form\":{\"bio-placeholder\":\"Say something about yourself or add a link to a social profile\",\"submit-button-text\":\"Update information\",\"account-update-success\":\"You have successfully update Your account!\"},\"chemical-table\":{\"element\":\"Element\",\"weight\":\"Weight %\",\"comment\":\"Comment\"},\"company-type\":{\"DATA_PROVIDER\":\"Data provider\",\"ASSOCIATION\":\"Association\",\"SUPER_ASSOCIATION\":\"Association\",\"CONSULTANCIES\":\"Consultancy\",\"MANUFACTURER_AND_PROCESSOR\":\"Manufacturer and Processor\",\"MANUFACTURER\":\"Manufacturer\",\"MANUFACTURER_AND_DISTRIBUTOR\":\"Manufacturer and Distributor\",\"PROCESSOR\":\"Processor\",\"DISTRIBUTOR\":\"Distributor\",\"MATERIAL_SOURCE\":\"Material source\",\"MANUFACTURER_AND_PROCESSOR_AND_DISTRIBUTOR\":\"Manufacturer, Processor and Distributor\"},\"retired-material\":{\"title\":\"This material is no longer available. Search below to find a relevant alternative material.\",\"title-superseded\":\"The material: '{{material}}' you were looking for has been superseded by the one below.\"},\"supplier\":{\"qualified-label\":\"Matmatch qualified supplier\"},\"application\":{\"meta\":{\"industry-title\":\"Find Materials by Industry and Application\",\"search-results\":\"Materials for {{industry}} - {{application}}\",\"navigation\":\"Find Materials - {{industry}}\"},\"application\":\"Application\",\"title\":\"Discover materials from your industry\",\"description\":\"Build better products by discovering new materials for your industry. Search directly for an application or browse our catalogue below.\",\"search-input-placeholder\":\"e.g. Aerospace, Aerospace Electric Equipment, Turbine Blades ...\",\"no-results\":\"No results for your application!\",\"no-properties\":\"No properties available\",\"no-properties-selected-message\":\"You should select at least 1 property to see the chart!\",\"reset-filters\":\"Reset filters\",\"radar-chart-materials-message\":\"You should apply at least 3 properties for radar chart!\",\"radar-chart-max-amount-of-materials\":\"Maximum number ({{amount}}) of materials for this type of chart achieved!\",\"available-properties\":\"Available properties\",\"textual-comparison-cta\":\"Go to textual comparison\",\"meta-title\":\"Applications\",\"search-by-application\":\"Application Search\",\"default-breadcrumbs-category-name\":\"Industries\",\"comparison-scroll-to-the-right\":\"Please, scroll to the right to see the comparison\"},\"new-features-presentation\":{\"saved-search-presentation-popup-body\":\"You can now save your searches on Matmatch to access them quickly in the future. Simply use the \\\"Save search\\\" button on the right side of the screen on search results page.\",\"saved-search-presentation-popup-header\":\"Hey, did you know?\",\"dismiss\":\"Dismiss\",\"see-the-feature\":\"See the feature\"},\"tools\":{\"tools\":\"Tools\",\"unit-converter\":{\"title\":\"Unit converter\",\"title-landing\":\"Convert {{fromUnit}} to {{toUnit}}\",\"meta-description-landing\":\"Convert {{fromUnit}} to {{toUnit}} and other {{unitCategory}} units with this easy-to-use online unit converter.\",\"header-landing\":\"Convert from {{fromUnit}} to {{toUnit}}\",\"description\":\"Convert data between a wide variety of different units in just a few clicks. You can currently convert dielectric strength, temperature, pressure, thermal conductivity, energy, electrical resistivity, stress, power, volume and density units.\",\"description-landing\":\"To convert from {{fromUnit}} to {{toUnit}} enter the desired value for {{fromUnit}} below and the tool will convert it to {{toUnit}} and all other available units. You can also select and convert other types of units. \\u003cbr/\\u003e\\u003cbr/\\u003e\\u003cstrong\\u003e{{formula}}\\u003c/strong\\u003e\",\"other-units-title\":\"{{selectedUnitValue}} {{fromUnit}} is also equivalent to:\",\"converter-title\":\"Chose type of unit for conversion\",\"group-placeholder\":\"Choose a group\",\"properties-message\":\"Did you know? You can now search materials by their properties. Try it\",\"quick-conversions\":\"Quick conversion chart of {{fromUnit}} to {{toUnit}}:\"},\"hardness-converter\":{\"meta-title\":\"Hardness Converter\",\"meta-description\":\"Convert values between different hardness testing methods based on the material category.\",\"title\":\"Hardness Converter\",\"description\":\"Convert values between different hardness testing methods based on the material category. The converted values are extrapolated from test data and collated tabular data, so should be take as approximations.\",\"material-category\":\"Material\",\"material-category-placeholder\":\"Select a Material Category\",\"testing-method\":\"Testing Method\",\"testing-method-placeholder\":\"Select testing method\",\"wrong-input-range\":\"Please enter a value between {{min}} and {{max}}\",\"info-message\":\"All converted values are given as approximations and are for reference only.\",\"found-materials\":\"There are {{count}} materials in our database matching the value you converted\",\"view-materials\":\"View matching materials \\u003ca href='{{url}}'\\u003enow\\u003c/a\\u003e.\"}},\"services\":{\"title\":\"Services\",\"get-connected\":\"Get connected\",\"material-consultancy\":\"Material consultancy\"},\"messages\":\"Messages\",\"roles\":{\"USER\":\"Website user\",\"BETA_USER\":\"Beta website user\",\"SUPPLIER_BETA_USER\":\"Beta Dashboard user\",\"SUPPLIER_CONTACT\":\"Message User\",\"SUPPLIER_USER\":\"Dashboard User\"},\"book-demo\":{\"form\":{\"subscription-label\":\"I would like to receive email news and updates from Matmatch\",\"checkbox-label\":\"By clicking below, you consent to allow Matmatch to store and process the personal information submitted above to provide you with more information about listing as a supplier on Matmatch.\",\"privacy-label\":\"View our \\u003ca href='/imprint#privacy-policy'\\u003eprivacy policy\\u003c/a\\u003e for more information on how your data is used.\"}},\"supplier-dashboard\":{\"menu-item-dashboard-home\":\"Dashboard Home\",\"menu-item-messages-board\":\"Messages Board\",\"menu-item-messages-admin\":\"Messages Admin\",\"menu-item-audience\":\"Audience ({{ numOfEventTypes }})\",\"menu-item-performance\":\"Performance\",\"menu-item-performance-temp\":\"Performance (Temp)\",\"menu-item-visibility\":\"Visibility\",\"menu-item-materials\":\"Materials\",\"menu-item-webinar-audience\":\"Webinar audience\",\"not-available-for-mobile\":\"Our analytics board is not supported in mobile version. You may access it on your PC or tablet.\",\"menu-item-support\":\"Supplier Support\",\"menu-item-contact-us\":\"Contact Us\",\"menu-item-faq\":\"FAQ\",\"geo-chart-item-compare-views\":\"Compare views\",\"geo-chart-item-content-views\":\"Content views\",\"geo-chart-item-material-views\":\"Material views\",\"geo-chart-item-profile-views\":\"Profile views\",\"table-header-material-name\":\"Material name\",\"table-header-count\":\"Count\",\"table-header-page-views\":\"Page views\",\"table-header-most-compared-material\":\"Most Compared material\",\"table-header-compared-material-producer\":\"Material producer\",\"table-header-company-name\":\"Company\",\"table-header-employee-count\":\"Employees\",\"table-header-visits\":\"Visits\",\"table-header-visitors\":\"Visitors\",\"table-header-count-views\":\"Views\",\"table-header-count-registered-views\":\"Views from Registered Users\",\"table-header-count-downloads\":\"Downloads\",\"table-header-count-copies\":\"Copies\",\"table-header-count-comparisons\":\"Comparisons\",\"table-header-date\":\"Date\",\"table-header-size\":\"Size\",\"table-header-keyword\":\"Keyword\",\"table-header-clicks\":\"Clicks\",\"table-header-impressions\":\"Impressions\",\"table-header-compared-materials\":\"Compared with\",\"table-header-compared-companies\":\"Compared suppliers\",\"table-header-compared-properties\":\"Compared properties\",\"table-header-supplier\":\"Supplier\",\"table-header-country\":\"Country\",\"table-header-city\":\"City\",\"table-comparison-expand\":\"Expand\",\"table-comparison-collapse\":\"Collapse\",\"table-header-full-name\":\"Name\",\"table-header-job-title\":\"Job Title\",\"table-header-status\":\"Status\",\"table-header-registered-date\":\"Registered On\",\"table-header-email\":\"E-mail\",\"table-header-grade\":\"Grade\",\"table-header-shape\":\"Shape\",\"table-header-equivalentMaterials\":\"Equivalent Materials\",\"table-header-standards\":\"Standard / Norm\",\"material-performance-by-interaction-type\":{\"title\":\"Material performance by interaction type\",\"tooltip\":\"Control metrics showing how people interact with your content on Matmatch.\"},\"material-details\":{\"title\":\"Material details\",\"tooltip\":\"See the detailed information of your material page performance on Matmatch.\"},\"material-comparisons\":{\"title\":\"Material comparisons\",\"tooltip\":\"See the detailed information of your materials that were compared with other materials on Matmatch.\"},\"visibility-by-type\":{\"title\":\"Visibility by type\",\"tooltip\":\"Control metrics showing how often your content is found on Matmatch.\"},\"visibility-by-country\":{\"title\":\"Visibility by country\",\"tooltip\":\"Control metrics showing countries of people accessing your content on Matmatch.\"},\"most-visited-materials\":{\"title\":\"Most visited materials\",\"tooltip\":\"See your best performing Material Pages.\"},\"top-compared-materials\":{\"title\":\"Top compared materials\",\"tooltip\":\"See your most compared Material Pages.\"},\"visibility-by-companies\":{\"title\":\"Large companies visiting your materials\",\"tooltip\":\"See the biggest companies that were accessing your content on Matmatch. Companies are identified based on visitor IP address.\"},\"top-google-keywords\":{\"title\":\"Top Google keywords\",\"tooltip\":\"Control metrics showing keywords entered in google search before accessing your content on Matmatch.\"},\"linked-materials-details\":{\"title\":\"Linked material details\",\"tooltip\":\"See the detailed information of material page performance on Matmatch where your company details have been shown.\"},\"day\":\"Day\",\"week\":\"Week\",\"month\":\"Month\",\"nothing-found\":\"No data available for the selected period\",\"sorry\":\"Sorry\",\"dashboard-not-available-for-mobiles\":\"This section is not available for mobile device yet. Try the desktop version for the full experience.\",\"attention-demo-mode\":\"Attention: you are in demo mode, static data is shown!\",\"webinars-label\":\"Webinars\",\"webinars-title\":\"Webinar registrants\"},\"go-to-message-board\":\"Go to message board\",\"sorry\":\"Sorry...\",\"cookies\":{\"banner-title\":\"Our cookie disclaimer\",\"accept\":\"Accept all\",\"open-settings\":\"Open cookie settings\",\"confirm\":\"Confirm my choices\",\"settings\":\"Cookie settings\",\"popup-description\":\"You can control how Matmatch use cookies and similar technologies by making choices below. But note that if you disable cookies and similar technologies entirely, Matmatch may not function properly.\",\"consent-title\":\"Necessary\",\"consent-description\":\"These cookies are required, and they are used to enable core functionality on Matmatch. Without them the site could not operate, so they cannot be disabled.\",\"preferences-title\":\"Preferences\",\"preferences-description\":\"These cookies enable Matmatch to deliver a more personalised experience to your interests on the platform.\",\"statistics-title\":\"Statistics\",\"statistics-description\":\"These cookies are used to analyze site usage to measure and improve performance. Without them Matmatch cannot know what content is most valued and how often unique visitors return to the site, making it hard to improve the information and services we offer to you.\",\"tracking-title\":\"Marketing\",\"tracking-description\":\"These cookies are used to enable Matmatch to serve content more relevant to your interests both on and off the platform.\",\"banner-disclaimer\":\"Matmatch uses cookies and similar technologies to improve your experience and measure your interactions with our website. We also use them to provide you more relevant information and improve our platform and search tools. If that’s okay, click “Accept all.” To change your preferences, click “Open cookie settings.” You will find more information about cookies on our \\u003ca style='text-decoration:underline;' href='/imprint#privacy-policy'\\u003eprivacy policy page\\u003ca/\\u003e.\"},\"sustainability\":{\"share-text\":\"Share this page\",\"pdf\":{\"question\":\"Download a PDF copy\",\"text\":\"Receive a copy of this article in PDF format via email\",\"button\":\"Get it now\",\"pop-up\":\"By clicking below you consent to allow Matmatch to store and process the personal information submitted above to provide you the content requested. View our privacy policy for more information on how your data is used.\"},\"how-to-source-title\":\"Get in touch\"}},\"navigation\":{\"20\":{\"header\":{\"materials\":\"Materials\",\"for-suppliers\":\"For Suppliers\",\"about-us\":\"About us\",\"get-connected\":\"Get Connected\",\"3d-printing-hub\":\"3D Printing\"}},\"companies-list\":\"Companies list\",\"material-review\":\"Material review\"},\"sign-in-up\":{\"password\":\"Password\",\"save-password\":\"Save password\",\"sign-in-up\":\"Sign In / Up\",\"not-signed-in\":\"You are not signed in\",\"view-my-profile\":\"View my Profile\",\"open-profile-menu\":\"Open profile menu\",\"close-profile-menu\":\"Close profile menu\",\"create-account-now\":\"Create your account now\",\"sign-in\":{\"password-placeholder\":\"Type your password\",\"new-to-matmatch\":\"New to Matmatch?\",\"email-placeholder\":\"Enter the address you signed up with\",\"welcome-back-message\":\"To sign in to your Matmatch account, please enter your email and password.\"},\"set-password\":{\"title\":\"Set a password\",\"password-placeholder\":\"Set your new password\",\"hint\":\"Your password should be at least 8 characters long.\"},\"forgot-password\":{\"title\":\"Forgot password?\",\"request-reset\":\"Request reset link\",\"email-placeholder\":\"Enter your e-mail address\",\"hint\":\"In case you forgot your password you can request to reset it here.\",\"instructions\":{\"one\":\"1. To reset a password, please enter your email address. Then click “Send me reset link” button.\",\"two\":\"2. Check your inbox for a password reset email. Click on the URL provided in the email and enter a new password.\",\"three\":\"3. If you don’t know your email address or it is no longer valid, please create a new Matmatch account \"}},\"success-popup\":{\"almost-done\":\"Almost done!\",\"back-to-sign-in\":\"Back to sign in\",\"back-to-matmatch\":\"Back to matmatch.com\",\"confirmation-mail-note\":\"We’ve sent you a confirmation email to {{email}}. Please click the link in the email to activate your account.\"},\"sign-up\":{\"signup-failed\":\"Signup failed\",\"create-account\":\"Create account\",\"create-your-account\":\"Create your account\",\"email-placeholder\":\"Your email address\",\"already-account\":\"Already have an account?\",\"last-name-placeholder\":\"Enter your last name\",\"first-name-placeholder\":\"Enter your first name\",\"newsletter-label\":\"I would like to receive the Matmatch e-mail newsletter\",\"terms-and-conditions-label\":\"I have read and agreed to the Matmatch \\u003ca href='/imprint#tnc-buyers'\\u003eTerms and Conditions\\u003c/a\\u003e and \\u003ca href='/imprint#privacy-policy'\\u003ePrivacy Policy.\\u003c/a\\u003e\",\"signup-failed-message\":\"Oops! Something went wrong during the signup process. We will investigate and fix the issue as fast as possible.\",\"do-you-work-for-material-supplier\":\"Do you work for a material supplier?\"},\"sign-in-page\":{\"meta-title\":\"Sign In\",\"title\":\"Sign In\"},\"sign-up-page\":{\"meta-title\":\"Sign Up\",\"title\":\"Create an account\"},\"activation-page\":{\"meta-title\":\"Account Activation\",\"activated-title\":\"Done!\",\"activated-message\":\"Your new password has been set and the account has been activated.\",\"sign-in\":\"Sign In\",\"account\":\"Account\"},\"info\":{\"sign-in-to-download\":\"Sign in or create your free Matmatch account to download this datasheet. A free account includes access to hundreds of thousands of detailed technical datasheets.\",\"sign-in-description\":\"Registered users have full access to all premium features for free.\",\"company-email-tooltip\":\"Matmatch is a platform that connects professionals in the materials industry. Please provide your valid company address.\"},\"value-propositions\":{\"title\":\"Create your Matmatch account for free and enjoy all premium features\",\"suppliers-title\":\"Our material data comes directly from material suppliers and verified data partners\",\"values\":{\"one\":{\"value\":\"Unlimited datasheet downloads.\",\"description\":\"Download technical datasheets for thousands of materials in .pdf and .xlsx formats.\"},\"two\":{\"value\":\"Ashby charts interactivity.\",\"description\":\" Get more technical data about material upon clicking.\"},\"three\":{\"value\":\"Ashby chart image.\",\"description\":\"Export Ashby chart in .png format.\"},\"four\":{\"value\":\"Property charts.\",\"description\":\"View material behaviour under different temperatures.\"},\"five\":{\"value\":\"SN-curves.\",\"description\":\"Request fatigue data (S-N curve) for different materials.\"},\"six\":{\"value\":\"Supplier contact.\",\"description\":\"Get in touch with suppliers and keep track of all your messages from the Matmatch message board.\"}}},\"premium-features\":{\"registered-only\":\"This feature is for registered users only\"}},\"advanced-search\":{\"common\":{\"categories\":\"Categories\",\"properties\":\"Properties\",\"nothing-added\":\"Nothing added\",\"more-search-options\":\"More search options\",\"title\":\"Advanced Search - Matmatch\",\"suppliers\":\"Suppliers\",\"applications\":\"Applications\",\"download-chart-as-png\":\"Download as .PNG\",\"teaser-description\":\"Sign up to get access to this premium feature for free.\"},\"sidebar\":{\"labels-title\":\"Search result for\",\"clear-all\":\"Clear all\",\"show-all\":\"Show all\",\"all\":\"All\",\"properties\":{\"cta\":\"Add a material property\"},\"suppliers\":{\"cta\":\"See all suppliers\"},\"applications\":{\"cta\":\"Add an application\"}},\"alerts\":{\"category-specific-filter-disabled\":{\"description\":\"Some filter options have been disabled following your previous selection.\"},\"selecting-materials-info\":{\"title\":\"Compare Materials Tip!\",\"description\":\"Select two or more Materials by pressing the checkbox on the right and then press the \\\"Compare and Visualise\\\" button.\"},\"all-categories-selected\":{\"title\":\"All Material Categories have now been selected.\"},\"properties-disabled\":{\"title\":\"Properties disabled\",\"description\":\"The following properties: [ {{properties}} ] are not linked to the existing material categories.\"},\"properties-disabled-due-applied-filters\":{\"title\":\"Properties disabled\",\"description\":\"The following properties: [ {{properties}} ] have been disabled due to applied filters.\"},\"categories-disabled\":{\"title\":\"Material categories disabled\",\"description\":\"The following categories: [ {{categories}} ] have been disabled due to applied filters.\"},\"no-materials-left\":{\"title\":\"All materials have been filtered out.\",\"description\":\"Please re-adjust the slider filters, or add additional categories to bring back some materials.\"},\"material-retired\":{\"title\":\"Warning!\",\"description\":\"This material is no longer available. Search below to find a relevant alternative material.\"}},\"main-content\":{\"supplied-by\":\"Supplied by: \",\"supplied-by-matmatch\":\"{{number}} Matmatch suppliers\",\"supplied-by-matmatch-singular\":\"{{number}} Matmatch supplier\"},\"comparison\":{\"compare-count\":\"Compare ({{count}})\",\"compare-materials\":\"Compare Materials\",\"compare-and-visualise\":\"Compare and Visualise\",\"materials-selected\":\"{{count}} materials selected\"},\"categories\":{\"popup\":{\"title\":\"Material categories\",\"selected-categories\":\"Selected Categories\"}},\"properties\":{\"popup\":{\"title\":\"Material properties\",\"search-placeholder\":\"Property Search\"}},\"suppliers\":{\"popup\":{\"title\":\"Material suppliers\",\"selected-suppliers\":\"Selected Suppliers\"}},\"header\":{\"property-placeholder\":\"- Property\",\"no-properties-in-sidebar-info\":\"You have no properties to compare, add some properties in the sidebar first.\"},\"category-specific-title\":{\"metal\":\"Metal Filters\",\"polymer\":\"Polymer Filters\",\"ceramic\":\"Ceramic Filters\",\"composite\":\"Composite Filters\"},\"category-specific-settings\":{\"forms\":\"Shape / Form\",\"modifications\":\"Modification\",\"fillers\":\"Filler\",\"processing\":\"Processing\",\"certifications\":\"Certification Group\",\"primary-phase\":\"Primary Phase\",\"secondary-phase\":\"Secondary Phase\",\"tooltip-add-forms\":\"Add a shape filter\",\"tooltip-add-modifications\":\"Add a modification filter\",\"tooltip-add-fillers\":\"Add a filler filter\",\"tooltip-add-processing\":\"Add a processing filter\",\"tooltip-add-certifications\":\"Add a certification filter\",\"tooltip-add-primary-phase\":\"Add a primary phase filter\",\"tooltip-add-secondary-phase\":\"Add a secondary phase filter\",\"tooltip-clear-all\":\"Clear all\"},\"applications\":{\"popup\":{\"selected-applications\":\"Selected applications\",\"no-applications\":\"No Applications found for these Materials!\"}},\"contextual-tags\":{\"results-number\":\"{{count}} results for\"},\"no-results\":{\"title\":\"Sorry, no results found\",\"text\":\"Try searching again by typing a material name in the search bar or choose a filter to add.\"},\"navigation\":{\"result-list\":\"Result list\",\"plot-materials\":\"Visualise in Ashby\"},\"plot-materials\":{\"title\":\"Setup Ashby Chart\",\"x-axis\":\"Change X - Axis\",\"y-axis\":\"Change Y - Axis\"}},\"search-and-filters\":{\"advanced-filters\":\"Advanced filters\",\"resetFilter\":\"Reset filter\",\"only-with-supplier\":\"Show materials with suppliers\",\"only-with-supplier-short\":\"Only with suppliers\",\"searchTips\":{\"headline\":\"\\u003cb\\u003eSearch tips:\\u003c/b\\u003e\",\"noMatches\":\"Sorry, no matches found for \\u003cb\\u003e{{text}}\\u003c/b\\u003e\",\"tip1\":\"Reduce the number of search terms\",\"tip2\":\"Try alternative spellings for your search terms\",\"tip3\":\"Use different search terms\"},\"wizard\":{\"inputPlaceholder\":\"Type to filter the list\"},\"search-bar-placeholders\":{\"1\":\"Aluminium\",\"2\":\"Density\",\"3\":\"Elastic Modulus\",\"4\":\"High carbon steel\",\"5\":\"AISI 201\",\"6\":\"Thermal diffusivity\",\"7\":\"Tungsten alloy\",\"empty-submission-error\":\"Type a material name or category to start a search\",\"default\":\"Type a material name, property, category or supplier\"},\"search\":\"Search\",\"results\":\"Results\",\"search-bar\":{\"title\":\"Make better material decisions\",\"sub-title\":\"Find and compare materials for your projects.\",\"filters\":{\"property\":{\"title\":\"Search by property\",\"text\":\"Find materials that meet specific requirements\"},\"category\":{\"title\":\"Search by category\",\"text\":\"Explore different materials in a certain category\"},\"supplier\":{\"title\":\"Search by supplier\",\"text\":\"Discover materials offered by a specific supplier\"}}}},\"ashby-chart\":{\"breadcrumbs-level-one\":\"All categories\",\"download-as-png\":\"Download Ashby chart as PNG: \",\"data-point\":{\"header-materials\":\"Materials\",\"supplier\":\"Supplied by:\"}}}},\"initialLanguage\":\"en\",\"i18nServerInstance\":null,\"pageProps\":{\"data\":{\"labels\":[],\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"unitsSystem\":\"metric\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true}]},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true}]},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true}]},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true}]},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true}]},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true}]}]},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true}]},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true}]},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true}]}]},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true}]},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true}]},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true}]},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true}]}]},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true}]},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true}]}]},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true}]},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true}]}]},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true}]},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true}]},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true}]},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true}]},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true}]},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true}]}]},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true}]},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true}]},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true}]},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true}]},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true}]},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true}]},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true}]},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true}]},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true}]},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true}]}]},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true}]},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true}]},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true}]},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true}]},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true}]},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true}]},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true}]}]},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true}]}]},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true}]},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true}]},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true}]},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true}]}]},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true}]},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true}]},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true}]},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true}]},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true}]},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true}]},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true}]},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true}]},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true}]}]},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true}]},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true}]}]}],\"propertySections\":[],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}],\"supplierMaterialsOnly\":false,\"polymerFilter\":{\"disabled\":true},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"specification\":{\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"clauses\":[{\"type\":\"tags\",\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}]},\"context\":{\"unitsSystem\":\"metric\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true}]},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true}]},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true}]},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true}]},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true}]},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true}]}]},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true}]},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true}]},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true}]}]},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true}]},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true}]},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true}]},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true}]}]},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true}]},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true}]}]},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true}]},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true}]}]},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true}]},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true}]},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true}]},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true}]},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true}]},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true}]}]},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true}]},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true}]},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true}]},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true}]},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true}]},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true}]},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true}]},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true}]},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true}]},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true}]}]},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true}]},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true}]},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true}]},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true}]},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true}]},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true}]},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true}]}]},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true}]}]},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true}]},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true}]},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true}]},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true}]}]},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true}]},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true}]},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true}]},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true}]},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true}]},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true}]},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true}]},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true}]},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true}]}]},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true}]},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true}]}]}],\"categorySpecificFilter\":{\"name\":\"metal\",\"disabled\":false,\"forms\":[{\"id\":\"bar\",\"label\":\"Bar\",\"checked\":true},{\"id\":\"billet\",\"label\":\"Billet\"},{\"id\":\"casting\",\"label\":\"Casting\",\"disabled\":true},{\"id\":\"coil\",\"label\":\"Coil\"},{\"id\":\"disc\",\"label\":\"Disc\",\"disabled\":true},{\"id\":\"flat\",\"label\":\"Flat\"},{\"id\":\"flat-bar\",\"label\":\"Flat Bar\"},{\"id\":\"foil\",\"label\":\"Foil\"},{\"id\":\"forging\",\"label\":\"Forging\"},{\"id\":\"full-section\",\"label\":\"Full Section\",\"disabled\":true},{\"id\":\"half-round-bar\",\"label\":\"Half Round Bar\",\"disabled\":true},{\"id\":\"hexagonal-bar\",\"label\":\"Hexagonal Bar\"},{\"id\":\"hexagonal-bright-bar\",\"label\":\"Hexagonal Bright Bar\",\"disabled\":true},{\"id\":\"hexagonal-rod\",\"label\":\"Hexagonal Rod\"},{\"id\":\"hexagonal-wire\",\"label\":\"Hexagonal Wire\"},{\"id\":\"hollow-bar\",\"label\":\"Hollow Bar\",\"disabled\":true},{\"id\":\"ingot\",\"label\":\"Ingot\",\"disabled\":true},{\"id\":\"pipe\",\"label\":\"Pipe\",\"disabled\":true},{\"id\":\"plate\",\"label\":\"Plate\"},{\"id\":\"powder\",\"label\":\"Powder\",\"disabled\":true},{\"id\":\"profile\",\"label\":\"Profile\"},{\"id\":\"profile-wire\",\"label\":\"Profile Wire\",\"disabled\":true},{\"id\":\"rod\",\"label\":\"Rod\"},{\"id\":\"round-bar\",\"label\":\"Round Bar\"},{\"id\":\"round-bright-bar\",\"label\":\"Round Bright Bar\",\"disabled\":true},{\"id\":\"round-rod\",\"label\":\"Round Rod\"},{\"id\":\"round-wire\",\"label\":\"Round Wire\"},{\"id\":\"seamless-tube\",\"label\":\"Seamless Tube\"},{\"id\":\"sheet\",\"label\":\"Sheet\"},{\"id\":\"spring\",\"label\":\"Spring\",\"disabled\":true},{\"id\":\"squar-bar\",\"label\":\"Squar Bar\",\"disabled\":true},{\"id\":\"square-bar\",\"label\":\"Square Bar\"},{\"id\":\"strip\",\"label\":\"Strip\"},{\"id\":\"tube\",\"label\":\"Tube\"},{\"id\":\"welded-tube\",\"label\":\"Welded Tube\",\"disabled\":true},{\"id\":\"wire\",\"label\":\"Wire\"}],\"fillers\":[],\"modifications\":[],\"processing\":[],\"certifications\":[],\"primaryPhase\":[],\"secondaryPhase\":[]},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}]},\"results\":{\"materials\":{\"data\":[{\"id\":\"DESTB19\",\"label\":\"Acidur 4529\",\"url\":\"/materials/destb19-acidur-4529\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11\",\"label\":\"Acidur 4401 +AT \",\"url\":\"/materials/dests11-acidur-4401-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS12\",\"label\":\"Acidur 4435 +AT \",\"url\":\"/materials/dests12-acidur-4435-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS13\",\"label\":\"Acidur 4541 +AT \",\"url\":\"/materials/dests13-acidur-4541-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS14\",\"label\":\"Acidur 4571 +AT \",\"url\":\"/materials/dests14-acidur-4571-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11A\",\"label\":\"Acidur 4404 +AT \",\"url\":\"/materials/dests11a-acidur-4404-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9\",\"label\":\"Acidur 4301 +AT \",\"url\":\"/materials/dests9-acidur-4301-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9A\",\"label\":\"Acidur 4307 +AT \",\"url\":\"/materials/dests9a-acidur-4307-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS10\",\"label\":\"Acidur 4305 +AT \",\"url\":\"/materials/dests10-acidur-4305-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"VDMM023\",\"label\":\"VDM® Alloy 926\",\"url\":\"/materials/vdmm023-vdm-alloy-926\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"VDMM\",\"label\":\"VDM Metals\",\"url\":\"/suppliers/vdmm-vdm-metals\"}},{\"id\":\"DESTS7\",\"label\":\"Acidur 4418 QT900 \",\"url\":\"/materials/dests7-acidur-4418-qt900-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS15\",\"label\":\"Acidur 4462 +AT \",\"url\":\"/materials/dests15-acidur-4462-at-\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS7A\",\"label\":\"Acidur 4418 QT760 \",\"url\":\"/materials/dests7a-acidur-4418-qt760-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"UGIT0076\",\"label\":\"UGIMA® 4460 Cold Finished\",\"url\":\"/materials/ugit0076-ugima-4460-cold-finished\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0077\",\"label\":\"UGIMA® 4460 Cold Finished and Drawn\",\"url\":\"/materials/ugit0077-ugima-4460-cold-finished-and-drawn\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0129\",\"label\":\"UGI® 4545 AIR H1025\",\"url\":\"/materials/ugit0129-ugi-4545-air-h1025\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"DESTS1\",\"label\":\"Corrodur 4021 QT800 \",\"url\":\"/materials/dests1-corrodur-4021-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS3\",\"label\":\"Corrodur 4034 Annealed \",\"url\":\"/materials/dests3-corrodur-4034-annealed-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS4\",\"label\":\"Acidur 4057 QT800 \",\"url\":\"/materials/dests4-acidur-4057-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS8\",\"label\":\"Acidur 4542 P800 \",\"url\":\"/materials/dests8-acidur-4542-p800-\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}}],\"materialsCount\":2214,\"page\":1}}},\"namespacesRequired\":[\"account\",\"common\",\"navigation\",\"sign-in-up\",\"advanced-search\",\"search-and-filters\",\"ashby-chart\"]},\"pathname\":\"/advanced-search\",\"host\":\"matmatch.com\",\"auth\":{\"oauth2Google\":false,\"oauth2Linkedin\":false,\"promotionalEmails\":false,\"acceptedTerms\":false}},\"initialState\":{\"company\":{},\"actionMessage\":{\"messageCode\":null,\"messageType\":null,\"messageText\":\"\",\"messageTranslationKey\":\"\",\"errorObj\":null,\"showPopup\":false,\"showMessage\":false,\"endPoint\":null},\"user\":{\"oauth2Google\":false,\"oauth2Linkedin\":false,\"promotionalEmails\":false,\"acceptedTerms\":false},\"companyUser\":{},\"companyUsers\":[],\"roles\":[],\"form\":{},\"popup\":{\"open\":false,\"popupComponent\":\"\",\"info\":{},\"companyCodes\":[],\"fieldsValues\":{},\"formConfiguration\":{},\"prePopulatedDataFetched\":false,\"signupEmail\":null},\"auth\":{\"isAuthenticated\":false,\"isLoginPopupVisible\":false,\"isRequestingLogin\":false,\"loginError\":\"\",\"isSignupPopupVisible\":false,\"isRequestingSignup\":false,\"isSignupSuccessPopupVisible\":false,\"signupError\":\"\",\"signupEmail\":\"\",\"isAuthPopupVisible\":false,\"form\":\"\",\"autoActionParams\":null,\"activePremiumFeature\":\"\"},\"targetUrl\":null,\"deviceWidth\":null,\"navigation\":{\"openOverlay\":false,\"categoriesTree\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"name\":\"Material category\",\"label\":\"Biological Material\",\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"name\":\"Material category\",\"label\":\"Wood\"}],\"materialsCount\":1},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"name\":\"Material category\",\"label\":\"Ceramic\",\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"name\":\"Material category\",\"label\":\"Carbon\"},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"name\":\"Material category\",\"label\":\"Engineering Ceramic\"},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"name\":\"Material category\",\"label\":\"Natural Ceramic\"}],\"materialsCount\":305},{\"id\":\"composite\",\"nodeId\":\"composite\",\"name\":\"Material category\",\"label\":\"Composite\",\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"name\":\"Material category\",\"label\":\"Ceramic Matrix Composite\"},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"name\":\"Material category\",\"label\":\"Metal Matrix Composite\"},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"name\":\"Material category\",\"label\":\"Polymer Matrix Composite\"}],\"materialsCount\":367},{\"id\":\"glass\",\"nodeId\":\"glass\",\"name\":\"Material category\",\"label\":\"Glass\",\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"name\":\"Material category\",\"label\":\"Glass Ceramic\"},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"name\":\"Material category\",\"label\":\"Lead Glass\"},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"name\":\"Material category\",\"label\":\"Silicate Glass\"}],\"materialsCount\":364},{\"id\":\"metal\",\"nodeId\":\"metal\",\"name\":\"Material category\",\"label\":\"Metal\",\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"name\":\"Material category\",\"label\":\"Aluminium\"},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"name\":\"Material category\",\"label\":\"Clad / Bimetal\"},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"name\":\"Material category\",\"label\":\"Cobalt\"},{\"id\":\"copper\",\"nodeId\":\"copper\",\"name\":\"Material category\",\"label\":\"Copper\"},{\"id\":\"iron\",\"nodeId\":\"iron\",\"name\":\"Material category\",\"label\":\"Iron\"},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"name\":\"Material category\",\"label\":\"Magnesium\"},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"name\":\"Material category\",\"label\":\"Manganese\"},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"name\":\"Material category\",\"label\":\"Nickel\"},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"name\":\"Material category\",\"label\":\"Noble Metal\"},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"name\":\"Material category\",\"label\":\"Other Metal\"},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"name\":\"Material category\",\"label\":\"Refractory Metal\"},{\"id\":\"steel\",\"nodeId\":\"steel\",\"name\":\"Material category\",\"label\":\"Steel\"},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"name\":\"Material category\",\"label\":\"Titanium\"}],\"materialsCount\":23895},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"name\":\"Material category\",\"label\":\"Polymer\",\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"name\":\"Material category\",\"label\":\"Elastomer\"},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"name\":\"Material category\",\"label\":\"Thermoplastic\"},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"name\":\"Material category\",\"label\":\"Thermosetting\"}],\"materialsCount\":6385}],\"expandedMenuIds\":[]},\"footerCompanies\":{\"loggedInSupplier\":{},\"suppliers\":[]},\"dynamicFilters\":{\"query\":\"\",\"appliedFilters\":[],\"filterDefinition\":{\"name\":\"root\",\"children\":[]}},\"autoSuggestions\":[],\"contactFormSuccess\":{\"formSubmitted\":false,\"success\":false,\"done\":false},\"newsletter\":{\"userSubscribed\":false},\"comparison\":{\"orderCounter\":0,\"selection\":{}},\"experiment\":null,\"previewMaterial\":null,\"supplierMaterials\":{\"report\":null,\"materials\":[],\"publishedCount\":0,\"approvalStatus\":\"unpublished\",\"showPublishAllTriggeredPopup\":false},\"reviewCompany\":null,\"applications\":{\"applicationListView\":[],\"materialsView\":{\"query\":\"\",\"materials\":[],\"filters\":[],\"appliedFilters\":[],\"breadcrumbs\":[],\"filterGroups\":[]},\"visualisedMaterials\":[],\"visualisedProperties\":[],\"selectedMaterialsForComparison\":[],\"selectedPropertiesForCharts\":[],\"selectedPropertiesForChartsLegendData\":[],\"selectedMaterialsForCharts\":[],\"chartType\":\"\",\"chartData\":{},\"compareData\":{},\"selectedApplication\":\"\",\"totalResults\":0,\"comparisonId\":\"\"},\"autoAction\":{\"apiUrl\":[],\"infoMessageTranslationKey\":\"\",\"successRedirect\":\"\",\"successApiUrl\":\"\",\"successApiMethod\":\"\",\"failedRedirect\":\"\",\"failedAction\":\"\",\"successAction\":\"\",\"eventsAnalyticsObj\":null},\"savedSuppliers\":{\"items\":[],\"openAuthPopup\":false,\"savingItem\":null},\"advancedSearch\":{\"labels\":[],\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true}]},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true}]},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true}]},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true}]},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true}]},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true}]}]},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true}]},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true}]},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true}]}]},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true}]},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true}]},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true}]},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true}]}]},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true}]},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true}]}]},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true}]},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true}]}]},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true}]},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true}]},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true}]},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true}]},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true}]},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true}]}]},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true}]},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true}]},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true}]},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true}]},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true}]},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true}]},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true}]},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true}]},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true}]},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true}]},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true}]}]},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true}]},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true}]},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true}]},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true}]},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true}]},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true}]},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true}]}]},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true}]}]},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true}]},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true}]},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true}]},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true}]}]},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true}]},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true}]},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true}]},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true}]},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true}]},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true}]},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true}]},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true}]},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true}]}]},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true}]},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true}]}]}],\"propertySections\":[],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}],\"supplierMaterialsOnly\":false,\"text\":\"\",\"results\":{\"materials\":{\"data\":[{\"id\":\"DESTB19\",\"label\":\"Acidur 4529\",\"url\":\"/materials/destb19-acidur-4529\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11\",\"label\":\"Acidur 4401 +AT \",\"url\":\"/materials/dests11-acidur-4401-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS12\",\"label\":\"Acidur 4435 +AT \",\"url\":\"/materials/dests12-acidur-4435-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS13\",\"label\":\"Acidur 4541 +AT \",\"url\":\"/materials/dests13-acidur-4541-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS14\",\"label\":\"Acidur 4571 +AT \",\"url\":\"/materials/dests14-acidur-4571-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS11A\",\"label\":\"Acidur 4404 +AT \",\"url\":\"/materials/dests11a-acidur-4404-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9\",\"label\":\"Acidur 4301 +AT \",\"url\":\"/materials/dests9-acidur-4301-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS9A\",\"label\":\"Acidur 4307 +AT \",\"url\":\"/materials/dests9a-acidur-4307-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS10\",\"label\":\"Acidur 4305 +AT \",\"url\":\"/materials/dests10-acidur-4305-at-\",\"category\":{\"id\":\"austenitic-stainless-steel\",\"label\":\"Austenitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"VDMM023\",\"label\":\"VDM® Alloy 926\",\"url\":\"/materials/vdmm023-vdm-alloy-926\",\"category\":{\"id\":\"superaustenitic-stainless-steel\",\"label\":\"Superaustenitic Stainless Steel\"},\"supplier\":{\"id\":\"VDMM\",\"label\":\"VDM Metals\",\"url\":\"/suppliers/vdmm-vdm-metals\"}},{\"id\":\"DESTS7\",\"label\":\"Acidur 4418 QT900 \",\"url\":\"/materials/dests7-acidur-4418-qt900-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS15\",\"label\":\"Acidur 4462 +AT \",\"url\":\"/materials/dests15-acidur-4462-at-\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS7A\",\"label\":\"Acidur 4418 QT760 \",\"url\":\"/materials/dests7a-acidur-4418-qt760-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"UGIT0076\",\"label\":\"UGIMA® 4460 Cold Finished\",\"url\":\"/materials/ugit0076-ugima-4460-cold-finished\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0077\",\"label\":\"UGIMA® 4460 Cold Finished and Drawn\",\"url\":\"/materials/ugit0077-ugima-4460-cold-finished-and-drawn\",\"category\":{\"id\":\"duplex-stainless-steel\",\"label\":\"Duplex Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"UGIT0129\",\"label\":\"UGI® 4545 AIR H1025\",\"url\":\"/materials/ugit0129-ugi-4545-air-h1025\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"UGIT\",\"label\":\"Ugitech\",\"url\":\"/suppliers/ugit-ugitech\"}},{\"id\":\"DESTS1\",\"label\":\"Corrodur 4021 QT800 \",\"url\":\"/materials/dests1-corrodur-4021-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS3\",\"label\":\"Corrodur 4034 Annealed \",\"url\":\"/materials/dests3-corrodur-4034-annealed-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS4\",\"label\":\"Acidur 4057 QT800 \",\"url\":\"/materials/dests4-acidur-4057-qt800-\",\"category\":{\"id\":\"martensitic-stainless-steel\",\"label\":\"Martensitic Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}},{\"id\":\"DESTS8\",\"label\":\"Acidur 4542 P800 \",\"url\":\"/materials/dests8-acidur-4542-p800-\",\"category\":{\"id\":\"precipitation-hardening-stainless-steel\",\"label\":\"Precipitation Hardening Stainless Steel\"},\"supplier\":{\"id\":\"DEST\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"url\":\"/suppliers/dest-deutsche-edelstahlwerke-dew-\"}}],\"materialsCount\":2214,\"page\":1}},\"alerts\":[\"advanced-search-alert-compare-hint\"],\"context\":{\"unitsSystem\":\"metric\",\"categories\":[{\"id\":\"biological-material\",\"nodeId\":\"biological-material\",\"humanReadableId\":\"Biological Material\",\"label\":\"Biological Material\",\"disabled\":true,\"children\":[{\"id\":\"wood\",\"nodeId\":\"wood\",\"humanReadableId\":\"Wood\",\"label\":\"Wood\",\"disabled\":true,\"ancestors\":[\"biological-material\"],\"rootNode\":\"biological-material\"}],\"rootNode\":\"biological-material\",\"childrenNr\":1,\"checked\":false},{\"id\":\"ceramic\",\"nodeId\":\"ceramic\",\"humanReadableId\":\"Ceramic\",\"label\":\"Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"carbon\",\"nodeId\":\"carbon\",\"humanReadableId\":\"Carbon\",\"label\":\"Carbon\",\"disabled\":true,\"children\":[{\"id\":\"carbon-nanotube\",\"nodeId\":\"carbon-nanotube\",\"humanReadableId\":\"Carbon Nanotube\",\"label\":\"Carbon Nanotube\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\"},{\"id\":\"diamond\",\"nodeId\":\"diamond\",\"humanReadableId\":\"Diamond\",\"label\":\"Diamond\",\"disabled\":true,\"children\":[{\"id\":\"natural-diamond\",\"nodeId\":\"natural-diamond\",\"humanReadableId\":\"Natural Diamond\",\"label\":\"Natural Diamond\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\",\"diamond\"],\"rootNode\":\"ceramic\"},{\"id\":\"synthetic-diamond\",\"nodeId\":\"synthetic-diamond\",\"humanReadableId\":\"Synthetic Diamond\",\"label\":\"Synthetic Diamond\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\",\"diamond\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\",\"childrenNr\":2},{\"id\":\"graphene\",\"nodeId\":\"graphene\",\"humanReadableId\":\"Graphene\",\"label\":\"Graphene\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\"},{\"id\":\"graphite\",\"nodeId\":\"graphite\",\"humanReadableId\":\"Graphite\",\"label\":\"Graphite\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"carbon\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":4},{\"id\":\"engineering-ceramic\",\"nodeId\":\"engineering-ceramic\",\"humanReadableId\":\"Engineering Ceramic\",\"label\":\"Engineering Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"non-oxide-based\",\"nodeId\":\"non-oxide-based\",\"humanReadableId\":\"Non Oxide Based\",\"label\":\"Non Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"boride-based\",\"nodeId\":\"boride-based\",\"humanReadableId\":\"Boride Based\",\"label\":\"Boride Based\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"carbide-based\",\"nodeId\":\"carbide-based\",\"humanReadableId\":\"Carbide Based\",\"label\":\"Carbide Based\",\"disabled\":true,\"children\":[{\"id\":\"boron-carbide\",\"nodeId\":\"boron-carbide\",\"humanReadableId\":\"Boron Carbide\",\"label\":\"Boron Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-carbide\",\"nodeId\":\"silicon-carbide\",\"humanReadableId\":\"Silicon Carbide\",\"label\":\"Silicon Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tantalum-carbide\",\"nodeId\":\"tantalum-carbide\",\"humanReadableId\":\"Tantalum Carbide\",\"label\":\"Tantalum Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"titanium-carbide\",\"nodeId\":\"titanium-carbide\",\"humanReadableId\":\"Titanium Carbide\",\"label\":\"Titanium Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tungsten-carbide\",\"nodeId\":\"tungsten-carbide\",\"humanReadableId\":\"Tungsten Carbide\",\"label\":\"Tungsten Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"zirconium-carbide\",\"nodeId\":\"zirconium-carbide\",\"humanReadableId\":\"Zirconium Carbide\",\"label\":\"Zirconium Carbide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"carbide-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":6},{\"id\":\"nitride-based\",\"nodeId\":\"nitride-based\",\"humanReadableId\":\"Nitride Based\",\"label\":\"Nitride Based\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nitirde\",\"nodeId\":\"aluminium-nitirde\",\"humanReadableId\":\"Aluminium Nitirde\",\"label\":\"Aluminium Nitirde\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"boron-nitride\",\"nodeId\":\"boron-nitride\",\"humanReadableId\":\"Boron Nitride\",\"label\":\"Boron Nitride\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-nitride\",\"nodeId\":\"silicon-nitride\",\"humanReadableId\":\"Silicon Nitride\",\"label\":\"Silicon Nitride\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"titanium-nitride\",\"nodeId\":\"titanium-nitride\",\"humanReadableId\":\"Titanium Nitride\",\"label\":\"Titanium Nitride\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"nitride-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":4},{\"id\":\"silicate-based\",\"nodeId\":\"silicate-based\",\"humanReadableId\":\"Silicate Based\",\"label\":\"Silicate Based\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"sulfide-based\",\"nodeId\":\"sulfide-based\",\"humanReadableId\":\"Sulfide Based\",\"label\":\"Sulfide Based\",\"disabled\":true,\"children\":[{\"id\":\"bismuth-sulfide\",\"nodeId\":\"bismuth-sulfide\",\"humanReadableId\":\"Bismuth Sulfide\",\"label\":\"Bismuth Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"copper-sulfide\",\"nodeId\":\"copper-sulfide\",\"humanReadableId\":\"Copper Sulfide\",\"label\":\"Copper Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"iron-sulfide\",\"nodeId\":\"iron-sulfide\",\"humanReadableId\":\"Iron Sulfide\",\"label\":\"Iron Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"manganese-sulfide\",\"nodeId\":\"manganese-sulfide\",\"humanReadableId\":\"Manganese Sulfide\",\"label\":\"Manganese Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"molybdenum-disulfide\",\"nodeId\":\"molybdenum-disulfide\",\"humanReadableId\":\"Molybdenum Disulfide\",\"label\":\"Molybdenum Disulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"multiphase-metal-sulfide\",\"nodeId\":\"multiphase-metal-sulfide\",\"humanReadableId\":\"Multiphase Metal Sulfide\",\"label\":\"Multiphase Metal Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tin-sulfide\",\"nodeId\":\"tin-sulfide\",\"humanReadableId\":\"Tin Sulfide\",\"label\":\"Tin Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"tungsten-disulfide\",\"nodeId\":\"tungsten-disulfide\",\"humanReadableId\":\"Tungsten Disulfide\",\"label\":\"Tungsten Disulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"zinc-sulfide\",\"nodeId\":\"zinc-sulfide\",\"humanReadableId\":\"Zinc Sulfide\",\"label\":\"Zinc Sulfide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\",\"sulfide-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"non-oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":9}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":5},{\"id\":\"oxide-based\",\"nodeId\":\"oxide-based\",\"humanReadableId\":\"Oxide Based\",\"label\":\"Oxide Based\",\"disabled\":true,\"children\":[{\"id\":\"advanced-ceramic-oxides\",\"nodeId\":\"advanced-ceramic-oxides\",\"humanReadableId\":\"Advanced Ceramic Oxides\",\"label\":\"Advanced Ceramic Oxides\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"aluminium-oxide\",\"nodeId\":\"aluminium-oxide\",\"humanReadableId\":\"Aluminium Oxide\",\"label\":\"Aluminium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"beryllium-oxide\",\"nodeId\":\"beryllium-oxide\",\"humanReadableId\":\"Beryllium Oxide\",\"label\":\"Beryllium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"ferrite\",\"nodeId\":\"ferrite\",\"humanReadableId\":\"Ferrite\",\"label\":\"Ferrite\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-silicate\",\"nodeId\":\"aluminium-silicate\",\"humanReadableId\":\"Aluminium Silicate\",\"label\":\"Aluminium Silicate\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\",\"silicon-oxide\"],\"rootNode\":\"ceramic\"},{\"id\":\"magnesium-silicate\",\"nodeId\":\"magnesium-silicate\",\"humanReadableId\":\"Magnesium Silicate\",\"label\":\"Magnesium Silicate\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\",\"silicon-oxide\"],\"rootNode\":\"ceramic\"},{\"id\":\"zirconium-silicate\",\"nodeId\":\"zirconium-silicate\",\"humanReadableId\":\"Zirconium Silicate\",\"label\":\"Zirconium Silicate\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\",\"silicon-oxide\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\",\"childrenNr\":3},{\"id\":\"titanium-oxide\",\"nodeId\":\"titanium-oxide\",\"humanReadableId\":\"Titanium Oxide\",\"label\":\"Titanium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"},{\"id\":\"zirconium-oxide\",\"nodeId\":\"zirconium-oxide\",\"humanReadableId\":\"Zirconium Oxide\",\"label\":\"Zirconium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":7},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"multi-oxide-ceramics\",\"nodeId\":\"multi-oxide-ceramics\",\"humanReadableId\":\"Multi-Oxide Ceramics\",\"label\":\"Multi-Oxide Ceramics\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"},{\"id\":\"silicon-oxide\",\"nodeId\":\"silicon-oxide-\",\"humanReadableId\":\"Silicon Oxide\",\"label\":\"Silicon Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"},{\"id\":\"ytterbium-oxide\",\"nodeId\":\"ytterbium-oxide\",\"humanReadableId\":\"Ytterbium Oxide\",\"label\":\"Ytterbium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"},{\"id\":\"yttrium-oxide\",\"nodeId\":\"yttrium-oxide\",\"humanReadableId\":\"Yttrium Oxide\",\"label\":\"Yttrium Oxide\",\"disabled\":true,\"ancestors\":[\"ceramic\",\"engineering-ceramic\",\"oxide-based-ceramic-matrix-composite\"],\"rootNode\":\"ceramic\"}],\"ancestors\":[\"ceramic\",\"engineering-ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":4}],\"ancestors\":[\"ceramic\"],\"rootNode\":\"ceramic\",\"childrenNr\":3},{\"id\":\"natural-ceramic\",\"nodeId\":\"natural-ceramic\",\"humanReadableId\":\"Natural Ceramic\",\"label\":\"Natural Ceramic\",\"disabled\":true,\"ancestors\":[\"ceramic\"],\"rootNode\":\"ceramic\"}],\"rootNode\":\"ceramic\",\"childrenNr\":3,\"checked\":false},{\"id\":\"composite\",\"nodeId\":\"composite\",\"humanReadableId\":\"Composite\",\"label\":\"Composite\",\"disabled\":true,\"children\":[{\"id\":\"ceramic-matrix-composite\",\"nodeId\":\"ceramic-matrix-composite\",\"humanReadableId\":\"Ceramic Matrix Composite\",\"label\":\"Ceramic Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"carbide-based-ceramic-matrix-composite\",\"nodeId\":\"carbide-based-ceramic-matrix-composite\",\"humanReadableId\":\"Carbide Based Ceramic Matrix Composite\",\"label\":\"Carbide Based Ceramic Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"ceramic-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"oxide-based-ceramic-matrix-composite\",\"nodeId\":\"oxide-based-ceramic-matrix-composite-\",\"humanReadableId\":\"Oxide Based Ceramic Matrix Composite\",\"label\":\"Oxide Based Ceramic Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"ceramic-matrix-composite\"],\"rootNode\":\"composite\"}],\"ancestors\":[\"composite\"],\"rootNode\":\"composite\",\"childrenNr\":2},{\"id\":\"metal-matrix-composite\",\"nodeId\":\"metal-matrix-composite\",\"humanReadableId\":\"Metal Matrix Composite\",\"label\":\"Metal Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-matrix-composite\",\"nodeId\":\"aluminium-matrix-composite\",\"humanReadableId\":\"Aluminium Matrix Composite\",\"label\":\"Aluminium Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"beryllium-matrix-composite\",\"nodeId\":\"beryllium-matrix-composite\",\"humanReadableId\":\"Beryllium Matrix Composite\",\"label\":\"Beryllium Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"cobalt-matrix-composite\",\"nodeId\":\"cobalt-matrix-composite\",\"humanReadableId\":\"Cobalt Matrix Composite\",\"label\":\"Cobalt Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"cobalt-and-nickel-matrix-composite\",\"nodeId\":\"cobalt-and-nickel-matrix-composite\",\"humanReadableId\":\"Cobalt and Nickel Matrix Composite\",\"label\":\"Cobalt and Nickel Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"iron-matrix-composite\",\"nodeId\":\"iron-matrix-composite\",\"humanReadableId\":\"Iron Matrix Composite\",\"label\":\"Iron Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"},{\"id\":\"nickel-matrix-composite\",\"nodeId\":\"nickel-matrix-composite\",\"humanReadableId\":\"Nickel Matrix Composite\",\"label\":\"Nickel Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"metal-matrix-composite\"],\"rootNode\":\"composite\"}],\"ancestors\":[\"composite\"],\"rootNode\":\"composite\",\"childrenNr\":6},{\"id\":\"polymer-matrix-composite\",\"nodeId\":\"polymer-matrix-composite\",\"humanReadableId\":\"Polymer Matrix Composite\",\"label\":\"Polymer Matrix Composite\",\"disabled\":true,\"children\":[{\"id\":\"thermoset-polymer-matrix-composite\",\"nodeId\":\"thermoset-polymer-matrix-composite\",\"humanReadableId\":\"Thermoset Polymer Matrix Composite\",\"label\":\"Thermoset Polymer Matrix Composite\",\"disabled\":true,\"ancestors\":[\"composite\",\"polymer-matrix-composite\"],\"rootNode\":\"composite\"}],\"ancestors\":[\"composite\"],\"rootNode\":\"composite\",\"childrenNr\":1}],\"rootNode\":\"composite\",\"childrenNr\":3,\"checked\":false},{\"id\":\"glass\",\"nodeId\":\"glass\",\"humanReadableId\":\"Glass\",\"label\":\"Glass\",\"disabled\":true,\"children\":[{\"id\":\"glass-ceramic\",\"nodeId\":\"glass-ceramic\",\"humanReadableId\":\"Glass Ceramic\",\"label\":\"Glass Ceramic\",\"disabled\":true,\"children\":[{\"id\":\"las-glass-ceramic\",\"nodeId\":\"las-glass-ceramic\",\"humanReadableId\":\"LAS Glass Ceramic\",\"label\":\"LAS Glass Ceramic\",\"disabled\":true,\"ancestors\":[\"glass\",\"glass-ceramic\"],\"rootNode\":\"glass\"}],\"ancestors\":[\"glass\"],\"rootNode\":\"glass\",\"childrenNr\":1},{\"id\":\"lead-glass\",\"nodeId\":\"lead-glass\",\"humanReadableId\":\"Lead Glass\",\"label\":\"Lead Glass\",\"disabled\":true,\"ancestors\":[\"glass\"],\"rootNode\":\"glass\"},{\"id\":\"silicate-glass\",\"nodeId\":\"silicate-glass\",\"humanReadableId\":\"Silicate Glass\",\"label\":\"Silicate Glass\",\"disabled\":true,\"children\":[{\"id\":\"aluminosilicate\",\"nodeId\":\"aluminosilicate\",\"humanReadableId\":\"Aluminosilicate\",\"label\":\"Aluminosilicate\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"},{\"id\":\"borosilicate\",\"nodeId\":\"borosilicate\",\"humanReadableId\":\"Borosilicate\",\"label\":\"Borosilicate\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"},{\"id\":\"fused-quartz\",\"nodeId\":\"fused-quartz\",\"humanReadableId\":\"Fused Quartz\",\"label\":\"Fused Quartz\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"},{\"id\":\"soda-lime-silicate\",\"nodeId\":\"soda-lime-silicate\",\"humanReadableId\":\"Soda Lime Silicate\",\"label\":\"Soda Lime Silicate\",\"disabled\":true,\"ancestors\":[\"glass\",\"silicate-glass\"],\"rootNode\":\"glass\"}],\"ancestors\":[\"glass\"],\"rootNode\":\"glass\",\"childrenNr\":4}],\"rootNode\":\"glass\",\"childrenNr\":3,\"checked\":false},{\"id\":\"metal\",\"nodeId\":\"metal\",\"humanReadableId\":\"Metal\",\"label\":\"Metal\",\"partiallyChecked\":true,\"materialsCount\":2214,\"children\":[{\"id\":\"aluminium\",\"nodeId\":\"aluminium\",\"humanReadableId\":\"Aluminium\",\"label\":\"Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-master-alloy\",\"nodeId\":\"aluminium-master-alloy\",\"humanReadableId\":\"Aluminium Master Alloy\",\"label\":\"Aluminium Master Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-aluminium\",\"nodeId\":\"cast-aluminium\",\"humanReadableId\":\"Cast Aluminium\",\"label\":\"Cast Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1xx-x\",\"nodeId\":\"1xx-x\",\"humanReadableId\":\"1xx.x\",\"label\":\"1xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"2xx-x\",\"nodeId\":\"2xx-x\",\"humanReadableId\":\"2xx.x\",\"label\":\"2xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"3xx-x\",\"nodeId\":\"3xx-x\",\"humanReadableId\":\"3xx.x\",\"label\":\"3xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"4xx-x\",\"nodeId\":\"4xx-x\",\"humanReadableId\":\"4xx.x\",\"label\":\"4xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"5xx-x\",\"nodeId\":\"5xx-x\",\"humanReadableId\":\"5xx.x\",\"label\":\"5xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"7xx-x\",\"nodeId\":\"7xx-x\",\"humanReadableId\":\"7xx.x\",\"label\":\"7xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"8xx-x\",\"nodeId\":\"8xx-x\",\"humanReadableId\":\"8xx.x\",\"label\":\"8xx.x\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"cast-aluminium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"aluminium\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"wrought-aluminium\",\"nodeId\":\"wrought-aluminium\",\"humanReadableId\":\"Wrought Aluminium\",\"label\":\"Wrought Aluminium\",\"disabled\":true,\"children\":[{\"id\":\"1000-series\",\"nodeId\":\"1000-series\",\"humanReadableId\":\"1000 Series\",\"label\":\"1000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"2000-series\",\"nodeId\":\"2000-series\",\"humanReadableId\":\"2000 Series\",\"label\":\"2000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"3000-series\",\"nodeId\":\"3000-series\",\"humanReadableId\":\"3000 Series\",\"label\":\"3000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"4000-series\",\"nodeId\":\"4000-series\",\"humanReadableId\":\"4000 Series\",\"label\":\"4000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"5000-series\",\"nodeId\":\"5000-series\",\"humanReadableId\":\"5000 Series\",\"label\":\"5000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"6000-series\",\"nodeId\":\"6000-series\",\"humanReadableId\":\"6000 Series\",\"label\":\"6000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"7000-series\",\"nodeId\":\"7000-series\",\"humanReadableId\":\"7000 Series\",\"label\":\"7000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"},{\"id\":\"8000-series\",\"nodeId\":\"8000-series\",\"humanReadableId\":\"8000 Series\",\"label\":\"8000 Series\",\"disabled\":true,\"ancestors\":[\"metal\",\"aluminium\",\"wrought-aluminium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"aluminium\"],\"rootNode\":\"metal\",\"childrenNr\":8}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"clad---bimetal\",\"nodeId\":\"clad---bimetal\",\"humanReadableId\":\"Clad / Bimetal\",\"label\":\"Clad / Bimetal\",\"disabled\":true,\"ancestors\":[\"metal\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt\",\"nodeId\":\"cobalt\",\"humanReadableId\":\"Cobalt\",\"label\":\"Cobalt\",\"disabled\":true,\"children\":[{\"id\":\"cobalt-chromium\",\"nodeId\":\"cobalt-chromium\",\"humanReadableId\":\"Cobalt Chromium\",\"label\":\"Cobalt Chromium\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-chromium-molybdenum\",\"nodeId\":\"cobalt-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Chromium Molybdenum\",\"label\":\"Cobalt Chromium Molybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-chromium-nickel-tungsten\",\"nodeId\":\"cobalt-chromium-nickel-tungsten\",\"humanReadableId\":\"Cobalt Chromium Nickel Tungsten\",\"label\":\"Cobalt Chromium Nickel Tungsten\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-chromium-tungsten\",\"nodeId\":\"cobalt-chromium-tungsten\",\"humanReadableId\":\"Cobalt Chromium Tungsten\",\"label\":\"Cobalt Chromium Tungsten\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-nickel-chromium-molybdenum\",\"nodeId\":\"cobalt-nickel-chromium-molybdenum\",\"humanReadableId\":\"Cobalt Nickel Chromium Molybdenum\",\"label\":\"Cobalt Nickel Chromium Molybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"cobalt-superalloy\",\"nodeId\":\"cobalt-superalloy\",\"humanReadableId\":\"Cobalt Superalloy\",\"label\":\"Cobalt Superalloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-cobalt-alloy\",\"nodeId\":\"unclassified-cobalt-alloy\",\"humanReadableId\":\"Unclassified Cobalt Alloy\",\"label\":\"Unclassified Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"cobalt\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"copper\",\"nodeId\":\"copper\",\"humanReadableId\":\"Copper\",\"label\":\"Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper\",\"nodeId\":\"cast-copper\",\"humanReadableId\":\"Cast Copper\",\"label\":\"Cast Copper\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass\",\"nodeId\":\"cast-copper-brass\",\"humanReadableId\":\"Cast Copper Brass\",\"label\":\"Cast Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-brass-yellow-brass\",\"nodeId\":\"cast-copper-brass-yellow-brass\",\"humanReadableId\":\"Cast Copper Brass Yellow Brass\",\"label\":\"Cast Copper Brass Yellow Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-silicon-brass\",\"nodeId\":\"cast-copper-silicon-brass\",\"humanReadableId\":\"Cast Copper Silicon Brass\",\"label\":\"Cast Copper Silicon Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"copper-bismuth-alloy\",\"nodeId\":\"copper-bismuth-alloy\",\"humanReadableId\":\"Copper Bismuth Alloy\",\"label\":\"Copper Bismuth Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"red-brass\",\"nodeId\":\"red-brass\",\"humanReadableId\":\"Red Brass\",\"label\":\"Red Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-brass\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"cast-copper-bronze\",\"nodeId\":\"cast-copper-bronze\",\"humanReadableId\":\"Cast Copper Bronze\",\"label\":\"Cast Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"cast-copper-bronze-aluminium-bronze\",\"nodeId\":\"cast-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Cast Copper Bronze Aluminium Bronze\",\"label\":\"Cast Copper Bronze Aluminium Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"leaded-tin-bronze\",\"nodeId\":\"leaded-tin-bronze\",\"humanReadableId\":\"Leaded Tin Bronze\",\"label\":\"Leaded Tin Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-tin-bronze\",\"nodeId\":\"nickel-tin-bronze\",\"humanReadableId\":\"Nickel Tin Bronze\",\"label\":\"Nickel Tin Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"tin-bronze\",\"nodeId\":\"tin-bronze\",\"humanReadableId\":\"Tin Bronze\",\"label\":\"Tin Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\",\"cast-copper-bronze\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"cast-copper-high-copper-alloy\",\"nodeId\":\"cast-copper-high-copper-alloy\",\"humanReadableId\":\"Cast Copper High Copper Alloy\",\"label\":\"Cast Copper High Copper Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-nickel-grade\",\"nodeId\":\"cast-copper-nickel-grade\",\"humanReadableId\":\"Cast Copper Nickel Grade\",\"label\":\"Cast Copper Nickel Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-nickel-silver-grade\",\"nodeId\":\"cast-copper-nickel-silver-grade\",\"humanReadableId\":\"Cast Copper Nickel Silver Grade\",\"label\":\"Cast Copper Nickel Silver Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"cast-copper-pure---low-alloyed-copper\",\"nodeId\":\"cast-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Cast Copper Pure / Low Alloyed Copper\",\"label\":\"Cast Copper Pure / Low Alloyed Copper\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"copper-lead-alloy\",\"nodeId\":\"copper-lead-alloy\",\"humanReadableId\":\"Copper-Lead Alloy\",\"label\":\"Copper-Lead Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"},{\"id\":\"special-alloy\",\"nodeId\":\"special-alloy\",\"humanReadableId\":\"Special Alloy\",\"label\":\"Special Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"cast-copper\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\"],\"rootNode\":\"metal\",\"childrenNr\":8},{\"id\":\"welding\",\"nodeId\":\"welding\",\"humanReadableId\":\"Welding\",\"label\":\"Welding\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper\",\"nodeId\":\"wrought-copper\",\"humanReadableId\":\"Wrought Copper\",\"label\":\"Wrought Copper\",\"disabled\":true,\"children\":[{\"id\":\"unclassified-wrought-copper\",\"nodeId\":\"unclassified-wrought-copper\",\"humanReadableId\":\"Unclassified Wrought Copper\",\"label\":\"Unclassified Wrought Copper\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-brass\",\"nodeId\":\"wrought-copper-brass\",\"humanReadableId\":\"Wrought Copper Brass\",\"label\":\"Wrought Copper Brass\",\"disabled\":true,\"children\":[{\"id\":\"leaded-brass\",\"nodeId\":\"leaded-brass\",\"humanReadableId\":\"Leaded Brass\",\"label\":\"Leaded Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"tin-brass\",\"nodeId\":\"tin-brass\",\"humanReadableId\":\"Tin Brass\",\"label\":\"Tin Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-brass-yellow-brass\",\"nodeId\":\"wrought-copper-brass-yellow-brass\",\"humanReadableId\":\"Wrought Copper Brass Yellow Brass\",\"label\":\"Wrought Copper Brass Yellow Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"},{\"id\":\"yellow-wrought-brass\",\"nodeId\":\"yellow-wrought-brass\",\"humanReadableId\":\"Yellow Wrought Brass\",\"label\":\"Yellow Wrought Brass\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-brass\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\",\"childrenNr\":5},{\"id\":\"wrought-copper-bronze\",\"nodeId\":\"wrought-copper-bronze\",\"humanReadableId\":\"Wrought Copper Bronze\",\"label\":\"Wrought Copper Bronze\",\"disabled\":true,\"children\":[{\"id\":\"copper-silver-zinc-alloy\",\"nodeId\":\"copper-silver-zinc-alloy\",\"humanReadableId\":\"Copper Silver Zinc Alloy\",\"label\":\"Copper Silver Zinc Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"leaded-phosphor-bronze\",\"nodeId\":\"leaded-phosphor-bronze\",\"humanReadableId\":\"Leaded Phosphor Bronze\",\"label\":\"Leaded Phosphor Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"other-copper-zinc-alloy\",\"nodeId\":\"other-copper-zinc-alloy-\",\"humanReadableId\":\"Other Copper Zinc Alloy\",\"label\":\"Other Copper Zinc Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"phosphor-bronze\",\"nodeId\":\"phosphor-bronze\",\"humanReadableId\":\"Phosphor Bronze\",\"label\":\"Phosphor Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-bronze-aluminium-bronze\",\"nodeId\":\"wrought-copper-bronze-aluminium-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Aluminium Bronze\",\"label\":\"Wrought Copper Bronze Aluminium Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-bronze-silicon-bronze\",\"nodeId\":\"wrought-copper-bronze-silicon-bronze\",\"humanReadableId\":\"Wrought Copper Bronze Silicon Bronze\",\"label\":\"Wrought Copper Bronze Silicon Bronze\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\",\"wrought-copper-bronze\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\",\"childrenNr\":6},{\"id\":\"wrought-copper-high-copper-alloy\",\"nodeId\":\"wrought-copper-high-copper-alloy\",\"humanReadableId\":\"Wrought Copper High Copper Alloy\",\"label\":\"Wrought Copper High Copper Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-nickel-grade\",\"nodeId\":\"wrought-copper-nickel-grade\",\"humanReadableId\":\"Wrought Copper Nickel Grade\",\"label\":\"Wrought Copper Nickel Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-nickel-silver-grade\",\"nodeId\":\"wrought-copper-nickel-silver-grade\",\"humanReadableId\":\"Wrought Copper Nickel Silver Grade\",\"label\":\"Wrought Copper Nickel Silver Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-copper-pure---low-alloyed-copper\",\"nodeId\":\"wrought-copper-pure---low-alloyed-copper\",\"humanReadableId\":\"Wrought Copper Pure / Low Alloyed Copper\",\"label\":\"Wrought Copper Pure / Low Alloyed Copper\",\"disabled\":true,\"ancestors\":[\"metal\",\"copper\",\"wrought-copper\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"copper\"],\"rootNode\":\"metal\",\"childrenNr\":7}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"iron\",\"nodeId\":\"iron\",\"humanReadableId\":\"Iron\",\"label\":\"Iron\",\"disabled\":true,\"children\":[{\"id\":\"alloy-iron\",\"nodeId\":\"alloy-iron\",\"humanReadableId\":\"Alloy Iron\",\"label\":\"Alloy Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"cast-iron\",\"nodeId\":\"cast-iron\",\"humanReadableId\":\"Cast Iron\",\"label\":\"Cast Iron\",\"disabled\":true,\"children\":[{\"id\":\"ductile--nodular--cast-iron\",\"nodeId\":\"ductile--nodular--cast-iron\",\"humanReadableId\":\"Ductile (Nodular) Cast Iron\",\"label\":\"Ductile (Nodular) Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"grey-cast-iron\",\"nodeId\":\"grey-cast-iron\",\"humanReadableId\":\"Grey Cast Iron\",\"label\":\"Grey Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"other-cast-iron-alloy\",\"nodeId\":\"other-cast-iron-alloy\",\"humanReadableId\":\"Other Cast Iron Alloy\",\"label\":\"Other Cast Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"},{\"id\":\"white-cast-iron\",\"nodeId\":\"white-cast-iron\",\"humanReadableId\":\"White Cast Iron\",\"label\":\"White Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"cast-iron\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\",\"childrenNr\":5},{\"id\":\"ferromolybdenum\",\"nodeId\":\"ferromolybdenum\",\"humanReadableId\":\"Ferromolybdenum\",\"label\":\"Ferromolybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"ferrosilicon\",\"nodeId\":\"ferrosilicon\",\"humanReadableId\":\"Ferrosilicon\",\"label\":\"Ferrosilicon\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"ferrovanadium\",\"nodeId\":\"ferrovanadium\",\"humanReadableId\":\"Ferrovanadium\",\"label\":\"Ferrovanadium\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"},{\"id\":\"iron-alloy\",\"nodeId\":\"iron-alloy\",\"humanReadableId\":\"Iron Alloy\",\"label\":\"Iron Alloy\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-nickel-cobalt-iron-alloy\",\"nodeId\":\"aluminium-nickel-cobalt-iron-alloy\",\"humanReadableId\":\"Aluminium Nickel Cobalt Iron Alloy\",\"label\":\"Aluminium Nickel Cobalt Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"iron-alloy\"],\"rootNode\":\"metal\"},{\"id\":\"miscellaneous-iron-alloy\",\"nodeId\":\"miscellaneous-iron-alloy\",\"humanReadableId\":\"Miscellaneous Iron Alloy\",\"label\":\"Miscellaneous Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"iron-alloy\"],\"rootNode\":\"metal\"},{\"id\":\"soft-magnetic-iron\",\"nodeId\":\"soft-magnetic-iron\",\"humanReadableId\":\"Soft Magnetic Iron\",\"label\":\"Soft Magnetic Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\",\"iron-alloy\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"malleable-cast-iron\",\"nodeId\":\"malleable-cast-iron-\",\"humanReadableId\":\"Malleable Cast Iron\",\"label\":\"Malleable Cast Iron\",\"disabled\":true,\"ancestors\":[\"metal\",\"iron\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"magnesium\",\"nodeId\":\"magnesium\",\"humanReadableId\":\"Magnesium\",\"label\":\"Magnesium\",\"disabled\":true,\"children\":[{\"id\":\"aluminium-grade\",\"nodeId\":\"aluminium-grade\",\"humanReadableId\":\"Aluminium Grade\",\"label\":\"Aluminium Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-aluminium-manganese-grade\",\"nodeId\":\"cast-aluminium-manganese-grade\",\"humanReadableId\":\"Cast Aluminium Manganese Grade\",\"label\":\"Cast Aluminium Manganese Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-rare-earth-grade\",\"nodeId\":\"cast-rare-earth-grade\",\"humanReadableId\":\"Cast Rare Earth Grade\",\"label\":\"Cast Rare Earth Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-wrought-aluminium-zinc-grade\",\"nodeId\":\"cast-wrought-aluminium-zinc-grade\",\"humanReadableId\":\"Cast/Wrought Aluminium Zinc Grade\",\"label\":\"Cast/Wrought Aluminium Zinc Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"cast-wrought-unclassified-grade\",\"nodeId\":\"cast-wrought-unclassified-grade\",\"humanReadableId\":\"Cast/Wrought Unclassified Grade\",\"label\":\"Cast/Wrought Unclassified Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"pure-magnesium\",\"nodeId\":\"pure-magnesium\",\"humanReadableId\":\"Pure Magnesium\",\"label\":\"Pure Magnesium\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"rare-earth-grade\",\"nodeId\":\"rare-earth-grade\",\"humanReadableId\":\"Rare Earth Grade\",\"label\":\"Rare Earth Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"wrought-zinc-grade\",\"nodeId\":\"wrought-zinc-grade\",\"humanReadableId\":\"Wrought Zinc Grade\",\"label\":\"Wrought Zinc Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"yttrium-grade\",\"nodeId\":\"yttrium-grade\",\"humanReadableId\":\"Yttrium Grade\",\"label\":\"Yttrium Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"},{\"id\":\"zinc-grade\",\"nodeId\":\"zinc-grade\",\"humanReadableId\":\"Zinc Grade\",\"label\":\"Zinc Grade\",\"disabled\":true,\"ancestors\":[\"metal\",\"magnesium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":10},{\"id\":\"manganese\",\"nodeId\":\"manganese\",\"humanReadableId\":\"Manganese\",\"label\":\"Manganese\",\"disabled\":true,\"ancestors\":[\"metal\"],\"rootNode\":\"metal\"},{\"id\":\"nickel\",\"nodeId\":\"nickel\",\"humanReadableId\":\"Nickel\",\"label\":\"Nickel\",\"disabled\":true,\"children\":[{\"id\":\"nickel-chromium-alloy\",\"nodeId\":\"nickel-chromium-alloy\",\"humanReadableId\":\"Nickel Chromium Alloy\",\"label\":\"Nickel Chromium Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-cobalt-alloy\",\"nodeId\":\"nickel-chromium-cobalt-alloy\",\"humanReadableId\":\"Nickel Chromium Cobalt Alloy\",\"label\":\"Nickel Chromium Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-iron-alloy\",\"nodeId\":\"nickel-chromium-iron-alloy\",\"humanReadableId\":\"Nickel Chromium Iron Alloy\",\"label\":\"Nickel Chromium Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-molybdenum-alloy\",\"nodeId\":\"nickel-chromium-molybdenum-alloy\",\"humanReadableId\":\"Nickel Chromium Molybdenum Alloy\",\"label\":\"Nickel Chromium Molybdenum Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-cobalt-alloy\",\"nodeId\":\"nickel-cobalt-alloy\",\"humanReadableId\":\"Nickel Cobalt Alloy\",\"label\":\"Nickel Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-copper-alloy\",\"nodeId\":\"nickel-copper-alloy\",\"humanReadableId\":\"Nickel Copper Alloy\",\"label\":\"Nickel Copper Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-iron-alloy\",\"nodeId\":\"nickel-iron-alloy\",\"humanReadableId\":\"Nickel Iron Alloy\",\"label\":\"Nickel Iron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-molybdenum-alloy\",\"nodeId\":\"nickel-molybdenum-alloy\",\"humanReadableId\":\"Nickel Molybdenum Alloy\",\"label\":\"Nickel Molybdenum Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-superalloy\",\"nodeId\":\"nickel-superalloy\",\"humanReadableId\":\"Nickel Superalloy\",\"label\":\"Nickel Superalloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-welding-filler\",\"nodeId\":\"nickel-welding-filler\",\"humanReadableId\":\"Nickel Welding Filler\",\"label\":\"Nickel Welding Filler\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"other-nickel-alloy\",\"nodeId\":\"other-nickel-alloy\",\"humanReadableId\":\"Other Nickel Alloy\",\"label\":\"Other Nickel Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"},{\"id\":\"pure-low-nickel-alloy\",\"nodeId\":\"pure-low-nickel-alloy\",\"humanReadableId\":\"Pure/Low Nickel Alloy\",\"label\":\"Pure/Low Nickel Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"nickel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":12},{\"id\":\"noble-metal\",\"nodeId\":\"noble-metal\",\"humanReadableId\":\"Noble Metal\",\"label\":\"Noble Metal\",\"disabled\":true,\"children\":[{\"id\":\"gold\",\"nodeId\":\"gold\",\"humanReadableId\":\"Gold\",\"label\":\"Gold\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"iridium\",\"nodeId\":\"iridium\",\"humanReadableId\":\"Iridium\",\"label\":\"Iridium\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"palladium\",\"nodeId\":\"palladium\",\"humanReadableId\":\"Palladium\",\"label\":\"Palladium\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"platinum\",\"nodeId\":\"platinum\",\"humanReadableId\":\"Platinum\",\"label\":\"Platinum\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"rhodium\",\"nodeId\":\"rhodium\",\"humanReadableId\":\"Rhodium\",\"label\":\"Rhodium\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"},{\"id\":\"silver\",\"nodeId\":\"silver\",\"humanReadableId\":\"Silver\",\"label\":\"Silver\",\"disabled\":true,\"ancestors\":[\"metal\",\"noble-metal\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":6},{\"id\":\"other-metal\",\"nodeId\":\"other-metal\",\"humanReadableId\":\"Other Metal\",\"label\":\"Other Metal\",\"disabled\":true,\"children\":[{\"id\":\"beryllium\",\"nodeId\":\"beryllium\",\"humanReadableId\":\"Beryllium\",\"label\":\"Beryllium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"cadmium\",\"nodeId\":\"cadmium\",\"humanReadableId\":\"Cadmium\",\"label\":\"Cadmium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"chromium\",\"nodeId\":\"chromium\",\"humanReadableId\":\"Chromium\",\"label\":\"Chromium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"lead\",\"nodeId\":\"lead\",\"humanReadableId\":\"Lead\",\"label\":\"Lead\",\"disabled\":true,\"children\":[{\"id\":\"lead-antimony\",\"nodeId\":\"lead-antimony\",\"humanReadableId\":\"Lead Antimony\",\"label\":\"Lead Antimony\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"lead\"],\"rootNode\":\"metal\"},{\"id\":\"lead-tin\",\"nodeId\":\"lead-tin\",\"humanReadableId\":\"Lead Tin\",\"label\":\"Lead Tin\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"lead\"],\"rootNode\":\"metal\"},{\"id\":\"pure-low-alloyed-lead\",\"nodeId\":\"pure-low-alloyed-lead\",\"humanReadableId\":\"Pure/Low Alloyed Lead\",\"label\":\"Pure/Low Alloyed Lead\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"lead\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":3},{\"id\":\"lithium\",\"nodeId\":\"lithium\",\"humanReadableId\":\"Lithium\",\"label\":\"Lithium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\"},{\"id\":\"neodymium\",\"nodeId\":\"neodymium\",\"humanReadableId\":\"Neodymium\",\"label\":\"Neodymium\",\"disabled\":true,\"children\":[{\"id\":\"neodymium-iron-boron-alloy\",\"nodeId\":\"neodymium-iron-boron-alloy\",\"humanReadableId\":\"Neodymium Iron Boron Alloy\",\"label\":\"Neodymium Iron Boron Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"neodymium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":1},{\"id\":\"samarium\",\"nodeId\":\"samarium\",\"humanReadableId\":\"Samarium\",\"label\":\"Samarium\",\"disabled\":true,\"children\":[{\"id\":\"samarium-cobalt-alloy\",\"nodeId\":\"samarium-cobalt-alloy\",\"humanReadableId\":\"Samarium Cobalt Alloy\",\"label\":\"Samarium Cobalt Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"samarium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":1},{\"id\":\"tin\",\"nodeId\":\"tin\",\"humanReadableId\":\"Tin\",\"label\":\"Tin\",\"disabled\":true,\"children\":[{\"id\":\"pure-low-alloyed-tin\",\"nodeId\":\"pure-low-alloyed-tin\",\"humanReadableId\":\"Pure/Low Alloyed Tin\",\"label\":\"Pure/Low Alloyed Tin\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"},{\"id\":\"tin-antimony\",\"nodeId\":\"tin-antimony\",\"humanReadableId\":\"Tin Antimony\",\"label\":\"Tin Antimony\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"},{\"id\":\"tin-lead\",\"nodeId\":\"tin-lead\",\"humanReadableId\":\"Tin Lead\",\"label\":\"Tin Lead\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-tin\",\"nodeId\":\"unclassified-tin\",\"humanReadableId\":\"Unclassified Tin\",\"label\":\"Unclassified Tin\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"tin\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"zinc\",\"nodeId\":\"zinc\",\"humanReadableId\":\"Zinc\",\"label\":\"Zinc\",\"disabled\":true,\"children\":[{\"id\":\"unalloyed-zinc\",\"nodeId\":\"unalloyed-zinc\",\"humanReadableId\":\"Unalloyed Zinc\",\"label\":\"Unalloyed Zinc\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"zinc\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-zinc\",\"nodeId\":\"unclassified-zinc\",\"humanReadableId\":\"Unclassified Zinc\",\"label\":\"Unclassified Zinc\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"zinc\"],\"rootNode\":\"metal\"},{\"id\":\"zinc-aluminium\",\"nodeId\":\"zinc-aluminium\",\"humanReadableId\":\"Zinc Aluminium\",\"label\":\"Zinc Aluminium\",\"disabled\":true,\"ancestors\":[\"metal\",\"other-metal\",\"zinc\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"other-metal\"],\"rootNode\":\"metal\",\"childrenNr\":3}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":9},{\"id\":\"refractory-metal\",\"nodeId\":\"refractory-metal\",\"humanReadableId\":\"Refractory Metal\",\"label\":\"Refractory Metal\",\"disabled\":true,\"children\":[{\"id\":\"hafnium\",\"nodeId\":\"hafnium\",\"humanReadableId\":\"Hafnium\",\"label\":\"Hafnium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"molybdenum\",\"nodeId\":\"molybdenum\",\"humanReadableId\":\"Molybdenum\",\"label\":\"Molybdenum\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"niobium\",\"nodeId\":\"niobium\",\"humanReadableId\":\"Niobium\",\"label\":\"Niobium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"rhenium\",\"nodeId\":\"rhenium\",\"humanReadableId\":\"Rhenium\",\"label\":\"Rhenium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"tantalum\",\"nodeId\":\"tantalum\",\"humanReadableId\":\"Tantalum\",\"label\":\"Tantalum\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"tungsten\",\"nodeId\":\"tungsten\",\"humanReadableId\":\"Tungsten\",\"label\":\"Tungsten\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"vanadium\",\"nodeId\":\"vanadium\",\"humanReadableId\":\"Vanadium\",\"label\":\"Vanadium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"},{\"id\":\"zirconium\",\"nodeId\":\"zirconium\",\"humanReadableId\":\"Zirconium\",\"label\":\"Zirconium\",\"disabled\":true,\"ancestors\":[\"metal\",\"refractory-metal\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":8},{\"id\":\"steel\",\"nodeId\":\"steel\",\"humanReadableId\":\"Steel\",\"label\":\"Steel\",\"checked\":true,\"children\":[{\"id\":\"alloy-steel\",\"nodeId\":\"alloy-steel\",\"humanReadableId\":\"Alloy Steel\",\"label\":\"Alloy Steel\",\"checked\":true,\"children\":[{\"id\":\"chromium-molybdenum-steel\",\"nodeId\":\"chromium-molybdenum-steel\",\"humanReadableId\":\"Chromium Molybdenum Steel\",\"label\":\"Chromium Molybdenum Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"chromium-molybdenum-vanadium-steel\",\"nodeId\":\"chromium-molybdenum-vanadium-steel\",\"humanReadableId\":\"Chromium Molybdenum Vanadium Steel\",\"label\":\"Chromium Molybdenum Vanadium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"chromium-steel\",\"nodeId\":\"chromium-steel\",\"humanReadableId\":\"Chromium Steel\",\"label\":\"Chromium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"chromium-vanadium-steel\",\"nodeId\":\"chromium-vanadium-steel\",\"humanReadableId\":\"Chromium Vanadium Steel\",\"label\":\"Chromium Vanadium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"manganese-steel\",\"nodeId\":\"manganese-steel\",\"humanReadableId\":\"Manganese Steel\",\"label\":\"Manganese Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"molybdenum-steel\",\"nodeId\":\"molybdenum-steel\",\"humanReadableId\":\"Molybdenum Steel\",\"label\":\"Molybdenum Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-molybdenum-steel\",\"nodeId\":\"nickel-chromium-molybdenum-steel\",\"humanReadableId\":\"Nickel Chromium Molybdenum Steel\",\"label\":\"Nickel Chromium Molybdenum Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-chromium-steel\",\"nodeId\":\"nickel-chromium-steel\",\"humanReadableId\":\"Nickel Chromium Steel\",\"label\":\"Nickel Chromium Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-molybdenum-steel\",\"nodeId\":\"nickel-molybdenum-steel\",\"humanReadableId\":\"Nickel Molybdenum Steel\",\"label\":\"Nickel Molybdenum Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nickel-steel\",\"nodeId\":\"nickel-steel\",\"humanReadableId\":\"Nickel Steel\",\"label\":\"Nickel Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"nitriding-steel\",\"nodeId\":\"nitriding-steel\",\"humanReadableId\":\"Nitriding Steel\",\"label\":\"Nitriding Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"silicon-manganese-steel\",\"nodeId\":\"silicon-manganese-steel\",\"humanReadableId\":\"Silicon Manganese Steel\",\"label\":\"Silicon Manganese Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"silicon-steel\",\"nodeId\":\"silicon-steel\",\"humanReadableId\":\"Silicon Steel\",\"label\":\"Silicon Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-low-alloy-steel\",\"nodeId\":\"unclassified-low-alloy-steel\",\"humanReadableId\":\"Unclassified Low Alloy Steel\",\"label\":\"Unclassified Low Alloy Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"alloy-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":14},{\"id\":\"carbon-steel\",\"nodeId\":\"carbon-steel\",\"humanReadableId\":\"Carbon Steel\",\"label\":\"Carbon Steel\",\"checked\":true,\"children\":[{\"id\":\"high-carbon-steel\",\"nodeId\":\"high-carbon-steel\",\"humanReadableId\":\"High Carbon Steel\",\"label\":\"High Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"},{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"},{\"id\":\"medium-carbon-steel\",\"nodeId\":\"medium-carbon-steel\",\"humanReadableId\":\"Medium Carbon Steel\",\"label\":\"Medium Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-carbon-steel\",\"nodeId\":\"unclassified-carbon-steel\",\"humanReadableId\":\"Unclassified Carbon Steel\",\"label\":\"Unclassified Carbon Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"carbon-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":4},{\"id\":\"low-alloy-steel\",\"nodeId\":\"low-alloy-steel\",\"humanReadableId\":\"Low Alloy Steel\",\"label\":\"Low Alloy Steel\",\"checked\":true,\"disabled\":true,\"children\":[{\"id\":\"low-carbon-steel\",\"nodeId\":\"low-carbon-steel-\",\"humanReadableId\":\"Low Carbon Steel\",\"label\":\"Low Carbon Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\",\"low-alloy-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":1},{\"id\":\"maraging-steel\",\"nodeId\":\"maraging-steel\",\"humanReadableId\":\"Maraging Steel\",\"label\":\"Maraging Steel\",\"checked\":true,\"disabled\":true,\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\"},{\"id\":\"stainless-steel\",\"nodeId\":\"stainless-steel\",\"humanReadableId\":\"Stainless Steel\",\"label\":\"Stainless Steel\",\"checked\":true,\"children\":[{\"id\":\"austenitic-stainless-steel\",\"nodeId\":\"austenitic-stainless-steel\",\"humanReadableId\":\"Austenitic Stainless Steel\",\"label\":\"Austenitic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"duplex-stainless-steel\",\"nodeId\":\"duplex-stainless-steel\",\"humanReadableId\":\"Duplex Stainless Steel\",\"label\":\"Duplex Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"ferritic-stainless-steel\",\"nodeId\":\"ferritic-stainless-steel\",\"humanReadableId\":\"Ferritic Stainless Steel\",\"label\":\"Ferritic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"martensitic-stainless-steel\",\"nodeId\":\"martensitic-stainless-steel\",\"humanReadableId\":\"Martensitic Stainless Steel\",\"label\":\"Martensitic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"precipitation-hardening-stainless-steel\",\"nodeId\":\"precipitation-hardening-stainless-steel\",\"humanReadableId\":\"Precipitation Hardening Stainless Steel\",\"label\":\"Precipitation Hardening Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"superaustenitic-stainless-steel\",\"nodeId\":\"superaustenitic-stainless-steel\",\"humanReadableId\":\"Superaustenitic Stainless Steel\",\"label\":\"Superaustenitic Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"},{\"id\":\"unclassified-stainless-steel\",\"nodeId\":\"unclassified-stainless-steel\",\"humanReadableId\":\"Unclassified Stainless Steel\",\"label\":\"Unclassified Stainless Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\",\"stainless-steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\",\"childrenNr\":7},{\"id\":\"tool-and-machining-steel\",\"nodeId\":\"tool-and-machining-steel\",\"humanReadableId\":\"Tool And Machining Steel\",\"label\":\"Tool And Machining Steel\",\"checked\":true,\"ancestors\":[\"metal\",\"steel\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":6},{\"id\":\"titanium\",\"nodeId\":\"titanium\",\"humanReadableId\":\"Titanium\",\"label\":\"Titanium\",\"disabled\":true,\"children\":[{\"id\":\"alpha-alloy\",\"nodeId\":\"alpha-alloy\",\"humanReadableId\":\"Alpha Alloy\",\"label\":\"Alpha Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"alpha-beta-alloy\",\"nodeId\":\"alpha-beta-alloy\",\"humanReadableId\":\"Alpha Beta Alloy\",\"label\":\"Alpha Beta Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"beta-alloy\",\"nodeId\":\"beta-alloy\",\"humanReadableId\":\"Beta Alloy\",\"label\":\"Beta Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"low-alloy-titanium\",\"nodeId\":\"low-alloy-titanium\",\"humanReadableId\":\"Low Alloy Titanium\",\"label\":\"Low Alloy Titanium\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"near-alpha-alloy\",\"nodeId\":\"near-alpha-alloy\",\"humanReadableId\":\"Near Alpha Alloy\",\"label\":\"Near Alpha Alloy\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"},{\"id\":\"pure-titanium\",\"nodeId\":\"pure-titanium\",\"humanReadableId\":\"Pure Titanium\",\"label\":\"Pure Titanium\",\"disabled\":true,\"ancestors\":[\"metal\",\"titanium\"],\"rootNode\":\"metal\"}],\"ancestors\":[\"metal\"],\"rootNode\":\"metal\",\"childrenNr\":6}],\"rootNode\":\"metal\",\"childrenNr\":13,\"checked\":false},{\"id\":\"polymer\",\"nodeId\":\"polymer\",\"humanReadableId\":\"Polymer\",\"label\":\"Polymer\",\"disabled\":true,\"children\":[{\"id\":\"elastomer\",\"nodeId\":\"elastomer\",\"humanReadableId\":\"Elastomer\",\"label\":\"Elastomer\",\"disabled\":true,\"children\":[{\"id\":\"butadiene-rubber--br-\",\"nodeId\":\"butadiene-rubber--br-\",\"humanReadableId\":\"Butadiene Rubber (BR)\",\"label\":\"Butadiene Rubber (BR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"chloroprene-rubber--cr-\",\"nodeId\":\"chloroprene-rubber--cr-\",\"humanReadableId\":\"Chloroprene Rubber (CR)\",\"label\":\"Chloroprene Rubber (CR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"ethylene-propylene-diene-rubber--epdm-\",\"nodeId\":\"ethylene-propylene-diene-rubber--epdm-\",\"humanReadableId\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"label\":\"Ethylene Propylene Diene Rubber (EPDM)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"ethylene-propylene-rubber--epr-\",\"nodeId\":\"ethylene-propylene-rubber--epr-\",\"humanReadableId\":\"Ethylene Propylene Rubber (EPR)\",\"label\":\"Ethylene Propylene Rubber (EPR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"fluorosilicone-rubber--fvmq-\",\"nodeId\":\"fluorosilicone-rubber--fvmq-\",\"humanReadableId\":\"Fluorosilicone Rubber (FVMQ)\",\"label\":\"Fluorosilicone Rubber (FVMQ)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"natural-rubber--nr-\",\"nodeId\":\"natural-rubber--nr-\",\"humanReadableId\":\"Natural Rubber (NR)\",\"label\":\"Natural Rubber (NR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"nitrile-rubber--nbr-\",\"nodeId\":\"nitrile-rubber--nbr-\",\"humanReadableId\":\"Nitrile Rubber (NBR)\",\"label\":\"Nitrile Rubber (NBR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"styrene-butadiene-rubber--sbr-\",\"nodeId\":\"styrene-butadiene-rubber--sbr-\",\"humanReadableId\":\"Styrene Butadiene Rubber (SBR)\",\"label\":\"Styrene Butadiene Rubber (SBR)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-elastomer--tpe-\",\"nodeId\":\"thermoplastic-elastomer--tpe-\",\"humanReadableId\":\"Thermoplastic Elastomer (TPE)\",\"label\":\"Thermoplastic Elastomer (TPE)\",\"disabled\":true,\"children\":[{\"id\":\"elastomeric-alloy--tpv-\",\"nodeId\":\"elastomeric-alloy--tpv-\",\"humanReadableId\":\"Elastomeric Alloy (TPV)\",\"label\":\"Elastomeric Alloy (TPV)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"styrene-butadiene-styrene--sbs-\",\"nodeId\":\"styrene-butadiene-styrene--sbs-\",\"humanReadableId\":\"Styrene Butadiene Styrene (SBS)\",\"label\":\"Styrene Butadiene Styrene (SBS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-copolyester--tpc-\",\"nodeId\":\"thermoplastic-copolyester--tpc-\",\"humanReadableId\":\"Thermoplastic Copolyester (TPC)\",\"label\":\"Thermoplastic Copolyester (TPC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyamide--tpa-\",\"nodeId\":\"thermoplastic-polyamide--tpa-\",\"humanReadableId\":\"Thermoplastic Polyamide (TPA)\",\"label\":\"Thermoplastic Polyamide (TPA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyester-elastomer--tpee-\",\"nodeId\":\"thermoplastic-polyester-elastomer--tpee-\",\"humanReadableId\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"label\":\"Thermoplastic Polyester Elastomer (TPEE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyolefin--tpo-\",\"nodeId\":\"thermoplastic-polyolefin--tpo-\",\"humanReadableId\":\"Thermoplastic Polyolefin (TPO)\",\"label\":\"Thermoplastic Polyolefin (TPO)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-polyurethane--tpu-\",\"nodeId\":\"thermoplastic-polyurethane--tpu-\",\"humanReadableId\":\"Thermoplastic Polyurethane (TPU)\",\"label\":\"Thermoplastic Polyurethane (TPU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"},{\"id\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"nodeId\":\"thermoplastic-styrenic-block-copolymer--tps-\",\"humanReadableId\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"label\":\"Thermoplastic Styrenic Block Copolymer (TPS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"elastomer\",\"thermoplastic-elastomer--tpe-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"elastomer\"],\"rootNode\":\"polymer\",\"childrenNr\":8}],\"ancestors\":[\"polymer\"],\"rootNode\":\"polymer\",\"childrenNr\":9},{\"id\":\"thermoplastic\",\"nodeId\":\"thermoplastic\",\"humanReadableId\":\"Thermoplastic\",\"label\":\"Thermoplastic\",\"disabled\":true,\"children\":[{\"id\":\"acrylic\",\"nodeId\":\"acrylic\",\"humanReadableId\":\"Acrylic\",\"label\":\"Acrylic\",\"disabled\":true,\"children\":[{\"id\":\"polyacrylonitrile--pan-\",\"nodeId\":\"polyacrylonitrile--pan-\",\"humanReadableId\":\"Polyacrylonitrile (PAN)\",\"label\":\"Polyacrylonitrile (PAN)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"acrylic\"],\"rootNode\":\"polymer\"},{\"id\":\"polymethyl-methacrylate--pmma-\",\"nodeId\":\"polymethyl-methacrylate--pmma-\",\"humanReadableId\":\"Polymethyl methacrylate (PMMA)\",\"label\":\"Polymethyl methacrylate (PMMA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"acrylic\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":2},{\"id\":\"fluoropolymer\",\"nodeId\":\"fluoropolymer\",\"humanReadableId\":\"Fluoropolymer\",\"label\":\"Fluoropolymer\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"nodeId\":\"ethylene-tetrafluoroethylene-copolymer--etfe-\",\"humanReadableId\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"label\":\"Ethylene Tetrafluoroethylene Copolymer (ETFE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"},{\"id\":\"fluorinated-ethylene-propylene--fep-\",\"nodeId\":\"fluorinated-ethylene-propylene--fep-\",\"humanReadableId\":\"Fluorinated ethylene propylene (FEP)\",\"label\":\"Fluorinated ethylene propylene (FEP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"},{\"id\":\"polytetrafluoroethylene--ptfe-\",\"nodeId\":\"polytetrafluoroethylene--ptfe-\",\"humanReadableId\":\"Polytetrafluoroethylene (PTFE)\",\"label\":\"Polytetrafluoroethylene (PTFE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"},{\"id\":\"polyvinylidenefluoride--pvdf-\",\"nodeId\":\"polyvinylidenefluoride--pvdf-\",\"humanReadableId\":\"Polyvinylidenefluoride (PVDF)\",\"label\":\"Polyvinylidenefluoride (PVDF)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"fluoropolymer\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":4},{\"id\":\"liquid-crystal-polymers--lcp-\",\"nodeId\":\"liquid-crystal-polymers--lcp-\",\"humanReadableId\":\"Liquid Crystal Polymers (LCP)\",\"label\":\"Liquid Crystal Polymers (LCP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide--pa-\",\"nodeId\":\"polyamide--pa-\",\"humanReadableId\":\"Polyamide (PA)\",\"label\":\"Polyamide (PA)\",\"disabled\":true,\"children\":[{\"id\":\"aramide\",\"nodeId\":\"aramide\",\"humanReadableId\":\"Aramide\",\"label\":\"Aramide\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-6-66--pa6-66-\",\"nodeId\":\"copolyamide-6-66--pa6-66-\",\"humanReadableId\":\"Copolyamide 6/66 (PA6/66)\",\"label\":\"Copolyamide 6/66 (PA6/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"other-polyamide--pa-\",\"nodeId\":\"other-polyamide--pa-\",\"humanReadableId\":\"Other Polyamide (PA)\",\"label\":\"Other Polyamide (PA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-1010--pa1010-\",\"nodeId\":\"polyamide-1010--pa1010-\",\"humanReadableId\":\"Polyamide 1010 (PA1010)\",\"label\":\"Polyamide 1010 (PA1010)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-1012--pa1012-\",\"nodeId\":\"polyamide-1012--pa1012-\",\"humanReadableId\":\"Polyamide 1012 (PA1012)\",\"label\":\"Polyamide 1012 (PA1012)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-11--pa11-\",\"nodeId\":\"polyamide-11--pa11-\",\"humanReadableId\":\"Polyamide 11 (PA11)\",\"label\":\"Polyamide 11 (PA11)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-12--pa12-\",\"nodeId\":\"polyamide-12--pa12-\",\"humanReadableId\":\"Polyamide 12 (PA12)\",\"label\":\"Polyamide 12 (PA12)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-410--pa410-\",\"nodeId\":\"polyamide-410--pa410-\",\"humanReadableId\":\"Polyamide 410 (PA410)\",\"label\":\"Polyamide 410 (PA410)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-46--pa46-\",\"nodeId\":\"polyamide-46--pa46-\",\"humanReadableId\":\"Polyamide 46 (PA46)\",\"label\":\"Polyamide 46 (PA46)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-6--pa6-\",\"nodeId\":\"polyamide-6--pa6-\",\"humanReadableId\":\"Polyamide 6 (PA6)\",\"label\":\"Polyamide 6 (PA6)\",\"disabled\":true,\"children\":[{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t-\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyamide-6--pa6-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\",\"childrenNr\":1},{\"id\":\"polyamide-6-66--pa6-66-\",\"nodeId\":\"polyamide-6-66--pa6-66-\",\"humanReadableId\":\"Polyamide 6/66 (PA6/66)\",\"label\":\"Polyamide 6/66 (PA6/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-610--pa610-\",\"nodeId\":\"polyamide-610--pa610-\",\"humanReadableId\":\"Polyamide 610 (PA610)\",\"label\":\"Polyamide 610 (PA610)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-612--pa612-\",\"nodeId\":\"polyamide-612--pa612-\",\"humanReadableId\":\"Polyamide 612 (PA612)\",\"label\":\"Polyamide 612 (PA612)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-66--pa66-\",\"nodeId\":\"polyamide-66--pa66-\",\"humanReadableId\":\"Polyamide 66 (PA66)\",\"label\":\"Polyamide 66 (PA66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphthalamide--ppa-\",\"nodeId\":\"polyphthalamide--ppa-\",\"humanReadableId\":\"Polyphthalamide (PPA)\",\"label\":\"Polyphthalamide (PPA)\",\"disabled\":true,\"children\":[{\"id\":\"copolyamide-66-6i--pa66-6i-\",\"nodeId\":\"copolyamide-66-6i--pa66-6i-\",\"humanReadableId\":\"Copolyamide 66/6I (PA66/6I)\",\"label\":\"Copolyamide 66/6I (PA66/6I)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-6t-66--pa6t-66-\",\"nodeId\":\"copolyamide-6t-66--pa6t-66-\",\"humanReadableId\":\"Copolyamide 6T/66 (PA6T/66)\",\"label\":\"Copolyamide 6T/66 (PA6T/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"nodeId\":\"copolyamide-6t-6i-66--pa6t-6i-66-\",\"humanReadableId\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"label\":\"Copolyamide 6T/6I/66 (PA6T/6I/66)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"nodeId\":\"copolyamide-pa6i-6t--pa6i-6t-\",\"humanReadableId\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"label\":\"Copolyamide PA6I/6T (PA6I/6T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-4t--pa4t-\",\"nodeId\":\"polyamide-4t--pa4t--\",\"humanReadableId\":\"Polyamide 4T (PA4T)\",\"label\":\"Polyamide 4T (PA4T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-6t--pa6t-\",\"nodeId\":\"polyamide-6t--pa6t-\",\"humanReadableId\":\"Polyamide 6T (PA6T)\",\"label\":\"Polyamide 6T (PA6T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-mxd6--pamxd6-\",\"nodeId\":\"polyamide-mxd6--pamxd6-\",\"humanReadableId\":\"Polyamide MXD6 (PAMXD6)\",\"label\":\"Polyamide MXD6 (PAMXD6)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyamide-pa6-6t--pa6-6t-\",\"nodeId\":\"polyamide-pa6-6t--pa6-6t-\",\"humanReadableId\":\"Polyamide PA6/6T (PA6/6T)\",\"label\":\"Polyamide PA6/6T (PA6/6T)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\",\"polyphthalamide--ppa-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyamide--pa-\"],\"rootNode\":\"polymer\",\"childrenNr\":8}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":15},{\"id\":\"polyaryletherketone--paek-\",\"nodeId\":\"polyaryletherketone--paek-\",\"humanReadableId\":\"Polyaryletherketone (PAEK)\",\"label\":\"Polyaryletherketone (PAEK)\",\"disabled\":true,\"children\":[{\"id\":\"polyether-ketone--pek-\",\"nodeId\":\"polyether-ketone--pek-\",\"humanReadableId\":\"Polyether Ketone (PEK)\",\"label\":\"Polyether Ketone (PEK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyaryletherketone--paek-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyetherether-ketone--peek-\",\"nodeId\":\"polyetherether-ketone--peek-\",\"humanReadableId\":\"Polyetherether Ketone (PEEK)\",\"label\":\"Polyetherether Ketone (PEEK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyaryletherketone--paek-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyetherketoneketone--pekk-\",\"nodeId\":\"polyetherketoneketone--pekk-\",\"humanReadableId\":\"Polyetherketoneketone (PEKK)\",\"label\":\"Polyetherketoneketone (PEKK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyaryletherketone--paek-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":3},{\"id\":\"polycarbonate--pc-\",\"nodeId\":\"polycarbonate--pc-\",\"humanReadableId\":\"Polycarbonate (PC)\",\"label\":\"Polycarbonate (PC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyester\",\"nodeId\":\"polyester\",\"humanReadableId\":\"Polyester\",\"label\":\"Polyester\",\"disabled\":true,\"children\":[{\"id\":\"polybutylene-terephthalate--pbt-\",\"nodeId\":\"polybutylene-terephthalate--pbt-\",\"humanReadableId\":\"Polybutylene Terephthalate (PBT)\",\"label\":\"Polybutylene Terephthalate (PBT)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polyethylene-terephthalate--pet-\",\"nodeId\":\"polyethylene-terephthalate--pet-\",\"humanReadableId\":\"Polyethylene Terephthalate (PET)\",\"label\":\"Polyethylene Terephthalate (PET)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polyethylene-terephthalate-glycol--petg-\",\"nodeId\":\"polyethylene-terephthalate-glycol--petg-\",\"humanReadableId\":\"Polyethylene Terephthalate Glycol (PETG)\",\"label\":\"Polyethylene Terephthalate Glycol (PETG)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polyglycolicide--pga-\",\"nodeId\":\"polyglycolicide--pga-\",\"humanReadableId\":\"Polyglycolicide (PGA)\",\"label\":\"Polyglycolicide (PGA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"},{\"id\":\"polytrimethylene-terephthalate--ptt-\",\"nodeId\":\"polytrimethylene-terephthalate--ptt-\",\"humanReadableId\":\"Polytrimethylene Terephthalate (PTT)\",\"label\":\"Polytrimethylene Terephthalate (PTT)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyester\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":5},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe-\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyimide--pi-\",\"nodeId\":\"polyimide--pi-\",\"humanReadableId\":\"Polyimide (PI)\",\"label\":\"Polyimide (PI)\",\"disabled\":true,\"children\":[{\"id\":\"polyamidimide--pai-\",\"nodeId\":\"polyamidimide--pai-\",\"humanReadableId\":\"Polyamidimide (PAI)\",\"label\":\"Polyamidimide (PAI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyimide--pi-\"],\"rootNode\":\"polymer\"},{\"id\":\"polybenzimidazole--pbi-\",\"nodeId\":\"polybenzimidazole--pbi-\",\"humanReadableId\":\"Polybenzimidazole (PBI)\",\"label\":\"Polybenzimidazole (PBI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyimide--pi-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyetherimide--pei-\",\"nodeId\":\"polyetherimide--pei-\",\"humanReadableId\":\"Polyetherimide (PEI)\",\"label\":\"Polyetherimide (PEI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyimide--pi-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":3},{\"id\":\"polyketone--pk-\",\"nodeId\":\"polyketone--pk-\",\"humanReadableId\":\"Polyketone (PK)\",\"label\":\"Polyketone (PK)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polylactic-acid--pla-\",\"nodeId\":\"polylactic-acid--pla-\",\"humanReadableId\":\"Polylactic Acid (PLA)\",\"label\":\"Polylactic Acid (PLA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polymer-blend\",\"nodeId\":\"polymer-blend\",\"humanReadableId\":\"Polymer Blend\",\"label\":\"Polymer Blend\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyolefin--po-\",\"nodeId\":\"polyolefin--po-\",\"humanReadableId\":\"Polyolefin (PO)\",\"label\":\"Polyolefin (PO)\",\"disabled\":true,\"children\":[{\"id\":\"polybutene--pb-\",\"nodeId\":\"polybutene--pb-\",\"humanReadableId\":\"Polybutene (PB)\",\"label\":\"Polybutene (PB)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\"},{\"id\":\"polyethylene--pe-\",\"nodeId\":\"polyethylene--pe--\",\"humanReadableId\":\"Polyethylene (PE)\",\"label\":\"Polyethylene (PE)\",\"disabled\":true,\"children\":[{\"id\":\"high-density-polyethylene--pe-hd-\",\"nodeId\":\"high-density-polyethylene--pe-hd-\",\"humanReadableId\":\"High Density Polyethylene (PE-HD)\",\"label\":\"High Density Polyethylene (PE-HD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"nodeId\":\"high-molecular-weight-polyethylene--pe-hmw-\",\"humanReadableId\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"label\":\"High Molecular Weight Polyethylene (PE-HMW)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"linear-low-density-polyethylene--pe-lld-\",\"nodeId\":\"linear-low-density-polyethylene--pe-lld-\",\"humanReadableId\":\"Linear Low Density Polyethylene (PE-LLD)\",\"label\":\"Linear Low Density Polyethylene (PE-LLD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"low-density-polyethylene--pe-ld-\",\"nodeId\":\"low-density-polyethylene--pe-ld-\",\"humanReadableId\":\"Low Density Polyethylene (PE-LD)\",\"label\":\"Low Density Polyethylene (PE-LD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"medium-density-polyethylene--pe-md-\",\"nodeId\":\"medium-density-polyethylene--pe-md-\",\"humanReadableId\":\"Medium Density Polyethylene (PE-MD)\",\"label\":\"Medium Density Polyethylene (PE-MD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"nodeId\":\"ultra-high-molecular-weight-polyethylene--pe-uhmw-\",\"humanReadableId\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"label\":\"Ultra High Molecular Weight Polyethylene (PE-UHMW)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"},{\"id\":\"very-low-density-polyethylene--pe-vld-\",\"nodeId\":\"very-low-density-polyethylene--pe-vld-\",\"humanReadableId\":\"Very Low Density Polyethylene (PE-VLD)\",\"label\":\"Very Low Density Polyethylene (PE-VLD)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\",\"polyethylene--pe--\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\",\"childrenNr\":7},{\"id\":\"polymethylpentene--pmp-\",\"nodeId\":\"polymethylpentene--pmp-\",\"humanReadableId\":\"Polymethylpentene (PMP)\",\"label\":\"Polymethylpentene (PMP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\"},{\"id\":\"polypropylene--pp-\",\"nodeId\":\"polypropylene--pp-\",\"humanReadableId\":\"Polypropylene (PP)\",\"label\":\"Polypropylene (PP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyolefin--po-\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":4},{\"id\":\"polyoxymethylene--pom-\",\"nodeId\":\"polyoxymethylene--pom-\",\"humanReadableId\":\"Polyoxymethylene (POM)\",\"label\":\"Polyoxymethylene (POM)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenyl\",\"nodeId\":\"polyphenyl\",\"humanReadableId\":\"Polyphenyl\",\"label\":\"Polyphenyl\",\"disabled\":true,\"children\":[{\"id\":\"polyphenyl-ether--ppe-\",\"nodeId\":\"polyphenyl-ether--ppe-\",\"humanReadableId\":\"Polyphenyl Ether (PPE)\",\"label\":\"Polyphenyl Ether (PPE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyphenyl\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenylene-oxide--ppo-\",\"nodeId\":\"polyphenylene-oxide--ppo-\",\"humanReadableId\":\"Polyphenylene Oxide (PPO)\",\"label\":\"Polyphenylene Oxide (PPO)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyphenyl\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenylene-sulfide--pps-\",\"nodeId\":\"polyphenylene-sulfide--pps-\",\"humanReadableId\":\"Polyphenylene Sulfide (PPS)\",\"label\":\"Polyphenylene Sulfide (PPS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polyphenyl\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":3},{\"id\":\"polysaccharide\",\"nodeId\":\"polysaccharide\",\"humanReadableId\":\"Polysaccharide\",\"label\":\"Polysaccharide\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\"},{\"id\":\"polysulphones\",\"nodeId\":\"polysulphones\",\"humanReadableId\":\"Polysulphones\",\"label\":\"Polysulphones\",\"disabled\":true,\"children\":[{\"id\":\"polyether-sulfone--pes-\",\"nodeId\":\"polyether-sulfone--pes-\",\"humanReadableId\":\"Polyether Sulfone (PES)\",\"label\":\"Polyether Sulfone (PES)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"},{\"id\":\"polyphenylsulphone--ppsu-\",\"nodeId\":\"polyphenylsulphone--ppsu-\",\"humanReadableId\":\"Polyphenylsulphone (PPSU)\",\"label\":\"Polyphenylsulphone (PPSU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"},{\"id\":\"polysulphone--psu-\",\"nodeId\":\"polysulphone--psu-\",\"humanReadableId\":\"Polysulphone (PSU)\",\"label\":\"Polysulphone (PSU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"},{\"id\":\"polysulphone-general--psu-\",\"nodeId\":\"polysulphone-general--psu-\",\"humanReadableId\":\"Polysulphone General (PSU)\",\"label\":\"Polysulphone General (PSU)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"polysulphones\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":4},{\"id\":\"styrene\",\"nodeId\":\"styrene\",\"humanReadableId\":\"Styrene\",\"label\":\"Styrene\",\"disabled\":true,\"children\":[{\"id\":\"acrylonitrile-butadiene-styrene--abs-\",\"nodeId\":\"acrylonitrile-butadiene-styrene--abs-\",\"humanReadableId\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"label\":\"Acrylonitrile Butadiene Styrene (ABS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"acrylonitrile-styrene-acrylate--asa-\",\"nodeId\":\"acrylonitrile-styrene-acrylate--asa-\",\"humanReadableId\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"label\":\"Acrylonitrile Styrene Acrylate (ASA)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"high-impact-polystyrene--hips-\",\"nodeId\":\"high-impact-polystyrene--hips-\",\"humanReadableId\":\"High Impact Polystyrene (HIPS)\",\"label\":\"High Impact Polystyrene (HIPS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"methacrylate-butadiene-styrene--mbs-\",\"nodeId\":\"methacrylate-butadiene-styrene--mbs-\",\"humanReadableId\":\"Methacrylate Butadiene Styrene (MBS)\",\"label\":\"Methacrylate Butadiene Styrene (MBS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"polystyrene--ps-\",\"nodeId\":\"polystyrene--ps-\",\"humanReadableId\":\"Polystyrene (PS)\",\"label\":\"Polystyrene (PS)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"},{\"id\":\"styrene-acrylonitrile--san-\",\"nodeId\":\"styrene-acrylonitrile--san-\",\"humanReadableId\":\"Styrene Acrylonitrile (SAN)\",\"label\":\"Styrene Acrylonitrile (SAN)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"styrene\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":6},{\"id\":\"vinyl\",\"nodeId\":\"vinyl\",\"humanReadableId\":\"Vinyl\",\"label\":\"Vinyl\",\"disabled\":true,\"children\":[{\"id\":\"ethylene-vinyl-acetate--evac-\",\"nodeId\":\"ethylene-vinyl-acetate--evac-\",\"humanReadableId\":\"Ethylene Vinyl Acetate (EVAC)\",\"label\":\"Ethylene Vinyl Acetate (EVAC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"vinyl\"],\"rootNode\":\"polymer\"},{\"id\":\"polyvinyl-chloride--pvc-\",\"nodeId\":\"polyvinyl-chloride--pvc-\",\"humanReadableId\":\"Polyvinyl Chloride (PVC)\",\"label\":\"Polyvinyl Chloride (PVC)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermoplastic\",\"vinyl\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermoplastic\"],\"rootNode\":\"polymer\",\"childrenNr\":2}],\"ancestors\":[\"polymer\"],\"rootNode\":\"polymer\",\"childrenNr\":19},{\"id\":\"thermosetting\",\"nodeId\":\"thermosetting\",\"humanReadableId\":\"Thermosetting\",\"label\":\"Thermosetting\",\"disabled\":true,\"children\":[{\"id\":\"amino-resin\",\"nodeId\":\"amino-resin\",\"humanReadableId\":\"Amino Resin\",\"label\":\"Amino Resin\",\"disabled\":true,\"children\":[{\"id\":\"bismaleimide--bmi-\",\"nodeId\":\"bismaleimide--bmi-\",\"humanReadableId\":\"Bismaleimide (BMI)\",\"label\":\"Bismaleimide (BMI)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\",\"amino-resin\"],\"rootNode\":\"polymer\"},{\"id\":\"melamine-formaldehyde--mf-\",\"nodeId\":\"melamine-formaldehyde--mf-\",\"humanReadableId\":\"Melamine formaldehyde (MF)\",\"label\":\"Melamine formaldehyde (MF)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\",\"amino-resin\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\",\"childrenNr\":2},{\"id\":\"epoxy-resin--ep-\",\"nodeId\":\"epoxy-resin--ep-\",\"humanReadableId\":\"Epoxy Resin (EP)\",\"label\":\"Epoxy Resin (EP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"phenol-formaldehyde-resin--pf-\",\"nodeId\":\"phenol-formaldehyde-resin--pf-\",\"humanReadableId\":\"Phenol Formaldehyde Resin (PF)\",\"label\":\"Phenol Formaldehyde Resin (PF)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"phthalonitrile--pn-\",\"nodeId\":\"phthalonitrile--pn-\",\"humanReadableId\":\"Phthalonitrile (PN)\",\"label\":\"Phthalonitrile (PN)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"polyester-resin--up-\",\"nodeId\":\"polyester-resin--up-\",\"humanReadableId\":\"Polyester Resin (UP)\",\"label\":\"Polyester Resin (UP)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"},{\"id\":\"vinyl-ester-resin--ve-\",\"nodeId\":\"vinyl-ester-resin--ve-\",\"humanReadableId\":\"Vinyl Ester Resin (VE)\",\"label\":\"Vinyl Ester Resin (VE)\",\"disabled\":true,\"ancestors\":[\"polymer\",\"thermosetting\"],\"rootNode\":\"polymer\"}],\"ancestors\":[\"polymer\"],\"rootNode\":\"polymer\",\"childrenNr\":6}],\"rootNode\":\"polymer\",\"childrenNr\":3,\"checked\":false}],\"categorySpecificFilter\":{\"name\":\"metal\",\"disabled\":false,\"forms\":[{\"id\":\"bar\",\"label\":\"Bar\",\"checked\":true},{\"id\":\"billet\",\"label\":\"Billet\"},{\"id\":\"casting\",\"label\":\"Casting\",\"disabled\":true},{\"id\":\"coil\",\"label\":\"Coil\"},{\"id\":\"disc\",\"label\":\"Disc\",\"disabled\":true},{\"id\":\"flat\",\"label\":\"Flat\"},{\"id\":\"flat-bar\",\"label\":\"Flat Bar\"},{\"id\":\"foil\",\"label\":\"Foil\"},{\"id\":\"forging\",\"label\":\"Forging\"},{\"id\":\"full-section\",\"label\":\"Full Section\",\"disabled\":true},{\"id\":\"half-round-bar\",\"label\":\"Half Round Bar\",\"disabled\":true},{\"id\":\"hexagonal-bar\",\"label\":\"Hexagonal Bar\"},{\"id\":\"hexagonal-bright-bar\",\"label\":\"Hexagonal Bright Bar\",\"disabled\":true},{\"id\":\"hexagonal-rod\",\"label\":\"Hexagonal Rod\"},{\"id\":\"hexagonal-wire\",\"label\":\"Hexagonal Wire\"},{\"id\":\"hollow-bar\",\"label\":\"Hollow Bar\",\"disabled\":true},{\"id\":\"ingot\",\"label\":\"Ingot\",\"disabled\":true},{\"id\":\"pipe\",\"label\":\"Pipe\",\"disabled\":true},{\"id\":\"plate\",\"label\":\"Plate\"},{\"id\":\"powder\",\"label\":\"Powder\",\"disabled\":true},{\"id\":\"profile\",\"label\":\"Profile\"},{\"id\":\"profile-wire\",\"label\":\"Profile Wire\",\"disabled\":true},{\"id\":\"rod\",\"label\":\"Rod\"},{\"id\":\"round-bar\",\"label\":\"Round Bar\"},{\"id\":\"round-bright-bar\",\"label\":\"Round Bright Bar\",\"disabled\":true},{\"id\":\"round-rod\",\"label\":\"Round Rod\"},{\"id\":\"round-wire\",\"label\":\"Round Wire\"},{\"id\":\"seamless-tube\",\"label\":\"Seamless Tube\"},{\"id\":\"sheet\",\"label\":\"Sheet\"},{\"id\":\"spring\",\"label\":\"Spring\",\"disabled\":true},{\"id\":\"squar-bar\",\"label\":\"Squar Bar\",\"disabled\":true},{\"id\":\"square-bar\",\"label\":\"Square Bar\"},{\"id\":\"strip\",\"label\":\"Strip\"},{\"id\":\"tube\",\"label\":\"Tube\"},{\"id\":\"welded-tube\",\"label\":\"Welded Tube\",\"disabled\":true},{\"id\":\"wire\",\"label\":\"Wire\"}],\"fillers\":[],\"modifications\":[],\"processing\":[],\"certifications\":[],\"primaryPhase\":[],\"secondaryPhase\":[]},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"suppliers\":[{\"id\":\"dest\",\"label\":\"Deutsche Edelstahlwerke (DEW)\",\"materialsCount\":93},{\"id\":\"ugit\",\"label\":\"Ugitech\",\"materialsCount\":50},{\"id\":\"sver\",\"label\":\"Sverdrup Steel AS\",\"materialsCount\":20},{\"id\":\"salo\",\"label\":\"Salomon's Metalen\",\"materialsCount\":16},{\"id\":\"hemp\",\"label\":\"Hempel Special Metals\",\"materialsCount\":4},{\"id\":\"vdmm\",\"label\":\"VDM Metals\",\"materialsCount\":1},{\"id\":\"song\",\"label\":\"Dongguan songshun mould steel Co., Ltd.\",\"materialsCount\":13},{\"id\":\"ambi\",\"label\":\"Ambica Steels Limited\",\"materialsCount\":10}]},\"collapsed\":{\"categories\":[]},\"specification\":{\"queryParams\":\"categories=steel\\u0026tags=form:bar\",\"clauses\":[{\"type\":\"tags\",\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}]},\"tags\":[{\"id\":\"form\",\"value\":\"bar\",\"label\":\"Bar\"}],\"view\":\"result-list\",\"sidebarCollapsed\":false,\"unitsSystem\":\"metric\",\"polymerFilter\":{\"disabled\":true}},\"supplierSearch\":{\"specification\":{\"grade\":{\"value\":\"\",\"touched\":false},\"form\":{\"value\":\"\",\"touched\":false},\"country\":{\"value\":[]},\"certification\":{\"value\":[]}},\"grades\":[],\"forms\":[],\"countries\":[],\"certifications\":[],\"results\":{\"companies\":{\"data\":[],\"companiesCount\":20,\"equivalentsCount\":20,\"page\":1}},\"view\":\"result-list\",\"map\":{\"selectedLocation\":{\"id\":\"Location 1\",\"companyCode\":\"Supplier A\"},\"locations\":[{\"companyCode\":\"Supplier A\",\"id\":\"Location 1\",\"position\":{\"lat\":41.3954,\"lng\":20.162}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 2\",\"position\":{\"lat\":41.3917,\"lng\":25.1649}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 3\",\"isEquivalent\":true,\"position\":{\"lat\":49.3773,\"lng\":28.1585}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 4\",\"position\":{\"lat\":45.3797,\"lng\":12.1682}},{\"companyCode\":\"Supplier A\",\"id\":\"Location 5\",\"isEquivalent\":true,\"position\":{\"lat\":38.3773,\"lng\":37.1915}}]}},\"categoriesTree\":{\"list\":[],\"selected\":{},\"recommended\":{}},\"messages\":{\"conversationsList\":[],\"currentConversation\":null,\"selectedConversationId\":\"\"},\"messagesAdmin\":{\"adminConversationsList\":[],\"adminCurrentConversation\":\"\",\"adminCurrentRecommendedSuppliers\":[],\"adminCurrentLinkedSuppliers\":[],\"selectedAdminConversationId\":\"\",\"filterType\":\"code\",\"filterValue\":\"\",\"resolution\":\"\",\"sort\":\"desc\",\"sortingField\":\"createdDate\",\"size\":10,\"page\":0,\"conversationsCount\":0,\"pagesCount\":0,\"suppliers\":[]},\"suppliersFilter\":{\"suppliersTree\":null,\"selectedSuppliers\":null},\"undo\":{},\"propertiesTree\":{\"list\":[],\"selected\":{}},\"retargeting\":{\"title\":\"\",\"data\":[],\"selectedUsersIds\":[],\"singleUserId\":\"\"},\"formData\":{\"materialId\":\"\",\"companyCodes\":[],\"categories\":[],\"formName\":\"\",\"verifiedDistributors\":[]},\"supplierDashboard\":{\"currentDashboardView\":\"\",\"currentDashboardMenuSubItem\":null,\"dashboardInfo\":{}},\"applicationsFilter\":{\"applications\":[],\"selectedApplications\":[]},\"unseen\":{\"unseenConversationsCount\":0},\"ashbyChart\":{\"data\":{},\"zoomedViewData\":{\"supplierMaterials\":[],\"context\":{}},\"clickedClusters\":[],\"suppliers\":[]},\"campaigns\":{\"categoryCampaigns\":[],\"defaultCampaigns\":[{\"name\":\"Default Ad\",\"category\":\"matmatch\",\"supplierId\":\"Default\",\"slots\":[\"Top\"],\"targetUrl\":\"https://go.matmatch.com/advertise\",\"targetWindow\":\"_blank\",\"banners\":[{\"size\":\"728x90\",\"imageId\":\"d792d789-c5c3-4a70-808b-3ec5ff2d9d33\"}]}]},\"searchBar\":{\"show\":true},\"advancedSearchPlotMaterials\":{\"ashbyChartSettings\":{\"propertyX\":\"density\",\"propertyY\":\"elastic-modulus\"}}}},\"page\":\"/advanced-search\",\"query\":{\"categories\":\"steel\",\"tags\":\"form:bar\"},\"buildId\":\"d4287122\",\"runtimeConfig\":{\"NODE_ENV\":\"production\",\"MATMATCH_CONFIG_ENV\":\"production\",\"SENTRY_DSN\":\"https://adb8811c666c47d48ea65639f264583b@sentry.io/189857\",\"RECAPTCHA_KEY\":\"6LcKSOAUAAAAALB76MApsk-XoTTzEBY2-oqMwwLm\",\"GA_ENABLED\":true,\"GA_ENABLE_LOG_TO_CONSOLE\":false,\"LEADFEEDER_ENABLED\":true,\"LEADFEEDER_TRACKING_ID\":\"Yn8J1xYRVZwgW0Rk\",\"HUBSPOT_ENABLED\":true,\"HUBSPOT_TRACKING_ID\":\"4597184\",\"HUBSPOT_SUBSCRIPTION_ID\":\"7207954\",\"HUBSPOT_NEWSLETTER_FORM_ID\":\"406d64d3-90e0-4174-902c-5fb4e72743ee\",\"HUBSPOT_CONTACT_FORM_ID\":\"1d836df6-1a29-42af-b067-822ad3021c1f\",\"HUBSPOT_SUSTAINABILITY_FORM_ID\":\"ac183d3d-8966-4086-b781-2d843b345377\",\"HUBSPOT_REQUEST_BOARD_FORM_ID\":\"0726b812-0d7c-4b9a-848b-ee6797c92db0\",\"HUBSPOT_CONTACT_FORM_ID_FIELD_NAMES\":{\"supplyMaterialsFieldName\":\"is_materials_supplier__c\"},\"HUBSPOT_REQUEST_MATERIAL_DATA_FORM_ID\":\"bce2daac-e6e7-41cb-ba4c-b4e27c7fec37\",\"HUBSPOT_REQUEST_BOOK_A_DEMO\":\"ed5d8d19-d961-48cf-b58c-f192500e6eb7\",\"HUBSPOT_REQUEST_BOOK_A_DEMO_FORM_LINK\":\"https://share.hsforms.com/17V2NGdlhSM-1jPGSUA5utw2qj7k\",\"HUBSPOT_REQUEST_BOOK_A_DEMO_FIELD_NAMES\":{\"supplierTypesFieldName\":\"plsuppliertype__c\"},\"HUBSPOT_REQUEST_BOOK_A_MEETING\":\"b4b7750c-75f8-4741-8fe6-daec03c1454b\",\"HUBSPOT_GET_IT_NOW\":\"818cf677-3f93-4f86-83dc-43996c9c8b2d\",\"ADBUTLER_ENABLED\":true,\"ADBUTLER_ACCOUNT_ID\":181075,\"ADBUTLER_ADVANCED_SEARCH_ZONE_ID\":470439,\"ADBUTLER_MATERIAL_PAGE_ZONE_ID\":470587,\"ADBUTLER_CONTENT_HUB_ZONE_ID\":473203,\"GA_TRACKING_ID\":\"UA-85033665-5\",\"GA_OPTIMIZE_ID\":\"GTM-KQK3NFF\",\"GTM_ID\":\"GTM-PV6RPFJ\"},\"isFallback\":false,\"customServer\":true,\"gip\":true,\"appGip\":true,\"scriptLoader\":[]}</script></body></html>\n\n\nUsing the ‘find_all’ function of soup we can find all these blocks by specifying the details of the block, i.e. <div class=”job_seen_beacon>\nThe length of jobs_soup should be the number of job panels on the page, and each should be for a specific job. The output for the first is shown below (different search criteria).\n\n#collapse-output\njobs_soup=soup.find_all(name=\"div\", attrs={\"class\":\"job_seen_beacon\"})\n\njobs_soup[0]\n\nIndexError: list index out of range\n\n\nWe now need to pick out the details of the job from these blocks. To do this we go back to Chrome.\n\nClicking on one of the job titles displays the job title is given as:\n<span title=\"Data Analyst\">Data Analyst</span>\nThere are a few ways we can extract this. What we want is a “span” with a feature called “title”. One way is to scroll through all “div” and find one with a title, using the except to help if it doesn’t have a title.\n\ndiv=jobs_soup[0]\nfor ab in div.find_all(name=\"span\"):\n            \n   try:                            \n      aJob=ab['title']   \n          \n   except:\n      pass\n        \naJob\n\n'Electricians Mate / Electrical Improver'\n\n\nEach category we want to extract is slightly different so requires a slightly different approach. Although, the same procedure of using the developer tools in chrome and then modifying how the soup is searched is used.\nFor the company name it is within <span class=”companyName”><a>Company X…\nSo can be accessed from the string within the span with class= companyName .\n\naaa=div.find_all(name=\"span\", attrs={\"class\":\"companyName\"})\naaa[0].string\n\n'Electrical Avenue'\n\n\n\n\nFunction to scrape\nThis can be done for other details we might want from the other job details as below in a single function\n\ndef extract_title(soup): \n    #initialse\n    jobs = []\n    company=[]\n    pay=[]\n    descr=[]\n    \n    #\"job_seen_beacon\" is the div for each job panel \n          # would be better to use <a> tag with \n    for div in soup.find_all(name=\"div\", attrs={\"class\":\"job_seen_beacon\"}):\n\n        #for the company name is in span tag with class=companyName\n        aComp=\"-\"\n        for a in div.find_all(name=\"span\", attrs={\"class\":\"companyName\"}):\n            try:\n                aComp=a.string\n            except:\n                print('exception comp')\n                pass \n        company.append(a.string)\n        \n        aJob='-'\n        for ab in div.find_all(name=\"span\"):\n            try:\n                aJob=ab['title']              \n            except: #Exception\n                pass\n        jobs.append(aJob)\n        \n        aPay=\"0\"\n        for abc in div.find_all(name=\"span\", attrs={\"class\":\"salary-snippet\"}):\n            try:\n                aPay=abc.string\n            except:\n                print('exception pay')\n                pass\n        pay.append(aPay)\n\n        \n        aDescr=''\n        abc = div.find_all(name='div',attrs={\"class\":\"job-snippet\"})\n        for abcd in abc[0].find_all(name='li'):\n            try:\n                aDescr=aDescr+abcd.getText()+'-'\n            except:\n                print('exception decr')\n                pass\n        \n        descr.append(aDescr)\n        \n    sa=soup.find_all(name='a',attrs={\"target\":\"_blank\"})\n    urlss=[]\n    \n    strURLstart='https://www.indeed.co.uk'\n    for aSect in sa:\n        li=[]\n        try:\n            aCheck=aSect['id']\n            li.append(aCheck)\n            urlss.append(strURLstart+aSect['href'])\n        except:\n            pass\n            \n    return jobs, company, pay, descr, urlss\n\nBut there may be more than the first page, so creating a function that can just take:\n\nJob details\nLocation\nMaximum number of returned results.\n\nWe get the following:\n\n## Cycle through pages and call inner function 'extract_title'\ndef extract_outer(jobtype,location,max_results):\n    import requests\n    import bs4\n    from bs4 import BeautifulSoup\n    import pandas as pd\n    import numpy as np\n    import copy as copy\n    import time\n    \n    #Split job into two string with plus - i.e. \"road sweeper\"->\"road + sweeper\"\n    jobtype=jobtype.replace(' ',' + ')\n    \n    #initialise values\n    df=pd.DataFrame(columns=['Company','Job Title','Pay','Details','URL'])\n    \n    #Scroll through pages i.e. 0-9 in page1 --10-19 in page2 (in theory!)\n    i=0\n    for start in range(0, max_results, 10):#Add 10 on till a max\n        \n        #initialise values\n        num = (len(df) + 1)\n        jobs_, company_, pay_, descr_, urlss_ = [], [] , [], [], []\n        num=str(start)\n        \n        #add a pause\n        time.sleep(1)\n        \n        #get URL\n        URL=\"https://uk.indeed.com/jobs?q=\"+jobtype+\"&l=\"+location+\"&start=\"+num#conducting a request of the stated URL above:\n        page = requests.get(URL)#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n        soup = BeautifulSoup(page.text, \"html.parser\")#printing soup in a more structured tree format that makes for easier reading\n        \n        #call the inner function\n        jobs_, company_, pay_, descr_, urlss_=extract_title(soup)\n        \n        # append the lists\n        if i==0:          ## on 1st go assign df values\n            df['Company']=company_\n            df['Job Title']=jobs_\n            df['Pay']=pay_\n            df['Details']=descr_\n            df['URL']=urlss_\n        else:            ## on next ones concat df with a new df \n            df_=pd.DataFrame(columns=['Company','Job Title','Pay','Details','URL'])\n            df_['Company']=company_\n            df_['Job Title']=jobs_\n            df_['Pay']=pay_\n            df_['Details']=descr_\n            df_['URL']=urlss_\n            \n            df=pd.concat(\n                [df,df_ \n                \n                ]\n                        )\n            del df_\n        i=i+1\n    \n        df=df.reset_index(drop=True)#reset index- drop stops index becoming a column\n    return df\n\nWhich can be called to return a pandas DataFrame with:\n\nCompany\nJob Title\nPay\nJob Details\nURL for more details\n\nThe function is called like this:\n\njobtitle='data analyst'\nmaxRes=50\nlocat=\"Swansea%2C+Swansea\"\nfname=\"indeed_\"+jobtitle+'_'+locat+'_maxRes='+str(maxRes)+'.csv'\ndf=extract_outer(jobtitle,locat,maxRes)\ndf.head(10)\n\n\n\n\n\n  \n    \n      \n      Company\n      Job Title\n      Pay\n      Details\n      URL\n    \n  \n  \n    \n      0\n      CAIS\n      Data / BI Analyst & Developer\n      0\n      This role will be instrumental in developing a...\n      https://www.indeed.co.uk/company/CAIS/jobs/Dat...\n    \n    \n      1\n      Jisc\n      Scholarly Communications Data Analyst\n      0\n      The Data analyst will be responsible for colle...\n      https://www.indeed.co.uk/pagead/clk?mo=r&ad=-6...\n    \n    \n      2\n      Digital Health and Care Wales\n      Support and Business Analyst\n      0\n      Until recently this type of information was he...\n      https://www.indeed.co.uk/rc/clk?jk=c95fc84ef57...\n    \n    \n      3\n      ERS Administration Services\n      Senior Risk Analyst\n      0\n      Are you an experienced Risk Analyst looking fo...\n      https://www.indeed.co.uk/rc/clk?jk=c239d92f7fa...\n    \n    \n      4\n      IQUW\n      Senior Risk Analyst\n      0\n      Are you an experienced Risk Analyst looking fo...\n      https://www.indeed.co.uk/rc/clk?jk=fd313f82db9...\n    \n    \n      5\n      Momentum Security Recruitment\n      Business Analyst\n      0\n      Collection and analysis of data to support man...\n      https://www.indeed.co.uk/company/Momentum-Secu...\n    \n    \n      6\n      Public Health Wales NHS Trust\n      Principal Information Analyst / Finance Delive...\n      0\n      The ideal candidate will be enthusiastic about...\n      https://www.indeed.co.uk/rc/clk?jk=2cbca7681eb...\n    \n    \n      7\n      IQUW Group\n      Senior Risk Analyst\n      0\n      As a key member of the Risk Management Team, t...\n      https://www.indeed.co.uk/company/IQUW-Group/jo...\n    \n    \n      8\n      Momentum Security Recruitment\n      Business Test Analyst\n      0\n      Understanding of data creation and manipulatio...\n      https://www.indeed.co.uk/company/Momentum-Secu...\n    \n    \n      9\n      Public Health Wales NHS Trust\n      Senior Business Analyst - Finance Delivery Unit\n      0\n      You will work within the Analytics Centre of E...\n      https://www.indeed.co.uk/rc/clk?jk=d354ad34b6a...\n    \n  \n\n\n\n\n\n\nLooking inside the individual pages\nSo far the data frame just has details available on the main search page. The information is limited (see details tab below).\nMore details can be found on the individual pages\n\ndf.iloc[0].Details\n\n'This role will be instrumental in developing a new infrastructure of data development and insights.-As part of this we are introducing new tools, technology and…-'\n\n\nFor each job the same webscraping procedure can be used to get information from the job page.\nBelow is how to get the full description\n\nURL=df.URL[0]\npage = requests.get(URL)#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\nsoup = BeautifulSoup(page.text, \"html.parser\")#printing soup in a more structured tree format that makes for easier reading\nasoup=soup.find(name=\"div\", attrs={\"id\":\"jobDescriptionText\"})\nasoup2=asoup.text\nasoup2\n\n'An opportunity has arisen for an enthusiastic and self-motivated individual to join our newly formed Data and Evaluation Department. Adferiad are embarking on a new Data, Insight and CRM Delivery Plan to maximise our data as an asset, create an insight driven culture and modernise our ways of working. As part of this we are introducing new tools, technology and processes to continually improve our data and CRM capabilities; and empower a digital-first approachThis is a new and exciting role and is based in our busy Office in Llansamlet, Swansea; however, as Adferiad provide services across all counties in Wales, some travel may be required. Working within a team of Data and IT colleagues, this role is an exciting opportunity for those interested in a career within the analytic field. This role will be instrumental in developing a new infrastructure of data development and insights.Reference ID: H69Job Type: PermanentSalary: £29,226.00 per yearBenefits:On-site parkingSchedule:Monday to Friday'\n\n\nDetails of this could then be extracted to look for key words, salary etc. Using Natural Language Processing.\n\n\nIndeed overview\nAt this stage one might think “I can do this in my web browser“. Which is obviously true.\nBut this data can now be processed further to find other things. Maybe we want to compare pay in different regions, look for where there are more jobs of a certain type, interrogate the jobs details for specific information."
  },
  {
    "objectID": "posts/2021-11-18-WebScraping.html#example-using-selenium",
    "href": "posts/2021-11-18-WebScraping.html#example-using-selenium",
    "title": "ThomasHSimm",
    "section": "Example using selenium",
    "text": "Example using selenium\n\nThis uses the same methodology as above but instead uses Selenium which controls a web browser.\nThis means links can be clicked, or other boxes can be okayed (e.g. accept cookie box).\nSince this was done it appears the website has slightly changed as the code does not work.\n\n# Some imports\n\nimport requests\nimport bs4\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium import webdriver\nimport time\nimport os\n\nGet web driver for chrome from https://chromedriver.chromium.org/downloads\nThen use it to open the website.\n\n#hide\nURLweb = \"https://matmatch.com/advanced-search?categories=steel&tags=form:bar\"\nbrowser_loc='C:/Users/44781/pyproj/chromedriver.exe'\n\n\n#import chrome webdriver\n\nURL = URLweb\nbrowser = webdriver.Chrome(browser_loc)\nbrowser.get(URL)\n\nChrome is now controlled from this notebook\n\n\n#get rid of cookie q\nelem2=browser.find_element_by_tag_name('button')\nbrowser.execute_script(\"arguments[0].click();\", elem2)\n\n\nThe functions\n\n1. innerPage\nthis scrolls through each search page\nand calls OneSearchPage\n\n\n2. OneSearchPage\nOne of the search pages\nFor each link calls gothrough_A_Link\n\n\n3. gothrough_A_Link\nThis looks on a materials page\nThis then calls getTableData function to extract table data\n\n\n4. getTableData\ngetTableData\n\ndef innerPage(browser):\n    import time\n    f=0\n    ii=0\n    #first time through\n    dfAll=OneSearchPage(browser)\n    foutname='steel_bar_'+str(ii)\n    dfAll.to_csv(foutname)\n    print('ii ',ii)\n    while f==0:\n        if ii<200:\n            \n            #find Next page button and click it\n            elemNext=browser.find_elements_by_xpath(\"//button[contains(@data-test-item,'next-page')]\")\n            try:\n                elemNext[0].click()#this should fail if last page\n            except:\n                f=1\n                print('failed',elemNext[0].text)\n                break\n            time.sleep(1)\n            #next timeS through\n            dfAll=OneSearchPage(browser)\n            \n            ii=ii+1\n            foutname='steel_bar_'+str(ii)\n            dfAll.to_csv(foutname)\n            print('ii ',ii)\n            \n        else:\n            break\n            \n        \n        \n    return dfAll\n\n\ndef OneSearchPage(browser,*dfnew):\n    #find each element with <a> and contain materials\n    elem2=browser.find_elements_by_xpath(\"//a[contains(@href,'/materials/')]\")\n\n    if 'df' in locals():\n        del df\n    if 'df_' in locals():\n        del df_\n\n\n    i=0\n    for eel in elem2:\n        if i<200:\n            print(eel.text)\n            time.sleep(1)\n\n            if len(dfnew)>0:##if we give dfnew as input\n                \n                df_=gothrough_A_Link(eel,browser)\n                if i==0:\n                    dfOne=dfnew[0].append(df_)\n                else:\n                    dfOne=dfOne.append(df_)\n            else:#if don't give input dfnew\n                if i==0:#on 1st call create dfOne\n                    dfOne=gothrough_A_Link(eel,browser)\n                else:#on 2nd call append\n                    df_=gothrough_A_Link(eel,browser)\n                    dfOne=dfOne.append(df_)\n\n            i=i+1\n            time.sleep(1)\n            print('i ',i)\n        else:\n            break\n    return dfOne\n\n\ndef gothrough_A_Link(pageElement,browser):\n    import time\n    from selenium.webdriver.common.keys import Keys \n    #give like gothrough_A_Link(elem2[ii],browser)\n    time.sleep(.6)\n#     print(pageElement)\n    #open element- but in new tab\n    try:\n        pageElement.click()#send_keys(Keys.RETURN)\n    except:\n        time.sleep(0.9)\n        time.sleep(0.9)\n    #switch to new window\n\n    #get current window\n    p = browser.current_window_handle\n    #get windows\n    chwd=browser.window_handles\n    for w in chwd:\n    #switch focus to child window\n        if(w!=p):\n            browser.switch_to.window(w)\n            break\n    time.sleep(0.9)\n    \n    \n    #get current url\n    url_current=browser.current_url\n    \n    #get table details\n    \n    df=getTableData(url_current)\n    \n    \n    #close new window\n    time.sleep(0.9)\n    browser.close()\n    browser.switch_to.window(browser.window_handles[0])\n\n    return df\n\n############################################################################################\n\n############################################################################################\n\n\n    \n\n\ndef getTableData(URL):\n    import requests\n    import bs4\n    from bs4 import BeautifulSoup\n    import pandas as pd\n    \n    \n    res = requests.get(URL)\n    soup = BeautifulSoup(res.content,'lxml')\n\n    # get alloy name\n    titla=soup.find('h1').text\n\n#     print(titla)\n    #get alloy description\n    descripta=soup.find('div',{'class':'common__SubSectionWrapper-sc-3st4qy-0 lbsGSv'}).getText()\n    descripta=descripta.replace('Description','Description: ')\n    descripta=descripta.split('More technical information')[0]#sometimes occurs\n\n\n    #get table\n    table = soup.find_all('table')\n\n    tdAll=[]\n    nomsAll=[]\n    accepted_strings={'Density','Elastic modulus','Elongation','Tensile strength','Yield strength'}\n    for ta in table:\n    #     print('-------------------\\n',ta.text[0:30])\n        tatr=ta.find_all('tr')\n        textdegC=\"°C\"\n        for trr in tatr:\n    #         print(trr.text[0:30])\n            tatrtd=trr.find_all('td')\n            try:\n                textaStartRow=tatrtd[0].text\n                \n                if textaStartRow==\"Density\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if 'g/cm' in tatrtd[1].p.text:\n                        tdAll.append(tatrtd[1].p.text)\n                    elif 'g/cm' in tatrtd[2].p.text:\n                        tdAll.append(tatrtd[2].p.text)\n                        \n                elif textaStartRow==\"Elastic modulus\":\n                    nomsAll.append(textaStartRow)\n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                    \n                elif textaStartRow==\"Elongation\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                    \n                elif textaStartRow==\"Charpy impact energy, V-notch\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                        \n                elif textaStartRow==\"Tensile strength\":\n                    nomsAll.append(textaStartRow)\n                   \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n                        \n                elif textaStartRow==\"Yield strength\":\n                    nomsAll.append(textaStartRow)\n                    \n                    if \"textdegC\" in tatrtd[1].text:#if has deg C\n                        tdAll.append(tatrtd[2].p.text)\n                    elif not tatrtd[1].text:\n                        tdAll.append(tatrtd[2].p.text)\n                    else:\n                        tdAll.append(tatrtd[1].p.text)\n        \n            except:\n                \n                pass\n            \n     #Chemical composition\n    tableComp=soup.find('p',text='Chemical properties')#know it is below a paragraph with title Chemical Properties \n    try:\n        taatta=tableComp.next_sibling\n        trComp=taatta.find_all('tr')\n        compPC=[]\n        compID=[]\n        for trr in trComp:\n            try:\n                tdd=trr.find_all('td')\n                nomsAll.append(tdd[0].text)\n                tdAll.append(tdd[1].p.text)\n            except:\n                pass\n    except:\n        pass\n    \n     #if we want to\n    dff=pd.DataFrame(tdAll).transpose()\n    print(nomsAll,tdAll)\n    dff.columns=nomsAll\n    \n    dff['Description']=descripta\n    dff.insert(0, 'Alloy', titla)\n    \n    return dff\n\n\ndfOUT=innerPage(browser)\n\n#and do some cleaning of data\ndf = cleanDFdatFunc(dfOUT)\n\n\n\n\nLook at the data\n\n#hide\ndf = pd.read_csv(\"C:/Users/44781/pyproj/JobScraping/steel_sheet_Comb_Clean\")\ndf.drop(columns=['Unnamed: 0'],inplace=True)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Alloy\n      Description\n      Elastic modulus\n      Elongation\n      Charpy impact energy, V-notch\n      Tensile strength\n      Yield strength\n      Carbon\n      Chromium\n      Copper\n      ...\n      Zirconium\n      Cobalt\n      Tungsten\n      Antimony\n      Arsenic\n      Bismuth\n      Calcium\n      Lead\n      Tin\n      Iron\n    \n  \n  \n    \n      0\n      VDM® Alloy 926\n      Description: 1.4529 (X1NiCrMoCuN25-20-7) is an...\n      193.0\n      0.0\n      0\n      650.0\n      0.0\n      0.020\n      20.5\n      1.00\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      45.240\n    \n    \n      1\n      1.4507 / X2CrNiMoCuN25-6-3\n      Description: The material 1.4507 is a duplex s...\n      200.0\n      0.0\n      0\n      800.0\n      0.0\n      0.030\n      25.0\n      1.75\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      59.715\n    \n    \n      2\n      1.4529 / X1NiCrMoCuN25-20-7\n      Description: The material 1.4529 is an austeni...\n      195.0\n      0.0\n      0\n      750.0\n      0.0\n      0.020\n      20.0\n      1.00\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      45.740\n    \n    \n      3\n      1.4521 / X2CrMoTi18-2\n      Description: The material 1.4521 is a ferritic...\n      220.0\n      0.0\n      0\n      550.0\n      0.0\n      0.025\n      18.5\n      0.00\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      76.440\n    \n    \n      4\n      DIN 17103 Grade TStE 285 normalized or normali...\n      Description: The fine grained steel TStE 285 i...\n      217.0\n      24.0\n      0\n      420.0\n      255.0\n      0.160\n      0.3\n      0.20\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      97.485\n    \n  \n\n5 rows × 32 columns\n\n\n\n\nimport matplotlib.pyplot as plt\ncoluse='Tensile strength'\ncoluse2='Elongation'\n\ndf_=df[df[coluse]>0]\ndf_=df_[df_[coluse2]>0]\nplt.scatter(x=df_[coluse2],y=df_[coluse])\n\nplt.xlabel(coluse2 +'%')\nplt.ylabel(coluse +' MPa')\nplt.grid('on')\n\n\n\n\n\n\nDo some Quick Machine Learning\n\nX=composition to predict Y=Elongation or Yield strength or Tensile strength\nUsed RandomForestRegressor from scikit learn https://scikit-learn.org/stable/\n\n30% test 70% to train\n\nResults from test data when trained on train data\n\nMAE: 2.7%\nTensile strength MAE: 74 Mpa\nYield strength MAE: 84 MPa"
  },
  {
    "objectID": "posts/2021-12-01-GolfPos1FastAI.html#introduction",
    "href": "posts/2021-12-01-GolfPos1FastAI.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nThis is a first step in a project to analyse golf swings.\nIn this first step I try to identify different parts of the body and golf equipment during the golf swing. This step is of limited success for overall analysis but the steps used are useful for the lessons learnt.\nThis work uses deep learning to identify locations (vectors) on images and fitting by regression.\nIn this step I will use a dataSet found at  Git Hub GolfSwing and the paper of the work https://arxiv.org/abs/1903.06528.\nWhat this dataset/paper does is split the golf swing into a number of sequences based on the position of the body and golf club, e.g. start, golf club parallel to ground, striking the ball etc. We will call these the golf positions. These positions are shown below.\n\n\n\nvia GIPHY\n\n\nThe dataset includes a series of videos that have been characterised based on the different swing sequences.\n\nSteps in this page\n\nDownload the video dataset and the details of the frames of the different positions\nCreate images at the different positions from the videos\nClassify points on the images and a file for each image of these\nUpload data to GitHub and download on notebook for analysis\nUse deep learning to identify the positions on the images"
  },
  {
    "objectID": "posts/2021-12-01-GolfPos1FastAI.html#use-the-video-analysis-dataset-to-create-images-of-golf-swings",
    "href": "posts/2021-12-01-GolfPos1FastAI.html#use-the-video-analysis-dataset-to-create-images-of-golf-swings",
    "title": "ThomasHSimm",
    "section": "Use the video analysis dataset to create images of golf swings",
    "text": "Use the video analysis dataset to create images of golf swings\nFirst I cloned the directory (https://github.com/wmcnally/golfdb) onto my local PC. I then need to identify which videos to use- I want the ones behind the golfer and preferably of lower frame rate.\nBelow are the names of the videos I selected\n\nimport numpy as np\nimport os\n\nuseVids=[1,3,5,7,13,24,43,46,48,71,77,81,83,89,93,242,681,1060]\nnp.shape(useVids)\n\n(18,)\n\n\nI now want to find the frames in each video that represent the selected positions.\nThese exist in a ‘.pkl’ file. So we open the file and then select the videos (rows) we want to use.\n\nimport pandas as pd\nimport pickle\n\nfile_path= cda + \"\\data\\\\golfDB.pkl\"\n\n\ndata = pickle.load(open(file_path,\"rb\"))\naa=[]\ni=0\nfor ii in useVids:\n    if i==0:\n        aa=data[ii==data.id]\n        \n    else:\n        aa=aa.append(data[ii==data.id])\n       \n    i=i+1\naa.reset_index(drop=True,inplace=True)\naa.tail()\n\n\nIn the DataFrame (aa) the details we want are just the ‘events’ so we know what frames to save as images from the videos\nFirst we create a function that takes a video location and details of the frames (or the selected golf positions) and then creates a new folder containing images of those frames.\nThis uses the library cv2 and a secondary check to normalise the positions if it is different from that given (this was useful in earlier versions but later ones the frame number matched that given by the aa dataFrame).\nThe function works by finding a frame rate then stepping through the video by adding the time per frame after each step. If the frame is at a position given by the input (from aa) it is saved as an image.\n\ndef createImages(fila,pos):\n    ''' \n    Given a video file location (fila) it will save as images to a folder\n    Given positions in video (pos) these images from the video are saved\n    pos is created based on positions of swings\n    '''\n    import cv2\n    import numpy as np\n    import os\n    \n    # create a video capture object\n    cap = cv2.VideoCapture(fila)\n    \n    # get details of the video clip\n    duration = cap.get(cv2.CAP_PROP_POS_MSEC)\n    \n    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    duration_seconds = frame_count / fps\n    print('duration is ',duration,'. frame_count is ',frame_count,'. fps is ',fps,'. duration sec is',duration_seconds)\n    \n    #alter pos based on frame count\n    posb4=pos\n    pos=(pos/(np.max(pos)/frame_count))\n    pos=np.array([int(nn) for nn in pos])\n    pos=pos[1:-2]#ignore first value and last two\n    \n    \n    # create a folder if it doesn't exist\n    folder = fila.split('\\\\')[-1].split('.')[0]\n    folder = '_images'+folder\n    print(folder)\n    try:\n        os.mkdir(folder)\n    except:\n        pass\n\n    \n    vidcap = cap\n    \n    # this function creates an image from part of a video and \n    # saves as a JPG file\n    def getFrame(sec,go):\n        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec)\n        hasFrames,image = vidcap.read()\n        if hasFrames and go:\n            cv2.imwrite(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)     # save frame as JPG file\n        return hasFrames\n    \n    # goes through the video clip and steps through based on frame rate\n    sec = 0\n    frameRate = 1000/fps \n    count=1\n    go=0\n    success = True\n    while success:\n        count = count + 1\n        sec = sec + frameRate\n        #only saves images if at positions in pos\n        if count in pos:\n            go=1\n        else:\n            go=0\n        success = getFrame(sec,go)\n\n    print(\"{} images are extacted in {}.\".format(count,folder))\n\nAnd below I call the script for the videos I selected\n\nimport cv2\nfila = cda + '\\\\data\\\\videos_160\\\\'\nfor ii,aai in enumerate(aa.id):\n    fold = fila + str(aai)+'.mp4'\n    pos=aa.iloc[ii,7]\n    pos=pos-pos[0]\n    if ii>1:\n        cII(fold,pos)\n        cap = createImages.VideoCapture(fold)\n\nSo now we have a series of folders for each video with images given by the selected positions"
  },
  {
    "objectID": "posts/2021-12-01-GolfPos1FastAI.html#manually-classify-points-on-the-images",
    "href": "posts/2021-12-01-GolfPos1FastAI.html#manually-classify-points-on-the-images",
    "title": "ThomasHSimm",
    "section": "Manually classify points on the images",
    "text": "Manually classify points on the images\nTo be able to perform analysis on the images they first need to be labelled.\nTo do this I decided to take the manual approach and classify the images myself. I decided to choose the following regions in each image: - The ball - The end of the golf club (clubhead) - The back wrist - the back elbow - the top of the head\nThis is done using the follwing function\n\ndef imDo(im):\n    \n    fig=plt.figure(figsize=(20, 15))\n    plt.imshow(im)\n\n    def tellme(s):\n        print(s)\n        plt.title(s, fontsize=16)\n\n    tellme('You will define golf swing, click to begin')\n\n    plt.waitforbuttonpress()\n\n    while True:\n        pts = []\n        while len(pts) < 5:\n            tellme('Select golf ball-golf club- wrist- elbow- head with mouse')\n            pts = np.asarray(plt.ginput(5, timeout=-1))\n            if len(pts) < 5:\n                tellme('Too few points, starting over')\n                time.sleep(1)  # Wait a second\n        \n        ph = plt.plot(pts[:, 0], pts[:, 1], marker='x',markersize=20,markeredgewidth=3)\n\n        tellme('Happy? Key click for yes, mouse click for no')\n\n        if plt.waitforbuttonpress():\n            break\n    plt.close(fig)\n    return pts\n\nBefore we can call this function we want to make sure the image appears as a new window\nAlso some imports\n\nimport fastbook\n\nfrom fastbook import *\nfrom fastai.vision.all import *\nimport matplotlib\n\ncda = os.getcwd()\n\nmatplotlib.use('TKAgg')\n\nNow for each image file created, the script below runs imDo which plots the image then asks the user to select 5 points on the image for classification.\nthese points are then save as txt file with the same name as the image file to be used later in modeling\n\n\nfoldOuta=cda+'//_dataSel//'\nlsa = os.listdir(foldOuta)\nlsa\nptsALL=[]\nfor ii,folds in enumerate(lsa):\n    if ii>0:\n        print(folds)\n        img_files = get_image_files(foldOuta+folds)\n        for fils in img_files:\n            im = PILImage.create(fils)\n            pts=imDo(im)\n            ptsALL.append(pts)\n            fnom=str(fils).split('\\\\')[-1].split('.')[0]\n            \n            np.savetxt(foldOuta+folds+'\\\\'+fnom+'.txt',pts)"
  },
  {
    "objectID": "posts/2021-12-01-GolfPos1FastAI.html#upload-data-for-use-in-modeling",
    "href": "posts/2021-12-01-GolfPos1FastAI.html#upload-data-for-use-in-modeling",
    "title": "ThomasHSimm",
    "section": "Upload data for use in modeling",
    "text": "Upload data for use in modeling\nFastai has a function called untar_data that prepares images in a .tgz folder ready to use for analysis.\nA tgz file can be made by a Python script, but all the ones I tried produced an error, so instead I used\nTo create a tar file see https://opensource.com/article/17/7/how-unzip-targz-file\nOpen up a terminal go to the folder that contains the folder wanting to compress and then tar with the command line\ntar –create –verbose –file GC.tgz GolfComb\nI have then uploaded it to GitHub. Go to the file on Github open it and right click on ‘view raw’ and select copy link."
  },
  {
    "objectID": "posts/2021-12-01-GolfPos1FastAI.html#model-the-data",
    "href": "posts/2021-12-01-GolfPos1FastAI.html#model-the-data",
    "title": "ThomasHSimm",
    "section": "Model the data",
    "text": "Model the data\nThe rest needs to be done with a GPU. I have done this with https://colab.research.google.com/ (free time is limited but details not published) and the code tab for a notebook on https://www.kaggle.com/ (36 h per month for free)\nFirst import the fastai stuff\n\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\nfrom fastbook import *\n\n\nfrom fastai.vision.all import *\n\nimport os\nimport re\nimport numpy\n\nuntar the data and set the path\n\nurl='https://github.com/ThomasHSimm/GolfSwingTSimm/blob/main/_dataSel/GC.tgz?raw=true'\n\npath = untar_data(url)\n\n\nPath.BASE_PATH = path\n\nHave a look at the data\n\n(path/'Test').ls()\n\n\nA function to classify the points on the image\nLoads the text file for each image and returns a TensorPoint object of points on the image\n\ndef get_pointa_img(fileo):\n     \n    txtfile = str(fileo)[0:-4] + '.txt'\n    # print(txtfile)\n    pts=np.loadtxt(txtfile)\n    pp=pts[-1,:]\n    # print(pp)\n    return TensorPoint(pp)\n\nCreate a DataBlock\nThe DataBlock is the foundation of the model. It needs to know - the location of the images, - the label for the images (points on images in this case) - separation of data into test and validation sets (done automatically if not specified) - the type of data used blocks=(ImageBlock, PointBlock) - any resizing of images - any transforms (Data Augmentation)\n\nitem_tfms = [Resize(448, method='squish')]\nbiwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    item_tfms=item_tfms,\n    get_y=get_pointa_img,\n    batch_tfms=[*aug_transforms(size=224, min_scale=0.75),\n                               Normalize.from_stats(*imagenet_stats)])\n\nNow create a DataLoaders object which has the path of the data and the batch size (here 30)\nBatch size is important to specify to avoid memory issues\n\ndls = biwi.dataloaders(path,30)\n\nNow create the learner\nPass it the dataLoaders, we’re doing transfer learning from resnet50 (imageNet trained model), what metrics we’ll use for loss, and the range in y values we want\n\nlearn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.02),y_range=(-1,1))\n\nHave a look at the data. Can see the transforms\n\ndls.show_batch(max_n=8, figsize=(12,12))\n\n\n\n\nFind the best learning rate\n\n\nlearn.lr_find()\n\n\nTo fit the model we have a few options:\n\nlearn.fit(10,lr=4e-3)\nlearn.fit_one_cycle()\nlearn.fine_tune(10, base_lr=1e-3, freeze_epochs=7)\nlearn.fine_tune(15, lr)\n\nFastAI adds an extra 2 layers on the end of neural network these can then be fitted using fine_tune. It is recommended to do a few fits frozen before unfreezing. This is normally the best option for transfer learning.\nBut the other ones can be used. In general fit can be more unstable and lead to bigger losses, but can be useful if fine_tune is not bringing losses down.\nhttps://forums.fast.ai/t/fine-tune-vs-fit-one-cycle/66029/6\nfit_one_cycle = New Model\nfine_tuning = with Transfer Learning?\n\nI’d say yes but with a very strong but, only because it’s easy to fall into a trap that way. fine_tuning is geared towards transfer learning specifically, but you can also just do fit_one_cycle as well! (Or flat_cos).\n\nFor beginners it’s a great starting fit function (and advanced too), but also don’t forget that you can then build on what that function is doing. For instance, I wonder how modifying/adapting that function for Ranger/flat_cos would need to change!\n\nlearn.fine_tune(10, base_lr=1e-3, freeze_epochs=7)\n\n\n\nlearn.lr_find()\n\n\nSome more fitting, reducing the learning rate after steps\n\nlearn.fit(20,lr=1e-4)\n\n\nSome more fitting\nMixing fit with fine_tune and reducing learning rate seems to work best for reducing loss\nLoss here is:\ntrain_loss  valid_loss\n\n0.054042    0.008305"
  },
  {
    "objectID": "posts/2021-12-01-GolfPos1FastAI.html#results",
    "href": "posts/2021-12-01-GolfPos1FastAI.html#results",
    "title": "ThomasHSimm",
    "section": "Results",
    "text": "Results\nLook at the results, pretty good for ~10 mins of 81 images of learning although doesn’t always get the top of the head.\n\nlearn.show_results()\n\n\n\n#save the model\nlearn.export(fname='headTry1.pkl')\n\nHowever, when this is generalised to other points, such as hands and clubhead, that are less static the results are poor.\nPresumably a combination of the low resolution of the images making it difficult to identify features and the lack of images.\n\nIncreasing the res of the images/videos improves the classification considerably.\nBut still not quite there, probably needs more labelling\ntrain_loss     valid_loss\n0.030079       0.031188"
  },
  {
    "objectID": "posts/2021-12-16-WorkingWithVideos.html#intoduction",
    "href": "posts/2021-12-16-WorkingWithVideos.html#intoduction",
    "title": "ThomasHSimm",
    "section": "Intoduction",
    "text": "Intoduction\nSome bits of python code to use videos\n\n#hide\nloca='C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\GolfSwingTSimm\\\\data\\\\golfDB.pkl'"
  },
  {
    "objectID": "posts/2021-12-16-WorkingWithVideos.html#some-imports",
    "href": "posts/2021-12-16-WorkingWithVideos.html#some-imports",
    "title": "ThomasHSimm",
    "section": "Some imports",
    "text": "Some imports\n\nimport pandas as pd\nimport os\nimport cv2\nimport numpy as np\n\ndf = pd.read_pickle(loca)\n\nidUSE = 6\n\ndf1=df.loc[idUSE]"
  },
  {
    "objectID": "posts/2021-12-16-WorkingWithVideos.html#youtube-videos",
    "href": "posts/2021-12-16-WorkingWithVideos.html#youtube-videos",
    "title": "ThomasHSimm",
    "section": "Youtube videos",
    "text": "Youtube videos\nCan have various issues so check https://pytube.io/en/latest/user/install.html if issues in use.\nI used !pip install pytube then after a week I was getting errors. So in terminal I did\n!pip install pytube then clone directory\ngit clone git://github.com/pytube/pytube.git and finally install\ncd pytube python -m pip install .\nImport the module, and here I’ll use the golf dataset from another post\n\nfrom pytube import YouTube\n\nytID=df1['youtube_id']\nyt = YouTube('http://youtube.com/watch?v='+ytID)\n\nThe youtube object contains several videos in different formats.\n\n#collapse-output\nyt.streams\n\n[<Stream: itag=\"17\" mime_type=\"video/3gpp\" res=\"144p\" fps=\"7fps\" vcodec=\"mp4v.20.3\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">]\n\n\nWe can then filter the results based on criteria. By running yt.streams.filter?? we can see more on the code, as shown below\n\nSignature:\nyt.streams.filter(\n    fps=None,\n    res=None,\n    resolution=None,\n    mime_type=None,\n    type=None,\n    subtype=None,\n    file_extension=None,\n    abr=None,\n    bitrate=None,\n    video_codec=None,\n    audio_codec=None,\n    only_audio=None,\n    only_video=None,\n    progressive=None,\n    adaptive=None,\n    is_dash=None,\n    custom_filter_functions=None,\n)\n\n\nstreams= yt.streams.filter(file_extension='mp4',res='360p')\nstreams\n\n[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">]\n\n\nDownload the stream\n\nstreams.first().download(filename=ytID+'.mp4')\n\n'C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\THS_website\\\\_notebooks\\\\iPuVhnI8pJU.mp4'"
  },
  {
    "objectID": "posts/2021-12-16-WorkingWithVideos.html#video-player",
    "href": "posts/2021-12-16-WorkingWithVideos.html#video-player",
    "title": "ThomasHSimm",
    "section": "Video Player",
    "text": "Video Player\nTo play the videos I’ll be using VLC. There can be some issues with installing so I used the exe file from here https://get.videolan.org/vlc/3.0.11/win64/vlc-3.0.11-win64.exe\nAnother fix to install issues is inserting a line like os.add_dll_directory(\"Location\\anaconda3\\\\Lib\\\\site-packages\") into the script\nMore details of using VLC with Python can be found here https://bigl.es/tooling-tuesday-using-vlc-with-python/\nImporting vlc and creating a media object and then playing it.\n\nimport vlc\n\nvidLoc=ytID+'.mp4'\n\nmedia = vlc.MediaPlayer(vidLoc)\n\nmedia.play()\n\n0\n\n\n\n.play opens a player as shown above. Note there is no pause/play/rewind buttons and the player cannot be closed. The only way to close is to use the command media.stop() or restart the kernel\n\nmedia.stop()\n\nTo make it more like a standard video player the following can be used:\n\nmedia.play() to play\nmedia.pause() to pause\nmedia.set_rate(3) to increase speed of video\nmedia.get_time() and media.set_time(5) to get and set the time of video\nmedia.stop() to close the video\n\nIntsead of doing these on the command line it makes sense to have them as button presses.\nI’ll use easygui here as it’s quite easy and I’m not too bothered about the aesthetics or functionality. Because easygui is a bit clunky. https://bigl.es/tooling-tuesday-easygui/\nSo to use create a easygui buttonbox with different features to control the video. Once clicked the button will then close (can’t keep same button open with this) and open again.\n\nimport easygui \n\n\nwhile True:\n    choice = easygui.buttonbox(title=\"@Golf Media Player\",\n       choices=[\"Play\",\"<<\",\"<<<\",\">>\",\">>>\",\"Pause\",\"Stop\"])\n\n    if choice == \"Play\":\n        media.set_rate(1)\n        media.play()\n    elif choice == \"Pause\":\n        media.pause()\n    elif choice ==\">>\":\n        media.set_rate(2)\n    elif choice==\">>>\":\n        media.set_rate(4)\n    elif choice==\"<<\":\n        timo=media.get_time()\n        timo=timo-2.5*1000\n        if timo<0:\n            timo=0\n        media.set_time(timo)\n    elif choice==\"<<<\":\n        timo=media.get_time()\n        timo=timo-5*1000\n        if timo<0:\n            timo=0\n        media.set_time(timo)\n    else:\n        time_use = media.get_time()/1000\n        print('the time is {}'.format(time_use))\n        media.stop()\n        break\n\nthe time is 15.652"
  },
  {
    "objectID": "posts/2021-12-16-WorkingWithVideos.html#extracting-images-from-the-video",
    "href": "posts/2021-12-16-WorkingWithVideos.html#extracting-images-from-the-video",
    "title": "ThomasHSimm",
    "section": "Extracting images from the video",
    "text": "Extracting images from the video\nTo work with a video it is most often easier to convert it to an image.\nTo do this I’ll use cv2 https://pypi.org/project/opencv-python/\nFirst we create a cv2 object of the video with cap = cv2.VideoCapture(vidLoc) then success, image = cap.read() to get images as we scroll through the frames, as shown below.\n\n#collapse-output\ncap = cv2.VideoCapture(vidLoc)\n\nsuccess, image = cap.read()\nwhile success:\n    success, image = cap.read()\n    print(success)\n\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\nSome useful features of the cap object that will be used are:\n\ncap.get(cv2.CAP_PROP_POS_MSEC) the duration of the video\ncap.get(cv2.CAP_PROP_FRAME_COUNT) the frame count\nframe_count / fps the duration in seconds (the previous two divided)\ncv2.CAP_PROP_FRAME_WIDTH) frame width\ncv2.CAP_PROP_FRAME_HEIGHT) frame height\ncv2.copyMakeBorder() to create an image object to save and select which area of the video to save\ncv2.imwrite(fnom, img) to save the frame as an image\n\nWe could instead use other ways as shown https://learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/ to extract images but I’ll use the above\nThe below is modified from https://github.com/wmcnally/golfdb\nIt creates images at a given frame where the video is cropped based on the variable bbox (which is between 0 and 1)\nNote also dim=600 which adjusts the size of the output image\n\n         \ndef getImages(cap,bbox,frame_use):\n    \n    x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * bbox[0])\n    y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * bbox[1])\n    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * bbox[2])\n    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * bbox[3])\n    \n    count = 0\n    success, image = cap.read()\n    while success:\n        count += 1\n        \n        if abs(count-frame_use)==0:\n                dim=600\n                crop_img = image[y:y + h, x:x + w]\n                crop_size = crop_img.shape[:2]\n                ratio = dim / max(crop_size)\n                new_size = tuple([int(x*ratio) for x in crop_size])\n                resized = cv2.resize(crop_img, (new_size[1], new_size[0]))\n                delta_w = dim - new_size[1]\n                delta_h = dim - new_size[0]\n                top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n                left, right = delta_w // 2, delta_w - (delta_w // 2)\n                b_img = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT,\n                                           value=[0.406*255, 0.456*255, 0.485*255])  # ImageNet means (BGR)\n                cv2.imwrite(os.path.join(ytID+str(count)+\".jpg\"),b_img)\n                \n        elif count > frame_use:\n            break\n        success, image = cap.read()\n\n        \n\nAnd to run the above function\n\ncap = cv2.VideoCapture(vidLoc)\ngetImages(cap,df1['bbox'],100)\n\n\nevent_names = {\n    0: 'Address',\n    1: 'Toe-up',\n    2: 'Mid-backswing (arm parallel)',\n    3: 'Top',\n    4: 'Mid-downswing (arm parallel)',\n    5: 'Impact',\n    6: 'Mid-follow-through (shaft parallel)',\n    7: 'Finish'\n}\n_, img = cap.read()\n# cv2.imshow(event_names[0], img)\n\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(img)\n\n<matplotlib.image.AxesImage at 0x23f1d3cc7f0>\n\n\n\n\n\n\nbbox\n\narray([0.1453125 , 0.00138889, 0.46796875, 0.99930556])"
  },
  {
    "objectID": "posts/2022-02-02-PythonBasics.html#print",
    "href": "posts/2022-02-02-PythonBasics.html#print",
    "title": "ThomasHSimm",
    "section": "Print",
    "text": "Print\n\n# to so many decimal places\n\nx=30.5557889\n\nprint('{:.5f}'.format(x))\n\n30.55579\n\n\n\n# add additional characters to string\n\nwidth = 20\nprint('HackerRank'.ljust(width,'-'))#or rjust\n\nHackerRank----------\n\n\n\nwidth = 20\nprint('HackerRank'.center(width,'-'))\n\n-----HackerRank-----\n\n\nhttps://docs.python.org/3/library/stdtypes.html#string-methods\nConversion……………………… Meaning\nd………………………………. Signed integer decimal.\ni………………………………. Signed integer decimal.\no………………………………. Signed octal value.\nu………………………………. Obsolete type – it is identical to ‘d’.\nx………………………………. Signed hexadecimal (lowercase).\nX………………………………. Signed hexadecimal (uppercase).\ne ………………………………. Floating point exponential format (lowercase).\nE………………………………. Floating point exponential format (uppercase).\nf………………………………. Floating point decimal format.\nF………………………………. Floating point decimal format.\ng………………………………. Floating point format. Uses lowercase exponential format if exponent is less than -4 or not less than precision, decimal format otherwise.\nG ………………………………. Floating point format. Uses uppercase exponential format if exponent is less than -4 or not less than precision, decimal format otherwise.\nc………………………………. Single character (accepts integer or single character string).\nr………………………………. String (converts any Python object using repr()).\ns………………………………. String (converts any Python object using str()).\na………………………………. String (converts any Python object using ascii()).\n%………………………………. No argument is converted, results in a ‘%’ character in the result."
  },
  {
    "objectID": "posts/2022-02-02-PythonBasics.html#lists",
    "href": "posts/2022-02-02-PythonBasics.html#lists",
    "title": "ThomasHSimm",
    "section": "Lists",
    "text": "Lists\n\nNew List\nCreate a list with list(XX)\n\na='1 2 3 4 5 6 7'\nlista = list(a)\nprint(lista)\n\n['1', ' ', '2', ' ', '3', ' ', '4', ' ', '5', ' ', '6', ' ', '7']\n\n\n\n\nCopy\nlist.copy\n\nlista =a.split(' ')\nlista=lista[0:3]\nprint('Original a=\\n',lista)\nlistb=lista\nlistc=lista.copy()\nlistd=lista[:]\n\nlistb[1]='po'\n\nprint('list b, where b=a and b[1] modified, b=\\n',listb,\n    '\\nJust using equals b=a after mods, a=\\n',lista,\n      '\\n Using a copy c=a.copy(), c=\\n',listc,\n      '\\n Using d=a[:] to create a copy, d=\\n',listd)\n\nOriginal a=\n ['1', '2', '3']\nlist b, where b=a and b[1] modified, b=\n ['1', 'po', '3'] \nJust using equals b=a after mods, a=\n ['1', 'po', '3'] \n Using a copy c=a.copy(), c=\n ['1', '2', '3'] \n Using d=a[:] to create a copy, d=\n ['1', '2', '3']\n\n\n\n\nAppend\nlist.append(x), add x to end of a list\n\nprint(lista)\nlista.append('ok')\nprint(lista)\n\n['1', 'po', '3']\n['1', 'po', '3', 'ok']\n\n\n\n\nInsert\nlista.insert(i,x) insert x at position i\n\nlista.insert(2,'two')\nprint(lista)\n\n['1', 'po', 'two', '3', 'ok']\n\n\n\n\nRemove\nlista.remove(x) Remove the first item from the list whose value is equal to x.\n\nlista.remove('two')\nprint(lista)\n\n['1', 'po', '3', 'ok']\n\n\n\n\nPop\nlista.pop([i]) Remove the item at the given position in the list, and return it\nlist.popleft at left\n\nprint(lista.pop(1))\n\npo\n\n\n\n\nRemove\nlist.clear() Remove all items from the list. Equivalent to del a[:].\n\nprint(lista.clear())\nprint(lista)\n\nNone\n[]\n\n\n\n\nIndex\nlist.index(x,i) Return position of x within list starting at position i\n\nlistc.append('1')\nprint(listc)\nprint(listc.index('1'),2)\n\n['1', '2', '3', '1', '1', '1']\n0 2\n\n\n\n\nCount\nlista.count(x) Return the number of times x appears in the list.\n\nprint(listc.count('1'))\n\n4\n\n\n\n\nSort\nlista.sort(*, key=None, reverse=False) Sort the items of the list in place (the arguments can be used for sort customization, see sorted() (https://docs.python.org/3/library/functions.html#sorted) for their explanation).\n\nlistc.sort()\nprint(listc)\n\n['1', '1', '1', '1', '2', '3']\n\n\n\n\nReverse\nlista.reverse() Reverse the elements of the list in place.\n\n\nDel\ndel lista[0] remove an item from a list given its index instead of its value\n\nprint(listc)\ndel listc[2]\nprint(listc)\n\n['1', '1', '1', '1', '2', '3']\n['1', '1', '1', '2', '3']\n\n\n\n\nComprehension\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition.\n\nsquares=[]\nfor x in range(10):\n    squares.append(x**2)\nprint(squares)\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n\n# the comprehension version\n\nprint([x**2 for x in range(10)])\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\nA list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for or if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if clauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n\n[(x,y) for x in [1,2,3] for y in [3, 1, 4] if x!=y]\n\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\n\n\n\nvec = [[1,2,3], [4,5,6], [7,8,9]]\n[num for elem in vec for num in elem]\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nmatrix=[[1,2,3,4],\n       [5,6,7,8],\n       [9,19,11,12]]\n[[col[i] for col in matrix] for i in range(4)]\n\n[[1, 5, 9], [2, 6, 19], [3, 7, 11], [4, 8, 12]]\n\n\n\n\nList to string\nConvert a list to a string with \"\".join(lista)\n\nstra = \"\".join(lista)\nprint(stra,'-',stra[4:])\n\n1po3 -"
  },
  {
    "objectID": "posts/2022-02-02-PythonBasics.html#strings",
    "href": "posts/2022-02-02-PythonBasics.html#strings",
    "title": "ThomasHSimm",
    "section": "Strings",
    "text": "Strings\nhttps://docs.python.org/3/library/stdtypes.html#string-methods\n\nSplit\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then there is no limit on the number of splits (all possible splits are made).\n\nstra='xsxhu csjoaij jsaijaio j dijoi'\nstra1=stra.split()\nprint(stra1)\nstra1=stra.split('j',maxsplit=2)\nprint(stra1)\n\n['xsxhu', 'csjoaij', 'jsaijaio', 'j', 'dijoi']\n['xsxhu cs', 'oai', ' jsaijaio j dijoi']\n\n\n\n\nStrip\nReturn a copy of the string with the leading and trailing characters removed.\n\n'   spacious   '.strip()\n\n'spacious'\n\n\nstr.isalnum()\nThis method checks if all the characters of a string are alphanumeric (a-z, A-Z and 0-9).\n\nstra='abcD1'\nprint(stra,stra.isalnum())\nstra='abcD1#'\nprint(stra,stra.isalnum())\n\nabcD1 True\nabcD1# False\n\n\nstr.isalpha()\nThis method checks if all the characters of a string are alphabetical (a-z and A-Z).\n\nstra='abcD1'\nprint(stra,stra.isalpha())\nstra='abcD'\nprint(stra,stra.isalpha())\n\nstr.isdigit()\nThis method checks if all the characters of a string are digits (0-9)\n\nstra='abcD1'\nprint(stra,stra.isdigit())\nstra='190'\nprint(stra,stra.isdigit())\n\nstr.islower()\nThis method checks if all the characters of a string are lowercase characters (a-z).\n\nstra='abcD1'\nprint(stra,stra.islower())\nstra='190'\nprint(stra,stra.islower())\n\nstr.lower or str.upper change whether upper or lower case\n\nstra='abcD1'\nprint(stra,stra.lower(),stra.upper())\n\nabcD1 abcd1 ABCD1\n\n\ncaptialize the first character\n\nprint(stra.capitalize())\n\nAbcd1\n\n\nFind the position of a substring within a string\nstring.find(stringIN) scan left to right\nstring.rfind(stringIN) scan right to left\n\nstra='ABCDCDC'\nstraa='BCD'\nstra.find('CD'),stra.rfind('CD')\n\n(2, 4)"
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#overview",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\nIn part 1 (https://thomashsimm.com/2021/08/04/Swansea-House-Price-Report.html) house price predictions were done using Census regions and information about the locations.\nWhereas, in this part the main focus is on using property sales data to obtain price predictions."
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#import-modules-and-prepare-the-data",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#import-modules-and-prepare-the-data",
    "title": "ThomasHSimm",
    "section": "Import modules and prepare the data",
    "text": "Import modules and prepare the data\n\nSome imports\n\nimport os\nimport requests\nimport wget\nimport pandas as pd\n\nfrom fastbook import *\nfrom kaggle import api\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG\n\npd.options.display.max_rows = 20\npd.options.display.max_columns = 8\n\nCreate a local path\n\npath = URLs.path('SwansProp')\nPath.BASE_PATH = path\npath\n\nPath('.')\n\n\n\nif not path.exists():\n    path.mkdir(parents=true)\n\n\n\nDownload the data\n\nGet the property sales from https://www.doogal.co.uk/PropertySalesCSV.ashx?area=\nAnd then the postcode details from https://www.doogal.co.uk/UKPostcodesCSV.ashx?Search=SA for\n\n\nlattitude and longitude\nCensus data and related data\n\nAvg income\nDeprivation index\netc\n\n\nUnique postcode starts SA1 SA2 SA3 SA4 SA5 SA6 SA7 SA8 SA9 SA10 SA11 SA12 SA13 SA80 SA99\n\ntry:\n    os.mkdir('data')\nexcept:\n    pass\n\npcodesSA=['SA1', 'SA2', 'SA3', 'SA4', 'SA5', 'SA6', 'SA7', 'SA8',\n          'SA9', 'SA10' ,'SA11', 'SA12', 'SA13', 'SA14','SA15','SA18']\n\n\n‘A’ Property Sales Data\nDownload the data\n\n\nurl='https://www.doogal.co.uk/PropertySalesCSV.ashx?area='\n\n\nfor pc in pcodesSA:\n    patha=path/'{}.csv'.format(pc)\n    wget.download(url+pc, str(patha))\n\n100% [............................................................................] 935424 / 935424\n\n\nCreate a dataframe from the downloaded csv files\n\nfor i,pc in enumerate(pcodesSA):\n    patha=path/'{}.csv'.format(pc)\n    dfTemp=pd.read_csv(str(patha))\n    \n    if i==0:\n        df=dfTemp\n        print(i)\n    else:\n        df=df.append(dfTemp)\n    print(df.shape[0])\n\ndf.reset_index(drop=True, inplace=True)\n\n0\n19432\n35015\n47639\n67896\n79210\n92148\n99680\n104480\n109669\n122570\n136404\n147937\n155697\n169021\n183674\n195094\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Date\n      Address\n      Postcode\n      Price\n      Type\n      Ownership\n      NewBuild\n    \n  \n  \n    \n      0\n      2021-10-22\n      60 Danygraig Road, Port Tennant\n      SA1 8LZ\n      192000\n      Terraced\n      Freehold\n      No\n    \n    \n      1\n      2021-10-01\n      2 Camona Drive, Maritime Quarter\n      SA1 1YJ\n      179950\n      Flat\n      Leasehold\n      No\n    \n    \n      2\n      2021-09-24\n      36 Balaclava Street, St Thomas\n      SA1 8BR\n      140000\n      Terraced\n      Freehold\n      No\n    \n    \n      3\n      2021-09-21\n      7 Abernethy Square, Maritime Quarter\n      SA1 1UH\n      133000\n      Flat\n      Leasehold\n      No\n    \n    \n      4\n      2021-09-17\n      6 Brynffordd, Townhill\n      SA1 6RA\n      176000\n      Semi-detached\n      Freehold\n      No\n    \n  \n\n\n\n\n\nimport copy\ndfOrig = copy.copy(df)\n\n\n\n‘B’ The PostCode data\nDwonload the data\n\nurl=\"https://www.doogal.co.uk/UKPostcodesCSV.ashx?Search=SA\"\npatha = path/'SA.csv'\nwget.download(url, str(patha))\n\n-1 / unknown\n\n\n'C:\\\\Users\\\\44781\\\\.fastai\\\\archive\\\\SwansProp\\\\SA (1).csv'\n\n\nhttps://www.doogal.co.uk/PostcodeCsvFields.php\n\nLatitude\nLongitude\nIntroduced\nRural/urban\nAltitude\nIndex of Multiple Deprivation\nAverage income\n\n[‘Latitude’,‘Longitude’,‘Introduced’,‘Rural/urban’,‘’Altitude’,‘Index of Multiple Deprivation’,‘Average income’]\nCreate a dataFrame from the data\n\ndfCensus=pd.read_csv(str(patha),usecols=[\"Postcode\",\"Ward Code\",\"District Code\",'Latitude','Longitude','Introduced','Rural/urban','Altitude','Index of Multiple Deprivation','Average Income'])\ndfCensus\n\n\n\n\n\n  \n    \n      \n      Postcode\n      Latitude\n      Longitude\n      District Code\n      ...\n      Rural/urban\n      Altitude\n      Index of Multiple Deprivation\n      Average Income\n    \n  \n  \n    \n      0\n      SA1 1AA\n      51.647984\n      -3.923586\n      W06000011\n      ...\n      Urban city and town\n      16.0\n      355\n      29200.0\n    \n    \n      1\n      SA1 1AB\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      2\n      SA1 1AD\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      3\n      SA1 1AE\n      51.618878\n      -3.939834\n      W06000011\n      ...\n      Urban city and town\n      10.0\n      1105\n      28600.0\n    \n    \n      4\n      SA1 1AF\n      51.619766\n      -3.939424\n      W06000011\n      ...\n      Urban city and town\n      13.0\n      36\n      28600.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      29399\n      SA99 1ZU\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29400\n      SA99 1ZW\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29401\n      SA99 1ZX\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29402\n      SA99 1ZY\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n    \n      29403\n      SA99 1ZZ\n      51.669997\n      -3.945445\n      W06000011\n      ...\n      Urban city and town\n      132.0\n      1230\n      30500.0\n    \n  \n\n29404 rows × 10 columns\n\n\n\n\n\n\nMerge the two data frames\n\ndf=pd.merge(df,dfCensus)\ndf.columns\n\nIndex(['Date', 'Address', 'Postcode', 'Price', 'Type', 'Ownership', 'NewBuild',\n       'Latitude', 'Longitude', 'District Code', 'Ward Code', 'Introduced',\n       'Rural/urban', 'Altitude', 'Index of Multiple Deprivation',\n       'Average Income'],\n      dtype='object')\n\n\n\ndf.dtypes\n\nDate                              object\nAddress                           object\nPostcode                          object\nPrice                              int64\nType                              object\nOwnership                         object\nNewBuild                          object\nLatitude                         float64\nLongitude                        float64\nDistrict Code                     object\nWard Code                         object\nIntroduced                        object\nRural/urban                       object\nAltitude                         float64\nIndex of Multiple Deprivation      int64\nAverage Income                   float64\ndtype: object\n\n\n\ndfOrig=dfOrig.iloc[df.index]"
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#modify-data-ready-for-model",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#modify-data-ready-for-model",
    "title": "ThomasHSimm",
    "section": "Modify data ready for model",
    "text": "Modify data ready for model\n\nAdd date details\nFrom date get Year, Month, Week etc\n\ndf = add_datepart(df, 'Date')\ndf.columns\n\nIndex(['Address', 'Postcode', 'Price', 'Type', 'Ownership', 'NewBuild',\n       'Latitude', 'Longitude', 'District Code', 'Ward Code', 'Introduced',\n       'Rural/urban', 'Altitude', 'Index of Multiple Deprivation',\n       'Average Income', 'Year', 'Month', 'Week', 'Day', 'Dayofweek',\n       'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n       'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'],\n      dtype='object')\n\n\n\n\nSeperate details of address out\nWant to sepaerate details of address so that\nchx='Flat 30, Henllys, Wind Street, Swansea'\ngives modAdd(chx)=('Swansea', 900, 'Henllys')\nOr\nchx='15A Bethania Road, Upper Tumble'\ngives modAdd(chx)=('Upper Tumble', 15, 'Bethania Road')\n\ndef modAdd(address):\n    import re\n\n    split1 = address.split(',')\n    if len(split1)<2:\n        split1 = address.split(' ')\n        print('####',split1 ) \n    \n    FirstLine=split1[0]\n    Region = split1[-1]\n    \n    try:\n        Region=re.search(\"[A-Za-z][A-Za-z\\s]*\",Region)[0]\n    except:\n        Region=Region\n    \n    \n    try:\n        HouseNo=re.search(\"[0-9]*\",FirstLine)\n#         print(HouseNo)\n        HouseNo =int(HouseNo[0])\n        \n    except:\n        FirstLine=split1[1]\n        HouseNo=re.search(\"[\\s0-9]*\",FirstLine)\n        try:\n            HouseNo =int(HouseNo[0])\n        except:\n            HouseNo=900\n        \n    try:    \n        Street=re.search(\"\\s[A-Za-z][A-Za-z\\s]*\",FirstLine)\n        Street=Street[0]\n        Street=Street[1:]\n    except:\n        try:\n            Street=split1[1]\n            Street=re.search(\"\\s[A-Za-z][A-Za-z\\s]*\",Street)[0]\n            Street=Street[1:]\n        except:\n            Street='NA'\n#         print(FirstLine)\n        \n#     print('Region {}\\n Number {} \\n Street {} '.format(Region,HouseNo,Street))\n\n    return Region,HouseNo,Street\n    \ndef addAdddets_df(df):\n    Street,HouseNo,Region=[],[],[]\n    for ita,oo in enumerate(df.index):\n        \n        addTemp=df.iloc[ita].Address\n        RegionTemp,HouseNoTemp,StreetTemp=modAdd(addTemp)\n        Region.append(RegionTemp)\n        HouseNo.append(HouseNoTemp)\n        Street.append(StreetTemp)\n    df.insert(1,'Street',Street)\n    df.insert(1,'HouseNo',HouseNo)    \n    df.insert(1,'Region',Region)\n    return df\n\n\ntry:\n    df.drop(columns=['Street','HouseNo','Region'],inplace=True)\nexcept:\n    pass\ndf=addAdddets_df(df)\n\n\n\nCreate train and validation sets\nDo this randomly in this case 97:3 split\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=3\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/train_idx.shape[0]\n\nSpecify which column we are fitting to\n\ndep_var = 'Price'\n\n# for this fit to the log of it\ndf[dep_var] = np.log(df[dep_var])\n\nSplit into test and validation and convert to TabularPandas\n\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\nWhat are the columns?\n\n#hide\nimport os\nimport pickle\n\ncda = 'C:\\\\Users\\\\44781\\\\Documents\\\\GitHub\\\\SwanseaProperty'\ncda = cda + '\\\\pickles\\\\'\nwith open(cda+'RFrand_to.pkl', 'rb')as f: \n    to = pickle.load(f)\n    \nwith open(cda+'RFrand_xs_final.pkl', 'rb')as f: \n    xs = pickle.load(f)\n    \nwith open(cda+'RFrand_y.pkl', 'rb')as f: \n    y = pickle.load(f)\n\n\n[ii for ii in to.all_col_names]\n\n['Address',\n 'Region',\n 'Street',\n 'Postcode',\n 'Type',\n 'Ownership',\n 'NewBuild',\n 'District Code',\n 'Ward Code',\n 'Introduced',\n 'Rural/urban',\n 'Is_month_end',\n 'Is_month_start',\n 'Is_quarter_end',\n 'Is_quarter_start',\n 'Is_year_end',\n 'Is_year_start',\n 'HouseNo',\n 'Latitude',\n 'Longitude',\n 'Altitude',\n 'Index of Multiple Deprivation',\n 'Average Income',\n 'Year',\n 'Month',\n 'Week',\n 'Day',\n 'Dayofweek',\n 'Dayofyear',\n 'Elapsed',\n 'Price']\n\n\n\n\nSome functions to fit or get results of fit\n\ndef r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n\ndef r_abs(pred,y): return round( (np.abs( np.exp(pred)-np.exp(y) ).mean()), 0)\ndef m_abs(m, xs, y): return r_abs(m.predict(xs), y)/1000\n\ndef rf(xs, y, n_estimators=400, max_samples=100_000,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)"
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#fit-the-model-and-optimise",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#fit-the-model-and-optimise",
    "title": "ThomasHSimm",
    "section": "Fit the model and optimise",
    "text": "Fit the model and optimise\nBasic model with 4 nodes\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\n\n\nm_rmse(m, xs, y),m_rmse(m, valid_xs, valid_y)\n\n(0.511491, 0.503983)\n\n\nIncrease the number of leafs, reduces the errors\n\nm = DecisionTreeRegressor(min_samples_leaf=25)\nm.fit(to.train.xs, to.train.y)\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n\n(0.338283, 0.370846)\n\n\nUsing the modified function above\n\nm = rf(xs, y)\nm_rmse(m, xs_imp, y), m_rmse(m, valid_xs_imp, valid_y)\n\n(0.287589, 0.335017)\n\n\n\nLook at which columns are important\n\ncluster_columns(xs)\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n\nfi = rf_feat_importance(m, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi[:30]);\n\n\n\nKeep ones with most importance\nReduces columns to use from 30 to 17\n\nto_keep = fi[fi.imp>0.01].cols\nlen(to_keep),len(fi.cols)\n\n(13, 30)\n\n\n\n# Get rid of the address one- is a number for each address\nto_keep=to_keep[to_keep!='Address']\n\n\nxs_imp = xs[to_keep]\nvalid_xs_imp = valid_xs[to_keep]\nm_imp = rf(xs_imp, y)\nm_rmse(m_imp, xs_imp, y), m_rmse(m_imp, valid_xs_imp, valid_y)\n\n(0.296979, 0.335829)\n\n\n\nfi2 = rf_feat_importance(m_imp, xs_imp)\n\ndef plot_fi(fi2):\n    return fi2.plot('cols', 'imp', 'barh', figsize=(10,6), legend=False)\n\nplot_fi(fi2[:30]);"
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#save-the-results",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#save-the-results",
    "title": "ThomasHSimm",
    "section": "Save the results",
    "text": "Save the results\nCombine the test and valid datasets\n\nxsAll=pd.concat([xs_imp,valid_xs_imp])\nyAll = pd.concat([y, valid_y])\n\n\nimport os\nimport pickle\n\ncda = os.getcwd()\ncda = cda + '\\\\pickles\\\\'\n\n# Saving the objects:\nwith open(cda+'RFrand_New4varB.pkl', 'wb') as f:\n    pickle.dump([m_imp, to, xsAll, yAll], f)\n\n\nnp.exp(0.335829)\n\n1.3990997582955578"
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#get-the-predictions",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#get-the-predictions",
    "title": "ThomasHSimm",
    "section": "Get the Predictions",
    "text": "Get the Predictions\nReload the data saved\n\nimport os\nimport pickle\n\nwith open(cda+'RFrand_New4varB.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n\n\nFirst need a way to convert sale date to today’s date\nFunction takes the dataFrame and changes ‘Date’ features to today’s date Taken from fastai functions\n\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    import re\n    import pandas as pd\n    import numpy as np\n    \n    def ifnone(a, b):\n        \"`b` if `a` is None else `a`\"\n        return b if a is None else a\n    \n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        \n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n            \n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    # Pandas removed `dt.week` in v1.1.10\n    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n    mask = ~field.isna()\n    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,np.nan)\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\nThe next function uses the above function to update the date details.\nThen looks up the address given so that predictions can be made. This is because address are not in xsAll2 dataFrame\n\nxsAll2.columns\n\nIndex(['Elapsed', 'Type', 'Year', 'Index of Multiple Deprivation', 'Latitude',\n       'Average Income', 'Longitude', 'Introduced', 'Postcode', 'Altitude',\n       'HouseNo', 'Street'],\n      dtype='object')\n\n\n\n# seperate columns into those related to date and those not\ncolsNoDate=[ 'Type',  'Index of Multiple Deprivation', 'Latitude',\n       'Average Income', 'Longitude', 'Introduced', 'Postcode', 'Altitude',\n       'HouseNo', 'Street']\ncolsDate=['Elapsed','Year']\n    \n\n\ndef get_predTodayNotExact(m,address,toTEMP,xs_final,y):\n    \"\"\"\n    Given model m, address, initial pd of houses to, and adjusted pd xs_final\n    output is house price prediction\n    \"\"\"\n    import copy\n\n    colsAll=xs_final.columns\n\n    #columns with dates need to remove\n    colsDate=['Elapsed','Year']\n    xsNoDate=copy.copy(xs_final.drop(columns=colsDate))\n    \n    # add date part to dataframe\n    xsNoDate['Date'] = pd.to_datetime(\"today\")\n    xsNoDate = add_datepart(xsNoDate, 'Date')\n    xs_finalTEMP=xsNoDate.loc[:,colsAll]\n\n    # each address has a unique number\n    aa=toTEMP.classes['Address']\n    # findwhich number is address give (take 1st if more than 1)\n    try:\n        ii=[ii for ii,aa1 in enumerate(aa) if aa1== address][0]\n        # 1 address can have multiple sales so we need index in dataframes\n        ii=toTEMP[toTEMP['Address']==ii].index[0]\n\n        preda = np.round( np.exp( m.predict(xs_finalTEMP.loc[ii:ii]) )/1000 ,1)\n        prev = np.round( np.exp(y.loc[ii])/1000 ,1)\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xs_finalTEMP.loc[ii:ii,'Type']][0]\n    \n    except:\n        aa=toTEMP.classes['Address']\n        aaStreet=toTEMP.classes['Street']\n        ii=[ii for ii,aa1 in enumerate(aaStreet) if aa1== Street][0]\n        xsTemp=copy.copy( xs_finalTEMP[xs_finalTEMP['Street']==ii] )\n        xsTemp.reset_index(inplace=True,drop=True)\n        # find nearest house by houseno\n        No=np.array(xsTemp['HouseNo'])\n\n        yo=(np.abs(No-HouseNo))\n        yo1=np.min(yo)\n        # get index of the nearest house\n        yo=No[yo==yo1][0]  \n\n        ii=[ii for ii,aa1 in enumerate(xsTemp.HouseNo) if aa1== yo][0]\n        xsTemp.loc[ii:ii,'HouseNo']=HouseNo\n        \n        # If want to change house type\n        \n#         xsTemp.loc[ii:ii,'Type']=2\n#         print(xsTemp.loc[ii:ii,'Type'])\n#         print(xsTemp.loc[ii:ii])\n        \n        preda = np.round( np.exp( m.predict(xsTemp.loc[ii:ii]) )/1000 ,1)[0]\n        prev=0\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xsTemp.loc[ii:ii,'Type']][0]\n        \n        \n    return preda, prev, typa\n\n\naddress='20 Malvern Terrace, Brynmill'\nget_predTodayNotExact(m2,address,to2,xsAll2,yAll2)\n\n(array([180.1]), 54.5, 'Terraced')"
  },
  {
    "objectID": "posts/2022-02-17-SwanseaHousePrices_Part2.html#summary",
    "href": "posts/2022-02-17-SwanseaHousePrices_Part2.html#summary",
    "title": "ThomasHSimm",
    "section": "Summary",
    "text": "Summary\n\ndef r_abs(pred,y): return round( (np.abs( np.exp(pred)-np.exp(y) ).mean()), 0)\ndef m_abs(m, xs, y): return r_abs(m.predict(xs), y)/1000\n\nm_abs(m2, xsAll2, yAll2)#, m_abs(m, valid_xs_final, valid_y)\n\n23.159\n\n\nThe average error in price predictions is £23,000\nWhich is comparable to values seen with regions and fairly good given the details of the houses used in the model are limited\nThis model is put into an app here https://thomashsimm.com/streamlit/randomforrests/houseprices/python/2022/02/23/SwanseaHousePriceApp.html\n\nyoutube: https://youtu.be/IGykZUeZqRA"
  },
  {
    "objectID": "posts/2022-02-23-SwanseaHousePriceApp.html#overview",
    "href": "posts/2022-02-23-SwanseaHousePriceApp.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\nThis is an app for predicting house prices in Swansea using Streamlit https://streamlit.io/\nThe app uses the following for predictions:\n\nHouse price sales (price and date)\nName of street and number\nLocation of property (Lattitude and Longitude)\nData on Census regions\n\nMore details of the prediction side of the app, using Random Forrests and neural networks, is dealt with here https://thomashsimm.com/jupyter/python/randomforests/tabulardata/sklearn/2022/02/17/SwanseaHousePrices_Part2.html.\nA video of the app is shown below or can be accessed via https://share.streamlit.io/dmaterialia/propertystreamlit/main/PropertyApp.py\nThe intention of the app is to provide a simple user interface to allow price predictions\n\nyoutube: https://youtu.be/IGykZUeZqRA"
  },
  {
    "objectID": "posts/2022-02-23-SwanseaHousePriceApp.html#the-python-script-for-the-app",
    "href": "posts/2022-02-23-SwanseaHousePriceApp.html#the-python-script-for-the-app",
    "title": "ThomasHSimm",
    "section": "The Python Script for the App",
    "text": "The Python Script for the App\n\nLoading the data\nThe following function is used to load the data.\nThe data consists of 4 parts: 1. m = the model (this is by far the biggest part in terms of data size) 1. to = a data frame object of the house data 1. xsAll = this is a form of ‘to’ used by the model (the input values of the model) 1. yAll = a form of ‘to’ the values the model is trying to predict (house price values)\nThe data is saved as a pickle file in a Jupyter Notebook, then uploaded to googledrive as filesize has to be less than 100 Mb on GitHub.\ngdown.download(url, output) downloads the data from GoogleDrive\n@st.cache(allow_output_mutation=True) This line at the top of the python file means the data is cached and don’t need to keep loading it\n\n@st.cache(allow_output_mutation=True)\ndef load_data():\n    \"\"\"\n    Loads the data\n    \"\"\"\n    import gdown\n    url = 'https://drive.google.com/uc?id=1OD2l7ynVzLlqY92gYiCx5xq32-D1wJMe'\n    output = 'one1.pkl'\n    gdown.download(url, output)\n\n    cda = os.getcwd()\n    with open('one1.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n    return m2, to2, xsAll2, yAll2\ndata_load_state = st.text('Loading data...')\nm1, to1, xsAll1, yAll1=load_data()\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n\n\nUpdating data so prediction is for today\nThe following function changes the date of sale details for each property so that they are today’s date\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n\n\nGetting the predictions\nThe following function takes the address selected and outputs the predicted property price\nget_predTodayNotExact(m,address,toTEMP,xs_final,y)\n\n\nHelp with reducing code for selecting data\nThe following function is used to allow to select different details from the dataframes. Really just a function to get around the slightly unusual way data is selected in ‘to’ and dataFrames\ndef doSelect(typee,option2,typeeOut,toTEMP):\n\n\nThe user interface parts of the app\noptionSELECT = st.sidebar.selectbox(     'Select how to search',      choice)\nThis is a select box loacted in the LHS sidebar. The options for the user are as follows and choice dictates what boxes they see:\nchoice=['Post Code','Region', 'Street']\nFor example if ‘Post code’ is selected the folowing selectbox is shown with all post code options for first part of the postcode:\noption2 = st.sidebar.selectbox(         'Select Postcode',         indexPCSA)\nWhatever option selected the individual address must be selected:\naddress = st.sidebar.selectbox(     'Select Address',     AdSel)\n\n\nPredictions and Output\nOnce the address is selected, teh predictions are found by calling the prediction function:\nPri1, Pri2, typa=get_predTodayNotExact(m,address,(to),(xsAll),(yAll))\nAnd then displayed in the main screen with the following code:\n'You selected: ', option2, 'and', address\n'Property type is ',typa\nstra = 'The predicted price is: ' st.subheader(stra) st.header('£'+ str(Pri1[0])+'k')"
  },
  {
    "objectID": "posts/2022-02-23-SwanseaHousePriceApp.html#creating-the-app",
    "href": "posts/2022-02-23-SwanseaHousePriceApp.html#creating-the-app",
    "title": "ThomasHSimm",
    "section": "Creating the App",
    "text": "Creating the App\nThe Python .py file along with a requirements file are uploaded to a GitHub repository. The one for this is at https://github.com/dMaterialia/PropertyStreamlit\nThe requirements file includes all the modules not included in python that need to be loaded. For this function the file is as follows:\nnumpy\npandas\nmatplotlib\ngdown\nscikit-learn\nfastai\nThen simply log into Streamlit select the repository and the python file and hit go to get the app working\n\nFull Python function\n\nimport streamlit as st\n# To make things easier later, we're also importing numpy and pandas for\n# working with sample data.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\nimport copy\nfrom sklearn.ensemble import RandomForestRegressor\n\nst.title('Swansea Property Price Predictor')\n\n@st.cache(allow_output_mutation=True)\ndef load_data():\n    \"\"\"\n    Loads the data\n    \"\"\"\n    import gdown\n    url = 'https://drive.google.com/uc?id=1OD2l7ynVzLlqY92gYiCx5xq32-D1wJMe'\n    output = 'one1.pkl'\n    gdown.download(url, output)\n\n    cda = os.getcwd()\n    with open('one1.pkl', 'rb')as f: \n        m2, to2, xsAll2, yAll2 = pickle.load(f)\n    return m2, to2, xsAll2, yAll2\ndata_load_state = st.text('Loading data...')\nm1, to1, xsAll1, yAll1=load_data()\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\ndef add_datepart(df, field_name, prefix=None, drop=True, time=False):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    import re\n    import pandas as pd\n    import numpy as np\n    \n    def ifnone(a, b):\n        \"`b` if `a` is None else `a`\"\n        return b if a is None else a\n    \n    def make_date(df, date_field):\n        \"Make sure `df[date_field]` is of the right date type.\"\n        \n        field_dtype = df[date_field].dtype\n        if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n            field_dtype = np.datetime64\n        if not np.issubdtype(field_dtype, np.datetime64):\n            df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n    \n    \n    make_date(df, field_name)\n    field = df[field_name]\n    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    # Pandas removed `dt.week` in v1.1.10\n    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week\n    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week\n    mask = ~field.isna()\n    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,np.nan)\n    if drop: df.drop(field_name, axis=1, inplace=True)\n    return df\n\ndef get_predTodayNotExact(m,address,toTEMP,xs_final,y):\n    \"\"\"\n    Given model m, address, initial pd of houses to, and adjusted pd xs_final\n    output is house price prediction\n    \"\"\"\n    import copy\n    # convert to current date\n    colsAll=xs_final.columns\n    colsNoDate=['Type', 'Index of Multiple Deprivation', 'Latitude',\n                'Average Income', 'Longitude', 'Postcode', 'Introduced', 'Address',\n           'Altitude']\n    xsNoDate=copy.copy(xs_final.drop(columns=['Elapsed','Year']))\n    \n    xsNoDate['Date'] = pd.to_datetime(\"today\")\n    xsNoDate = add_datepart(xsNoDate, 'Date')\n    xs_finalTEMP=xsNoDate.loc[:,colsAll]\n\n    # each address has a unique number\n    aa=toTEMP.classes['Address']\n    # findwhich number is address give (take 1st if more than 1)\n    try:\n        ii=[ii for ii,aa1 in enumerate(aa) if aa1== address][0]\n        # 1 address can have multiple sales so we need index in dataframes\n        ii=toTEMP[toTEMP['Address']==ii].index[0]\n\n        preda = np.round( np.exp( m.predict(xs_finalTEMP.loc[ii:ii]) )/1000 ,1)\n        prev = np.round( np.exp(y.loc[ii])/1000 ,1)\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xs_finalTEMP.loc[ii:ii,'Type']][0]\n    \n    except:\n        aa=toTEMP.classes['Address']\n        aaStreet=toTEMP.classes['Street']\n        ii=[ii for ii,aa1 in enumerate(aaStreet) if aa1== Street][0]\n        xsTemp=copy.copy( xs_finalTEMP[xs_finalTEMP['Street']==ii] )\n        xsTemp.reset_index(inplace=True,drop=True)\n        # find nearest house by houseno\n        No=np.array(xsTemp['HouseNo'])\n\n        yo=(np.abs(No-HouseNo))\n        yo1=np.min(yo)\n        # get index of the nearest house\n        yo=No[yo==yo1][0]  \n\n        ii=[ii for ii,aa1 in enumerate(xsTemp.HouseNo) if aa1== yo][0]\n        xsTemp.loc[ii:ii,'HouseNo']=HouseNo\n        # If want to change house type\n        \n#         xsTemp.loc[ii:ii,'Type']=2\n#         print(xsTemp.loc[ii:ii,'Type'])\n#         print(xsTemp.loc[ii:ii])\n        \n        preda = np.round( np.exp( m.predict(xsTemp.loc[ii:ii]) )/1000 ,1)[0]\n        prev=0\n        \n        typeAll=toTEMP.classes['Type']\n        typa=typeAll[xsTemp.loc[ii:ii,'Type']][0]\n        \n        \n    return preda, prev, typa\n\n\ndef doSelect(typee,option2,typeeOut,toTEMP):\n        streetAll=toTEMP.classes[typee]\n        AdAll=toTEMP.classes[typeeOut]\n        # this finds index of postcode for example SA1 0EA = 62\n        indexPC1=[ita for ita,ij in enumerate(streetAll) if ij==option2][0]\n\n        # finds all indexes of addresses with given post code index \n        indexAdds=[ita for ita, ij in enumerate(toTEMP[typee]) if ij==indexPC1]\n\n        # Find address index numbers for those given above\n        indexAddSel=toTEMP.iloc[indexAdds][typeeOut]\n\n        # Convert these to actual addresses\n        AdSel=AdAll[indexAddSel]\n        \n        # unique values\n        AdSel=np.unique(AdSel)\n        return AdSel\n    \n\npcodesSA=['SA1', 'SA2', 'SA3', 'SA4', 'SA5', 'SA6', 'SA7', 'SA8',          \n          'SA9', 'SA10' ,'SA11', 'SA12', 'SA13', 'SA14','SA15','SA18']\n\nchoice=['Post Code','Region', 'Street']\n\nto=copy.copy(to1)\nm=copy.copy(m1)\nxsAll=copy.copy(xsAll1)\nyAll=copy.copy(yAll1)\n# These are the list of all addresses etc by actual name\nAdAll=(to.classes['Address'])\npcAll=(to.classes['Postcode'])\nregionAll=(to.classes['Region'])\nstreetAll=(to.classes['Street'])\n\n# An optionbox- Select How search\noptionSELECT = st.sidebar.selectbox(\n    'Select how to search',\n     choice)\n\nif optionSELECT=='Post Code':\n    # An optionbox- Select Postcode Start e.g. SA1\n    option = st.sidebar.selectbox(\n        'Select Area',\n         pcodesSA)\n\n\n    # Select Postcode All\n\n    # This finds a set of postcodes given by optionbox\n    indexPCSA=[ij for ij in pcAll if ij.split(' ')[0]==option]\n\n    # optionbox to select particular postcode \n    # Outcome e.g. SA1 0EA\n    option2 = st.sidebar.selectbox(\n        'Select Postcode',\n        indexPCSA)\n\n    AdSel = doSelect(typee='Postcode',option2=option2,typeeOut='Address',toTEMP=(to))\n    \n\nelif optionSELECT=='Region':\n\n    \n    option2 = st.sidebar.selectbox(\n         'Select Region',\n         regionAll)\n    \n    StreetSel = doSelect(typee='Region',option2=option2,typeeOut='Street',toTEMP=(to))\n       \n        \n    option3 = st.sidebar.selectbox(\n         'Select Street',\n         StreetSel)\n    \n    AdSel = doSelect(typee='Street',option2=option3,typeeOut='Address',toTEMP=(to))\n        \n    \n\nelif optionSELECT=='Street':\n\n    \n    option2 = st.sidebar.selectbox(\n         'Select Street',\n         streetAll)\n    \n    AdSel = doSelect(typee='Street',option2=option2,typeeOut='Address',toTEMP=(to))\n    \n    \n\naddress = st.sidebar.selectbox(\n    'Select Address',\n    AdSel)\n\nPri1, Pri2, typa=get_predTodayNotExact(m,address,(to),(xsAll),(yAll))\n\n#tell user what they selected\n'You selected: ', option2, 'and', address\n'Property type is ',typa\n\nstra = 'The predicted price is: '\nst.subheader(stra)\nst.header('£'+ str(Pri1[0])+'k')"
  },
  {
    "objectID": "posts/2022-02-26-GolfSwingPart2.html#overview",
    "href": "posts/2022-02-26-GolfSwingPart2.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\nIn a previous part Part 1 a neural network model was used to find positions on the body during a golf swing. This work used images taken from videos of golf swing (analysed using the code below by the authors listed) because it is often easier to work with images rather than videos.\nBut to get images of the golf swing to analyse it can be useful to get them at different parts of the golf swing. This is what this part does.\nTaken from https://github.com/wmcnally/golfdb and shown in the paper here https://arxiv.org/abs/1903.06528\n[Ref Paper] McNally, William, et al. \"Golfdb: A video database for golf swing sequencing.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 2019\nThe code separates the golf swing into a number of different segments based on body and golf club positions.\nThis code can be run on kaggle here https://www.kaggle.com/thomassimm/golfdb-lessimports\nThe input is an mp3 file of a golf swing\nThe ouput is a series of images at different parts of the golf swing"
  },
  {
    "objectID": "posts/2022-02-26-GolfSwingPart2.html#the-code",
    "href": "posts/2022-02-26-GolfSwingPart2.html#the-code",
    "title": "ThomasHSimm",
    "section": "The Code",
    "text": "The Code\n\nSpecify the file to use\nAdd downloaded directory (not always necsessary) and specify the video file.\n\n!cp -r ../input/golfdb3/* ./\n\nstra='../input/golfdb3/test_video.mp4'\nstra='../input/golfdb2/golfdb/data/videos_160/1017.mp4'\nstra\n\n\n\nImports, classes and defs\nSome imports. Neural nets using Torch\n\nimport scipy.io\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n# from eval import ToTensor, Normalize\n# from model import EventDetector\nimport numpy as np\nimport torch.nn.functional as F\nimport cv2\nfrom torch.autograd import Variable\n\nThe following classes and definitions are taken from the files in the GitHub directory\n\nclass SampleVideo(Dataset):\n    def __init__(self, path, input_size=160, transform=None):\n        self.path = path\n        self.input_size = input_size\n        self.transform = transform\n\n    def __len__(self):\n        return 1\n\n    def __getitem__(self, idx):\n        cap = cv2.VideoCapture(self.path)\n        frame_size = [cap.get(cv2.CAP_PROP_FRAME_HEIGHT), cap.get(cv2.CAP_PROP_FRAME_WIDTH)]\n        ratio = self.input_size / max(frame_size)\n        new_size = tuple([int(x * ratio) for x in frame_size])\n        delta_w = self.input_size - new_size[1]\n        delta_h = self.input_size - new_size[0]\n        top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n        left, right = delta_w // 2, delta_w - (delta_w // 2)\n\n        # preprocess and return frames\n        images = []\n        for pos in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n            _, img = cap.read()\n            resized = cv2.resize(img, (new_size[1], new_size[0]))\n            b_img = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT,\n                                       value=[0.406 * 255, 0.456 * 255, 0.485 * 255])  # ImageNet means (BGR)\n\n            b_img_rgb = cv2.cvtColor(b_img, cv2.COLOR_BGR2RGB)\n            images.append(b_img_rgb)\n        cap.release()\n        labels = np.zeros(len(images)) # only for compatibility with transforms\n        sample = {'images': np.asarray(images), 'labels': np.asarray(labels)}\n        if self.transform:\n            sample = self.transform(sample)\n        return sample\n\n\nclass ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n    def __call__(self, sample):\n        images, labels = sample['images'], sample['labels']\n        images = images.transpose((0, 3, 1, 2))\n        return {'images': torch.from_numpy(images).float().div(255.),\n                'labels': torch.from_numpy(labels).long()}\n\n\nclass Normalize(object):\n    def __init__(self, mean, std):\n        self.mean = torch.tensor(mean, dtype=torch.float32)\n        self.std = torch.tensor(std, dtype=torch.float32)\n\n    def __call__(self, sample):\n        images, labels = sample['images'], sample['labels']\n        images.sub_(self.mean[None, :, None, None]).div_(self.std[None, :, None, None])\n        return {'images': images, 'labels': labels}\n\n\nimport torch.nn as nn\nimport math\n\n\"\"\"\nhttps://github.com/tonylins/pytorch-mobilenet-v2\n\"\"\"\n\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU6(inplace=True)\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU6(inplace=True)\n    )\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio):\n        super(InvertedResidual, self).__init__()\n        self.stride = stride\n        assert stride in [1, 2]\n\n        hidden_dim = round(inp * expand_ratio)\n        self.use_res_connect = self.stride == 1 and inp == oup\n\n        if expand_ratio == 1:\n            self.conv = nn.Sequential(\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # pw\n                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n\n    def forward(self, x):\n        if self.use_res_connect:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass MobileNetV2(nn.Module):\n    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n        super(MobileNetV2, self).__init__()\n        block = InvertedResidual\n        min_depth = 16\n        input_channel = 32\n        last_channel = 1280\n        interverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # building first layer\n        assert input_size % 32 == 0\n        input_channel = int(input_channel * width_mult) if width_mult >= 1.0 else input_channel\n        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n        self.features = [conv_bn(3, input_channel, 2)]\n        # building inverted residual blocks\n        for t, c, n, s in interverted_residual_setting:\n            output_channel = max(int(c * width_mult), min_depth)\n            for i in range(n):\n                if i == 0:\n                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n                else:\n                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n                input_channel = output_channel\n        # building last several layers\n        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n        # make it nn.Sequential\n        self.features = nn.Sequential(*self.features)\n\n        # building classifier\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(self.last_channel, n_class),\n        )\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.mean(3).mean(2)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\nimport torch.nn as nn\nclass EventDetector(nn.Module):\n    def __init__(self, pretrain, width_mult, lstm_layers, lstm_hidden, bidirectional=True, dropout=True):\n        super(EventDetector, self).__init__()\n        self.width_mult = width_mult\n        self.lstm_layers = lstm_layers\n        self.lstm_hidden = lstm_hidden\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n\n        net = MobileNetV2(width_mult=width_mult)\n        state_dict_mobilenet = torch.load('mobilenet_v2.pth.tar')\n        if pretrain:\n            net.load_state_dict(state_dict_mobilenet)\n\n        self.cnn = nn.Sequential(*list(net.children())[0][:19])\n        self.rnn = nn.LSTM(int(1280*width_mult if width_mult > 1.0 else 1280),\n                           self.lstm_hidden, self.lstm_layers,\n                           batch_first=True, bidirectional=bidirectional)\n        if self.bidirectional:\n            self.lin = nn.Linear(2*self.lstm_hidden, 9)\n        else:\n            self.lin = nn.Linear(self.lstm_hidden, 9)\n        if self.dropout:\n            self.drop = nn.Dropout(0.5)\n\n    def init_hidden(self, batch_size):\n        if self.bidirectional:\n            return (Variable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True),\n                    Variable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True))\n        else:\n            return (Variable(torch.zeros(self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True),\n                    Variable(torch.zeros(self.lstm_layers, batch_size, self.lstm_hidden).cuda(), requires_grad=True))\n\n    def forward(self, x, lengths=None):\n        batch_size, timesteps, C, H, W = x.size()\n        self.hidden = self.init_hidden(batch_size)\n\n        # CNN forward\n        c_in = x.view(batch_size * timesteps, C, H, W)\n        c_out = self.cnn(c_in)\n        c_out = c_out.mean(3).mean(2)\n        if self.dropout:\n            c_out = self.drop(c_out)\n\n        # LSTM forward\n        r_in = c_out.view(batch_size, timesteps, -1)\n        r_out, states = self.rnn(r_in, self.hidden)\n        out = self.lin(r_out)\n        out = out.view(batch_size*timesteps,9)\n\n        return out\n\n\n\nRun the code\n\nseq_length=64\n\nds = SampleVideo(stra, transform=transforms.Compose([ToTensor(),\n                                Normalize([0.485, 0.456, 0.406],\n                                          [0.229, 0.224, 0.225])]))\n\ndl = DataLoader(ds, batch_size=1, shuffle=False, drop_last=False)\n\nmodel = EventDetector(pretrain=True,\n                      width_mult=1.,\n                      lstm_layers=1,\n                      lstm_hidden=256,\n                      bidirectional=True,\n                      dropout=False)\ntry:\n    save_dict = torch.load('models/swingnet_1800.pth.tar')\nexcept:\n    print(\"Model weights not found. Download model weights and place in 'models' folder. See README for instructions\")\n    \n    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nmodel.load_state_dict(save_dict['model_state_dict'])\nmodel.to(device)\nmodel.eval()\nprint(\"Loaded model weights\")\n\nprint('Testing...')\nfor sample in dl:\n    images = sample['images']\n    # full samples do not fit into GPU memory so evaluate sample in 'seq_length' batches\n    batch = 0\n    while batch * seq_length < images.shape[1]:\n        if (batch + 1) * seq_length > images.shape[1]:\n            image_batch = images[:, batch * seq_length:, :, :, :]\n        else:\n            image_batch = images[:, batch * seq_length:(batch + 1) * seq_length, :, :, :]\n        logits = model(image_batch.cuda())\n        if batch == 0:\n            probs = F.softmax(logits.data, dim=1).cpu().numpy()\n        else:\n            probs = np.append(probs, F.softmax(logits.data, dim=1).cpu().numpy(), 0)\n        batch += 1\n\n        \nevents = np.argmax(probs, axis=0)[:-1]\nprint('Predicted event frames: {}'.format(events))\n\n\nconfidence = []\nfor i, e in enumerate(events):\n    confidence.append(probs[e, i])\nprint('Confidence: {}'.format([np.round(c, 3) for c in confidence]))\n\nOutput:\nUsing device: cuda\nLoaded model weights\nTesting…\nPredicted event frames: [ 82 121 137 166 189 203 213 245]\nConfidence: [0.215, 0.376, 0.79, 0.767, 0.827, 0.968, 0.935, 0.247]"
  },
  {
    "objectID": "posts/2022-02-26-GolfSwingPart2.html#plot-the-results",
    "href": "posts/2022-02-26-GolfSwingPart2.html#plot-the-results",
    "title": "ThomasHSimm",
    "section": "Plot the results",
    "text": "Plot the results\n\nimport os\n##delte images\nlsa=os.listdir()\nfimg=[ ll for ll in lsa if ll.split('.')[-1]=='jpg']\n# print(fimg)\nimgs=[os.remove(ff) for ff in fimg]\n\nfimg=[ ll for ll in lsa if ll.split('.')[-1]=='jpg']\n\n\ndef createImages(fila,pos,nomS):\n    ''' \n    Given a video file location (fila) it will save as images to a folder\n    Given positions in video (pos) these images from the video are saved\n    pos is created based on positions of swings\n    '''\n    import cv2\n    cap = cv2.VideoCapture(fila)\n    eventNom=[0,1,2,3,4,5,6,7]\n    for i, e in enumerate(events):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, e)\n        _, img = cap.read()\n        cv2.imwrite(os.path.join(os.getcwd(),'_'+ nomS+'_'+\"frame{:d}.jpg\".format(eventNom[i])), img)     # save frame as JPG file\n    \n    \nfila=stra\npos=events\ncreateImages(fila,pos,'10')\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nlsa=os.listdir()\nfimg=[ ll for ll in lsa if ll.split('.')[-1]=='jpg']\nfimg.sort()\n\nimgs=[mpimg.imread(ff) for ff in fimg]\n\n\ncap = cv2.VideoCapture(stra)\n\n\n# plt.subplot(4,2,1)\nf, axs = plt.subplots(4,2,figsize=(15,15))\nfor i, e in enumerate(events):\n    cap.set(cv2.CAP_PROP_POS_FRAMES, e)\n    _, img = cap.read()\n    plt.subplot(4,2,i+1)\n    plt.imshow(img)\n    plt.title(e)"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#overview",
    "href": "posts/2022-02-27-GolfSwingPart3.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\nIn a previous part Part 1 a neural network model was used to find positions on the body during a golf swing. The model was not particularly succesful, perhaps due to the lack of data (specific to the golf swing) that was used to train the model on.\nThis problem can be got around by using a model that has been pre-trained on human gestures. Several pre-trained models can be found here Pre-trained models. I tried a few and found the chose the model keypoint-rcnn-resnet50-fpn-coco-torch worked well with this data. Link to model and Paper of model.\nThe input to the model is taken from Part 2 which separated a golf video into a series of images of the swing.\nIn this page I use the model with both fiftyOne and as a streamlit app.\n\nyoutube: https://youtu.be/Q0BB0huWb6s https://youtu.be/Q0BB0huWb6s"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#code",
    "href": "posts/2022-02-27-GolfSwingPart3.html#code",
    "title": "ThomasHSimm",
    "section": "Code",
    "text": "Code\nThe code can be run on google colab here COCO50_1 (works best on google chrome)"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#installs-and-imports",
    "href": "posts/2022-02-27-GolfSwingPart3.html#installs-and-imports",
    "title": "ThomasHSimm",
    "section": "Installs and imports",
    "text": "Installs and imports\n\n!pip uninstall opencv_python_headless\n\n!pip install opencv-python-headless==4.5.4.60\n\n!pip install fiftyone\n\nimport fiftyone as fo"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#upoad-some-images-to-the-workspace",
    "href": "posts/2022-02-27-GolfSwingPart3.html#upoad-some-images-to-the-workspace",
    "title": "ThomasHSimm",
    "section": "Upoad some images to the workspace",
    "text": "Upoad some images to the workspace\nUntar and create a dataset object from them\nAnd look at them\nThe image files can be found here GC2.tgz\n\nimport tarfile\nmy_tar = tarfile.open('/content/GC2.tgz')\nmy_tar.extractall('/content/my_folder') # specify which folder to extract to\nmy_tar.close()\n\n\nimport fiftyone as fo\nimport fiftyone.zoo as foz\n\nimport fiftyone as fo\n\nname = \"my_folder\"\ndataset_dir = \"/content\"\n\n# Create the dataset\ndataset = fo.Dataset.from_dir(\n    dataset_dir=dataset_dir,\n    dataset_type=fo.types.ImageDirectory,\n    name=name,\n)\n\nsession = fo.launch_app(dataset)\n\n\nThis screen is interative and allows us to look at the images"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#load-the-trained-model",
    "href": "posts/2022-02-27-GolfSwingPart3.html#load-the-trained-model",
    "title": "ThomasHSimm",
    "section": "Load the trained model",
    "text": "Load the trained model\nApply the model to the dataset\nView the results\n\nmodel = foz.load_zoo_model(\"keypoint-rcnn-resnet50-fpn-coco-torch\")\n\n# label_types=[\"classification\", \"classifications\", \"detections\", \"instances\", \"segmentations\", \"keypoints\", \"polylines\", \"polygons\", \"scalar\"],\n\ndataset.apply_model(model, label_field=\"predictions\",label_types='predictions_keypoints')\n\nsession = fo.launch_app(dataset)\n\n\n\nyoutube: https://youtu.be/dkxtOBWD7Vw"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#extract-data-from-the-model",
    "href": "posts/2022-02-27-GolfSwingPart3.html#extract-data-from-the-model",
    "title": "ThomasHSimm",
    "section": "Extract data from the model",
    "text": "Extract data from the model\nWe might want to use the data from the model outside of fiftyOne.\nIn the following I extract the data so that it can be plotted.\n\ndef plotPredOne(i):\n  import numpy as np\n\n  import matplotlib.pyplot as plt\n  import matplotlib.image as mpimg\n\n  img = mpimg.imread(i['filepath'])\n\n  #need to take account of more than one person in image\n  points1 = np.array(i['predictions_keypoints']['keypoints'][0]['points'])\n  adjPts = np.shape(img)[0]\n  box1 = np.array(i['predictions_detections']['detections'][0]['bounding_box']) \n  box1=box1*adjPts\n  # Bboxes are in [top-left-x, top-left-y, width, height] format\n  box2=np.array([ \n      [box1[0], box1[1]],\n      [box1[0] +box1[2] ,box1[1] ],\n      [box1[0] +box1[2] ,box1[1] +box1[3]] ,\n      [box1[0]  ,box1[1] +box1[3]],\n      [box1[0], box1[1]]\n      ])\n \n  plt.figure()\n  plt.imshow(img)\n\n  plt.plot(points1[:,0]*adjPts,points1[:,1]*adjPts, '+k',markersize=10,linewidth=3)\n  plt.plot(box2[:,0],box2[:,1], '--og',markersize=10,linewidth=3)\n\n    #back of body\n  v=[4,6,12,14,16]\n  plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-k<',markersize=10,linewidth=2)\n\n  #front of body\n  v=[0,5,11,13,15]\n  plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w>',markersize=10,linewidth=2)\n\n  vects = np.array([[ 5,6],#shoulders also 4?\n         [11,12], #hips\n         [13,14], #knees\n         [15,16],#heels\n         [7,8],#elbows\n         [9,10],#hands\n         ]) \n  mak='gcyrmb'\n  for iv,v in enumerate(vects):\n    plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-'+mak[iv],markersize=10,linewidth=3)\n\n\nfor iii,i in enumerate(dataset):\n  \n  plotPredOne(i)"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#convert-into-a-streamlit-app",
    "href": "posts/2022-02-27-GolfSwingPart3.html#convert-into-a-streamlit-app",
    "title": "ThomasHSimm",
    "section": "Convert into a Streamlit App",
    "text": "Convert into a Streamlit App\nTo convert to a streamlit app I will use the PyTorch module rather than the fiftyOne.\nI will also keep it simple by loading only 3 images- start of swing, top of backswing and at impact- and modeling these at the start of the load part of the app.\nThe app will then just plot the images as shown above.\n\nImports and give the app a title\n\nimport streamlit as st\nimport torch\nimport torchvision\nfrom torchvision import transforms\nfrom PIL import Image\nimport tarfile\nimport os\nfrom torchvision.io import read_image\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nst.title('Golf Swing')\n\n\n\nLoading the data & applying the model\nCreate a function to load data and model the data\nload_data(choi)\nImages are loaded from Gc2.tgz\nmy_tar = tarfile.open(cda2+'/GC2.tgz')\nThe particular model to use is loaded\nmodel = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()\nImages are loaded and converted to a tensor\nnumber_img = Image.open(cda2+'/images/'+image_filename)\nconvert_tensor = transforms.ToTensor()\nAnd predictions are made\npredictions=model(imgTens)\nIn the main body the function is called\ndata_load_state = st.text('Loading data...')\npredictions,imgLocAll,cda2=load_data(1)\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n# So only have to do this when app launches\n@st.cache()\n\n# the function 'choi' is the video file to use\ndef load_data(choi):\n\n    # the images are in the GC2.tgz file- this needs to be untarred first\n    cda = os.getcwd()\n    cda2=cda\n    my_tar = tarfile.open(cda2+'/GC2.tgz')\n    my_tar.extractall(cda2) # specify which folder to extract to\n    my_tar.close()\n\n    # Create a variable of the image names and which video they are part of\n    imgAll=[]\n    vidAll=[]\n    i=0\n    last1=' '\n    for xx in os.listdir(cda2+'/images/'):\n        if xx[-1]=='g':\n            imgAll = np.append(imgAll, xx)\n            if xx.split('_')[1]!=last1:\n                i=i+1\n            vidAll=np.append(vidAll,i)\n            last1=xx.split('_')[1]\n\n    vidAllUnq=np.unique(vidAll)\n    \n    # Load the model to be used\n    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n    model.eval()\n    \n    # Select the images to be used\n    imgs = imgAll[vidAll==vidAllUnq[choi]]\n\n    # make sure in correct order\n    aa=[int(xx.split('_')[-1].split('e')[1].split('.')[0]) for xx in imgs]\n    ind=sorted(range(len(aa)), key=lambda k: aa[k])\n    imgs=imgs[ind]\n\n    # create tensor of images to be used- here 3 (images) X width X height\n    imgTens=[]\n    imgLocAll=[]\n    \n    # Just use the start, top and impact of swing\n    iiUse=[0,3,5]\n    for ii,image_filename in enumerate(imgs):\n    #             print(cda2+'images/'+image_filename)\n        if ii in iiUse:\n            number_img = Image.open(cda2+'/images/'+image_filename)\n            convert_tensor = transforms.ToTensor()\n            number_img=convert_tensor(number_img)\n            imgTens.append(number_img)\n            imgLocAll.append(image_filename)\n\n    # Make the predictions\n    predictions=model(imgTens)\n    \n    return predictions,imgLocAll,cda2\n\n# Outside the function, the load function is called\ndata_load_state = st.text('Loading data...')\npredictions,imgLocAll,cda2=load_data(1)\ndata_load_state.text(\"Loaded data (using st.cache)\")\n\n\n\nStreamlit user interface\nUser selects the images from this box:\nchoice=imgLocAll\nimgSEL = st.sidebar.selectbox(     'Select how to search',      choice)\nDisplay to user what swing it is:\nSwingPos=['Start','Back','Through']\nSwingPos[numSEL]\nAnd at the end of the file the figure is displayed in streamlit with the following command:\nst.pyplot(fig)\n\n\nThe plot part\nExtract the data from the model about different parts of the body:\npoints1=np.array([x.detach().numpy()[0:2] for x in predictions[numSEL]['keypoints'][0]])\nThe plot lines plot different parts of the body, the following plot the back of the body\nv=[4,6,12,14,16]\nplt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w<',markersize=10,linewidth=2)\n\n# load the images so can be plotted\nimg = mpimg.imread(cda2+'/images/'+imgSEL)\n\n# the image selected\nnumSEL=[oo for oo,x in enumerate(choice) if x==imgSEL][0]\n\n# get data from model as a numpy array - here want keypoints other info is also available\npoints1=np.array([x.detach().numpy()[0:2] for x in predictions[numSEL]['keypoints'][0]])\n\n# create a plot\nfig=plt.figure(figsize=(7,7))\nplt.imshow(img)\n\n# Plot across back and front of body\nadjPts=1\n#back of body\nv=[4,6,12,14,16]\nplt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w<',markersize=10,linewidth=2)\n\n#front of body\nv=[0,5,11,13,15]\nplt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-k>',markersize=10,linewidth=2)\n\n# Plot over lines on body\nvects = np.array([[ 5,6],#shoulders also 4?\n     [11,12], #hips\n     [13,14], #knees\n     [15,16],#heels\n     [7,8],#elbows\n     [9,10],#hands\n     ]) \nmak='gcyrmb'\nfor iv,v in enumerate(vects):\n    plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-'+mak[iv],markersize=10,linewidth=3)\n\nLEG=['Back','Front','Shoulders','Hips','Knees','Heels','Elbows','Hands']\nplt.legend(LEG)\nfor x in points1:\n    plt.plot(x[0],x[1],'+b')\n\n\n\nRequirements.txt\nFinally streamlit needs a requirements text in the GitHub repository\n\ntorch\ntorchvision\nPillow\nmatplotlib\nnumpy"
  },
  {
    "objectID": "posts/2022-02-27-GolfSwingPart3.html#the-streamlit-app",
    "href": "posts/2022-02-27-GolfSwingPart3.html#the-streamlit-app",
    "title": "ThomasHSimm",
    "section": "The Streamlit App",
    "text": "The Streamlit App\nStreamlit App\nGitHub page\n\nyoutube: https://youtu.be/Q0BB0huWb6s"
  },
  {
    "objectID": "posts/2022-03-15-FastaiCheatSheets.html#misc.",
    "href": "posts/2022-03-15-FastaiCheatSheets.html#misc.",
    "title": "ThomasHSimm",
    "section": "Misc.",
    "text": "Misc.\n\nCreating a path\nWhere the data is\n\n# current directory\npath=Path()\n\nPath.BASE_PATH = path\n\n# another folder off cwd\npath = Path('bears')\n#if doesn't exist can do\npath.mkdir()\n\n# as part of downloading inbuilt data\npath = untar_data(URLs.IMDB)\n\n\n# When using path to select a subfolder\n`trains = path/'train'`\nOr to view\n`(path/'train').ls()"
  },
  {
    "objectID": "posts/2022-03-15-FastaiCheatSheets.html#loading-the-data",
    "href": "posts/2022-03-15-FastaiCheatSheets.html#loading-the-data",
    "title": "ThomasHSimm",
    "section": "Loading the data",
    "text": "Loading the data\nDataLoaders is a thin class that just stores whatever DataLoader objects you pass to it, and makes them available as train and valid. Although it’s a very simple class, it’s very important in fastai: it provides the data for your model. The key functionality in DataLoaders is provided with just these four lines of code (it has some other minor functionality we’ll skip over for now):\nclass DataLoaders(GetAttr):\n    def __init__(self, *loaders): self.loaders = loaders\n    def __getitem__(self, i): return self.loaders[i]\n    train,valid = add_props(lambda i,self: self[i])\nTo turn our downloaded data into a DataLoaders object we need to tell fastai at least four things:\n\nWhat kinds of data we are working with\nHow to get the list of items\nHow to label these items\nHow to create the validation set\n\n\nDataBlocks\n\ndBlock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\nblocks what format is the data? - ImageBlock - CategoryBlock - TextBlock\nget_items takes a function that that gives the list of all data (images/text etc) - get_image_files - partial(get_text_files, folders=['train', 'test', 'unsup'])\nsplitter how data is plit into test and validation sets - RandomSplitter(valid_pct=0.2, seed=42) randomly - def splitter(df):     train = df.index[~df['is_valid']].tolist()     valid = df.index[df['is_valid']].tolist()     return train,valid use a function this one uses data frame\nget_x and get_y get the independent (x) and dependent variables (y) takes a function that provides labels for the data - parent_label gets the name of the parent folder e.g. when doing categorical data put rabbits in ‘rabbits’ folder and horses in ‘horses’ folder - def get_y(r): return r['labels'].split(' ')\nitem_tfms runs on individual items- allows for data augmentation, making images the same size etc - Resize(128) resize all images to 128 - Resize(128, ResizeMethod.Pad, pad_mode='zeros' resize with zeros\nbatch_tfms similar to the above but apply to all batch - [*aug_transforms(size=size, min_scale=0.75), Normalize.from_stats(*imagenet_stats)]\n\n\nDataLoaders\nThe data block is like a template for creating a DataLoaders. We still need to tell fastai the actual source of our data—in this case, the path where the images can be found along with some other details.\nA DataLoaders includes validation and training DataLoaders. DataLoader is a class that provides batches of a few items at a time to the GPU. When you loop through a DataLoader fastai will give you 64 (by default) items at a time, all stacked up into a single tensor.\n\ndls = dBlock.dataloaders(path, \n            path=path, \n            bs=128, \n            seq_len=80)\n\nafter_item applied after each item equivalent of item_tfms\nbefore_batch applied on list of items before they’re collated\nafter_batch applied on the batch as a whole after construction- equivalent to batch_tfms\nbs batch size\nseq_len\npath path to data"
  },
  {
    "objectID": "posts/2022-03-15-FastaiCheatSheets.html#the-model",
    "href": "posts/2022-03-15-FastaiCheatSheets.html#the-model",
    "title": "ThomasHSimm",
    "section": "The model",
    "text": "The model\n\nDifferent models\n\nVision\nfrom fastai.vision import models\nlearn = cnn_learner(data, models.resnet18, metrics=accuracy)\nTorchvision models\n\nresnet18, resnet34, resnet50, resnet101, resnet152\nsqueezenet1_0, squeezenet1_1\ndensenet121, densenet169, densenet201, densenet161\nvgg16_bn, vgg19_bn\nalexnet Others\nDarknet\nunet\n\n\n\nText\nfrom fastai.text import *\nlearn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\nOr for classification\nlearn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n\n\nTabular\nfrom fastai.tabular import *\nlearn = tabular_learner(data, layers=[200,100], emb_szs={'native-country': 10}, metrics=accuracy)\n\n\n\nLearning\nTo fit the model we have a few options:\n\nlearn.fit(10,lr=4e-3)\nlearn.fit_one_cycle()\nlearn.fine_tune(10, base_lr=1e-3, freeze_epochs=7)\nlearn.fine_tune(15, lr)\n\nFastAI adds an extra 2 layers on the end of neural network when doing transfer learning, these can then be fitted using fine_tune. It is recommended to do a few fits frozen before unfreezing. This is normally the best option for transfer learning.\nBut the other ones can be used. In general fit can be more unstable and lead to bigger losses, but can be useful if fine_tune is not bringing losses down.\nhttps://forums.fast.ai/t/fine-tune-vs-fit-one-cycle/66029/6\nfit_one_cycle = New Model\n\nfine_tuning = with Transfer Learning?\n\nI’d say yes but with a very strong but, only because it’s easy to fall into a trap that way. fine_tuning is geared towards transfer learning specifically, but you can also just do fit_one_cycle as well! (Or flat_cos).\n\nFor beginners it’s a great starting fit function (and advanced too), but also don’t forget that you can then\nAn alternative to fine_tuning with transfer learning is to specify which layers are frozen:\nUnfreeze layers, to freeze all except the last two parameter groups use freeze_to:\nlearn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))\nAnd unfreeze a bit more\nlearn.freeze_to(-3)\nOr unfreeze the whole model\nlearn.unfreeze\nCan see the difference between fine_tune and fit_one_cycle from the fine_tune function:\n\ndef fine_tune(self:Learner, epochs, base_lr=2e-3, freeze_epochs=1, lr_mult=100,\n              pct_start=0.3, div=5.0, **kwargs):\n    \"Fine tune with `freeze` for `freeze_epochs` then with `unfreeze` from `epochs` using discriminative LR\"\n    self.freeze()\n    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n    base_lr /= 2\n    self.unfreeze()\n    self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)\n\n\n\nSome other useful bits\nFind the best learing rate:\nlearn.lr_find()"
  },
  {
    "objectID": "posts/2022-03-15-NLPtextgenerator.html#introduction",
    "href": "posts/2022-03-15-NLPtextgenerator.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\n\nNLP\nNLP, or natural language processing, is a machine learning priocess used on language data. Some applications include:\n\nsearch, ranking\nspam detection\nads recommendation\nemail categorization\nmachine translation\nspeech recognition\nSentiment analysis\n\nFrom FastAI FastBooks:\nWhat we call a language model is a model that has been trained to guess what the next word in a text is (having read the ones before). This kind of task is called self-supervised learning: we do not need to give labels to our model, just feed it lots and lots of texts. It has a process to automatically get labels from the data, and this task isn't trivial: to properly guess the next word in a sentence, the model will have to develop an understanding of the English (or other) language\n\nEven if our language model knows the basics of the language we are using in the task (e.g., our pretrained model is in English), it helps to get used to the style of the corpus we are targeting. It may be more informal language, or more technical, with new words to learn or different ways of composing sentences. In the case of the IMDb dataset, there will be lots of names of movie directors and actors, and often a less formal style of language than that seen in Wikipedia.\n\nWe already saw that with fastai, we can download a pretrained English language model and use it to get state-of-the-art results for NLP classification."
  },
  {
    "objectID": "posts/2022-03-15-NLPtextgenerator.html#what-is-below",
    "href": "posts/2022-03-15-NLPtextgenerator.html#what-is-below",
    "title": "ThomasHSimm",
    "section": "What is below",
    "text": "What is below\nHere I’ll use the IMDB dataset and train it on the works of Shakespeare to generate text in the style of his work given a starting few words.\nUses fastAI, modified from “10_nlp.ipynb” in fastAI/fastbook\nhttps://colab.research.google.com/drive/11JRjYu7XsmSzo3IT8oH2KNf-e-v6W5tf?usp=sharing"
  },
  {
    "objectID": "posts/2022-03-15-NLPtextgenerator.html#code",
    "href": "posts/2022-03-15-NLPtextgenerator.html#code",
    "title": "ThomasHSimm",
    "section": "Code",
    "text": "Code\n\n# Some imports\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\nfrom fastbook import *\nfrom IPython.display import display,HTML\n\nfrom fastai.text.all import *\n\n\nGet some text to act as a style\n\n# A URL containing the works of Shakespeare\nurl='https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n\n# Going to put in a folder called BARD which we create\ndest='BARD'\nimport os\nos.mkdir(dest)\n\n# get the text from the url and put as data\nimport requests\nresponse = requests.get(url)\ndata = response.text\n\n# reduce data to miss start and end guff\nxstart=10450\nxend=580\ndata = data[xstart:-xend]\n\n# create a text file every 1000\n# use format number_0.txt seems to work best for DataBlock\nrr=int(len(data)/1000)\nfor i in range(rr):\n    with open(dest + '/{}_0.txt'.format(str(i)),'w') as f:\n        f.writelines(data[ (i-1)*1000:i*1000 ])\n\n\n\nLanguage model using DataBlock\n\n# create path\npath=Path()\n\n# get's the text parts- will just come from folder dest \n# where the text files are saved\nget_shak = partial(get_text_files,folders=dest)\n\n# Craete a dataBlock- using the Class of TextBlock and the classes \n# in-built function from folder\ndbb = DataBlock(\n    blocks=TextBlock.from_folder(path, is_lm=True),\n    get_items=get_shak, splitter=RandomSplitter(0.1)\n)\n\n# Now create the dataLoaders\ndls =dbb.dataloaders(path, path=path, bs=128, seq_len=80)\n\n# Have a look at the batches\ndls.show_batch(max_n=2)\n\n\n\n\nCreate model and Run\n\nlearn = language_model_learner(\n    dls, AWD_LSTM, drop_mult=0.3, \n    metrics=[accuracy, Perplexity()]).to_fp16()\n\n\nlearn.fit_one_cycle(1, 2e-2)\n\n\n\nlearn.unfreeze()\nlearn.fit_one_cycle(10, 2e-3)"
  },
  {
    "objectID": "posts/2022-03-15-NLPtextgenerator.html#model-text-generation",
    "href": "posts/2022-03-15-NLPtextgenerator.html#model-text-generation",
    "title": "ThomasHSimm",
    "section": "Model Text Generation",
    "text": "Model Text Generation\n\nTEXT = \"Hi Romeo how are you?\"\nN_WORDS = 40\nN_SENTENCES = 4\npreds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n         for _ in range(N_SENTENCES)]\n\n\nprint(\"\\n\".join(preds))\n\n“Cannot get rid of this spot” 30 words, 2 sentences\nCan not get rid of this spot ? No ; I 'll set a foot to Caesar . If i can tell you , Triumvirate , that know the heads of\n\nCan not get rid of this spot ? When one sees England here , he next is sure to be sent for . If i be not , my King , you must\n“Hi Romeo how are you?” 60words 2sent. 0.75temp.\nHi Romeo how are you ? What 's your will ? My heart is split . What , my soul ! My body 's as cold as wax ; my heart is now as a nail in my heart ; thou shalt see Romeo set a crown on't ! Come , and that ring i gave him , the ring\n“Where shall i go for my holiday?”\nWhere shall i go for my holiday ? Am i to France ? Are you English ? Are you a Spanish man ? [ aside ] i know not what ; nor no other man but this . [ they speak ] If i speak , i am going .\n“Poor me , poor me , poor me another drink”\nPoor me , poor me , poor me another drink , I 'll burn out King Lear 's grave . Thou art too dear to me ; i am perfect i am least of all . I 'll go live i ' th ' middle , and there will i not live in this ."
  },
  {
    "objectID": "posts/2022-04-05-speechRecog.html#resources-sources",
    "href": "posts/2022-04-05-speechRecog.html#resources-sources",
    "title": "ThomasHSimm",
    "section": "Resources / Sources",
    "text": "Resources / Sources\n\nhttps://www.thepythoncode.com/article/using-speech-recognition-to-convert-speech-to-text-python\nhttps://www.geeksforgeeks.org/create-a-voice-recorder-using-python/\nhttps://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14\nhttps://github.com/Uberi/speech_recognition/blob/master/examples/audio_transcribe.py"
  },
  {
    "objectID": "posts/2022-04-05-speechRecog.html#installs",
    "href": "posts/2022-04-05-speechRecog.html#installs",
    "title": "ThomasHSimm",
    "section": "Installs",
    "text": "Installs\n\n\n!pip install speechrecognition pydub\n!pip3 install sounddevice\n!pip3 install wavio\n!pip install scipy"
  },
  {
    "objectID": "posts/2022-04-05-speechRecog.html#create-a-recording",
    "href": "posts/2022-04-05-speechRecog.html#create-a-recording",
    "title": "ThomasHSimm",
    "section": "Create a recording",
    "text": "Create a recording\n\n# import required libraries\nimport sounddevice as sd\nfrom scipy.io.wavfile import write\nimport wavio as wv\n  \n# Sampling frequency\nfreq = 44100\n  \n# Recording duration\nduration = 20\n  \n# Start recorder with the given values \n# of duration and sample frequency\nrecording = sd.rec(int(duration * freq), \n                   samplerate=freq, channels=2)\n  \n# Record audio for the given number of seconds\nsd.wait()\n  \n# This will convert the NumPy array to an audio\n# file with the given sampling frequency\n# write(\"recording0.wav\", freq, recording)\n  \n# Convert the NumPy array to audio file\nfileo=\"recording1.wav\"\nwv.write(fileo, recording, freq, sampwidth=2)\n\nTo make it an arbitrary duration\nhttps://python-sounddevice.readthedocs.io/en/0.3.12/examples.html#recording-with-arbitrary-duration"
  },
  {
    "objectID": "posts/2022-04-05-speechRecog.html#convert-audio-to-text",
    "href": "posts/2022-04-05-speechRecog.html#convert-audio-to-text",
    "title": "ThomasHSimm",
    "section": "Convert Audio to text",
    "text": "Convert Audio to text\n\nimport speech_recognition as sr\n\nAUDIO_FILE = fileo\nr = sr.Recognizer()\nwith sr.AudioFile(AUDIO_FILE) as source:\n    audio = r.record(source)  # read the entire audio file\n\n\ntry:\n    # we're just using the default API key\n    print(\"->> \" + r.recognize_google(audio))\nexcept sr.UnknownValueError:\n    print(\"Google Speech Recognition could not understand audio\")\nexcept sr.RequestError as e:\n    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n\n->> I heard you have a compilation of every good song ever done by anybody every great song by The Beach Boys All the underground hits all the modern lovers tracks I heard you have a vinyl record on German imports I heard that you have a white label every cm\n\n\nWhen reading out Losing My Edge by LCD Soundsystem\nI heard you have a compilation of every good song ever done by anybody. Every great song by the Beach Boys. All the underground hits. All the Modern Lovers tracks. I heard you have a vinyl of every Niagra record on German import. I heard that you have a white label of every semina"
  },
  {
    "objectID": "posts/2022-04-08-Tweepy.html#resources",
    "href": "posts/2022-04-08-Tweepy.html#resources",
    "title": "ThomasHSimm",
    "section": "Resources",
    "text": "Resources\n\nA. Getting started with twitter API - Twitter Developer Platform\nhttps://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api\n\n\nB. Tweepy Documentation\nhttps://docs.tweepy.org/en/stable/index.html\n\n\nC. A comprehensive guide for using the Twitter API v2 with Tweepy in Python - Suhem Parack\nhttps://dev.to/twitterdev/a-comprehensive-guide-for-using-the-twitter-api-v2-using-tweepy-in-python-15d9\n\n\nD. Making queries to Twitter API on tweepy - Roberto Aguilar\nhttps://medium.com/@robguilarr/making-queries-to-twitter-api-on-tweepy-66afeb7184a4\n\n\nE. Accessing the Twitter API with Python - Mihajlo Pavloski\nhttps://stackabuse.com/accessing-the-twitter-api-with-python/\n\n\nF. How to Apply for a Twitter Developer Account - jean-christophe-chouinard\nhttps://www.jcchouinard.com/apply-for-a-twitter-developer-account/\n\n\nG. How to get Twitter API Credentials (API Keys) - jean-christophe-chouinard\nhttps://www.jcchouinard.com/twitter-api-credentials/\n\n\nH. Twitter API with Python (Complete Guide) - jean-christophe-chouinard\nhttps://www.jcchouinard.com/twitter-api/"
  },
  {
    "objectID": "posts/2022-04-08-Tweepy.html#setting-up-twitter-api",
    "href": "posts/2022-04-08-Tweepy.html#setting-up-twitter-api",
    "title": "ThomasHSimm",
    "section": "Setting up twitter API",
    "text": "Setting up twitter API\n\n1. Apply for a developer account\nBefore using the Twitter API, you first need a Twitter account, and to have obtained some credentials. The process of getting credentials could change with time, but currently it is as follows:\n\nVisit the Application Management page at https://apps.twitter.com/, and sign in with your Twitter account\nClick on the \"Create New App\" button, fill in the details and agree the Terms of Service\nNavigate to \"Keys and Access Tokens\" section and take a note of your Consumer Key and Secret\nIn the same section click on \"Create my access token\" button\nTake note of your Access Token and Access Token Secret\nAnd that's all. The consumer key/secret is used to authenticate the app that is using the Twitter API, while the access token/secret authenticates the user. All of these parameters should be treated as passwords, and should not be included in your code in plain text. One suitable way is to store them in a JSON file \"twitter_credentials.json\" and load these values from your code when needed.\nSource E. Accessing the Twitter API with Python - Mihajlo Pavloski\nTwitter API access levels and versions\n\nWhile the Twitter API v2 is the primary Twitter API, the platform currently supports previous versions (v1.1, Gnip 2.0) as well. We recommend that all users start with v2 as this is where all future innovation will happen. \n\nThe Twitter API v2 includes a few access levels to help you scale your usage on the platform. In general, new accounts can quickly sign up for free, Essential access. Should you want additional access, you may choose to apply for free Elevated access and beyond. \nSource A. Getting started with twitter API - Twitter Developer Platform\n\nI applied for elevated access. This involved filling in several questions about what I would user twitter API for and a follow up email.\nFor more info on how to apply for a twitter development account see F. How to Apply for a Twitter Developer Account - jean-christophe-chouinard\n\n\n2. Create a project/app\nTo use the twitter API you need to create a twitter App. From this you can then get the security IDs, bearer_token, API_key etc.\nFor more details on this see G. How to get Twitter API Credentials (API Keys) - jean-christophe-chouinard\n\n\n3. Set up an environment\nTwitter API bestows us several endpoints at the moment we request our App access. From which 3 of them are for searching methods, those that bring samples of the tweets we want according to specific criteria.\napi.search_30_day()\n\nPremium Search for tweets from the last 30 days.\nMonthly limitation of 4500 tweets per minute, without exceeding 25K tweets per month — Sandbox\n\napi.search_full_archive()\n\nPremium Search for tweets from March of 2006.\nMonthly limitation of 3000 tweets per minute, without exceeding 5K tweets per month — Sandbox\n\napi.search_tweets()\n\nRegular Search for tweets from the last 6–9 days as maximum.\nMonthly limitation of 3000 tweets per minute — Sandbox, this is the one that we gonna use in this case.\nFrom D. Making queries to Twitter API on tweepy - Roberto Aguilar\nThese environments are found at https://developer.twitter.com/en/account/environments.\nAnd the name of the environment is included in the particular search (as shown below label=XXX.\n\n\n4. Install tweepy\npip install tweepy"
  },
  {
    "objectID": "posts/2022-04-08-Tweepy.html#tweepy-code",
    "href": "posts/2022-04-08-Tweepy.html#tweepy-code",
    "title": "ThomasHSimm",
    "section": "Tweepy code",
    "text": "Tweepy code\n\nimport os\nos.environ[\"BEARER_TOKEN\"]=\" insert here \"\nos.environ[\"API_key\"]='insert here'\nos.environ[\"API_secret\"]=' insert here'\nos.environ[\"access_token\"] = \" insert here \"\nos.environ[\"access_token_secret\"]=\" insert here \"\n\n\nImport and check it is authenticated\n\nimport tweepy\n\n# API keys that yous saved earlier\napi_key = os.environ.get(\"API_KEY\")\napi_secrets = os.environ.get(\"API_secret\")\naccess_token = os.environ.get(\"access_token\")\naccess_secret = os.environ.get(\"access_token_secret\")\n \n# Authenticate to Twitter\nauth = tweepy.OAuthHandler(api_key,api_secrets)\nauth.set_access_token(access_token,access_secret)\n \napi = tweepy.API(auth)\n \ntry:\n    api.verify_credentials()\n    print('Successful Authentication')\nexcept:\n    print('Failed authentication')\n\n\n\nSearch tweets\nTwo main ones:\nFor last 30 days:\nouta = api.search_30_day(label, query, *, tag, fromDate, toDate, maxResults,next)\nAnd for any times:\nouta = api.search_full_archive(label, query, *, tag, fromDate, toDate,                                maxResults, next)\n\nQuery\nfrom the python script:\nThe equivalent of one premium rule/filter, with up to 1,024 characters (256 with Sandbox dev environments).\n\nThis parameter should include ALL portions of the rule/filter,including all operators, and portions of the rule should not be separated into other parameters of the query.\nFollowing adapted from D. Making queries to Twitter API on tweepy - Roberto Aguilar\n\nSearch for a term\n\nquery = 'holiday' - Containing two words\nquery = 'holiday jet2' - Containing exact words\nquery='\"jet2 braces\" \"holiday\"' - Contain one word OR another\nquery='jet2 OR \"tuiuk\"' - Hashtags and mentions\nquery = '@jet2tweets #holiday' - Exclude words\nquery='@jet2tweets -travel' - Who the tweet is sent from and to\nquery='holiday from:jet2tweets'\nquery='holiday to:jet2tweets'\n\n\nDates\nDates are in the format YYYYMMDDHHmm\nSo 0:00 21st March 2021 = ‘202103210000’\n#hide #### Tag\nfrom script:\nTags can be used to segregate rules and their matching data into\ndifferent logical groups. If a rule tag is provided, the rule tag\nis included in the 'matching_rules' attribute.\n\nIt is recommended to assign rule-specific UUIDs to rule tags and\nmaintain desired mappings on the client side.\nFollowing adapted from D. Making queries to Twitter API on tweepy - Roberto Aguilar\n\nRetweets\n\ntag='-filter:retweets' without retweets\ntag='filter:retweets' and just RTs\n\nHas links\n\ntag='-filter:links'\n\nHas media\n\ntag='-filter:media'\n\nTrusted\n\ntag='-filter:trusted'\nMore filters can be seen in the Docs\n\n\n\nThe results file\nouta=api.search_full_archive(label=label,          query=query,toDate=end_time,fromDate=start_time)\nThe information from outa is accessed for each element using _json, i.e. \nouta[0]._json gives the first search result\n\nxx=outa[0]._json\nfor ii,x in enumerate(xx):\n    print(ii,x)\n\n\nIf the tweet is longer than 140 char the text property doesn’t display all the text of the tweet.\nThis will normally then be in the extended_tweet property but also sometimes in the retweeted_status property.\nSo to get around this put in exceptions.\n\ntextAll=[]\n\nfor numa in range(0,10):\n    xx=outa1[numa]._json\n    \n    try:\n        textAll.append(numa,'1', xx['created_at'],\n              xx['retweeted_status']['extended_tweet']['full_text'] )\n    except:\n        try:\n            textAll.append(numa,'2',xx['created_at'],\n                  xx['extended_tweet']['full_text'])\n        except:\n            textAll.append(numa,'3',xx['created_at'],xx['text'])"
  },
  {
    "objectID": "posts/2022-04-25-NLP-Of-TravelTweets.html#introduction",
    "href": "posts/2022-04-25-NLP-Of-TravelTweets.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nTravel analysis of twitter feeds of UK travel companies TUI and Jet2 twitter accounts before and during the COVID pandemic.\n\nTwitter data is obtained from the twitter API using tweepy.\nNLP analysis is done using a zero-shot method from transformers.\nAnalyis of NLP data is kept at a basic level using pandas and matplotlib"
  },
  {
    "objectID": "posts/2022-04-25-NLP-Of-TravelTweets.html#twitter-data",
    "href": "posts/2022-04-25-NLP-Of-TravelTweets.html#twitter-data",
    "title": "ThomasHSimm",
    "section": "Twitter Data",
    "text": "Twitter Data\nTweets were obtained using the twitter API and tweepy more details on twitter and API here- tweepy.\nI decided to keep the query simple and just use tweets containing the handle of TUI and Jet2’s UK twitter accounts, as shown below. This was mainly because of the API limitation meant experimenting on the best query took away from getting data.\nquery='@tuiuk' or query='@jet2tweets'\nI also decided to get tweets from a 3 day period, at first the start of a month and later in the middle. The tweets were focussed on dates around January 2020 (the start of the pandemic), with data obtained up to ~2 years before this and just over 2 years after this to the present (April 2022). And Use the search_full_archive call from twitter api. Broadly the call is as shown below.\nfrom datetime import date\nfrom datetime import timedelta\nstart_time = date.fromisoformat('2020-02-01') end_time = start_time + timedelta(3)\nouta=api.search_full_archive(label=\"mytwitterlabel\",          query=query,toDate=toDate,fromDate=fromDate)\nThis leads to around 1500 tweets per firm at the time of analysis, due to twitter API call being limited.\n\nThe number of tweets for Tui and Jet2 after removing ‘duplicate’ tweets"
  },
  {
    "objectID": "posts/2022-04-25-NLP-Of-TravelTweets.html#natural-language-processing-nlp",
    "href": "posts/2022-04-25-NLP-Of-TravelTweets.html#natural-language-processing-nlp",
    "title": "ThomasHSimm",
    "section": "Natural Language Processing (NLP)",
    "text": "Natural Language Processing (NLP)\nThe most ‘reliable’ way to analyse text data is to do a two step process:\n\ncreating a language model for the data\nusing this language model with labelled data to classify different texts\n\nThis method is shown here https://www.kaggle.com/code/thomassimm/imdb-sentiment-analysis for sentiment analysis (i.e. are reviews positive or negative) of IMDB data. But the labels need not be positive or negative but can be more nuanced.\nHowever, for this twitter data there is no labelled data. I could label the data myself but will first try an alternative approach-> the zero shot learning method. The advantage is no labelled data is needed nor any prior training. But the accuracy will be reduced without any training as shown below.\n\nAnother advantage of the method is that it can be used to classify text data by broad labels based on the language model as shown by the example from the link below:\nsentence = 'Who are you voting for in 2020?'\nlabels = ['business', 'art & culture', 'politics']\nAnd the similarity for each label (high the better):\nlabel: politics     similarity: 0.21561521291732788\nlabel: business     similarity: 0.004524140153080225\nlabel: art & culture    similarity: -0.027396833524107933\n\nLabels for travel data\nAt this point in analysis the goals are broad, I mainly want to know if I can understand how customers were reacting to the travel restriction changes being imposed on them and how this differed for the two travel companies. So what may be things we would want to classify from the tweets:\n\nHow happy/unhappy are the customers?\nIs there a change in the number of what would be classed as complaints?\nCan sentiments be separated by what is the cause? e.g. customer service, cancellations, company policies\n(similar to above) What do the tweets refer to?\nCan we remove customer tweets from spam/promotional details/business changes etc?\n\nAfter a bit of iterating I decided on the following labels (see https://www.kaggle.com/code/thomassimm/travel-tweets-nlp/ for trying out different labels).\ncandidate_labels=['query','complaint',                   'holiday','hotel',                   'flight','flight cancellation','flight delay',                   'website or app problem','customer service',                   'travel regulations','price',                  'holiday cancellation']\nLet us examine how the labels work for different tweets (picked randomly but avoiding tweets with similarity):\n    A) Hi there, do you know the transfer time? I couldn’t see it on the website. Thanks \n\nquery 0.98\ncomplaint 0.73\n\nholiday 0.00\n\nhotel 0.62\nflight 0.24\n\nflight cancellation 0.01\n\nflight delay 0.15\n\nwebsite or app problem 0.89\n\ncustomer service 0.97\n\ntravel regulations 0.26\n\nprice 0.00\nholiday cancellation 0.00\n  B) Worst ever sent details of complaint Florida villa including memory stick with photos sent in never heard a thing don’t bother they just ignore you\nquery 0.72\ncomplaint 0.98\n\nholiday 0.73\n\nhotel 0.03\nflight 0.00\n\nflight cancellation 0.00\n\nflight delay 0.00\n\nwebsite or app problem 0.00\n\ncustomer service 0.82\n\ntravel regulations 0.06\n\nprice 0.09\nholiday cancellation 0.13\n      C) hi I’ve been trying to book a holiday for a few days on my pc or via the mobile app but when I try to check out I get this error message\nquery 0.73\ncomplaint 0.97\n\nholiday 0.94\n\nhotel 0.47\nflight 0.17\n\nflight cancellation 0.00\n\nflight delay 0.00\n\nwebsite or app problem 1.00\n\ncustomer service 0.70\n\ntravel regulations 0.22\n\nprice 0.07\nholiday cancellation 0.94\n      D) how do I amend dates on my holiday. Iv tried ringing customer service but was given wrong number to ring. Thanks \nquery 0.91\ncomplaint 0.93\n\nholiday 0.99\n\nhotel 0.17\nflight 0.11\n\nflight cancellation 0.02\n\nflight delay 0.02\n\nwebsite or app problem 0.00\n\ncustomer service 0.67\n\ntravel regulations 0.57\n\nprice 0.00\nholiday cancellation 0.38\n      E) Maybe not quite neighbouring - Trinidad and Tobago 😁😁😂 \nquery 0.37\ncomplaint 0.87\n\nholiday 0.03\n\nhotel 0.03\nflight 0.03\n\nflight cancellation 0.01\n\nflight delay 0.01\n\nwebsite or app problem 0.02\n\ncustomer service 0.06\n\ntravel regulations 0.08\n\nprice 0.04\nholiday cancellation 0.06\n\nSome quick comments:\n\nOverall the labels make sense to the particular tweets.\nComplaint seems to be high for all even when they are clearly not complaints (D and E). Although, obvious complaints have higher values. Maybe combine with sentiment analysis?\nWebsite and app issues well picked up, preseumably as they use the words website or app\nThe one with no relevance to customer service (E) scores low for query and customer service, so maybe the metric can help to distinguish these.\nHighest value for flight was for A even though flight not explicitly mentioned\n\nLots of positives from this small selection. But to get a good idea of classification may take some more modication in terms of what to use and what values they give for different things. Perhaps this can be done as a neural network after some sort of labelling?"
  },
  {
    "objectID": "posts/2022-04-25-NLP-Of-TravelTweets.html#analysis-of-labelled-data",
    "href": "posts/2022-04-25-NLP-Of-TravelTweets.html#analysis-of-labelled-data",
    "title": "ThomasHSimm",
    "section": "Analysis of Labelled data",
    "text": "Analysis of Labelled data\nA brief analysis of the NLP results is given here https://www.kaggle.com/code/thomassimm/travel-tweets-analyseresults and presented below.\nThe most obvious thing to check first is the change in the sentiment of tweets. The figure below does this by taking the average of the positive sentiment for each time period.\n\nSentiment\n\nSome initial comments:\n\nJet2 gets more positive tweets than Tui\nThe data may be noisy. The changes before the pandemic are noticeably large and it is not obvious if these are real trends or just noise. More digging would need to be done to establish what the changes are before COVID before the change during COVID could be assessed.\nThe overall sentiment appears to be at a low in early 2022, the easing of restrictions may be suggesting a more positive sentiment in the future.\nSince this is an average of a random selection of tweets. A change in the nature of the tweets would have a big influence on the results.\n\n\n\nCustomer Service Queries\nGiven the last of the comments (the nature of the tweets), we may wish to separate tweets based on some overall criteria- e.g. review (inclusing complaint), query and other (including none customer queries, general comments, spam etc). Or remove the last of these by some other criteria such as ‘customer service’ and/or ‘query’ more than a certain amount.\n \nBased on the above figures the percentage of tweets that are labelled ‘query’ or ‘customer service’ increase sharply during the pandemic. This would make sense given the confusion around the situation and the questions that customers will have around COVID regulations and company policies in dealing with these changes.\n\n\nComplaints\nReturning to the overall sentiment figure above, can a classification of tweets based on whether they are a complaint help with the changes?\nAs shown in the figure below the complaint classification shows a clearer increase during the COVID period. Perhaps this offers a better way instead of the sentiment analysis to understand the nature of the tweets, but more analysis would be required.\nThe maximum values for this metric for both cmpanies at the end of 2021 / start of 2022, are worth exploring in more detail"
  },
  {
    "objectID": "posts/2022-07-01-RandomForests.html#decision-trees",
    "href": "posts/2022-07-01-RandomForests.html#decision-trees",
    "title": "ThomasHSimm",
    "section": "Decision Trees",
    "text": "Decision Trees\nA decision tree asks a series of binary questions about the data, whereupon the data is split into two branches. For each of these branches another question can be asked, or a prediction made. The branches continue until a prediction is made.\nThese are created using training data and can subsequently be used with test data.\nDecisionTreeRegressor?\nDecisionTreeRegressor(     *,     criterion='squared_error',     splitter='best',     max_depth=None,     min_samples_split=2,     min_samples_leaf=1,     min_weight_fraction_leaf=0.0,     max_features=None,     random_state=None,     max_leaf_nodes=None,     min_impurity_decrease=0.0,     ccp_alpha=0.0, )\n\nChanging paramaters\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,max_depth=2)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,min_samples_split=30_000)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\nm = DecisionTreeRegressor(max_leaf_nodes=7,min_samples_leaf=30_000)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n# DecisionTreeRegressor?\n\n\n\nm = DecisionTreeRegressor(max_features=3,max_leaf_nodes=10)\nm.fit(xs, y);\ndraw_tree(m, xs, size=10, leaves_parallel=True, precision=2)\n\n\n\n\nHyper Parameters\n\n\n\n\n\n\n\n\nParameter\nDescription\nDefault\n\n\n\n\nmax_depth\nThe maximum number of branches to get to the result.  ie top to bottom length.\nNone\n\n\nmax_leaf_nodes\nThe total number of branches\nNone\n\n\nmin_samples_split\nThe minimum number of samples required to split an internal node\n2\n\n\nmin_samples_leaf\nThe minimum number of samples required to be at a leaf node.\n1\n\n\nmax_features\nMaximum number of features (i.e. parameters using to fit or X)\nNone"
  },
  {
    "objectID": "posts/2022-07-01-RandomForests.html#random-forests",
    "href": "posts/2022-07-01-RandomForests.html#random-forests",
    "title": "ThomasHSimm",
    "section": "Random Forests",
    "text": "Random Forests\nRandom forests use many decision trees using ensembling (combining multiple models). Today it is, perhaps, the most widely used and practically important machine learning method.\nRandom forests uses Bagging as the ensemble method. The other main one being Boosting.\nIn bagging many decision tree models are combined together by averaging them. Each decision tree is trained on a different data subset and can have different parameters to fit to the data.\n“Bagging Predictors” Leo Breiman > : Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions… The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests… show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.\nHere is the procedure that Breiman is proposing:\n\nRandomly choose a subset of the rows of your data (i.e., “bootstrap replicates of your learning set”).\nTrain a model using this subset.\nSave that model, and then return to step 1 a few times.\nThis will give you a number of trained models. To make a prediction, predict using all of the models, and then take the average of each of those model’s predictions.\n\n\n\n\n\n\n\n\nDecision trees\nRandom Forests\n\n\n\n\nCan suffer from overfitting.  Care should be taken with the hyper parameters and use of validation data\nSubsets of the data are used for each model and the results averaged  So overfitting is mostly taken care of\n\n\nFaster computation\nSlower\n\n\nFormulate a set of rules fore predictions\nNo rules\n\n\n\n\nHyper Parameters\n\n\n\n\n\n\n\n\nParameter\nDescription\nDefault\n\n\n\n\nn_estimators\nnumber of trees the algorithm builds before averaging the predictions\n100\n\n\nmax_features\nMaximum number of features (i.e. parameters using to fit or X)\n1.0 (regression or sqrt (classification)\n\n\nmin_samples_leaf\nThe minimum number of samples required to be at a leaf node.\n1\n\n\nn_jobs\nHow many processors can be used  =1 uses one processor, =-1 no limit on number\nNone\n\n\noob_score\nOOB=Out of the bag. In this one-third of the sample is not used to train the data instead used to evaluate its performance\nFalse\n\n\n\n\nOne of the most important properties of random forests is that they aren’t very sensitive to the hyperparameter choices, such as max_features. You can set n_estimators to as high a number as you have time to train—the more trees you have, the more accurate the model will be. max_samples can often be left at its default, unless you have over 200,000 data points, in which case setting it to 200,000 will make it train faster with little impact on accuracy. max_features=0.5 and min_samples_leaf=4 both tend to work well, although sklearn’s defaults work well too.\n\nFastAI\n https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html > In the plot, the blue plot line uses the fewest features and the green line uses the most (it uses all the features). As you can see in <>, the models with the lowest error result from using a subset of features but with a larger number of trees.\nFastAI\n\nm = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y); \n\nsamp_idx = np.random.permutation(len(y))[:500]\ndtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')"
  },
  {
    "objectID": "posts/2022-07-01-RandomForests.html#implementaion",
    "href": "posts/2022-07-01-RandomForests.html#implementaion",
    "title": "ThomasHSimm",
    "section": "Implementaion",
    "text": "Implementaion\nhttps://www.kaggle.com/thomassimm/rf-swanseahouses"
  },
  {
    "objectID": "posts/2022-07-01-RandomForests.html#bibliography",
    "href": "posts/2022-07-01-RandomForests.html#bibliography",
    "title": "ThomasHSimm",
    "section": "Bibliography",
    "text": "Bibliography\n\nFast AI - 09- Tabular Data - https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb\nUnderstanding Random Forest - https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/\nScikit learn - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html & https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#select-from",
    "href": "posts/2022-07-07-SQL-Copy1.html#select-from",
    "title": "ThomasHSimm",
    "section": "Select, From",
    "text": "Select, From\nThe general syntax of SELECT statments is:\nselect FirstName, LastName from Employees ;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nNancy\nEdwards\n\n\nJane\nPeacock\n\n\nMargaret\nPark\n\n\nSteve\nJohnson\n\n\nMichael\nMitchell\n\n\nRobert\nKing\n\n\nLaura\nCallahan\n\n\n\nTo retrieve all columns from the Employees table we could use “*” instead of specifying individual column names:\nselect * from Employees ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n5\nJohnson\nSteve\nSales Support Agent\n2\n1965-03-03 00:00:00\n2003-10-17 00:00:00\n7727B 41 Ave\nCalgary\nAB\nCanada\nT3B 1Y7\n1 (780) 836-9987\n1 (780) 836-9543\nsteve@chinookcorp.com\n\n\n6\nMitchell\nMichael\nIT Manager\n1\n1973-07-01 00:00:00\n2003-10-17 00:00:00\n5827 Bowness Road NW\nCalgary\nAB\nCanada\nT3B 0C5\n+1 (403) 246-9887\n+1 (403) 246-9899\nmichael@chinookcorp.com\n\n\n7\nKing\nRobert\nIT Staff\n6\n1970-05-29 00:00:00\n2004-01-02 00:00:00\n590 Columbia Boulevard West\nLethbridge\nAB\nCanada\nT1K 5N8\n+1 (403) 456-9986\n+1 (403) 456-8485\nrobert@chinookcorp.com\n\n\n8\nCallahan\nLaura\nIT Staff\n6\n1968-01-09 00:00:00\n2004-03-04 00:00:00\n923 7 ST NW\nLethbridge\nAB\nCanada\nT1H 1Y8\n+1 (403) 467-3351\n+1 (403) 467-8772\nlaura@chinookcorp.com"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#where",
    "href": "posts/2022-07-07-SQL-Copy1.html#where",
    "title": "ThomasHSimm",
    "section": "Where",
    "text": "Where\nThe WHERE clause can be added to your query to filter results or get specific rows of data. To retrieve data for all rows in the Employees table where the ID is less than 5:\nselect * from Employees where EmployeeID < 5 ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n\nIn case of character based columns the values of the predicates in the where clause need to be enclosed in single quotes. To retrieve the data for the Employees names with First Name “Jane” we would issue:\nselect LastName, FirstName from Employees where FirstName = 'Jane';\n\n\n\nLastName\nFirstName\n\n\n\n\nPeacock\nJane"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#in-or-not",
    "href": "posts/2022-07-07-SQL-Copy1.html#in-or-not",
    "title": "ThomasHSimm",
    "section": "In, Or, Not",
    "text": "In, Or, Not\nIn is used when we want to specify a range of conditions.\nFor example, find values of employees with last name Adams or Park\nselect FirstName, LastName from Employees\nwhere LastName In ('Adams','Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nCan do a similar thing with the OR operator. When using OR it is often helpful to use with brackets ()\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nWhy the order matters and use of ()\nselect FirstName, LastName from Employees\nwhere LastName = 'Adams' OR LastName ='Park'\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park')\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\n\nThis is because SQL processes AND before OR\nIn benefits over or - Long list of options - In is faster - Don’t have to consider order with IN - Can contain another select\nThe not command is represented as <>\nfor example select the titles not beginning with c\nselect title from albums\nwhere substr(title,1,1) <> 'C'\n\n\n\nTitle\n\n\n\n\nFor Those About To Rock We Salute You\n\n\nBalls to the Wall\n\n\nRestless and Wild\n\n\nLet There Be Rock\n\n\nBig Ones\n\n\nJagged Little Pill\n\n\nFacelift\n\n\nWarner 25 Anos\n\n\nPlays Metallica By Four Cellos\n\n\nAudioslave\n\n\n\nIf it is used with IN then we use NOT\nfor example cities names not starting with a vowel\nselect distinct city from station\nwhere substr(city,1,1) not in ('a','e','i','o','u')\n\n\n\nCity\n\n\n\n\nKissee Mills\n\n\nLoma Mar\n\n\nSandy Hook\n\n\nTipton\n\n\nTurner\n\n\nSlidell\n\n\nNegreet"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#distinct",
    "href": "posts/2022-07-07-SQL-Copy1.html#distinct",
    "title": "ThomasHSimm",
    "section": "Distinct",
    "text": "Distinct\nFind unique values\nselect distinct artistid from albums\n\n\n\nAlbumId\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#wildcards",
    "href": "posts/2022-07-07-SQL-Copy1.html#wildcards",
    "title": "ThomasHSimm",
    "section": "Wildcards",
    "text": "Wildcards\nTo find parts within a string can use the % wildcard\n_ works in a similar way but matches a single character (not supported by DB2)\n\n\n\n\n\n\n\nWildcard\nAction\n\n\n\n\n‘%ly’\nFind all strings ending ‘ly’\n\n\n‘To%’\nFind all strings starting ‘To’\n\n\n‘t%@gmail.com’\nFind all gmail address strings starting ‘t’\n\n\n’_ill’\nFind all strings ending ill with one other chaharacter  e.g. Kill, Bill\n\n\n\nImplementation, to implement use where and like.\nFind Names ending in t\nselect FirstName, LastName from Employees\nwhere FirstName like '%t';\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\nRobert\nKing\n\n\n\nDownsides of wildcards:\n\nTakes longer to run (particularly at end of pattern\nBetter to use another operator e.g. =,>,<"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#order-data",
    "href": "posts/2022-07-07-SQL-Copy1.html#order-data",
    "title": "ThomasHSimm",
    "section": "Order Data",
    "text": "Order Data\norder by - take name of 1 or more columns - Can use a column not retrieved - The last clause in a statement - Can use a number to represent column number - Add dsc or asc after column name to order acending or descending\nOrder employee names by last name ascending then last name descending\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nLaura\nCallahan\n\n\nNancy\nEdwards\n\n\nSteve\nJohnson\n\n\nRobert\nKing\n\n\nMichael\nMitchell\n\n\nMargaret\nPark\n\n\nJane\nPeacock"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#aggregate-functions",
    "href": "posts/2022-07-07-SQL-Copy1.html#aggregate-functions",
    "title": "ThomasHSimm",
    "section": "Aggregate Functions",
    "text": "Aggregate Functions\n\naverage average of a column (avg)\ncount counts number of values\nmin finds the minimum value\nmax finds the maximum value\nsum sums the column values\n\nselect count(trackid) from tracks\nwhere albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#group-by-and-having",
    "href": "posts/2022-07-07-SQL-Copy1.html#group-by-and-having",
    "title": "ThomasHSimm",
    "section": "Group by and Having",
    "text": "Group by and Having\nDo the same command as above but with group by, instead of where need to use having after the group by statement\nwhere filters before data is grouped and having after data is grouped\nselect count(trackid) from tracks\ngroup by albumid\nhaving albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14\n\n\n\nor could get the number of tracks in all albums\nselect count(trackid) from tracks\ngroup by albumid\n\n\n\ncount(trackid)\n\n\n\n\n10\n\n\n1\n\n\n3\n\n\n8\n\n\n15\n\n\n13\n\n\n12\n\n\n14\n\n\n8\n\n\n14"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#windowing",
    "href": "posts/2022-07-07-SQL-Copy1.html#windowing",
    "title": "ThomasHSimm",
    "section": "Windowing",
    "text": "Windowing\n\nA window function performs a calculation across a set of table rows that are somehow related to the current row.\nComparable to the type of calculation that can be done with an aggregate function.\nUnlike regular aggregate functions, windowing does not cause rows to become grouped into a single output row — the rows retain their separate identities.\nBehind the scenes, the window function is able to access more than just the current row of the query result.\nhttps://www.postgresql.org/docs/9.1/tutorial-window.html\n\nFor example, compare each song track’s length to the average salength for each composer\nselect composer, name,\nmilliseconds/(1000*60)                                    AS track_length,\navg(milliseconds/(1000*60)) over (partition by composer)  AS avg_track_length\nfrom ah_uyekita.chinook_track\n\n\n\ncomposer\nname\ntrack_length\navg_track_length\n\n\n\n\nAaron Copland\nFanfare for the Common Man\n3.3011\n3.3011\n\n\nAaron Goldberg\nOAM’s Blues\n4.4489\n4.4489\n\n\nA.Bouchard/J.Bouchard/S.Pearlman\nAstronomy\n6.6255\n6.6255\n\n\nAC/DC\nLet There Be Rock\n6.1109\n5.1110\n\n\nAC/DC\nOverdose\n6.1553 5.1110\n\n\n\nAC/DC\nProblem Child\n5.4173\n5.1110\n\n\nAC/DC\nBad Boy Boogie\n4.4621\n5.1110\n\n\nAC/DC\nGo Down\n5.5197\n5.1110\n\n\n\n\nWindow functions\n\nCUME_DIST Calculate the cumulative distribution of a value in a set of values\nDENSE_RANK Assign a rank value to each row within a partition of a result, with no gaps in rank values.\nFIRST_VALUE Get the value of the first row in an ordered partition of a result set.\nLAG Provide access to a row at a given physical offset that comes before the current row.\nLAST_VALUE Get the value of the last row in an ordered partition of a result set.\nLEAD Provide access to a row at a given physical offset that follows the current row.\nNTILE Distribute rows of an ordered partition into a number of groups or buckets\nPERCENT_RANK Calculate the percent rank of a value in a set of values.\nRANK Assign a rank value to each row within a partition of a result set\nROW_NUMBER Assign a unique sequential integer to rows within a partition of a result set, the first row starts from 1.\n\nhttps://www.sqlservertutorial.net/sql-server-window-functions/"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#subqueries",
    "href": "posts/2022-07-07-SQL-Copy1.html#subqueries",
    "title": "ThomasHSimm",
    "section": "Subqueries",
    "text": "Subqueries\nThese are queries within other queries Which merge data from multiple sources together\nget customerid and city when their invoice total is more than 20\nselect CustomerID, City\nfrom customers\nwhere customerid in (select customerid\nfrom invoices\nwhere total>20)\n\n\n\nCustomerId\nCity\n\n\n\n\n6\nPrague\n\n\n26\nFort Worth\n\n\n45\nBudapest\n\n\n46\nDublin\n\n\n\nHow many albums does the band LEd Zeppelin have?\nselect count(*)\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Led Zeppelin')\n\n\n\ncount(*)\n\n\n\n\n14\n\n\n\nOr what are the name of the tracks for the artist Audioslave?\nselect Name\nfrom tracks\nwhere albumid IN\n(select albumid\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Audioslave'))\n\n\n\nName\n\n\n\n\nCochise\n\n\nShow Me How to Live\n\n\nGasoline\n\n\nWhat You Are\n\n\nLike a Stone\n\n\nSet It Off\n\n\nShadow on the Sun\n\n\nI am the Highway\n\n\nExploder\n\n\nHypnotize"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#joins",
    "href": "posts/2022-07-07-SQL-Copy1.html#joins",
    "title": "ThomasHSimm",
    "section": "Joins",
    "text": "Joins\n\nefficient storage\neasier manipulation\ngreater scalability\nlogically models a process\ntables are related through common values or keys\ndata retrival from multiple tables in one query\nonly persist for the duration of the query\n\n\nCartesian cross joins\n\neach row from first table joins with all rows from the other table\noutput size of joins in A multiplied rows in B\ncomputationally taxing\nrarely used\n\n\nselect a.title, ar.name from albums as a\ncross join artists as ar\norder by a.title\n\n\n\nTitle\nName\n\n\n\n\n…And Justice For All\nAC/DC\n\n\n…And Justice For All\nAccept\n\n\n\ntotal rows = 95425\ntotal rows of albums = 347\ntotal rows of artists = 275\n\n\nInner join\n\nselect records that have matching values in both tables\nUse on to select what joining on\njoining more table affects database performance\nCan join multiple tables- no limit\n\n\nFor example get the artist name and title of each album. N.B. albums has columns AlbumID, Title and ArtistID only\nselect artists.Name, albums.Title\nfrom artists\nINNER JOIN albums\non artists.artistid = albums.artistID\n\n\n\nName\nTitle\n\n\n\n\nAC/DC\nFor Those About To Rock We Salute You\n\n\nAC/DC\nLet There Be Rock\n\n\nAccept\nBalls to the Wall\n\n\nAccept\nRestless and Wild\n\n\nAerosmith\nBig Ones\n\n\nAlanis Morissette\nJagged Little Pill\n\n\nAlice In Chains\nFacelift\n\n\nAntônio Carlos Jobim\nWarner 25 Anos\n\n\nAntônio Carlos Jobim\nChill: Brazil (Disc 2)\n\n\nApocalyptica\nPlays Metallica By Four Cellos\n\n\n\nOr as a multiple join\nSELECT o.orderId, c.CompanyName, e.LastName\nFROM ((orders o INNER JOIN customers c ON o.customerID = c.CustomerID)\n`INNER JOIN employees e ON o.EmployeeID = e.EmployeeID);\n\n\nSelf joins\n\nTakes the table and treats it like two separate tables\nJoin the original table to itself\n\nFor example, match cities from the same state\nselect A.city,A.state,B.city, B.state\nfrom station A, station B\nwhere A.city=B.city\nand A.state=B.state\norder by A.state;\n\n\n\ncity A\nstate A\ncity B\nstate B\n\n\n\n\nSeward\nAK\nSeward\nAK\n\n\nChignik Lagoon\nAK\nChignik Lagoon\nAK\n\n\nFive Points\nAL\nFive Points\nAL\n\n\nGroveoak\nAL\nGroveoak\nAL\n\n\nNotasulga\nAL\nNotasulga\nAL\n\n\nJackson\nAL\nJackson\nAL\n\n\n….\n….\n….\n…."
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#advanced-joins",
    "href": "posts/2022-07-07-SQL-Copy1.html#advanced-joins",
    "title": "ThomasHSimm",
    "section": "Advanced Joins",
    "text": "Advanced Joins\n\nLeft Joins\nReturns all records from the left table and the matched records from the righ table\nThe result is NULL from the right hand side if there is no match\nRight joins are the same but from the RHS. Can be converted to left join by reversing the order\n\nFor example, find all the customers who have an invoice\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nLEFT JOIN invoices i on c.customerid = i.customerid\norder by c.customerid\n\n\n\nFirstName\nLastName\nInvoiceId\n\n\n\n\nLuís\nGonçalves\n98\n\n\nLuís\nGonçalves\n121\n\n\nLuís\nGonçalves\n143\n\n\nLuís\nGonçalves\n195\n\n\nLuís\nGonçalves\n316\n\n\nLuís\nGonçalves\n327\n\n\nLuís\nGonçalves\n382\n\n\nLeonie\nKöhler\n1\n\n\nLeonie\nKöhler\n12\n\n\nLeonie\nKöhler\n67\n\n\nLeonie\nKöhler\n196\n\n\nLeonie\nKöhler\n219\n\n\nLeonie\nKöhler\n241\n\n\nLeonie\nKöhler\n293\n\n\nFrançois\nTremblay\n99\n\n\n\n\n\nFull outer join\nReturns all records where there is a match in either table\n“Give me everything”\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nFULL OUTER JOIN invoices i on c.customerid = i.customerid\norder by c.customerid"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#unions",
    "href": "posts/2022-07-07-SQL-Copy1.html#unions",
    "title": "ThomasHSimm",
    "section": "Unions",
    "text": "Unions\nCombine two or more select statements - Each select must have the same number of columns - Columns must have similar data types - Columns in the same order - Less commonly used\ne.g. combine two string statements, the first a list of occupations and the second a summary of the above\n(select concat(name,'(',substr(occupation,1,1),')') from occupations)\nunion\n(select concat('There are a total number of ',count(*),' ',occupation,'s.')\nfrom occupations\ngroup by occupation\norder by count(occupation));"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#substr",
    "href": "posts/2022-07-07-SQL-Copy1.html#substr",
    "title": "ThomasHSimm",
    "section": "Substr",
    "text": "Substr\nReturns part of a string\nsubstr(string name, string position, number of characters to return)\nIf string position is negative counts from the end\ne.g., find city names that start and end with a vowel\nselect city from station\nwhere substr(city,1,1) in ('a','e','i','o','u')\nand substr(city,-1,1) in ('a','e','i','o','u')"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#others",
    "href": "posts/2022-07-07-SQL-Copy1.html#others",
    "title": "ThomasHSimm",
    "section": "Others",
    "text": "Others\nLimit 1 limit the results to 1\nconcat combine multiple parts\nselect concat(name, '(', substr(occupation,1,1), ')')\nfrom occupations\nround(X,5)\nrounds X to 5 decimal places\nor round(x) to nearest integer"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#mode",
    "href": "posts/2022-07-07-SQL-Copy1.html#mode",
    "title": "ThomasHSimm",
    "section": "Mode",
    "text": "Mode\nMode seems like a good free way to perform SQL. I’ve yet to work out if the course provided me a link to access datasets or if these are freely available for everyone opeing a new account. The website is not easy to navigate and I only found access to my workspaces from a link I saved and not from links on the website.\nhttps://app.mode.com/thomassimm/reports/e9412b22b846/runs/c4e7c78695f3\n\nSpark SQL\n\nhttps://files.training.databricks.com/courses/ucdavis/Lessons.dbc\nSpark SQL and DataFrames and Datasets Guides -SQL Guide from Databricks\nLearning Spark, 2nd Edition (eBook compliments of Databricks).\nIntroduction - The Internals of Spark SQL (free gitbook)"
  },
  {
    "objectID": "posts/2022-07-07-SQL-Copy1.html#appendix",
    "href": "posts/2022-07-07-SQL-Copy1.html#appendix",
    "title": "ThomasHSimm",
    "section": "Appendix",
    "text": "Appendix\nhttps://dev.mysql.com/doc/refman/8.0/en/union.html\nhttps://www.w3schools.com/sql/default.asp\nhttps://blog.sqlauthority.com/category/sql-puzzle/\nhttps://sqlzoo.net/wiki/SQL_Tutorial\nhttps://mode.com/sql-tutorial/introduction-to-sql\nhttps://www.postgresql.org/docs/9.1/tutorial.html\nhttps://www.coursera.org/specializations/learn-sql-basics-data-science#courses"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#select-from",
    "href": "posts/2022-07-07-SQL.html#select-from",
    "title": "ThomasHSimm",
    "section": "Select, From",
    "text": "Select, From\nThe general syntax of SELECT statments is:\nselect FirstName, LastName from Employees ;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nNancy\nEdwards\n\n\nJane\nPeacock\n\n\nMargaret\nPark\n\n\nSteve\nJohnson\n\n\nMichael\nMitchell\n\n\nRobert\nKing\n\n\nLaura\nCallahan\n\n\n\nTo retrieve all columns from the Employees table we could use “*” instead of specifying individual column names:\nselect * from Employees ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n5\nJohnson\nSteve\nSales Support Agent\n2\n1965-03-03 00:00:00\n2003-10-17 00:00:00\n7727B 41 Ave\nCalgary\nAB\nCanada\nT3B 1Y7\n1 (780) 836-9987\n1 (780) 836-9543\nsteve@chinookcorp.com\n\n\n6\nMitchell\nMichael\nIT Manager\n1\n1973-07-01 00:00:00\n2003-10-17 00:00:00\n5827 Bowness Road NW\nCalgary\nAB\nCanada\nT3B 0C5\n+1 (403) 246-9887\n+1 (403) 246-9899\nmichael@chinookcorp.com\n\n\n7\nKing\nRobert\nIT Staff\n6\n1970-05-29 00:00:00\n2004-01-02 00:00:00\n590 Columbia Boulevard West\nLethbridge\nAB\nCanada\nT1K 5N8\n+1 (403) 456-9986\n+1 (403) 456-8485\nrobert@chinookcorp.com\n\n\n8\nCallahan\nLaura\nIT Staff\n6\n1968-01-09 00:00:00\n2004-03-04 00:00:00\n923 7 ST NW\nLethbridge\nAB\nCanada\nT1H 1Y8\n+1 (403) 467-3351\n+1 (403) 467-8772\nlaura@chinookcorp.com"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#where",
    "href": "posts/2022-07-07-SQL.html#where",
    "title": "ThomasHSimm",
    "section": "Where",
    "text": "Where\nThe WHERE clause can be added to your query to filter results or get specific rows of data. To retrieve data for all rows in the Employees table where the ID is less than 5:\nselect * from Employees where EmployeeID < 5 ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n\nIn case of character based columns the values of the predicates in the where clause need to be enclosed in single quotes. To retrieve the data for the Employees names with First Name “Jane” we would issue:\nselect LastName, FirstName from Employees where FirstName = 'Jane';\n\n\n\nLastName\nFirstName\n\n\n\n\nPeacock\nJane"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#in-or-not",
    "href": "posts/2022-07-07-SQL.html#in-or-not",
    "title": "ThomasHSimm",
    "section": "In, Or, Not",
    "text": "In, Or, Not\nIn is used when we want to specify a range of conditions.\nFor example, find values of employees with last name Adams or Park\nselect FirstName, LastName from Employees\nwhere LastName In ('Adams','Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nCan do a similar thing with the OR operator. When using OR it is often helpful to use with brackets ()\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nWhy the order matters and use of ()\nselect FirstName, LastName from Employees\nwhere LastName = 'Adams' OR LastName ='Park'\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park')\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\n\nThis is because SQL processes AND before OR\nIn benefits over or - Long list of options - In is faster - Don’t have to consider order with IN - Can contain another select\nThe not command is represented as <>\nfor example select the titles not beginning with c\nselect title from albums\nwhere substr(title,1,1) <> 'C'\n\n\n\nTitle\n\n\n\n\nFor Those About To Rock We Salute You\n\n\nBalls to the Wall\n\n\nRestless and Wild\n\n\nLet There Be Rock\n\n\nBig Ones\n\n\nJagged Little Pill\n\n\nFacelift\n\n\nWarner 25 Anos\n\n\nPlays Metallica By Four Cellos\n\n\nAudioslave\n\n\n\nIf it is used with IN then we use NOT\nfor example cities names not starting with a vowel\nselect distinct city from station\nwhere substr(city,1,1) not in ('a','e','i','o','u')\n\n\n\nCity\n\n\n\n\nKissee Mills\n\n\nLoma Mar\n\n\nSandy Hook\n\n\nTipton\n\n\nTurner\n\n\nSlidell\n\n\nNegreet"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#distinct",
    "href": "posts/2022-07-07-SQL.html#distinct",
    "title": "ThomasHSimm",
    "section": "Distinct",
    "text": "Distinct\nFind unique values\nselect distinct artistid from albums\n\n\n\nAlbumId\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#wildcards",
    "href": "posts/2022-07-07-SQL.html#wildcards",
    "title": "ThomasHSimm",
    "section": "Wildcards",
    "text": "Wildcards\nTo find parts within a string can use the % wildcard\n_ works in a similar way but matches a single character (not supported by DB2)\n\n\n\n\n\n\n\nWildcard\nAction\n\n\n\n\n‘%ly’\nFind all strings ending ‘ly’\n\n\n‘To%’\nFind all strings starting ‘To’\n\n\n‘t%@gmail.com’\nFind all gmail address strings starting ‘t’\n\n\n’_ill’\nFind all strings ending ill with one other chaharacter  e.g. Kill, Bill\n\n\n\nImplementation, to implement use where and like.\nFind Names ending in t\nselect FirstName, LastName from Employees\nwhere FirstName like '%t';\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\nRobert\nKing\n\n\n\nDownsides of wildcards:\n\nTakes longer to run (particularly at end of pattern\nBetter to use another operator e.g. =,>,<"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#order-data",
    "href": "posts/2022-07-07-SQL.html#order-data",
    "title": "ThomasHSimm",
    "section": "Order Data",
    "text": "Order Data\norder by - take name of 1 or more columns - Can use a column not retrieved - The last clause in a statement - Can use a number to represent column number - Add dsc or asc after column name to order acending or descending\nOrder employee names by last name ascending then last name descending\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nLaura\nCallahan\n\n\nNancy\nEdwards\n\n\nSteve\nJohnson\n\n\nRobert\nKing\n\n\nMichael\nMitchell\n\n\nMargaret\nPark\n\n\nJane\nPeacock"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#aggregate-functions",
    "href": "posts/2022-07-07-SQL.html#aggregate-functions",
    "title": "ThomasHSimm",
    "section": "Aggregate Functions",
    "text": "Aggregate Functions\n\naverage average of a column (avg)\ncount counts number of values\nmin finds the minimum value\nmax finds the maximum value\nsum sums the column values\n\nselect count(trackid) from tracks\nwhere albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#group-by-and-having",
    "href": "posts/2022-07-07-SQL.html#group-by-and-having",
    "title": "ThomasHSimm",
    "section": "Group by and Having",
    "text": "Group by and Having\nDo the same command as above but with group by, instead of where need to use having after the group by statement\nwhere filters before data is grouped and having after data is grouped\nselect count(trackid) from tracks\ngroup by albumid\nhaving albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14\n\n\n\nor could get the number of tracks in all albums\nselect count(trackid) from tracks\ngroup by albumid\n\n\n\ncount(trackid)\n\n\n\n\n10\n\n\n1\n\n\n3\n\n\n8\n\n\n15\n\n\n13\n\n\n12\n\n\n14\n\n\n8\n\n\n14"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#windowing",
    "href": "posts/2022-07-07-SQL.html#windowing",
    "title": "ThomasHSimm",
    "section": "Windowing",
    "text": "Windowing\n\nA window function performs a calculation across a set of table rows that are somehow related to the current row.\nComparable to the type of calculation that can be done with an aggregate function.\nUnlike regular aggregate functions, windowing does not cause rows to become grouped into a single output row — the rows retain their separate identities.\nBehind the scenes, the window function is able to access more than just the current row of the query result.\nhttps://www.postgresql.org/docs/9.1/tutorial-window.html\n\nFor example, compare each song track’s length to the average salength for each composer\nselect composer, name,\nmilliseconds/(1000*60)                                    AS track_length,\navg(milliseconds/(1000*60)) over (partition by composer)  AS avg_track_length\nfrom ah_uyekita.chinook_track\n\n\n\ncomposer\nname\ntrack_length\navg_track_length\n\n\n\n\nAaron Copland\nFanfare for the Common Man\n3.3011\n3.3011\n\n\nAaron Goldberg\nOAM’s Blues\n4.4489\n4.4489\n\n\nA.Bouchard/J.Bouchard/S.Pearlman\nAstronomy\n6.6255\n6.6255\n\n\nAC/DC\nLet There Be Rock\n6.1109\n5.1110\n\n\nAC/DC\nOverdose\n6.1553 5.1110\n\n\n\nAC/DC\nProblem Child\n5.4173\n5.1110\n\n\nAC/DC\nBad Boy Boogie\n4.4621\n5.1110\n\n\nAC/DC\nGo Down\n5.5197\n5.1110\n\n\n\n\nWindow functions\n\nCUME_DIST Calculate the cumulative distribution of a value in a set of values\nDENSE_RANK Assign a rank value to each row within a partition of a result, with no gaps in rank values.\nFIRST_VALUE Get the value of the first row in an ordered partition of a result set.\nLAG Provide access to a row at a given physical offset that comes before the current row.\nLAST_VALUE Get the value of the last row in an ordered partition of a result set.\nLEAD Provide access to a row at a given physical offset that follows the current row.\nNTILE Distribute rows of an ordered partition into a number of groups or buckets\nPERCENT_RANK Calculate the percent rank of a value in a set of values.\nRANK Assign a rank value to each row within a partition of a result set\nROW_NUMBER Assign a unique sequential integer to rows within a partition of a result set, the first row starts from 1.\n\nhttps://www.sqlservertutorial.net/sql-server-window-functions/"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#subqueries",
    "href": "posts/2022-07-07-SQL.html#subqueries",
    "title": "ThomasHSimm",
    "section": "Subqueries",
    "text": "Subqueries\nThese are queries within other queries Which merge data from multiple sources together\nget customerid and city when their invoice total is more than 20\nselect CustomerID, City\nfrom customers\nwhere customerid in (select customerid\nfrom invoices\nwhere total>20)\n\n\n\nCustomerId\nCity\n\n\n\n\n6\nPrague\n\n\n26\nFort Worth\n\n\n45\nBudapest\n\n\n46\nDublin\n\n\n\nHow many albums does the band LEd Zeppelin have?\nselect count(*)\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Led Zeppelin')\n\n\n\ncount(*)\n\n\n\n\n14\n\n\n\nOr what are the name of the tracks for the artist Audioslave?\nselect Name\nfrom tracks\nwhere albumid IN\n(select albumid\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Audioslave'))\n\n\n\nName\n\n\n\n\nCochise\n\n\nShow Me How to Live\n\n\nGasoline\n\n\nWhat You Are\n\n\nLike a Stone\n\n\nSet It Off\n\n\nShadow on the Sun\n\n\nI am the Highway\n\n\nExploder\n\n\nHypnotize"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#joins",
    "href": "posts/2022-07-07-SQL.html#joins",
    "title": "ThomasHSimm",
    "section": "Joins",
    "text": "Joins\n\nefficient storage\neasier manipulation\ngreater scalability\nlogically models a process\ntables are related through common values or keys\ndata retrival from multiple tables in one query\nonly persist for the duration of the query\n\n\nCartesian cross joins\n\neach row from first table joins with all rows from the other table\noutput size of joins in A multiplied rows in B\ncomputationally taxing\nrarely used\n\n\nselect a.title, ar.name from albums as a\ncross join artists as ar\norder by a.title\n\n\n\nTitle\nName\n\n\n\n\n…And Justice For All\nAC/DC\n\n\n…And Justice For All\nAccept\n\n\n\ntotal rows = 95425\ntotal rows of albums = 347\ntotal rows of artists = 275\n\n\nInner join\n\nselect records that have matching values in both tables\nUse on to select what joining on\njoining more table affects database performance\nCan join multiple tables- no limit\n\n\nFor example get the artist name and title of each album. N.B. albums has columns AlbumID, Title and ArtistID only\nselect artists.Name, albums.Title\nfrom artists\nINNER JOIN albums\non artists.artistid = albums.artistID\n\n\n\nName\nTitle\n\n\n\n\nAC/DC\nFor Those About To Rock We Salute You\n\n\nAC/DC\nLet There Be Rock\n\n\nAccept\nBalls to the Wall\n\n\nAccept\nRestless and Wild\n\n\nAerosmith\nBig Ones\n\n\nAlanis Morissette\nJagged Little Pill\n\n\nAlice In Chains\nFacelift\n\n\nAntônio Carlos Jobim\nWarner 25 Anos\n\n\nAntônio Carlos Jobim\nChill: Brazil (Disc 2)\n\n\nApocalyptica\nPlays Metallica By Four Cellos\n\n\n\nOr as a multiple join\nSELECT o.orderId, c.CompanyName, e.LastName\nFROM ((orders o INNER JOIN customers c ON o.customerID = c.CustomerID)\n`INNER JOIN employees e ON o.EmployeeID = e.EmployeeID);\n\n\nSelf joins\n\nTakes the table and treats it like two separate tables\nJoin the original table to itself\n\nFor example, match cities from the same state\nselect A.city,A.state,B.city, B.state\nfrom station A, station B\nwhere A.city=B.city\nand A.state=B.state\norder by A.state;\n\n\n\ncity A\nstate A\ncity B\nstate B\n\n\n\n\nSeward\nAK\nSeward\nAK\n\n\nChignik Lagoon\nAK\nChignik Lagoon\nAK\n\n\nFive Points\nAL\nFive Points\nAL\n\n\nGroveoak\nAL\nGroveoak\nAL\n\n\nNotasulga\nAL\nNotasulga\nAL\n\n\nJackson\nAL\nJackson\nAL\n\n\n….\n….\n….\n…."
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#advanced-joins",
    "href": "posts/2022-07-07-SQL.html#advanced-joins",
    "title": "ThomasHSimm",
    "section": "Advanced Joins",
    "text": "Advanced Joins\n\nLeft Joins\nReturns all records from the left table and the matched records from the righ table\nThe result is NULL from the right hand side if there is no match\nRight joins are the same but from the RHS. Can be converted to left join by reversing the order\n\nFor example, find all the customers who have an invoice\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nLEFT JOIN invoices i on c.customerid = i.customerid\norder by c.customerid\n\n\n\nFirstName\nLastName\nInvoiceId\n\n\n\n\nLuís\nGonçalves\n98\n\n\nLuís\nGonçalves\n121\n\n\nLuís\nGonçalves\n143\n\n\nLuís\nGonçalves\n195\n\n\nLuís\nGonçalves\n316\n\n\nLuís\nGonçalves\n327\n\n\nLuís\nGonçalves\n382\n\n\nLeonie\nKöhler\n1\n\n\nLeonie\nKöhler\n12\n\n\nLeonie\nKöhler\n67\n\n\nLeonie\nKöhler\n196\n\n\nLeonie\nKöhler\n219\n\n\nLeonie\nKöhler\n241\n\n\nLeonie\nKöhler\n293\n\n\nFrançois\nTremblay\n99\n\n\n\n\n\nFull outer join\nReturns all records where there is a match in either table\n“Give me everything”\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nFULL OUTER JOIN invoices i on c.customerid = i.customerid\norder by c.customerid"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#unions",
    "href": "posts/2022-07-07-SQL.html#unions",
    "title": "ThomasHSimm",
    "section": "Unions",
    "text": "Unions\nCombine two or more select statements - Each select must have the same number of columns - Columns must have similar data types - Columns in the same order - Less commonly used\ne.g. combine two string statements, the first a list of occupations and the second a summary of the above\n(select concat(name,'(',substr(occupation,1,1),')') from occupations)\nunion\n(select concat('There are a total number of ',count(*),' ',occupation,'s.')\nfrom occupations\ngroup by occupation\norder by count(occupation));"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#substr",
    "href": "posts/2022-07-07-SQL.html#substr",
    "title": "ThomasHSimm",
    "section": "Substr",
    "text": "Substr\nReturns part of a string\nsubstr(string name, string position, number of characters to return)\nIf string position is negative counts from the end\ne.g., find city names that start and end with a vowel\nselect city from station\nwhere substr(city,1,1) in ('a','e','i','o','u')\nand substr(city,-1,1) in ('a','e','i','o','u')"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#others",
    "href": "posts/2022-07-07-SQL.html#others",
    "title": "ThomasHSimm",
    "section": "Others",
    "text": "Others\nLimit 1 limit the results to 1\nconcat combine multiple parts\nselect concat(name, '(', substr(occupation,1,1), ')')\nfrom occupations\nround(X,5)\nrounds X to 5 decimal places\nor round(x) to nearest integer"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#mode",
    "href": "posts/2022-07-07-SQL.html#mode",
    "title": "ThomasHSimm",
    "section": "Mode",
    "text": "Mode\nMode seems like a good free way to perform SQL. I’ve yet to work out if the course provided me a link to access datasets or if these are freely available for everyone opeing a new account. The website is not easy to navigate and I only found access to my workspaces from a link I saved and not from links on the website.\nhttps://app.mode.com/thomassimm/reports/e9412b22b846/runs/c4e7c78695f3\n\nSpark SQL\n\nhttps://files.training.databricks.com/courses/ucdavis/Lessons.dbc\nSpark SQL and DataFrames and Datasets Guides -SQL Guide from Databricks\nLearning Spark, 2nd Edition (eBook compliments of Databricks).\nIntroduction - The Internals of Spark SQL (free gitbook)"
  },
  {
    "objectID": "posts/2022-07-07-SQL.html#appendix",
    "href": "posts/2022-07-07-SQL.html#appendix",
    "title": "ThomasHSimm",
    "section": "Appendix",
    "text": "Appendix\nhttps://dev.mysql.com/doc/refman/8.0/en/union.html\nhttps://www.w3schools.com/sql/default.asp\nhttps://blog.sqlauthority.com/category/sql-puzzle/\nhttps://sqlzoo.net/wiki/SQL_Tutorial\nhttps://mode.com/sql-tutorial/introduction-to-sql\nhttps://www.postgresql.org/docs/9.1/tutorial.html\nhttps://www.coursera.org/specializations/learn-sql-basics-data-science#courses"
  },
  {
    "objectID": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#background",
    "href": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#background",
    "title": "ThomasHSimm",
    "section": "Background",
    "text": "Background\nI did some initial plots on the changes in the characteristics of athletes given in the data, height, weight and age, of athletes attending the Olympics by year (see below).\nFrom these plots I was really intrigued as to what may be the cause of these changes.\nMainly what was happening between 1960 and 1980 were there seemed to be changes in each of the parameters?\nMy initial thought was this could be related to some combination of - a switch from amateurs to professionals - the Cold War between USA and USSR - an after effect of WWII\n\n\n\n\nOlympic Background\nThroughout much of the Olympic’s history there has been tension around professionals and amateur athletes. The games were intended for amateur athletes, and those who played sport professionally were banned or even had their medals stripped.\nThe reasoning behind amateurism was based on how sport was seen by the aristrocracy and greatly influenced Pierre de Coubertin, who is thought of as the father of the Olympic games:\n\"There was also a prevailing concept of fairness, in which practising or training was considered tantamount to cheating.[2] Those who practised a sport professionally were considered to have an unfair advantage over those who practised it merely as a hobby.[2]\"\nThe Soviet Union, who competed from 1952-1988, entered teams of athletes who were all nominally students, soldiers, or working in a profession, but all of whom were in reality paid by the state to train on a full-time basis.[3] The situation greatly disadvantaged American and Western European athletes, and was a major factor in the decline of American medal hauls in the 1970s and 1980s. However, workarounds in Western countries also allowed individuals to focus full-time on sport while passing the amateur rules.[4]\nThis abuse of amateur rules by the Eastern Bloc nations prompted the IOC to shift away from pure amateurism.The rules were steadily relaxed from 1972, amounting only to technicalities and lip service, until being completely abandoned in the 1990s\n\nWikipedia Olympic Games And Amateurism\nEassom 1994, pp. 120–123\n“The Role of Sports in The Soviet Union – Guided History”. blogs.bu.edu.\nDegrees of Difficulty: How Women’s Gymnastics Rose to Prominence and Fell from Grace”, by Georgia Cervin"
  },
  {
    "objectID": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#load-data-and-libraries",
    "href": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandasql import sqldf\nimport copy\nimport numpy as np\nimport scipy.stats\n\n\ndf_F_S =pd.read_csv('athlete_F_S')\ndf_F_W=pd.read_csv('athlete_F_W')\ndf_M_S=pd.read_csv('athlete_M_S')\ndf_M_W=pd.read_csv('athlete_M_W')\n\ndf_all_athletes= pd.read_csv('all_athletes')\ndf_country= pd.read_csv('country')\ndf_event= pd.read_csv('event')\n# df_games= pd.read_csv('games')\n# df_population= pd.read_csv('population')\n\n# df_country = df_country.groupby('NOC').max()\n# df_country.head(10)"
  },
  {
    "objectID": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#what-are-the-best-weight-height-age",
    "href": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#what-are-the-best-weight-height-age",
    "title": "ThomasHSimm",
    "section": "What are the best Weight, Height, Age?",
    "text": "What are the best Weight, Height, Age?\nObviously this will depend on event. But if we average across events what are - the best of values of these? - and how do these change with time?\nTo get this figure the methodology is fairly simple, in the SQL query: - We take the average of weight, height, age across years and medal type - Because we want a simple binary answer (medal or not) we create a variable called medal which is 1 if they got a medal and 0 otherwise - We then group on this and take an average - The two function below are just so we can plot for avg_weight, avg_height and avg_age without repeating the same steps\nhere Male summer athletes are used but the result for female summer athletes show the same trend\n\nmedalQ=sqldf('\\\n    SELECT                                 \\\n        Year,                              \\\n        medal,                             \\\n        AVG(avg_weight)    AS avg_weight,  \\\n        AVG(avg_height)    AS avg_height,  \\\n        AVG(avg_age)       AS avg_age      \\\n    FROM                                   \\\n         (SELECT                           \\\n         Year,                             \\\n         MAX(Medal_Gold,Medal_Silver,Medal_Bronze)\\\n                           AS medal,       \\\n         avg(Weight)       AS avg_weight,  \\\n         AVG(Height)       AS avg_height,  \\\n         AVG(age)          AS avg_age      \\\n         from df_M_S                       \\\n         group by                          \\\n             Year,                         \\\n             Medal_Gold,Medal_Silver,Medal_Bronze           \\\n         order by Year asc) A              \\\n     GROUP BY Year, medal;',locals())  \nmedalQ.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      medal\n      avg_weight\n      avg_height\n      avg_age\n    \n  \n  \n    \n      0\n      1896\n      0\n      70.444444\n      169.916667\n      23.896552\n    \n    \n      1\n      1896\n      1\n      71.551282\n      175.217949\n      23.211671\n    \n    \n      2\n      1900\n      0\n      76.971429\n      175.054545\n      29.428571\n    \n    \n      3\n      1900\n      1\n      72.711355\n      178.202932\n      28.454139\n    \n    \n      4\n      1904\n      0\n      71.742424\n      175.131579\n      26.752080\n    \n  \n\n\n\n\n\ndef modname(string):\n    string=''.join([string[0].upper(),string[1:].lower()])\n    string=string.replace('_',' ')\n    return string\n    \ndef plotMedal(plotchoi,medalQ):\n    plt.subplots(figsize=(8,5))\n    plt.plot(medalQ[medalQ.medal==1].Year,medalQ[medalQ.medal==1][plotchoi],'g*-')\n\n    plt.plot(medalQ[medalQ.medal==0].Year,medalQ[medalQ.medal==0][plotchoi],'rv--')\n\n    plt.legend(['Medal','No medal'])\n    plt.grid(True)\n    plt.xlabel('Year')\n    plt.ylabel(modname(plotchoi))\n\n\nplotchoi='avg_height'\nplotMedal(plotchoi,medalQ)\n\nplotchoi='avg_weight'\nplotMedal(plotchoi,medalQ)\n\nplotchoi='avg_age'\nplotMedal(plotchoi,medalQ)\nplt.ylim([18,40])\n\n(18.0, 40.0)\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer: What is the best weight, height and age?\n\nAge, height and weight of athletes change with year\nAfter the initial years (> ~1930)\n\nAthletes who get more medals have greater height and weight\nWhereas, the age is indistinguishable"
  },
  {
    "objectID": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#the-change-in-athletes-based-on-weight-height-and-age",
    "href": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#the-change-in-athletes-based-on-weight-height-and-age",
    "title": "ThomasHSimm",
    "section": "The change in athletes based on weight, height and age",
    "text": "The change in athletes based on weight, height and age\nHere the methodology used to produce the figures in the background section is presented.\nThe method is fairly simple, we just use each athlete table and then GROUP BY year and take the averages\n\ndf_F=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_F_S AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\ndf_M=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_M_S AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\n               \ndf_Fw=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_F_W AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\ndf_Mw=\\\n     sqldf('SELECT                              \\\n              Year,                             \\\n               avg(Height) AS avg_height,       \\\n               avg(Weight) AS avg_weight,       \\\n               avg(Age)    AS avg_age           \\\n            FROM                                \\\n                df_M_W AS d                     \\\n            GROUP BY                            \\\n               Year                             \\\n            ORDER BY                            \\\n                Year asc;',locals())\n               \ndf_F.head()                    \n\n\n\n\n\n  \n    \n      \n      Year\n      avg_height\n      avg_weight\n      avg_age\n    \n  \n  \n    \n      0\n      1900\n      NaN\n      NaN\n      29.791667\n    \n    \n      1\n      1904\n      NaN\n      NaN\n      50.230769\n    \n    \n      2\n      1906\n      NaN\n      NaN\n      23.500000\n    \n    \n      3\n      1908\n      NaN\n      NaN\n      33.897436\n    \n    \n      4\n      1912\n      NaN\n      NaN\n      22.379310\n    \n  \n\n\n\n\n\ndef yrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_weight'): \n    cola=['r>','b<','mo','cs']\n\n    plt.subplots(figsize=(6,4))\n    plt.plot(df_F.Year,df_F[whatplot],cola[0],markersize=10)\n\n    plt.plot(df_M.Year,df_M[whatplot],cola[1],markersize=10)\n\n    plt.plot(df_Fw.Year,df_Fw[whatplot],cola[2])\n    plt.plot(df_Mw.Year,df_Mw[whatplot],cola[3])\n\n    def doPlot(df_F,avgNo,whatplot,col,lw):\n        bb = df_F.Year.rolling(avgNo).mean()\n        cc = df_F[whatplot]\n        cc = cc.rolling(avgNo).mean()\n        plt.plot(bb,cc,col,linewidth=lw)\n\n    doPlot(df_F,3,whatplot,'r-',4)\n    doPlot(df_M,3,whatplot,'b-',4)\n\n    doPlot(df_Fw,3,whatplot,'m--',2)\n    doPlot(df_Mw,3,whatplot,'c--',2)\n\n    plt.legend(['Female Summer','Male Summer','Female Winter','Male Winter'])\n    plt.ylabel(modname(whatplot),fontsize=14)\n    plt.xlabel('Year',fontsize=14)\n    plt.xlim([1890, 2020])\n    plt.grid(True)\n\n\nyrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_weight')\nyrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_height')\nyrplot(df_F,df_M,df_Fw,df_Mw,whatplot= 'avg_age')\nplt.ylim([18,35]);\n\n\n\n\n\n\n\n\n\n\n\nAre the changes due to changes in athletes or changes in the Olympics?\n\nJoin athlete table df_M_S with event table df_event\n\nUse this to get a list of events and the year they occur\n\nGroup this table\n\nTo get which event meet criteria of a minimum date, maximum date and having occured so many times\n\n\n(select\nEvent_id\n……\nAND max(year)>1990) usea\n\nGroup the table of events with the athlete table df_M_S\nTake the average over the events and year\nTake this average just over year\n\nThis stops changes due to changes in number of athletes in a particular event\n\n\nThere are 15-20 events included in the results below. Although, a relatively low figure this still represents a lot of athletes. Furthermore, when we split these events into 2 the same trends we find in all the data are seen in the two splits. The absolute values can differ but the min./max. values seem to fairly consistent. But obviously more exploration would be beneficial if this is led by theories or experts in the areas. Without this we could spend forever looking for trends.\n\n# --find events that have occured more than a set amount within a range of dates\n# -- i.e. events that can focus on to see results of changes with time\n\ndef do_same_event(df_M_S,df_F_S,df_event,athlete_df_name='df_M_S',counta='17',yr_start='1900',yr_end='1990'):\n    tempa= sqldf('                               \\\n    SELECT                                   \\\n        Year,                                \\\n        avg(wgt)            AS avg_weight,   \\\n        avg(hgt)            AS avg_height,   \\\n        avg(aga)            AS avg_age       \\\n    FROM                                     \\\n        (SELECT                              \\\n        Year,                                \\\n        AVG(weight)         AS wgt,          \\\n        AVG(height)         AS hgt,          \\\n        AVG(age)            AS aga           \\\n        FROM                                 \\\n        (SELECT                              \\\n          Event_id                           \\\n        FROM                                 \\\n            (SELECT                          \\\n            E.Event_id,                      \\\n            Year,                            \\\n            count(*)        AS counta        \\\n            FROM                             \\\n                {0}         AS A             \\\n            LEFT JOIN                        \\\n                df_event    AS E             \\\n            ON                               \\\n                E.event_id = A.event_id      \\\n            GROUP BY                         \\\n                E.Event_id,                  \\\n                Year                         \\\n            ORDER BY year asc) AA            \\\n        GROUP BY AA.Event_id                 \\\n        HAVING COUNT(*) >{1}                 \\\n        AND MIN(year)<{2}                    \\\n        AND MAX(year)>{3}                    \\\n        ORDER BY event_id asc                \\\n        LIMIT 80) usea                       \\\n        LEFT JOIN                            \\\n            {0}              AS a            \\\n        ON                                   \\\n            usea.event_id = a.event_id       \\\n        GROUP BY                             \\\n            year,                            \\\n            usea.event_id                    \\\n        ORDER BY year asc) two               \\\n        GROUP BY year;'.format(athlete_df_name,counta,yr_start,yr_end),locals())\n    return tempa\n\n\ntempaM = do_same_event(df_M_S,df_F_S,df_event,'df_M_S')\ntempaF = do_same_event(df_M_S,df_F_S,df_event,'df_F_S',counta='12',yr_start='1945',yr_end='1990')\n\ntempaF.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      avg_weight\n      avg_height\n      avg_age\n    \n  \n  \n    \n      0\n      1900\n      NaN\n      NaN\n      25.250000\n    \n    \n      1\n      1906\n      NaN\n      NaN\n      23.500000\n    \n    \n      2\n      1908\n      NaN\n      NaN\n      31.200000\n    \n    \n      3\n      1912\n      NaN\n      NaN\n      21.759259\n    \n    \n      4\n      1920\n      NaN\n      160.145833\n      21.737132\n    \n  \n\n\n\n\n\ndef modname(string):\n    string=''.join([string[0].upper(),string[1:].lower()])\n    string=string.replace('_',' ')\n    return string\n\ndef yrplot1(df_F,df_M,whatplot): \n    cola=['r>','b<','mo','cs']\n\n    fig,ax=plt.subplots(figsize=(8,5))\n    ax.plot(df_F.Year,df_F[whatplot],cola[0],markersize=10)\n    ax2=ax.twinx()\n    ax2.plot(df_M.Year,df_M[whatplot],cola[1],markersize=10)\n\n#     plt.plot(df_Fw.Year,df_Fw[whatplot],cola[2])\n#     plt.plot(df_Mw.Year,df_Mw[whatplot],cola[3])\n\n\n    def doPlot(df_F,avgNo,whatplot,col,lw,xx):\n        bb = df_F.Year.rolling(avgNo).mean()\n        cc = df_F[whatplot]\n        cc = cc.rolling(avgNo).mean()\n        xx.plot(bb,cc,col,linewidth=lw)\n\n    doPlot(df_F,3,whatplot,'r-',4,ax)\n    doPlot(df_M,3,whatplot,'b-',4,ax2)\n\n#     doPlot(df_Fw,3,whatplot,'m--',2)\n#     doPlot(df_Mw,3,whatplot,'c--',2)\n\n    fig.legend(['Female Summer','-','Male Summer','-'],loc='upper center')#,'Female Winter','Male Winter'])\n    ax.set_ylabel('Female ' + modname(whatplot),fontsize=14)\n    ax2.set_ylabel('Male ' + modname(whatplot),fontsize=14)\n    ax.set_xlabel('Year',fontsize=14)\n    plt.xlim([1890, 2020])\n    ax2.grid(True)\n    \n\n\nyrplot1(tempaF,tempaM,whatplot= 'avg_weight')\nyrplot1(tempaF,tempaM,whatplot= 'avg_height')\nyrplot1(tempaF,tempaM,whatplot= 'avg_age')\n# no limit"
  },
  {
    "objectID": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#the-cold-war",
    "href": "posts/2022-07-20-OlympicsSQL-HeightWeightAge.html#the-cold-war",
    "title": "ThomasHSimm",
    "section": "The Cold War",
    "text": "The Cold War\n\ndef yrplot(df__,whatplot= 'avg_weight'): \n    \n    countries=['EST', 'EUN' ,'ROW', 'USA' ,'WES']\n    \n#     df__.NOCSMALL.unique()\n#     countries=np.sort(countries)\n    print(countries)\n    cola=['>','o','+','*','<']\n    colur=[[1,0.6,.6],[1,0,0],[.5,.5,.5],[0,0,1],[.6,.6,1]]\n#     ['EST' 'EUN' 'ROW' 'USA' 'WES']\n#     'EST','USA','WES','ROW','EUN'\n\n    fig,ax1=plt.subplots(figsize=(8,5))\n    \n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1.plot(df__[df__.NOCSMALL==country].Year,\\\n                 df__[df__.NOCSMALL==country][whatplot],\\\n                 marker=cola[i],linestyle='None',color=colur[i]\\\n                 ,markersize=10)\n\n\n    def doPlot(df_F,avgNo,whatplot,country,col,lw,ax1):\n        bb = df_F[df__.NOCSMALL==country].Year.rolling(avgNo).mean()\n        cc = df_F[df__.NOCSMALL==country][whatplot]\n        cc = cc.rolling(avgNo).mean()\n        ax1.plot(bb,cc,linewidth=lw,color=col)\n        return ax1\n\n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1=doPlot(df__,avgNo=3,whatplot=whatplot,country=country,col=colur[i],lw=3,ax1=ax1)\n    \n    lega = ['East Europe','Russia','USA','West Europe']\n    plt.legend(lega)\n    plt.grid(True)\n    plt.ylabel(modname(whatplot))\n    \n    return ax1\n\n\ndef get_df_USA_USSR(df_M_S,df_F_S,nameDF):\n    USA_USSR=sqldf(\\\n           'SELECT                            \\\n              Year,                           \\\n              NOCSMALL,                       \\\n              AVG(avg_height)  AS avg_height, \\\n              AVG(avg_weight)  AS avg_weight, \\\n              AVG(avg_age)     AS avg_age,    \\\n              SUM(number_of_athletes) AS number_of_athletes         \\\n           FROM                                    \\\n               (SELECT                             \\\n                   Year,                           \\\n                   AVG(avg_height)  AS avg_height, \\\n                   AVG(avg_weight)  AS avg_weight, \\\n                   AVG(avg_age)     AS avg_age,    \\\n                   SUM(num_ath) AS number_of_athletes,        \\\n                   CASE                                \\\n                       WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n                       WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n                       WHEN NOC=\"USA\" THEN \"USA\"       \\\n                       WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n                       ELSE \"ROW\"\\\n                   END AS NOCSMALL,                     \\\n                   NOC\\\n               FROM                               \\\n                  (SELECT                         \\\n                  Year,                           \\\n                  NOC,                            \\\n                  avg(Height) AS avg_height,      \\\n                  avg(Weight) AS avg_weight,      \\\n                  avg(Age)    AS avg_age,         \\\n                  count(*)    AS num_ath          \\\n                  FROM                            \\\n                    {} AS d                       \\\n                  GROUP BY                        \\\n                    Year,NOC                      \\\n                  ORDER BY                        \\\n                    Year asc) A                   \\\n              GROUP BY                            \\\n                Year,NOC) B                       \\\n           GROUP BY Year, NOCSMALL ;'.format(nameDF),locals())\n    return USA_USSR\n\n\ndef do_USA_USSR(df_M_S,df_F_S,men_women,whatplot):\n    if men_women=='men':\n        nameDF='df_M_S'\n    elif men_women=='women':\n        nameDF='df_F_S'\n    \n        \n    USA_USSR_F = get_df_USA_USSR(df_M_S,df_F_S,nameDF)\n    ax1=yrplot(USA_USSR_F,whatplot)\n    \n    return ax1\n    \n    \n\n\ndo_USA_USSR(df_M_S,df_F_S,'men','avg_weight')\nplt.ylim([65, 90])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n(65.0, 90.0)\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'women','avg_weight')\nplt.ylim([50, 70])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n(50.0, 70.0)\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'men','avg_height')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Avg height'>\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'women','avg_height')\n# plt.ylim([65, 90])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Avg height'>\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'men','avg_age')\n# plt.ylim([65, 90])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Avg age'>\n\n\n\n\n\n\ndo_USA_USSR(df_M_S,df_F_S,'women','avg_age')\nplt.ylim([18, 35])\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n(18.0, 35.0)\n\n\n\n\n\n\ndef number_of_athletes_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"F\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         group by athlete_ID,Year               \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL               \\\n     UNION ALL                                 \\\n     SELECT                                \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"M\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         group by athlete_ID,Year          \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL;',locals()  )\n    return testa2\n\ndef number_of_medals_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n            COUNT(*) AS number_of_medals,\\\n            Year, Sex, NOCSMALL\\\n        FROM \\\n        (SELECT NOCSMALL,Year,Sex,COUNT(*) AS counta\\\n        FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"F\"   AS Sex,                      \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         UNION ALL                                 \\\n         SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"M\" AS Sex,                       \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         order by Year asc) A\\\n     GROUP BY \\\n         Year, NOCSMALL,event_id,Medal_Gold,Medal_Silver,Medal_Bronze)  AS B\\\n GROUP BY Year, NOCSMALL, Sex\\\n                 ;',locals()  )                                       \n    return testa2\n\n\nUSA_USSR_medals=number_of_medals_USA_USSR(df_F_S,df_M_S)\nUSA_USSR_athletes=number_of_athletes_USA_USSR(df_F_S,df_M_S)\n\n\nUSA_USSR_medals.head()\n\n\n\n\n\n  \n    \n      \n      number_of_medals\n      Year\n      Sex\n      NOCSMALL\n    \n  \n  \n    \n      0\n      11\n      1896\n      M\n      EST\n    \n    \n      1\n      61\n      1896\n      M\n      ROW\n    \n    \n      2\n      19\n      1896\n      M\n      USA\n    \n    \n      3\n      29\n      1896\n      M\n      WES\n    \n    \n      4\n      2\n      1900\n      F\n      EST\n    \n  \n\n\n\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='F'],whatplot= 'number_of_medals')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of medals'>\n\n\n\n\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='M'],whatplot= 'number_of_medals')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of medals'>\n\n\n\n\n\n\nyrplot(USA_USSR_athletes[USA_USSR_athletes.Sex=='F'],whatplot= 'number_of_athletes')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of athletes'>\n\n\n\n\n\n\nyrplot(USA_USSR_athletes[USA_USSR_athletes.Sex=='M'],whatplot= 'number_of_athletes')\n\n['EST', 'EUN', 'ROW', 'USA', 'WES']\n\n\n<AxesSubplot:ylabel='Number of athletes'>"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createCountryDF.html#overview",
    "href": "posts/2022-07-29-OlympicsSQL_createCountryDF.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\nThe country table needed extra analysis so I seperated it from the rest of the analysis.\nIt also requires importing some new data, which I will add here too\n\nimport pandas as pd\nfrom pandasql import sqldf\nimport matplotlib.pyplot as plt\nimport re \n\n\ndf= pd.read_csv(\"athlete_events.csv\")\ndf2=pd.read_csv(\"noc_regions.csv\")\n\nThe next line is just to add a unique ID for athletes when the data is split up later\n\ndf= df.reset_index()\ndf.rename(columns={'index':'event_athlete_ID','ID':'athlete_ID'},inplace=True)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n  \n\n\n\n\n\ndf2.head()\n\n\n\n\n\n  \n    \n      \n      NOC\n      region\n      notes\n    \n  \n  \n    \n      0\n      AFG\n      Afghanistan\n      NaN\n    \n    \n      1\n      AHO\n      Curacao\n      Netherlands Antilles\n    \n    \n      2\n      ALB\n      Albania\n      NaN\n    \n    \n      3\n      ALG\n      Algeria\n      NaN\n    \n    \n      4\n      AND\n      Andorra\n      NaN\n    \n  \n\n\n\n\n\nWhat do we use to value to identify a nation\n\nprint('There are {} unique teams and {} unique NOCs in df.\\n     \\\nAnd {} unique NOC values, {} unique regions and {} unique notes in df2.'.format( \\\n    len(pd.unique(df.Team)),len(pd.unique(df.NOC)), \n    len(pd.unique(df2.region)),len(pd.unique(df2.region)),len(pd.unique(df2.notes)) ))\n\n\nThere are 1184 unique teams and 230 unique NOCs in df.\n     And 207 unique NOC values, 207 unique regions and 22 unique notes in df2.\n\n\n1184 Seems a lot of teams to consider, it may be best to stick with using NOC as a unique identifier for a country. We can then probably use regions as the name of the country.\nLet’s have a look at the values of teams,NOC and regions\n\nsqldf(\"SELECT                                \\\n         NOC,                                \\\n         Team,                               \\\n         count(*)                            \\\n       FROM                                  \\\n         df                                  \\\n       GROUP BY                              \\\n         Team, NOC                           \\\n       ORDER BY team DESC                    \\\n       LIMIT 30;\",locals())\n\n\n\n\n\n  \n    \n      \n      NOC\n      Team\n      count(*)\n    \n  \n  \n    \n      0\n      FIN\n      rn-2\n      5\n    \n    \n      1\n      BEL\n      Zut\n      3\n    \n    \n      2\n      ZIM\n      Zimbabwe\n      309\n    \n    \n      3\n      GRE\n      Zefyros\n      2\n    \n    \n      4\n      ZAM\n      Zambia\n      183\n    \n    \n      5\n      YUG\n      Yugoslavia-2\n      10\n    \n    \n      6\n      YUG\n      Yugoslavia-1\n      10\n    \n    \n      7\n      YUG\n      Yugoslavia\n      2558\n    \n    \n      8\n      SUI\n      Ylliam VIII\n      5\n    \n    \n      9\n      SUI\n      Ylliam VII\n      6\n    \n    \n      10\n      SUI\n      Ylliam II\n      5\n    \n    \n      11\n      GBR\n      Yeoman XII\n      3\n    \n    \n      12\n      GBR\n      Yeoman VII\n      3\n    \n    \n      13\n      RSA\n      Yeoman V\n      3\n    \n    \n      14\n      BAH\n      Yeoman\n      4\n    \n    \n      15\n      YEM\n      Yemen\n      32\n    \n    \n      16\n      MYA\n      Yangon\n      2\n    \n    \n      17\n      MEX\n      Xolotl\n      3\n    \n    \n      18\n      FIN\n      Xantippa\n      3\n    \n    \n      19\n      GBR\n      Wolseley-Siddeley-1\n      4\n    \n    \n      20\n      CAN\n      Winnipeg Shamrocks-1\n      12\n    \n    \n      21\n      CAN\n      Windor\n      2\n    \n    \n      22\n      NED\n      Willem-Six\n      3\n    \n    \n      23\n      ARG\n      Wiking\n      5\n    \n    \n      24\n      USA\n      Widgeon\n      2\n    \n    \n      25\n      FRA\n      Whitini Star\n      1\n    \n    \n      26\n      DEN\n      White Lady\n      3\n    \n    \n      27\n      JPN\n      Whisper\n      1\n    \n    \n      28\n      CAN\n      Whirlaway\n      2\n    \n    \n      29\n      USA\n      Western Rowing Club-3\n      6\n    \n  \n\n\n\n\nTeam in df seems to not reflect the country very well. e.g. Whisper is not a country but JPN probably represents Japan.\nSo the use of NOC seems to make sense\nNow let us consider the NOC, region and notes variables\n\nsqldf(\"SELECT                                \\\n         NOC,                                \\\n         Region,                             \\\n         Notes,                              \\\n         count(*)                            \\\n       FROM                                  \\\n         df2                                 \\\n       GROUP BY                              \\\n         NOC, Region, Notes                  \\\n       ORDER BY Region DESC                  \\\n       LIMIT 30;\",locals())\n\n\n\n\n\n  \n    \n      \n      NOC\n      region\n      notes\n      count(*)\n    \n  \n  \n    \n      0\n      RHO\n      Zimbabwe\n      None\n      1\n    \n    \n      1\n      ZIM\n      Zimbabwe\n      None\n      1\n    \n    \n      2\n      ZAM\n      Zambia\n      None\n      1\n    \n    \n      3\n      YAR\n      Yemen\n      North Yemen\n      1\n    \n    \n      4\n      YEM\n      Yemen\n      None\n      1\n    \n    \n      5\n      YMD\n      Yemen\n      South Yemen\n      1\n    \n    \n      6\n      ISV\n      Virgin Islands, US\n      Virgin Islands\n      1\n    \n    \n      7\n      IVB\n      Virgin Islands, British\n      None\n      1\n    \n    \n      8\n      VIE\n      Vietnam\n      None\n      1\n    \n    \n      9\n      VNM\n      Vietnam\n      None\n      1\n    \n    \n      10\n      VEN\n      Venezuela\n      None\n      1\n    \n    \n      11\n      VAN\n      Vanuatu\n      None\n      1\n    \n    \n      12\n      UZB\n      Uzbekistan\n      None\n      1\n    \n    \n      13\n      URU\n      Uruguay\n      None\n      1\n    \n    \n      14\n      UAE\n      United Arab Emirates\n      None\n      1\n    \n    \n      15\n      UKR\n      Ukraine\n      None\n      1\n    \n    \n      16\n      UGA\n      Uganda\n      None\n      1\n    \n    \n      17\n      USA\n      USA\n      None\n      1\n    \n    \n      18\n      GBR\n      UK\n      None\n      1\n    \n    \n      19\n      TKM\n      Turkmenistan\n      None\n      1\n    \n    \n      20\n      TUR\n      Turkey\n      None\n      1\n    \n    \n      21\n      TUN\n      Tunisia\n      None\n      1\n    \n    \n      22\n      TTO\n      Trinidad\n      Trinidad and Tobago\n      1\n    \n    \n      23\n      WIF\n      Trinidad\n      West Indies Federation\n      1\n    \n    \n      24\n      TGA\n      Tonga\n      None\n      1\n    \n    \n      25\n      TOG\n      Togo\n      None\n      1\n    \n    \n      26\n      TLS\n      Timor-Leste\n      None\n      1\n    \n    \n      27\n      THA\n      Thailand\n      None\n      1\n    \n    \n      28\n      TAN\n      Tanzania\n      None\n      1\n    \n    \n      29\n      TJK\n      Tajikistan\n      None\n      1\n    \n  \n\n\n\n\nNOC doesn’t look unique enough for us. For example, - Zimbabwe is RHO and ZIM and this probably just reflects a name change in the country - Yemen has 3 NOC values, presumably reflecting the unification that took place in 1990. Most of these differences are not that important to what I am looking at, where it would be better to have a broader description of a nation\nSo what I will do is - use the region tag as a unique identifier of a country - replace multiple NOC values of a single country with a single NOC value\nThe first step is to identify which regions have multiple NOC values. We can do this again in SQL by creating a new table\n\nd1=sqldf(\"SELECT                               \\\n            NOC,                               \\\n            region,                            \\\n            notes,                             \\\n            count(*)                           \\\n         FROM                                  \\\n            df2                                \\\n         GROUP BY                              \\\n            region                             \\\n         HAVING COUNT(*)>1                     \\\n         ORDER BY count(*) DESC;\",locals())\nd1\n\n\n\n\n\n  \n    \n      \n      NOC\n      region\n      notes\n      count(*)\n    \n  \n  \n    \n      0\n      FRG\n      Germany\n      None\n      4\n    \n    \n      1\n      YAR\n      Yemen\n      North Yemen\n      3\n    \n    \n      2\n      SCG\n      Serbia\n      Serbia and Montenegro\n      3\n    \n    \n      3\n      EUN\n      Russia\n      None\n      3\n    \n    \n      4\n      MAL\n      Malaysia\n      None\n      3\n    \n    \n      5\n      BOH\n      Czech Republic\n      Bohemia\n      3\n    \n    \n      6\n      ROT\n      None\n      Refugee Olympic Team\n      3\n    \n    \n      7\n      RHO\n      Zimbabwe\n      None\n      2\n    \n    \n      8\n      VIE\n      Vietnam\n      None\n      2\n    \n    \n      9\n      TTO\n      Trinidad\n      Trinidad and Tobago\n      2\n    \n    \n      10\n      SYR\n      Syria\n      None\n      2\n    \n    \n      11\n      CRT\n      Greece\n      Crete\n      2\n    \n    \n      12\n      CHN\n      China\n      None\n      2\n    \n    \n      13\n      CAN\n      Canada\n      None\n      2\n    \n    \n      14\n      ANZ\n      Australia\n      Australasia\n      2\n    \n  \n\n\n\n\nWe can then create a table to get - the country, - the new NOC value for each country - all the NOC values that correspond to that country\n\nd2=sqldf(\"SELECT                            \\\n            d1.NOC      AS new_NOC,         \\\n            df2.NOC     AS orig_NOC,        \\\n            df2.region,                     \\\n            df2.notes                       \\\n          FROM                              \\\n            d1                              \\\n          LEFT JOIN                         \\\n            df2                             \\\n          ON                                \\\n            d1.region=df2.region            \\\n          ORDER BY                          \\\n            df2.region DESC;\",locals())\nd2\n\n\n\n\n\n  \n    \n      \n      new_NOC\n      orig_NOC\n      region\n      notes\n    \n  \n  \n    \n      0\n      RHO\n      RHO\n      Zimbabwe\n      None\n    \n    \n      1\n      RHO\n      ZIM\n      Zimbabwe\n      None\n    \n    \n      2\n      YAR\n      YAR\n      Yemen\n      North Yemen\n    \n    \n      3\n      YAR\n      YEM\n      Yemen\n      None\n    \n    \n      4\n      YAR\n      YMD\n      Yemen\n      South Yemen\n    \n    \n      5\n      VIE\n      VIE\n      Vietnam\n      None\n    \n    \n      6\n      VIE\n      VNM\n      Vietnam\n      None\n    \n    \n      7\n      TTO\n      TTO\n      Trinidad\n      Trinidad and Tobago\n    \n    \n      8\n      TTO\n      WIF\n      Trinidad\n      West Indies Federation\n    \n    \n      9\n      SYR\n      SYR\n      Syria\n      None\n    \n    \n      10\n      SYR\n      UAR\n      Syria\n      United Arab Republic\n    \n    \n      11\n      SCG\n      SCG\n      Serbia\n      Serbia and Montenegro\n    \n    \n      12\n      SCG\n      SRB\n      Serbia\n      None\n    \n    \n      13\n      SCG\n      YUG\n      Serbia\n      Yugoslavia\n    \n    \n      14\n      EUN\n      EUN\n      Russia\n      None\n    \n    \n      15\n      EUN\n      RUS\n      Russia\n      None\n    \n    \n      16\n      EUN\n      URS\n      Russia\n      None\n    \n    \n      17\n      MAL\n      MAL\n      Malaysia\n      None\n    \n    \n      18\n      MAL\n      MAS\n      Malaysia\n      None\n    \n    \n      19\n      MAL\n      NBO\n      Malaysia\n      North Borneo\n    \n    \n      20\n      CRT\n      CRT\n      Greece\n      Crete\n    \n    \n      21\n      CRT\n      GRE\n      Greece\n      None\n    \n    \n      22\n      FRG\n      FRG\n      Germany\n      None\n    \n    \n      23\n      FRG\n      GDR\n      Germany\n      None\n    \n    \n      24\n      FRG\n      GER\n      Germany\n      None\n    \n    \n      25\n      FRG\n      SAA\n      Germany\n      None\n    \n    \n      26\n      BOH\n      BOH\n      Czech Republic\n      Bohemia\n    \n    \n      27\n      BOH\n      CZE\n      Czech Republic\n      None\n    \n    \n      28\n      BOH\n      TCH\n      Czech Republic\n      None\n    \n    \n      29\n      CHN\n      CHN\n      China\n      None\n    \n    \n      30\n      CHN\n      HKG\n      China\n      Hong Kong\n    \n    \n      31\n      CAN\n      CAN\n      Canada\n      None\n    \n    \n      32\n      CAN\n      NFL\n      Canada\n      Newfoundland\n    \n    \n      33\n      ANZ\n      ANZ\n      Australia\n      Australasia\n    \n    \n      34\n      ANZ\n      AUS\n      Australia\n      None\n    \n    \n      35\n      ROT\n      None\n      None\n      None\n    \n  \n\n\n\n\nAnd finally replace the values of NOC in df and df2 with the new values for countries with duplicate values\nEasier to do this with Python\n\nfor i,old_NOC in enumerate(d2.orig_NOC):\n    df.loc[df.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n    df2.loc[df2.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n    \n\n\n\nGDP data\nWikipedia was used to get data on population and GDP of different countries. The data was imported using Excel’s capability to give it a url to obtain the table, and saved as different tabs in the file CountryData.xlsx. For GDP I selected the World Bank Estimate.\n\nGDP data\nPopulation data\n\nWebsite urls correct as of 23/7/22\n\ndf_GDP = pd.read_excel('CountryData.xlsx',sheet_name=2)\n\ndf_GDP=df_GDP.drop(columns=['IMF[1][12] Estimate','IMF[1][12] Year','United Nations[13] Estimate','United Nations[13] Year','World Bank[14][15] Year'])\ndf_GDP=df_GDP.rename(columns={'World Bank[14][15] Estimate':'GDP','Country/Territory':'Country','UN Region':'Continent'},errors='raise')\n\ndf_GDP.head(10)\n\n\n\n\n\n  \n    \n      \n      Country\n      Continent\n      GDP\n    \n  \n  \n    \n      0\n      World\n      -\n      84,705,567\n    \n    \n      1\n      United States\n      Americas\n      20,936,600\n    \n    \n      2\n      China\n      Asia\n      14,722,731\n    \n    \n      3\n      Japan\n      Asia\n      4,975,415\n    \n    \n      4\n      Germany\n      Europe\n      3,806,060\n    \n    \n      5\n      India\n      Asia\n      2,622,984\n    \n    \n      6\n      United Kingdom\n      Europe\n      2,707,744\n    \n    \n      7\n      France\n      Europe\n      2,603,004\n    \n    \n      8\n      Canada\n      Americas\n      1,643,408\n    \n    \n      9\n      Italy\n      Europe\n      1,886,445\n    \n  \n\n\n\n\nmake column GDP an integer, and remove the comma\n\ndf_GDP['GDP']=[x.replace(',','') for x in df_GDP['GDP']]\n\ndf_GDP['GDP']=pd.to_numeric(df_GDP['GDP'],errors='coerce').fillna(0).astype('int')\n\nWe now need to match the names of countries from the data we have found on the internet with the Olympics data.\nA good example of this is United Kingdom, which can be named several ways (with slightly different meanings) including: UK, Great Britain, Great Britain, Great Britain and Northern Ireland, GB.\nThe function changeDF_country takes the imported dataframes and df2 as inputs and outputs the imported dataframes with corrected NOC and country values\n\nChecks whether country in imported df matches region in df\n\n\nIf so country doesn’t need to be changed and can provide matching NOC value\n\n\nIf not above then see if df2.notes matches the country\n\n\nIf so can return country and NOC matching the notes that match\n\n\nIf not aboves, try some name changes, like United States to USA\n\n\nThen return the matching NOC and country and NOC matching values\n\n\nNone of the above\n\n\nThen return country given and give NOC a name to show there was no match.\nPrint out the name of the country where no match was found. To see if missing anything big or obvious\n\n\ndef getNation(region_to_check):\n       \n    if region_to_check=='United States':\n        region_out = 'USA'\n    elif bool(re.search(r'Germany', region_to_check)):\n        region_out='Germany'\n    elif region_to_check=='United Kingdom':\n        region_out = 'UK'\n    elif region_to_check=='Soviet Union':\n        region_out='Russia'\n    else:\n        region_out=region_to_check\n        print('nothing found for {}'.format(region_out))\n    \n    return region_out\n\ndef changeDF_country(df__,df2):\n    xALL,nocALL=[],[]\n    for i in range(len(df__)):\n        country_check = df__.loc[i,'Country']\n#         print(i,country_check)\n        boolCountry=df2.region==country_check\n        x=df2[boolCountry].region\n        \n        try:\n            x=str(x.iloc[0])\n            df2.loc[boolCountry,'region']=x\n        except:\n            if len(x)<1:\n                boolCountry=df2.notes==df__.loc[i,'Country']\n                x=df2[boolCountry].region\n                try:\n                    x=str(x.iloc[0])\n                    df2.loc[boolCountry,'region']=x\n                except:\n                    if len(x)<1:\n                        country_check=getNation(df__.loc[i,'Country'])\n                        boolCountry=df2.region==country_check\n                        x=df2[boolCountry].region\n                        try:\n                            x=str(x.iloc[0])\n                            df2.loc[boolCountry,'region']=x\n                        except:\n                            x=country_check\n        xALL.append(x)\n        try:\n            nocALL.append(df2[boolCountry].NOC.iloc[0])\n        except:\n            nocALL.append('---')\n            \n#         print('x= ',x)\n#         print('-------------------')\n#         if i==42:\n#             break\n#     print(nocALL)\n    try:\n        df__.insert(1,'NOC',nocALL)\n        df__.insert(1,'Nation',xALL)#,'Nation',xALL})\n    except:\n        print('done allready')\n    return df__\n        \n\n\ndf_GDP=changeDF_country(df_GDP,df2)\n\nnothing found for World\nnothing found for DR Congo\nnothing found for Bolivia\nnothing found for Macau\nnothing found for Congo\nnothing found for North Macedonia\nnothing found for New Caledonia\nnothing found for French Polynesia\nnothing found for Eswatini\nnothing found for Greenland\nnothing found for Curaçao\nnothing found for East Timor\nnothing found for Zanzibar\nnothing found for British Virgin Islands\nnothing found for Northern Mariana Islands\nnothing found for Saint Kitts and Nevis\nnothing found for Saint Vincent and the Grenadines\nnothing found for Sint Maarten\nnothing found for São Tomé and Príncipe\nnothing found for Anguilla\nnothing found for Montserrat\n\n\n\n\nPopulation table\nThe same thing as above but for the population data\n\ndf_population = pd.read_excel('CountryData.xlsx',sheet_name=0)\ndf_population.head(5)\n\n\n\n\n\n  \n    \n      \n      Rank\n      Country / Dependency\n      UN Region\n      Population\n      Percentage of the world\n      Date\n      Source (official or from the United Nations)\n      Notes\n      Column9\n    \n  \n  \n    \n      0\n      –\n      World\n      NaN\n      7965207000\n      1.0000\n      2022-07-20\n      UN projection[2]\n      NaN\n      NaN\n    \n    \n      1\n      1\n      China\n      Asia\n      1412600000\n      0.1770\n      2021-12-31\n      National annual estimate\n      The population figure refers to mainland China...\n      NaN\n    \n    \n      2\n      2\n      India\n      Asia\n      1373761000\n      0.1720\n      2022-03-01\n      Annual national estimate\n      The figure includes the population of Indian-a...\n      NaN\n    \n    \n      3\n      3\n      United States\n      Americas\n      332906919\n      0.0418\n      2022-07-20\n      National population clock\n      The figure includes the 50 states and the Dist...\n      NaN\n    \n    \n      4\n      4\n      Indonesia\n      Asia\n      272248500\n      0.0342\n      2021-07-01\n      National annual estimate\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\ndf_population.drop(columns=['Percentage of the world','Date','Source (official or from the United Nations)','Column9','Notes'],inplace=True)\ndf_population=df_population.rename(columns={'Country / Dependency':'Country','UN Region':'Continent'},errors='raise')\n\ndf_population\n\n\n\n\n\n  \n    \n      \n      Rank\n      Country\n      Continent\n      Population\n    \n  \n  \n    \n      0\n      –\n      World\n      NaN\n      7965207000\n    \n    \n      1\n      1\n      China\n      Asia\n      1412600000\n    \n    \n      2\n      2\n      India\n      Asia\n      1373761000\n    \n    \n      3\n      3\n      United States\n      Americas\n      332906919\n    \n    \n      4\n      4\n      Indonesia\n      Asia\n      272248500\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      237\n      –\n      Niue\n      Oceania\n      1549\n    \n    \n      238\n      –\n      Tokelau (New Zealand)\n      Oceania\n      1501\n    \n    \n      239\n      195\n      Vatican City\n      Europe\n      825\n    \n    \n      240\n      –\n      Cocos (Keeling) Islands (Australia)\n      Oceania\n      573\n    \n    \n      241\n      –\n      Pitcairn Islands (United Kingdom)\n      Oceania\n      40\n    \n  \n\n242 rows × 4 columns\n\n\n\n\ndf_population=changeDF_country(df_population,df2)\n\nnothing found for World\nnothing found for DR Congo\nnothing found for Bolivia\nnothing found for Hong Kong (China)\nnothing found for Congo\nnothing found for Puerto Rico (United States)\nnothing found for North Macedonia\nnothing found for East Timor\nnothing found for Eswatini\nnothing found for Macau (China)\nnothing found for Western Sahara\nnothing found for Northern Cyprus\nnothing found for Transnistria\nnothing found for French Polynesia (France)\nnothing found for New Caledonia (France)\nnothing found for Abkhazia\nnothing found for São Tomé and Príncipe\nnothing found for Guam (United States)\nnothing found for Curaçao (Netherlands)\nnothing found for Artsakh\nnothing found for Aruba (Netherlands)\nnothing found for Saint Vincent and the Grenadines\nnothing found for Jersey (British Crown Dependency)\nnothing found for U.S. Virgin Islands (United States)\nnothing found for Isle of Man (British Crown Dependency)\nnothing found for Cayman Islands (United Kingdom)\nnothing found for Bermuda (United Kingdom)\nnothing found for Guernsey (British Crown Dependency)\nnothing found for Greenland (Denmark)\nnothing found for Saint Kitts and Nevis\nnothing found for Faroe Islands (Denmark)\nnothing found for South Ossetia\nnothing found for American Samoa (United States)\nnothing found for Northern Mariana Islands (United States)\nnothing found for Turks and Caicos Islands (United Kingdom)\nnothing found for Sint Maarten (Netherlands)\nnothing found for Gibraltar (United Kingdom)\nnothing found for Saint Martin (France)\nnothing found for Åland (Finland)\nnothing found for British Virgin Islands (United Kingdom)\nnothing found for Anguilla (United Kingdom)\nnothing found for Wallis and Futuna (France)\nnothing found for Saint Barthélemy (France)\nnothing found for Saint Helena, Ascension and Tristan da Cunha (United Kingdom)\nnothing found for Saint Pierre and Miquelon (France)\nnothing found for Montserrat (United Kingdom)\nnothing found for Falkland Islands (United Kingdom)\nnothing found for Christmas Island (Australia)\nnothing found for Norfolk Island (Australia)\nnothing found for Niue\nnothing found for Tokelau (New Zealand)\nnothing found for Vatican City\nnothing found for Cocos (Keeling) Islands (Australia)\nnothing found for Pitcairn Islands (United Kingdom)\n\n\n\n\nCombine everything for one country table\nNow we merge all data sets together. I’ll use pandas but this is the same as a SQL left outer join. Because we want to keep all the NOC values in df2 we start with that then join each one after\n\ndf_country=[]\ndf_country=df2.merge(df_population,left_on='NOC',right_on='NOC')\n\ndf_country=df_country.merge(df_GDP,left_on='Nation',right_on='Nation')\ndf_country.drop(columns=['Continent_y','Country_x','Country_y','NOC_y','Rank','notes','region'],inplace=True)\ndf_country=df_country.rename(columns={'NOC_x':'NOC','Continent_x':'Continent'},errors='raise')\n\n# We have multiple versions of Nation so we just take the max one\ndf_country = df_country.groupby('NOC').max()\n\n\ndf_country.to_csv('country')\n\ndf.to_csv(\"athlete_events.csv\")\ndf2.to_csv(\"noc_regions.csv\")"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#introduction",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nTwo csv files (representing two different tables) were imported to databricks.\nThe main table (athlete_events) consists of 270,000 rows, whereas the unique names in the table are 135,000, or around half the total.\n\nLots of columns and lots that are objects,\n\nso we want to refine this by reducing columns and making it an integer or something smaller than object if possible\n\nThere are some NaN values, particularly for height/weight at earlier games and also for medals\nAn athlete can be represented in several rows if they do multiple events or at different games (e.g. Christine Jacoba Aaftink). So we may want a seperate ID that incorporate the athlete and the event/games that is unique\nThe TEAM, NOC we only want one identifier and a seperate table for countries\n\nThe first step was to split the table up. - First the users are split up based on whether they are male or female and whether they are in the summer or winter games. So split into 4. - Secondly not all data is needed for these athletes table, so instead of 15 columns this is reduced to 9 - Thirdly, the size of these athlete table is reduced by replacing several variables from string to int to reduce the size. Since for example, there is only a limited number of events.\nAn entity relationship diagram (ERD) of the tables described above was developed as shown below.\nThose highlighted in blue and light blue would require additional data, the darkness of blue representing how much new data is needed.\nLucid Chart was used to produce the ERD\n\nN.B. Most of these are steps not really necessary for this dataset, but I wanted to practice SQL (and pandas). If this was a real world problem I would weigh up the benefits of the splitting in terms of my time and computation to see if it was really necessary.\n\nCreating a country table\nIn a separate page (https://thomashsimm.com/sql/pandas/python/olympics/2022/07/29/OlympicsSQL_createCountryDF.html) I show how I created the country table.\nI also made some slight changes to the two main DataFrames df2 and df. Basically just to change the country label and add unique athlete and athlete + event ids\ndf= df.reset_index()\ndf.rename(columns={'index':'event_athlete_ID','ID':'athlete_ID'},inplace=True)\nThe main part is to get rid of some duplicate NOC values, mostly correct but will not work in some regards e.g. China and Hong Kong.\n\n# This gets region (or countries) which are repeated with different NOC values\nd1=sqldf(\"SELECT                              \\\n       NOC, region,notes,count(*)             \\\n       FROM df2                               \\\n       GROUP BY region                        \\\n       HAVING COUNT(*)>1                      \\\n       ORDER BY count(*) DESC;\",locals())\n\n# this then creates a table with one NOC per region and the original NOC values\n# we'll use the new NOC (one per region) a the new index\nd2=sqldf(\"SELECT                              \\\n       d1.NOC as new_NOC,df2.NOC orig_NOC,df2.region,df2.notes             \\\n       FROM d1                                \\\n       LEFT JOIN df2                          \\\n       ON d1.region=df2.region                \\\n      ORDER BY df2.region DESC;\",locals())\n\n\n# then replace the regions with several NOC values with the new one\nfor i,old_NOC in enumerate(d2.orig_NOC):\n    df.loc[df.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n    df2.loc[df2.NOC==old_NOC,'NOC']=d2.loc[i,'new_NOC']\n\n\ndf= pd.read_csv(\"athlete_events.csv\")\ntry:\n    df.drop(columns='Unnamed: 0',inplace=True)\nexcept:\n    pass\ndf2=pd.read_csv(\"noc_regions.csv\")"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#look-at-the-data",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#look-at-the-data",
    "title": "ThomasHSimm",
    "section": "Look at the data",
    "text": "Look at the data\n\n# !pip install pandasql\nimport pandas as pd\nfrom pandasql import sqldf\nimport matplotlib.pyplot as plt\nimport re \n\ndf\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271111\n      271111\n      135569\n      Andrzej ya\n      M\n      29.0\n      179.0\n      89.0\n      Poland-1\n      POL\n      1976 Winter\n      1976\n      Winter\n      Innsbruck\n      Luge\n      Luge Mixed (Men)'s Doubles\n      NaN\n    \n    \n      271112\n      271112\n      135570\n      Piotr ya\n      M\n      27.0\n      176.0\n      59.0\n      Poland\n      POL\n      2014 Winter\n      2014\n      Winter\n      Sochi\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Individual\n      NaN\n    \n    \n      271113\n      271113\n      135570\n      Piotr ya\n      M\n      27.0\n      176.0\n      59.0\n      Poland\n      POL\n      2014 Winter\n      2014\n      Winter\n      Sochi\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Team\n      NaN\n    \n    \n      271114\n      271114\n      135571\n      Tomasz Ireneusz ya\n      M\n      30.0\n      185.0\n      96.0\n      Poland\n      POL\n      1998 Winter\n      1998\n      Winter\n      Nagano\n      Bobsleigh\n      Bobsleigh Men's Four\n      NaN\n    \n    \n      271115\n      271115\n      135571\n      Tomasz Ireneusz ya\n      M\n      34.0\n      185.0\n      96.0\n      Poland\n      POL\n      2002 Winter\n      2002\n      Winter\n      Salt Lake City\n      Bobsleigh\n      Bobsleigh Men's Four\n      NaN\n    \n  \n\n271116 rows × 16 columns\n\n\n\n\ndf.dtypes\n\nevent_athlete_ID      int64\nathlete_ID            int64\nName                 object\nSex                  object\nAge                 float64\nHeight              float64\nWeight              float64\nTeam                 object\nNOC                  object\nGames                object\nYear                  int64\nSeason               object\nCity                 object\nSport                object\nEvent                object\nMedal                object\ndtype: object\n\n\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      athlete_ID\n      Age\n      Height\n      Weight\n      Year\n    \n  \n  \n    \n      count\n      271116.000000\n      271116.000000\n      261642.000000\n      210945.000000\n      208241.000000\n      271116.000000\n    \n    \n      mean\n      135557.500000\n      68248.954396\n      25.556898\n      175.338970\n      70.702393\n      1978.378480\n    \n    \n      std\n      78264.592128\n      39022.286345\n      6.393561\n      10.518462\n      14.348020\n      29.877632\n    \n    \n      min\n      0.000000\n      1.000000\n      10.000000\n      127.000000\n      25.000000\n      1896.000000\n    \n    \n      25%\n      67778.750000\n      34643.000000\n      21.000000\n      168.000000\n      60.000000\n      1960.000000\n    \n    \n      50%\n      135557.500000\n      68205.000000\n      24.000000\n      175.000000\n      70.000000\n      1988.000000\n    \n    \n      75%\n      203336.250000\n      102097.250000\n      28.000000\n      183.000000\n      79.000000\n      2002.000000\n    \n    \n      max\n      271115.000000\n      135571.000000\n      97.000000\n      226.000000\n      214.000000\n      2016.000000"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#create-all_athletes-table",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#create-all_athletes-table",
    "title": "ThomasHSimm",
    "section": "Create all_athletes table",
    "text": "Create all_athletes table\nBecause we are splitting the athlete data based on Summer/Winter and Male/Female we need a folder to be able to join or access different parts of the individual athlete tables.\n\ndf= df.reset_index()\ndf.rename(columns={'index':'event_athlete_ID','ID':'athlete_ID'},inplace=True)\ndf.head(10)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      5\n      5\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      6\n      6\n      6\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      7\n      7\n      7\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      8\n      8\n      8\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      9\n      9\n      9\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n  \n\n\n\n\n\ndf_all_athletes=df[['event_athlete_ID','athlete_ID','Name','Sex','Season']]\ndf_all_athletes                    \n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      athlete_ID\n      Name\n      Sex\n      Season\n    \n  \n  \n    \n      0\n      0\n      0\n      1\n      A Dijiang\n      M\n      Summer\n    \n    \n      1\n      1\n      1\n      2\n      A Lamusi\n      M\n      Summer\n    \n    \n      2\n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      Summer\n    \n    \n      3\n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      Summer\n    \n    \n      4\n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      Winter\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271111\n      271111\n      271111\n      135569\n      Andrzej ya\n      M\n      Winter\n    \n    \n      271112\n      271112\n      271112\n      135570\n      Piotr ya\n      M\n      Winter\n    \n    \n      271113\n      271113\n      271113\n      135570\n      Piotr ya\n      M\n      Winter\n    \n    \n      271114\n      271114\n      271114\n      135571\n      Tomasz Ireneusz ya\n      M\n      Winter\n    \n    \n      271115\n      271115\n      271115\n      135571\n      Tomasz Ireneusz ya\n      M\n      Winter\n    \n  \n\n271116 rows × 6 columns"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#creating-an-events-table",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#creating-an-events-table",
    "title": "ThomasHSimm",
    "section": "Creating an Events Table",
    "text": "Creating an Events Table\nIn this table the individual events are displayed. e.g. 100m Mens Sprint Athletics or Womens Football\n\nprint(\"There are {} unique sports and {} unique events \".format(len(pd.unique(df.Sport)), len(pd.unique(df.Event))))\n\nThere are 66 unique sports and 765 unique events \n\n\nBecause of the way that events are named they won’t be duplicated, e.g. 400m breaststroke swimming will be different from 400m athletics running because the name is prefixed with Athletics Women, Swimming Men etc\nInstead of using one hot encoding (get_dummies for pandas as done with medals) we want a different number for each unique event in one column. To do this we can use factorize\naa=pd.factorize(df.ColumnCheck)\nwill give us a variable where - aa[0] is a list of numbers of length of rows in df, where each value represents a different event - aa[1] is then a list of the events of length of the unique events, aa[1][0] is event = 0, aa[1][1] is event = 1 etc - so below aa[1][0] = ‘Basketball Men’s Basketball’ and each row in the df with this event will have a 0 in aa[0]\n\nevent_details=pd.factorize(df.Event)\nevent_details[1][0:100], event_details[0][1:10]\n\n(Index(['Basketball Men's Basketball', 'Judo Men's Extra-Lightweight',\n        'Football Men's Football', 'Tug-Of-War Men's Tug-Of-War',\n        'Speed Skating Women's 500 metres',\n        'Speed Skating Women's 1,000 metres',\n        'Cross Country Skiing Men's 10 kilometres',\n        'Cross Country Skiing Men's 50 kilometres',\n        'Cross Country Skiing Men's 10/15 kilometres Pursuit',\n        'Cross Country Skiing Men's 4 x 10 kilometres Relay',\n        'Cross Country Skiing Men's 30 kilometres',\n        'Athletics Women's 100 metres',\n        'Athletics Women's 4 x 100 metres Relay', 'Ice Hockey Men's Ice Hockey',\n        'Swimming Men's 400 metres Freestyle', 'Badminton Men's Singles',\n        'Sailing Women's Windsurfer', 'Biathlon Women's 7.5 kilometres Sprint',\n        'Swimming Men's 200 metres Breaststroke',\n        'Swimming Men's 400 metres Breaststroke',\n        'Gymnastics Men's Individual All-Around',\n        'Gymnastics Men's Team All-Around', 'Gymnastics Men's Floor Exercise',\n        'Gymnastics Men's Horse Vault', 'Gymnastics Men's Parallel Bars',\n        'Gymnastics Men's Horizontal Bar', 'Gymnastics Men's Rings',\n        'Gymnastics Men's Pommelled Horse', 'Athletics Men's Shot Put',\n        'Art Competitions Mixed Sculpturing, Unknown Event',\n        'Alpine Skiing Men's Downhill', 'Alpine Skiing Men's Super G',\n        'Alpine Skiing Men's Giant Slalom', 'Alpine Skiing Men's Slalom',\n        'Alpine Skiing Men's Combined', 'Handball Women's Handball',\n        'Weightlifting Women's Super-Heavyweight',\n        'Wrestling Men's Light-Heavyweight, Greco-Roman',\n        'Speed Skating Men's 500 metres', 'Speed Skating Men's 1,500 metres',\n        'Gymnastics Men's Team All-Around, Free System', 'Luge Women's Singles',\n        'Water Polo Men's Water Polo', 'Sailing Mixed Three Person Keelboat',\n        'Hockey Women's Hockey', 'Rowing Men's Lightweight Double Sculls',\n        'Athletics Men's Pole Vault', 'Athletics Men's High Jump',\n        'Sailing Men's Two Person Dinghy', 'Athletics Men's 1,500 metres',\n        'Bobsleigh Men's Four', 'Swimming Men's 100 metres Butterfly',\n        'Swimming Men's 200 metres Butterfly',\n        'Swimming Men's 4 x 100 metres Medley Relay',\n        'Football Women's Football', 'Fencing Men's Foil, Individual',\n        'Fencing Men's epee, Individual', 'Fencing Men's epee, Team',\n        'Speed Skating Men's 5,000 metres', 'Speed Skating Men's 10,000 metres',\n        'Sailing Mixed 8 metres', 'Equestrianism Mixed Jumping, Individual',\n        'Cross Country Skiing Men's 15 kilometres',\n        'Shooting Men's Small-Bore Rifle, Prone, 50 metres',\n        'Shooting Men's Rapid-Fire Pistol, 25 metres', 'Shooting Men's Trap',\n        'Athletics Men's 4 x 100 metres Relay', 'Athletics Men's Long Jump',\n        'Boxing Men's Light-Welterweight', 'Athletics Women's Javelin Throw',\n        'Wrestling Men's Heavyweight, Freestyle', 'Taekwondo Men's Flyweight',\n        'Boxing Men's Heavyweight', 'Athletics Men's 5,000 metres',\n        'Cycling Men's Road Race, Individual', 'Cycling Men's Road Race, Team',\n        'Weightlifting Men's Lightweight', 'Weightlifting Men's Middleweight',\n        'Rowing Men's Coxless Pairs', 'Judo Men's Half-Middleweight',\n        'Taekwondo Women's Flyweight', 'Boxing Men's Flyweight',\n        'Basketball Women's Basketball', 'Diving Men's Platform',\n        'Canoeing Men's Canadian Doubles, 500 metres',\n        'Canoeing Men's Canadian Doubles, 1,000 metres',\n        'Canoeing Men's Kayak Fours, 1,000 metres', 'Handball Men's Handball',\n        'Rowing Women's Coxless Pairs', 'Boxing Men's Middleweight',\n        'Judo Men's Lightweight', 'Boxing Men's Featherweight',\n        'Tennis Men's Doubles', 'Shooting Mixed Skeet',\n        'Wrestling Men's Featherweight, Freestyle',\n        'Sailing Mixed Two Person Heavyweight Dinghy',\n        'Athletics Women's Shot Put', 'Rowing Men's Coxed Eights',\n        'Cycling Women's Sprint', 'Cycling Women's 500 metres Time Trial'],\n       dtype='object'),\n array([1, 2, 3, 4, 5, 4, 5, 4, 5], dtype=int64))\n\n\n\ndf.insert(2,'event_id',event_details[0])\ndf.head(10)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      0\n      0\n      1\n      A Dijiang\n      M\n      24.0\n      180.0\n      80.0\n      China\n      CHN\n      1992 Summer\n      1992\n      Summer\n      Barcelona\n      Basketball\n      Basketball Men's Basketball\n      NaN\n    \n    \n      1\n      1\n      1\n      1\n      2\n      A Lamusi\n      M\n      23.0\n      170.0\n      60.0\n      China\n      CHN\n      2012 Summer\n      2012\n      Summer\n      London\n      Judo\n      Judo Men's Extra-Lightweight\n      NaN\n    \n    \n      2\n      2\n      2\n      2\n      3\n      Gunnar Nielsen Aaby\n      M\n      24.0\n      NaN\n      NaN\n      Denmark\n      DEN\n      1920 Summer\n      1920\n      Summer\n      Antwerpen\n      Football\n      Football Men's Football\n      NaN\n    \n    \n      3\n      3\n      3\n      3\n      4\n      Edgar Lindenau Aabye\n      M\n      34.0\n      NaN\n      NaN\n      Denmark/Sweden\n      DEN\n      1900 Summer\n      1900\n      Summer\n      Paris\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      Gold\n    \n    \n      4\n      4\n      4\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      5\n      5\n      5\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      21.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1988 Winter\n      1988\n      Winter\n      Calgary\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      6\n      6\n      6\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      7\n      7\n      7\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      25.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1992 Winter\n      1992\n      Winter\n      Albertville\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n    \n      8\n      8\n      8\n      4\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 500 metres\n      NaN\n    \n    \n      9\n      9\n      9\n      5\n      5\n      Christine Jacoba Aaftink\n      F\n      27.0\n      185.0\n      82.0\n      Netherlands\n      NED\n      1994 Winter\n      1994\n      Winter\n      Lillehammer\n      Speed Skating\n      Speed Skating Women's 1,000 metres\n      NaN\n    \n  \n\n\n\n\n\nevent_details=pd.factorize(df.Event)\ndf_event = pd.DataFrame(event_details[1])\ndf_event\n\n\n\n\n\n  \n    \n      \n      0\n    \n  \n  \n    \n      0\n      Basketball Men's Basketball\n    \n    \n      1\n      Judo Men's Extra-Lightweight\n    \n    \n      2\n      Football Men's Football\n    \n    \n      3\n      Tug-Of-War Men's Tug-Of-War\n    \n    \n      4\n      Speed Skating Women's 500 metres\n    \n    \n      ...\n      ...\n    \n    \n      760\n      Weightlifting Men's All-Around Dumbbell Contest\n    \n    \n      761\n      Archery Men's Au Chapelet, 33 metres\n    \n    \n      762\n      Archery Men's Au Cordon Dore, 33 metres\n    \n    \n      763\n      Archery Men's Target Archery, 28 metres, Indiv...\n    \n    \n      764\n      Aeronautics Mixed Aeronautics\n    \n  \n\n765 rows × 1 columns\n\n\n\n\n\ndf_event = df[['Sport','Event','Sex','Season']]\n\nevent_details=pd.factorize(df.Sport)\ndf_event.insert(0,'sport_id',event_details[0])\n\nevent_details=pd.factorize(df.Event)\ndf_event.insert(0,'event_id',event_details[0])\n\n\ndf_event\n\n\n\n\n\n  \n    \n      \n      event_id\n      sport_id\n      Sport\n      Event\n      Sex\n      Season\n    \n  \n  \n    \n      0\n      0\n      0\n      Basketball\n      Basketball Men's Basketball\n      M\n      Summer\n    \n    \n      1\n      1\n      1\n      Judo\n      Judo Men's Extra-Lightweight\n      M\n      Summer\n    \n    \n      2\n      2\n      2\n      Football\n      Football Men's Football\n      M\n      Summer\n    \n    \n      3\n      3\n      3\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      M\n      Summer\n    \n    \n      4\n      4\n      4\n      Speed Skating\n      Speed Skating Women's 500 metres\n      F\n      Winter\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271111\n      461\n      18\n      Luge\n      Luge Mixed (Men)'s Doubles\n      M\n      Winter\n    \n    \n      271112\n      418\n      48\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Individual\n      M\n      Winter\n    \n    \n      271113\n      419\n      48\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Team\n      M\n      Winter\n    \n    \n      271114\n      50\n      22\n      Bobsleigh\n      Bobsleigh Men's Four\n      M\n      Winter\n    \n    \n      271115\n      50\n      22\n      Bobsleigh\n      Bobsleigh Men's Four\n      M\n      Winter\n    \n  \n\n271116 rows × 6 columns\n\n\n\n\ndf_event = df_event.drop_duplicates().reset_index(drop=True)\ndf_event#[df_event.Sex=='F'].head(30)\n\n\n\n\n\n  \n    \n      \n      event_id\n      sport_id\n      Sport\n      Event\n      Sex\n      Season\n    \n  \n  \n    \n      0\n      0\n      0\n      Basketball\n      Basketball Men's Basketball\n      M\n      Summer\n    \n    \n      1\n      1\n      1\n      Judo\n      Judo Men's Extra-Lightweight\n      M\n      Summer\n    \n    \n      2\n      2\n      2\n      Football\n      Football Men's Football\n      M\n      Summer\n    \n    \n      3\n      3\n      3\n      Tug-Of-War\n      Tug-Of-War Men's Tug-Of-War\n      M\n      Summer\n    \n    \n      4\n      4\n      4\n      Speed Skating\n      Speed Skating Women's 500 metres\n      F\n      Winter\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      824\n      221\n      10\n      Sailing\n      Sailing Mixed 7 metres\n      F\n      Summer\n    \n    \n      825\n      333\n      10\n      Sailing\n      Sailing Mixed 6 metres\n      F\n      Summer\n    \n    \n      826\n      764\n      65\n      Aeronautics\n      Aeronautics Mixed Aeronautics\n      M\n      Summer\n    \n    \n      827\n      677\n      13\n      Art Competitions\n      Art Competitions Mixed Sculpturing, Medals And...\n      F\n      Summer\n    \n    \n      828\n      648\n      13\n      Art Competitions\n      Art Competitions Mixed Unknown Event\n      F\n      Summer\n    \n  \n\n829 rows × 6 columns\n\n\n\n\nAn additional columns in event_table\nLets add a column representing if the sport is a team sport or individual. We can’t do this on the unique members of a team in that event because the team can have multiple members in an individual event. Instead, we can look for how many people took the gold medal. Should work for most circumstances as the gold shouldn’t be shared- so if 2 people won gold it should represent a team sport of 2 people.\nThis is a little convoluted so I’ll do it in two steps in SQL. One way to calculate and one to join this new table back in with df_event\n\ndf_event_temp=sqldf(\"SELECT                   \\\n      event_id,event,num_athletes    \\\n      FROM                                    \\\n      (SELECT                                 \\\n          event,                              \\\n          event_id,                           \\\n          COUNT(*)    as num_athletes         \\\n      FROM df                                 \\\n      WHERE Medal='Gold'                      \\\n      GROUP BY Team, event_id, Games          \\\n      ORDER BY event_id                       \\\n      )                                       \\\n      GROUP BY event_id                       \\\n                    ;\",   locals())                               \n\ndf_event_temp\n\n\n\n\n\n  \n    \n      \n      event_id\n      event\n      num_athletes\n    \n  \n  \n    \n      0\n      0\n      Basketball Men's Basketball\n      12\n    \n    \n      1\n      1\n      Judo Men's Extra-Lightweight\n      1\n    \n    \n      2\n      2\n      Football Men's Football\n      16\n    \n    \n      3\n      3\n      Tug-Of-War Men's Tug-Of-War\n      6\n    \n    \n      4\n      4\n      Speed Skating Women's 500 metres\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      745\n      760\n      Weightlifting Men's All-Around Dumbbell Contest\n      1\n    \n    \n      746\n      761\n      Archery Men's Au Chapelet, 33 metres\n      1\n    \n    \n      747\n      762\n      Archery Men's Au Cordon Dore, 33 metres\n      1\n    \n    \n      748\n      763\n      Archery Men's Target Archery, 28 metres, Indiv...\n      1\n    \n    \n      749\n      764\n      Aeronautics Mixed Aeronautics\n      1\n    \n  \n\n750 rows × 3 columns\n\n\n\n\ndf_event_temp      = sqldf(\"SELECT                                \\\n                      d.event_id,                            \\\n                      d.sport_id,                            \\\n                      d.Sport,                               \\\n                      d.Event,                               \\\n                      d.Sex,                                 \\\n                      d.Season,                              \\\n                      t.num_athletes                         \\\n                FROM df_event  as d                          \\\n                LEFT JOIN                                    \\\n                    df_event_temp  as t                      \\\n                ON                                           \\\n                    t.event_id=d.event_id                    \\\n                ORDER BY d.event_id                          \\\n                      ;\",locals())\n\n\n\n# df_event_temp[((df_event_temp.Sex=='F') & (df_event_temp.Season=='Winter'))].head(30)\n\ndf_event=df_event_temp\n\nAnd make the last column int not float (CAST didn’t seem to work perhaps due to NaN values?)\n\ndf_event.fillna(0,inplace=True)\ndf_event = df_event.astype({'num_athletes':'int'})\n\n\n# sanity check\ndf_event[((df_event['num_athletes']==4) & (df_event['Season']=='Winter'))]\n\n\n\n\n\n  \n    \n      \n      event_id\n      sport_id\n      Sport\n      Event\n      Sex\n      Season\n      num_athletes\n    \n  \n  \n    \n      9\n      9\n      5\n      Cross Country Skiing\n      Cross Country Skiing Men's 4 x 10 kilometres R...\n      M\n      Winter\n      4\n    \n    \n      53\n      50\n      22\n      Bobsleigh\n      Bobsleigh Men's Four\n      M\n      Winter\n      4\n    \n    \n      215\n      204\n      40\n      Nordic Combined\n      Nordic Combined Men's Team\n      M\n      Winter\n      4\n    \n    \n      238\n      226\n      11\n      Biathlon\n      Biathlon Men's 4 x 7.5 kilometres Relay\n      M\n      Winter\n      4\n    \n    \n      274\n      259\n      11\n      Biathlon\n      Biathlon Mixed 2 x 6 kilometres and 2 x 7.5 ki...\n      M\n      Winter\n      4\n    \n    \n      275\n      259\n      11\n      Biathlon\n      Biathlon Mixed 2 x 6 kilometres and 2 x 7.5 ki...\n      F\n      Winter\n      4\n    \n    \n      330\n      310\n      11\n      Biathlon\n      Biathlon Women's 4 x 7.5 kilometres Relay\n      F\n      Winter\n      4\n    \n    \n      451\n      419\n      48\n      Ski Jumping\n      Ski Jumping Men's Large Hill, Team\n      M\n      Winter\n      4\n    \n    \n      470\n      435\n      52\n      Short Track Speed Skating\n      Short Track Speed Skating Men's 5,000 metres R...\n      M\n      Winter\n      4\n    \n    \n      478\n      443\n      11\n      Biathlon\n      Biathlon Women's 4 x 6 kilometres Relay\n      F\n      Winter\n      4\n    \n    \n      504\n      466\n      5\n      Cross Country Skiing\n      Cross Country Skiing Women's 4 x 5 kilometres ...\n      F\n      Winter\n      4\n    \n    \n      510\n      472\n      22\n      Bobsleigh\n      Bobsleigh Men's Four/Five\n      M\n      Winter\n      4\n    \n    \n      533\n      492\n      52\n      Short Track Speed Skating\n      Short Track Speed Skating Women's 3,000 metres...\n      F\n      Winter\n      4\n    \n    \n      615\n      572\n      18\n      Luge\n      Luge Mixed Team Relay\n      M\n      Winter\n      4\n    \n    \n      616\n      572\n      18\n      Luge\n      Luge Mixed Team Relay\n      F\n      Winter\n      4\n    \n    \n      640\n      594\n      59\n      Military Ski Patrol\n      Military Ski Patrol Men's Military Ski Patrol\n      M\n      Winter\n      4\n    \n  \n\n\n\n\n\ndf[df.event_id==572][['Sport','Event','Sex']].tail(6),df_event[df_event.event_id==572]\n\n(       Sport                  Event Sex\n 255927  Luge  Luge Mixed Team Relay   M\n 258882  Luge  Luge Mixed Team Relay   M\n 262369  Luge  Luge Mixed Team Relay   F\n 267369  Luge  Luge Mixed Team Relay   M\n 268477  Luge  Luge Mixed Team Relay   M\n 270261  Luge  Luge Mixed Team Relay   M,\n      event_id  sport_id Sport                  Event Sex  Season  num_athletes\n 615       572        18  Luge  Luge Mixed Team Relay   M  Winter             4\n 616       572        18  Luge  Luge Mixed Team Relay   F  Winter             4)"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#add-a-games-table",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#add-a-games-table",
    "title": "ThomasHSimm",
    "section": "Add a Games table",
    "text": "Add a Games table\nThe games table is used to give information about a particular Olympic games including - Where it was staged - Is it a summer or winter games - The year it was staged\nUsing the same methodology as before we want to - create a unique id for the games - replace this in the athlete tables - add a new table with the unique id and additional information about the particular games\nThis is more complex than the events table because we want to add additional data about the cities where the games were held. This data is obtained from wikipedia as before. So some of the methodology used in creating the country table is used here.\nThere’s a strange thing that there are two summer games in one year\n\ndf=df.sort_values(by=['Year','City'])\n\n\n# event_details=pd.factorize(pd.lib.fast_zip([df.Games, df.City]))\ntuples = df[['Games', 'City']].apply(tuple, axis=1)\nevent_details = pd.factorize( tuples )\nevent_details[1][0:10], event_details[0][1:10],len(event_details[1]),len(event_details[0])\n\n(Index([   ('1896 Summer', 'Athina'),     ('1900 Summer', 'Paris'),\n        ('1904 Summer', 'St. Louis'),    ('1906 Summer', 'Athina'),\n           ('1908 Summer', 'London'), ('1912 Summer', 'Stockholm'),\n        ('1920 Summer', 'Antwerpen'),  ('1924 Winter', 'Chamonix'),\n            ('1924 Summer', 'Paris'), ('1928 Summer', 'Amsterdam')],\n       dtype='object'),\n array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n 52,\n 271116)\n\n\n\ndf.insert(3,'games_id',event_details[0])\ndf\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      3079\n      3079\n      3079\n      191\n      0\n      1724\n      Aristidis Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Singles\n      NaN\n    \n    \n      3080\n      3080\n      3080\n      92\n      0\n      1724\n      Aristidis Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Doubles\n      NaN\n    \n    \n      3081\n      3081\n      3081\n      191\n      0\n      1725\n      Konstantinos \"Kostas\" Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Singles\n      NaN\n    \n    \n      3082\n      3082\n      3082\n      92\n      0\n      1725\n      Konstantinos \"Kostas\" Akratopoulos\n      M\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Tennis\n      Tennis Men's Doubles\n      NaN\n    \n    \n      7348\n      7348\n      7348\n      100\n      0\n      4113\n      Anastasios Andreou\n      M\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896 Summer\n      1896\n      Summer\n      Athina\n      Athletics\n      Athletics Men's 110 metres Hurdles\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      271024\n      271024\n      271024\n      15\n      51\n      135528\n      Marc Zwiebler\n      M\n      32.0\n      181.0\n      75.0\n      Germany\n      FRG\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Badminton\n      Badminton Men's Singles\n      NaN\n    \n    \n      271053\n      271053\n      271053\n      11\n      51\n      135547\n      Viktoriya Viktorovna Zyabkina\n      F\n      23.0\n      174.0\n      62.0\n      Kazakhstan\n      KAZ\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Athletics\n      Athletics Women's 100 metres\n      NaN\n    \n    \n      271054\n      271054\n      271054\n      174\n      51\n      135547\n      Viktoriya Viktorovna Zyabkina\n      F\n      23.0\n      174.0\n      62.0\n      Kazakhstan\n      KAZ\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Athletics\n      Athletics Women's 200 metres\n      NaN\n    \n    \n      271055\n      271055\n      271055\n      12\n      51\n      135547\n      Viktoriya Viktorovna Zyabkina\n      F\n      23.0\n      174.0\n      62.0\n      Kazakhstan\n      KAZ\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Athletics\n      Athletics Women's 4 x 100 metres Relay\n      NaN\n    \n    \n      271110\n      271110\n      271110\n      82\n      51\n      135568\n      Olga Igorevna Zyuzkova\n      F\n      33.0\n      171.0\n      69.0\n      Belarus\n      BLR\n      2016 Summer\n      2016\n      Summer\n      Rio de Janeiro\n      Basketball\n      Basketball Women's Basketball\n      NaN\n    \n  \n\n271116 rows × 19 columns\n\n\n\n\ndf[['games_id','Games','City']].groupby(['games_id','Games']).count()\n\n\n\n\n\n  \n    \n      \n      \n      City\n    \n    \n      games_id\n      Games\n      \n    \n  \n  \n    \n      0\n      1896 Summer\n      380\n    \n    \n      1\n      1900 Summer\n      1936\n    \n    \n      2\n      1904 Summer\n      1301\n    \n    \n      3\n      1906 Summer\n      1733\n    \n    \n      4\n      1908 Summer\n      3101\n    \n    \n      5\n      1912 Summer\n      4040\n    \n    \n      6\n      1920 Summer\n      4292\n    \n    \n      7\n      1924 Winter\n      460\n    \n    \n      8\n      1924 Summer\n      5233\n    \n    \n      9\n      1928 Summer\n      4992\n    \n    \n      10\n      1928 Winter\n      582\n    \n    \n      11\n      1932 Winter\n      352\n    \n    \n      12\n      1932 Summer\n      2969\n    \n    \n      13\n      1936 Summer\n      6506\n    \n    \n      14\n      1936 Winter\n      895\n    \n    \n      15\n      1948 Summer\n      6405\n    \n    \n      16\n      1948 Winter\n      1075\n    \n    \n      17\n      1952 Summer\n      8270\n    \n    \n      18\n      1952 Winter\n      1088\n    \n    \n      19\n      1956 Winter\n      1307\n    \n    \n      20\n      1956 Summer\n      4829\n    \n    \n      21\n      1956 Summer\n      298\n    \n    \n      22\n      1960 Summer\n      8119\n    \n    \n      23\n      1960 Winter\n      1116\n    \n    \n      24\n      1964 Winter\n      1778\n    \n    \n      25\n      1964 Summer\n      7702\n    \n    \n      26\n      1968 Winter\n      1891\n    \n    \n      27\n      1968 Summer\n      8588\n    \n    \n      28\n      1972 Summer\n      10304\n    \n    \n      29\n      1972 Winter\n      1655\n    \n    \n      30\n      1976 Winter\n      1861\n    \n    \n      31\n      1976 Summer\n      8641\n    \n    \n      32\n      1980 Winter\n      1746\n    \n    \n      33\n      1980 Summer\n      7191\n    \n    \n      34\n      1984 Summer\n      9454\n    \n    \n      35\n      1984 Winter\n      2134\n    \n    \n      36\n      1988 Winter\n      2639\n    \n    \n      37\n      1988 Summer\n      12037\n    \n    \n      38\n      1992 Winter\n      3436\n    \n    \n      39\n      1992 Summer\n      12977\n    \n    \n      40\n      1994 Winter\n      3160\n    \n    \n      41\n      1996 Summer\n      13780\n    \n    \n      42\n      1998 Winter\n      3605\n    \n    \n      43\n      2000 Summer\n      13821\n    \n    \n      44\n      2002 Winter\n      4109\n    \n    \n      45\n      2004 Summer\n      13443\n    \n    \n      46\n      2006 Winter\n      4382\n    \n    \n      47\n      2008 Summer\n      13602\n    \n    \n      48\n      2010 Winter\n      4402\n    \n    \n      49\n      2012 Summer\n      12920\n    \n    \n      50\n      2014 Winter\n      4891\n    \n    \n      51\n      2016 Summer\n      13688\n    \n  \n\n\n\n\n\n# Load the games table \ndf_games = pd.read_excel('CitiesOlympics.xlsx',sheet_name=0)\n\n# then sort by year and city like did with df, reset the index\ndf_games=df_games.sort_values(by=['Year','City']).reset_index(drop=True)\n# and replace games_id with new ordered index\ndf_games['games_id']=df_games.index\n\n## sanity check to see if the two tables for games match\n# sanity\ndtemp=df[['games_id','Games','City','Year']].groupby(['games_id','Games','City']).count()\ndtemp.reset_index(inplace=True)\n\npd.concat([df_games[['City','Year','Summer']], dtemp ], axis=1)\n\n# \n\n\n\n\n\n  \n    \n      \n      City\n      Year\n      Summer\n      games_id\n      Games\n      City\n      Year\n    \n  \n  \n    \n      0\n      Athens\n      1896\n      1\n      0\n      1896 Summer\n      Athina\n      380\n    \n    \n      1\n      Paris\n      1900\n      1\n      1\n      1900 Summer\n      Paris\n      1936\n    \n    \n      2\n      St. Louis\n      1904\n      1\n      2\n      1904 Summer\n      St. Louis\n      1301\n    \n    \n      3\n      Athens\n      1906\n      1\n      3\n      1906 Summer\n      Athina\n      1733\n    \n    \n      4\n      London\n      1908\n      1\n      4\n      1908 Summer\n      London\n      3101\n    \n    \n      5\n      Stockholm\n      1912\n      1\n      5\n      1912 Summer\n      Stockholm\n      4040\n    \n    \n      6\n      Antwerp\n      1920\n      1\n      6\n      1920 Summer\n      Antwerpen\n      4292\n    \n    \n      7\n      Chamonix\n      1924\n      0\n      7\n      1924 Winter\n      Chamonix\n      460\n    \n    \n      8\n      Paris\n      1924\n      1\n      8\n      1924 Summer\n      Paris\n      5233\n    \n    \n      9\n      Amsterdam\n      1928\n      1\n      9\n      1928 Summer\n      Amsterdam\n      4992\n    \n    \n      10\n      St. Moritz\n      1928\n      0\n      10\n      1928 Winter\n      Sankt Moritz\n      582\n    \n    \n      11\n      Lake Placid\n      1932\n      0\n      11\n      1932 Winter\n      Lake Placid\n      352\n    \n    \n      12\n      Los Angeles\n      1932\n      1\n      12\n      1932 Summer\n      Los Angeles\n      2969\n    \n    \n      13\n      Berlin\n      1936\n      1\n      13\n      1936 Summer\n      Berlin\n      6506\n    \n    \n      14\n      Garmisch-Partenkirchen\n      1936\n      0\n      14\n      1936 Winter\n      Garmisch-Partenkirchen\n      895\n    \n    \n      15\n      London\n      1948\n      1\n      15\n      1948 Summer\n      London\n      6405\n    \n    \n      16\n      St. Moritz\n      1948\n      0\n      16\n      1948 Winter\n      Sankt Moritz\n      1075\n    \n    \n      17\n      Helsinki\n      1952\n      1\n      17\n      1952 Summer\n      Helsinki\n      8270\n    \n    \n      18\n      Oslo\n      1952\n      0\n      18\n      1952 Winter\n      Oslo\n      1088\n    \n    \n      19\n      Cortina d'Ampezzo\n      1956\n      0\n      19\n      1956 Winter\n      Cortina d'Ampezzo\n      1307\n    \n    \n      20\n      Melbourne\n      1956\n      1\n      20\n      1956 Summer\n      Melbourne\n      4829\n    \n    \n      21\n      Stockholm\n      1956\n      0\n      21\n      1956 Summer\n      Stockholm\n      298\n    \n    \n      22\n      Rome\n      1960\n      1\n      22\n      1960 Summer\n      Roma\n      8119\n    \n    \n      23\n      Squaw Valley\n      1960\n      0\n      23\n      1960 Winter\n      Squaw Valley\n      1116\n    \n    \n      24\n      Innsbruck\n      1964\n      0\n      24\n      1964 Winter\n      Innsbruck\n      1778\n    \n    \n      25\n      Tokyo\n      1964\n      1\n      25\n      1964 Summer\n      Tokyo\n      7702\n    \n    \n      26\n      Grenoble\n      1968\n      0\n      26\n      1968 Winter\n      Grenoble\n      1891\n    \n    \n      27\n      Mexico City\n      1968\n      1\n      27\n      1968 Summer\n      Mexico City\n      8588\n    \n    \n      28\n      Munich\n      1972\n      1\n      28\n      1972 Summer\n      Munich\n      10304\n    \n    \n      29\n      Sapporo\n      1972\n      0\n      29\n      1972 Winter\n      Sapporo\n      1655\n    \n    \n      30\n      Innsbruck\n      1976\n      0\n      30\n      1976 Winter\n      Innsbruck\n      1861\n    \n    \n      31\n      Montreal\n      1976\n      1\n      31\n      1976 Summer\n      Montreal\n      8641\n    \n    \n      32\n      Lake Placid\n      1980\n      0\n      32\n      1980 Winter\n      Lake Placid\n      1746\n    \n    \n      33\n      Moscow\n      1980\n      1\n      33\n      1980 Summer\n      Moskva\n      7191\n    \n    \n      34\n      Los Angeles\n      1984\n      1\n      34\n      1984 Summer\n      Los Angeles\n      9454\n    \n    \n      35\n      Sarajevo\n      1984\n      0\n      35\n      1984 Winter\n      Sarajevo\n      2134\n    \n    \n      36\n      Calgary\n      1988\n      0\n      36\n      1988 Winter\n      Calgary\n      2639\n    \n    \n      37\n      Seoul\n      1988\n      1\n      37\n      1988 Summer\n      Seoul\n      12037\n    \n    \n      38\n      Albertville\n      1992\n      0\n      38\n      1992 Winter\n      Albertville\n      3436\n    \n    \n      39\n      Barcelona\n      1992\n      1\n      39\n      1992 Summer\n      Barcelona\n      12977\n    \n    \n      40\n      Lillehammer\n      1994\n      0\n      40\n      1994 Winter\n      Lillehammer\n      3160\n    \n    \n      41\n      Atlanta\n      1996\n      1\n      41\n      1996 Summer\n      Atlanta\n      13780\n    \n    \n      42\n      Nagano\n      1998\n      0\n      42\n      1998 Winter\n      Nagano\n      3605\n    \n    \n      43\n      Sydney\n      2000\n      1\n      43\n      2000 Summer\n      Sydney\n      13821\n    \n    \n      44\n      Salt Lake City\n      2002\n      0\n      44\n      2002 Winter\n      Salt Lake City\n      4109\n    \n    \n      45\n      Athens\n      2004\n      1\n      45\n      2004 Summer\n      Athina\n      13443\n    \n    \n      46\n      Turin\n      2006\n      0\n      46\n      2006 Winter\n      Torino\n      4382\n    \n    \n      47\n      Beijing\n      2008\n      1\n      47\n      2008 Summer\n      Beijing\n      13602\n    \n    \n      48\n      Vancouver\n      2010\n      0\n      48\n      2010 Winter\n      Vancouver\n      4402\n    \n    \n      49\n      London\n      2012\n      1\n      49\n      2012 Summer\n      London\n      12920\n    \n    \n      50\n      Sochi\n      2014\n      0\n      50\n      2014 Winter\n      Sochi\n      4891\n    \n    \n      51\n      Rio de Janeiro\n      2016\n      1\n      51\n      2016 Summer\n      Rio de Janeiro\n      13688\n    \n  \n\n\n\n\n\nimport re\n\n# starts with a digit (at start of string) or '.'- goes on for undefinable length  \nregex_pattern=r'^[\\d|.]*'\n# starts with a comma then spaces then digits or '.'\nregex_pattern2=',\\s*[\\d|.|]*'\n\ntest_string = df_games.iloc[1,-2]\nprint(test_string)\na=re.search(regex_pattern2, test_string)\n\nfor i in range(len(df_games)):\n#     print(df_games.iloc[i,-2])\n    try:\n        df_games.iloc[i,-1]= re.search(regex_pattern2,df_games.iloc[i,-2])[0][2:] \n        df_games.iloc[i,-2]= re.search(regex_pattern,df_games.iloc[i,-2])[0] \n    except:\n        pass\n\n48.8566° N, 2.3522°\n\n\n\ndef getNation(region_to_check):\n    import re    \n    if region_to_check=='United States':\n        region_out = 'USA'\n    elif bool(re.search(r'Germany', region_to_check)):\n        region_out='Germany'\n    elif region_to_check=='United Kingdom':\n        region_out = 'UK'\n    elif region_to_check=='Soviet Union':\n        region_out='Russia'\n    else:\n        region_out=region_to_check\n        print('nothing found for {}'.format(region_out))\n    \n    return region_out\n\nfor i in range(len(df_games)):\n    x=df2[df2.region==df_games.iloc[i,2]].region\n    if len(x)<1:\n        x=df2[df2.notes==df_games.iloc[i,2]].region\n        if len(x)<1:\n            x=getNation(df_games.iloc[i,2])\n#     \n    try:\n        df_games.iloc[i,2]=str(x.iloc[0]) \n    except:\n        df_games.iloc[i,2]=str(x) \n#     print(x)\n#     if len(x)<1:\n#         print('----------------------------------')\n        \n        \n\n\ndf_games.iloc[10:20,:]\n\n\n\n\n\n  \n    \n      \n      games_id\n      City\n      Country\n      Year\n      Region\n      Summer\n      Winter\n      Latitude\n      Longitude\n    \n  \n  \n    \n      10\n      10\n      St. Moritz\n      Switzerland\n      1928\n      Europe\n      0\n      1\n      46.4908\n      9.8355\n    \n    \n      11\n      11\n      Lake Placid\n      USA\n      1932\n      North America\n      0\n      1\n      27.2931\n      81.3629\n    \n    \n      12\n      12\n      Los Angeles\n      USA\n      1932\n      North America\n      1\n      0\n      34.0522\n      118.2437\n    \n    \n      13\n      13\n      Berlin\n      Germany\n      1936\n      Europe\n      1\n      0\n      52.5200\n      13.4050\n    \n    \n      14\n      14\n      Garmisch-Partenkirchen\n      Germany\n      1936\n      Europe\n      0\n      1\n      47.4919\n      11.0948\n    \n    \n      15\n      15\n      London\n      UK\n      1948\n      Europe\n      1\n      0\n      51.5072\n      0.1276\n    \n    \n      16\n      16\n      St. Moritz\n      Switzerland\n      1948\n      Europe\n      0\n      1\n      46.4908\n      9.8355\n    \n    \n      17\n      17\n      Helsinki\n      Finland\n      1952\n      Europe\n      1\n      0\n      60.1699\n      24.9384\n    \n    \n      18\n      18\n      Oslo\n      Norway\n      1952\n      Europe\n      0\n      1\n      59.9139\n      10.7522\n    \n    \n      19\n      19\n      Cortina d'Ampezzo\n      Italy\n      1956\n      Europe\n      0\n      1\n      46.5405\n      12.1357\n    \n  \n\n\n\n\n\ndf.groupby(['games_id','Year','Games','City']).count().reset_index()\n\n\n\n\n\n  \n    \n      \n      games_id\n      Year\n      Games\n      City\n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Season\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      0\n      1896\n      1896 Summer\n      Athina\n      380\n      380\n      380\n      380\n      380\n      380\n      217\n      46\n      49\n      380\n      380\n      380\n      380\n      380\n      143\n    \n    \n      1\n      1\n      1900\n      1900 Summer\n      Paris\n      1936\n      1936\n      1936\n      1936\n      1936\n      1936\n      1146\n      116\n      79\n      1936\n      1936\n      1936\n      1936\n      1936\n      604\n    \n    \n      2\n      2\n      1904\n      1904 Summer\n      St. Louis\n      1301\n      1301\n      1301\n      1301\n      1301\n      1301\n      1027\n      213\n      147\n      1301\n      1301\n      1301\n      1301\n      1301\n      486\n    \n    \n      3\n      3\n      1906\n      1906 Summer\n      Athina\n      1733\n      1733\n      1733\n      1733\n      1733\n      1733\n      990\n      257\n      205\n      1733\n      1733\n      1733\n      1733\n      1733\n      458\n    \n    \n      4\n      4\n      1908\n      1908 Summer\n      London\n      3101\n      3101\n      3101\n      3101\n      3101\n      3101\n      2452\n      475\n      483\n      3101\n      3101\n      3101\n      3101\n      3101\n      831\n    \n    \n      5\n      5\n      1912\n      1912 Summer\n      Stockholm\n      4040\n      4040\n      4040\n      4040\n      4040\n      4040\n      3884\n      721\n      596\n      4040\n      4040\n      4040\n      4040\n      4040\n      941\n    \n    \n      6\n      6\n      1920\n      1920 Summer\n      Antwerpen\n      4292\n      4292\n      4292\n      4292\n      4292\n      4292\n      3447\n      767\n      471\n      4292\n      4292\n      4292\n      4292\n      4292\n      1308\n    \n    \n      7\n      7\n      1924\n      1924 Winter\n      Chamonix\n      460\n      460\n      460\n      460\n      460\n      460\n      403\n      89\n      41\n      460\n      460\n      460\n      460\n      460\n      130\n    \n    \n      8\n      8\n      1924\n      1924 Summer\n      Paris\n      5233\n      5233\n      5233\n      5233\n      5233\n      5233\n      4148\n      885\n      649\n      5233\n      5233\n      5233\n      5233\n      5233\n      832\n    \n    \n      9\n      9\n      1928\n      1928 Summer\n      Amsterdam\n      4992\n      4992\n      4992\n      4992\n      4992\n      4992\n      4119\n      853\n      670\n      4992\n      4992\n      4992\n      4992\n      4992\n      734\n    \n    \n      10\n      10\n      1928\n      1928 Winter\n      Sankt Moritz\n      582\n      582\n      582\n      582\n      582\n      582\n      492\n      122\n      48\n      582\n      582\n      582\n      582\n      582\n      89\n    \n    \n      11\n      11\n      1932\n      1932 Winter\n      Lake Placid\n      352\n      352\n      352\n      352\n      352\n      352\n      329\n      196\n      55\n      352\n      352\n      352\n      352\n      352\n      92\n    \n    \n      12\n      12\n      1932\n      1932 Summer\n      Los Angeles\n      2969\n      2969\n      2969\n      2969\n      2969\n      2969\n      2662\n      1017\n      495\n      2969\n      2969\n      2969\n      2969\n      2969\n      647\n    \n    \n      13\n      13\n      1936\n      1936 Summer\n      Berlin\n      6506\n      6506\n      6506\n      6506\n      6506\n      6506\n      6304\n      1056\n      909\n      6506\n      6506\n      6506\n      6506\n      6506\n      917\n    \n    \n      14\n      14\n      1936\n      1936 Winter\n      Garmisch-Partenkirchen\n      895\n      895\n      895\n      895\n      895\n      895\n      884\n      136\n      78\n      895\n      895\n      895\n      895\n      895\n      108\n    \n    \n      15\n      15\n      1948\n      1948 Summer\n      London\n      6405\n      6405\n      6405\n      6405\n      6405\n      6405\n      5233\n      1053\n      1040\n      6405\n      6405\n      6405\n      6405\n      6405\n      852\n    \n    \n      16\n      16\n      1948\n      1948 Winter\n      Sankt Moritz\n      1075\n      1075\n      1075\n      1075\n      1075\n      1075\n      1071\n      116\n      111\n      1075\n      1075\n      1075\n      1075\n      1075\n      135\n    \n    \n      17\n      17\n      1952\n      1952 Summer\n      Helsinki\n      8270\n      8270\n      8270\n      8270\n      8270\n      8270\n      7993\n      2038\n      2038\n      8270\n      8270\n      8270\n      8270\n      8270\n      897\n    \n    \n      18\n      18\n      1952\n      1952 Winter\n      Oslo\n      1088\n      1088\n      1088\n      1088\n      1088\n      1088\n      1088\n      150\n      149\n      1088\n      1088\n      1088\n      1088\n      1088\n      136\n    \n    \n      19\n      19\n      1956\n      1956 Winter\n      Cortina d'Ampezzo\n      1307\n      1307\n      1307\n      1307\n      1307\n      1307\n      1282\n      344\n      342\n      1307\n      1307\n      1307\n      1307\n      1307\n      150\n    \n    \n      20\n      20\n      1956\n      1956 Summer\n      Melbourne\n      4829\n      4829\n      4829\n      4829\n      4829\n      4829\n      4256\n      2234\n      2232\n      4829\n      4829\n      4829\n      4829\n      4829\n      857\n    \n    \n      21\n      21\n      1956\n      1956 Summer\n      Stockholm\n      298\n      298\n      298\n      298\n      298\n      298\n      258\n      108\n      106\n      298\n      298\n      298\n      298\n      298\n      36\n    \n    \n      22\n      22\n      1960\n      1960 Summer\n      Roma\n      8119\n      8119\n      8119\n      8119\n      8119\n      8119\n      7906\n      7738\n      7675\n      8119\n      8119\n      8119\n      8119\n      8119\n      911\n    \n    \n      23\n      23\n      1960\n      1960 Winter\n      Squaw Valley\n      1116\n      1116\n      1116\n      1116\n      1116\n      1116\n      1108\n      536\n      512\n      1116\n      1116\n      1116\n      1116\n      1116\n      147\n    \n    \n      24\n      24\n      1964\n      1964 Winter\n      Innsbruck\n      1778\n      1778\n      1778\n      1778\n      1778\n      1778\n      1765\n      1369\n      1348\n      1778\n      1778\n      1778\n      1778\n      1778\n      186\n    \n    \n      25\n      25\n      1964\n      1964 Summer\n      Tokyo\n      7702\n      7702\n      7702\n      7702\n      7702\n      7702\n      7659\n      7430\n      7424\n      7702\n      7702\n      7702\n      7702\n      7702\n      1029\n    \n    \n      26\n      26\n      1968\n      1968 Winter\n      Grenoble\n      1891\n      1891\n      1891\n      1891\n      1891\n      1891\n      1872\n      1833\n      1817\n      1891\n      1891\n      1891\n      1891\n      1891\n      199\n    \n    \n      27\n      27\n      1968\n      1968 Summer\n      Mexico City\n      8588\n      8588\n      8588\n      8588\n      8588\n      8588\n      8489\n      8493\n      8493\n      8588\n      8588\n      8588\n      8588\n      8588\n      1057\n    \n    \n      28\n      28\n      1972\n      1972 Summer\n      Munich\n      10304\n      10304\n      10304\n      10304\n      10304\n      10304\n      10211\n      10018\n      9928\n      10304\n      10304\n      10304\n      10304\n      10304\n      1215\n    \n    \n      29\n      29\n      1972\n      1972 Winter\n      Sapporo\n      1655\n      1655\n      1655\n      1655\n      1655\n      1655\n      1652\n      1640\n      1642\n      1655\n      1655\n      1655\n      1655\n      1655\n      199\n    \n    \n      30\n      30\n      1976\n      1976 Winter\n      Innsbruck\n      1861\n      1861\n      1861\n      1861\n      1861\n      1861\n      1850\n      1343\n      1302\n      1861\n      1861\n      1861\n      1861\n      1861\n      211\n    \n    \n      31\n      31\n      1976\n      1976 Summer\n      Montreal\n      8641\n      8641\n      8641\n      8641\n      8641\n      8641\n      8600\n      8283\n      8280\n      8641\n      8641\n      8641\n      8641\n      8641\n      1320\n    \n    \n      32\n      32\n      1980\n      1980 Winter\n      Lake Placid\n      1746\n      1746\n      1746\n      1746\n      1746\n      1746\n      1745\n      1388\n      1374\n      1746\n      1746\n      1746\n      1746\n      1746\n      218\n    \n    \n      33\n      33\n      1980\n      1980 Summer\n      Moskva\n      7191\n      7191\n      7191\n      7191\n      7191\n      7191\n      7005\n      6961\n      6967\n      7191\n      7191\n      7191\n      7191\n      7191\n      1384\n    \n    \n      34\n      34\n      1984\n      1984 Summer\n      Los Angeles\n      9454\n      9454\n      9454\n      9454\n      9454\n      9454\n      9249\n      9032\n      9031\n      9454\n      9454\n      9454\n      9454\n      9454\n      1476\n    \n    \n      35\n      35\n      1984\n      1984 Winter\n      Sarajevo\n      2134\n      2134\n      2134\n      2134\n      2134\n      2134\n      2123\n      1958\n      1954\n      2134\n      2134\n      2134\n      2134\n      2134\n      222\n    \n    \n      36\n      36\n      1988\n      1988 Winter\n      Calgary\n      2639\n      2639\n      2639\n      2639\n      2639\n      2639\n      2635\n      2024\n      2018\n      2639\n      2639\n      2639\n      2639\n      2639\n      263\n    \n    \n      37\n      37\n      1988\n      1988 Summer\n      Seoul\n      12037\n      12037\n      12037\n      12037\n      12037\n      12037\n      11931\n      11719\n      11730\n      12037\n      12037\n      12037\n      12037\n      12037\n      1582\n    \n    \n      38\n      38\n      1992\n      1992 Winter\n      Albertville\n      3436\n      3436\n      3436\n      3436\n      3436\n      3436\n      3435\n      2785\n      2783\n      3436\n      3436\n      3436\n      3436\n      3436\n      318\n    \n    \n      39\n      39\n      1992\n      1992 Summer\n      Barcelona\n      12977\n      12977\n      12977\n      12977\n      12977\n      12977\n      12934\n      10453\n      10473\n      12977\n      12977\n      12977\n      12977\n      12977\n      1712\n    \n    \n      40\n      40\n      1994\n      1994 Winter\n      Lillehammer\n      3160\n      3160\n      3160\n      3160\n      3160\n      3160\n      3158\n      2973\n      2971\n      3160\n      3160\n      3160\n      3160\n      3160\n      331\n    \n    \n      41\n      41\n      1996\n      1996 Summer\n      Atlanta\n      13780\n      13780\n      13780\n      13780\n      13780\n      13780\n      13772\n      11909\n      11959\n      13780\n      13780\n      13780\n      13780\n      13780\n      1842\n    \n    \n      42\n      42\n      1998\n      1998 Winter\n      Nagano\n      3605\n      3605\n      3605\n      3605\n      3605\n      3605\n      3603\n      3521\n      3519\n      3605\n      3605\n      3605\n      3605\n      3605\n      440\n    \n    \n      43\n      43\n      2000\n      2000 Summer\n      Sydney\n      13821\n      13821\n      13821\n      13821\n      13821\n      13821\n      13820\n      13698\n      13695\n      13821\n      13821\n      13821\n      13821\n      13821\n      2004\n    \n    \n      44\n      44\n      2002\n      2002 Winter\n      Salt Lake City\n      4109\n      4109\n      4109\n      4109\n      4109\n      4109\n      4109\n      4080\n      4062\n      4109\n      4109\n      4109\n      4109\n      4109\n      478\n    \n    \n      45\n      45\n      2004\n      2004 Summer\n      Athina\n      13443\n      13443\n      13443\n      13443\n      13443\n      13443\n      13443\n      13407\n      13406\n      13443\n      13443\n      13443\n      13443\n      13443\n      2001\n    \n    \n      46\n      46\n      2006\n      2006 Winter\n      Torino\n      4382\n      4382\n      4382\n      4382\n      4382\n      4382\n      4382\n      4376\n      4366\n      4382\n      4382\n      4382\n      4382\n      4382\n      526\n    \n    \n      47\n      47\n      2008\n      2008 Summer\n      Beijing\n      13602\n      13602\n      13602\n      13602\n      13602\n      13602\n      13600\n      13451\n      13443\n      13602\n      13602\n      13602\n      13602\n      13602\n      2048\n    \n    \n      48\n      48\n      2010\n      2010 Winter\n      Vancouver\n      4402\n      4402\n      4402\n      4402\n      4402\n      4402\n      4402\n      4400\n      4378\n      4402\n      4402\n      4402\n      4402\n      4402\n      520\n    \n    \n      49\n      49\n      2012\n      2012 Summer\n      London\n      12920\n      12920\n      12920\n      12920\n      12920\n      12920\n      12920\n      12752\n      12560\n      12920\n      12920\n      12920\n      12920\n      12920\n      1941\n    \n    \n      50\n      50\n      2014\n      2014 Winter\n      Sochi\n      4891\n      4891\n      4891\n      4891\n      4891\n      4891\n      4891\n      4871\n      4673\n      4891\n      4891\n      4891\n      4891\n      4891\n      597\n    \n    \n      51\n      51\n      2016\n      2016 Summer\n      Rio de Janeiro\n      13688\n      13688\n      13688\n      13688\n      13688\n      13688\n      13688\n      13512\n      13465\n      13688\n      13688\n      13688\n      13688\n      13688\n      2023"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#create-some-smaller-athlete-tables",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#create-some-smaller-athlete-tables",
    "title": "ThomasHSimm",
    "section": "Create some smaller athlete tables",
    "text": "Create some smaller athlete tables\nFinally the main athletes df file can be split the up by sex and season, since the id’s for different fields have been added\n\nWe don’t really need sex and Season so we can drop these\nWe can also reorder the index (not the athlete ID)\nIf Medals = NaN this probably means they didn’t get one. So we can replace medals with Gold, Silver and Bronze (one-hot encoding)\nInstead of Games, Year, City lets replace with a uniques INT id. And put that data in another dataframe for cities\n\n\n# split and Reset index, so it increases 1,2,3,4,etc\n\ndf_M_S = df[(df.Sex=='M') & (df.Season=='Summer')]\ndf_M_S.reset_index(inplace = True,drop=True)\n\ndf_F_S = df[(df.Sex=='F') & (df.Season=='Summer')]\ndf_F_S.reset_index(inplace = True,drop=True)\n\ndf_M_W = df[(df.Sex=='M') & (df.Season=='Winter')]\ndf_M_W.reset_index(inplace = True,drop=True)\n\ndf_F_W = df[(df.Sex=='F') & (df.Season=='Winter')]\ndf_F_W.reset_index(inplace = True,drop=True)\n\n\n# Look at the data\n\ndf_M_W.head(10)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Name\n      Sex\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Games\n      Year\n      Season\n      City\n      Sport\n      Event\n      Medal\n    \n  \n  \n    \n      0\n      672\n      672\n      13\n      7\n      391\n      Clarence John Abel\n      M\n      23.0\n      185.0\n      102.0\n      United States\n      USA\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ice Hockey\n      Ice Hockey Men's Ice Hockey\n      Silver\n    \n    \n      1\n      1791\n      1791\n      205\n      7\n      992\n      Josef Adolf\n      M\n      25.0\n      NaN\n      NaN\n      Czechoslovakia\n      BOH\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Nordic Combined\n      Nordic Combined Men's Individual\n      NaN\n    \n    \n      2\n      1951\n      1951\n      300\n      7\n      1077\n      Xavier Affentranger\n      M\n      26.0\n      NaN\n      NaN\n      Switzerland\n      SUI\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ski Jumping\n      Ski Jumping Men's Normal Hill, Individual\n      NaN\n    \n    \n      3\n      1952\n      1952\n      385\n      7\n      1077\n      Xavier Affentranger\n      M\n      26.0\n      NaN\n      NaN\n      Switzerland\n      SUI\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Cross Country Skiing\n      Cross Country Skiing Men's 18 kilometres\n      NaN\n    \n    \n      4\n      1953\n      1953\n      205\n      7\n      1077\n      Xavier Affentranger\n      M\n      26.0\n      NaN\n      NaN\n      Switzerland\n      SUI\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Nordic Combined\n      Nordic Combined Men's Individual\n      NaN\n    \n    \n      5\n      2397\n      2397\n      305\n      7\n      1341\n      Johan Petter hln (Andersson-)\n      M\n      44.0\n      NaN\n      NaN\n      Sweden\n      SWE\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Curling\n      Curling Men's Curling\n      Silver\n    \n    \n      6\n      4040\n      4040\n      300\n      7\n      2329\n      Louis Albert\n      M\n      25.0\n      NaN\n      NaN\n      France\n      FRA\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ski Jumping\n      Ski Jumping Men's Normal Hill, Individual\n      NaN\n    \n    \n      7\n      4249\n      4249\n      472\n      7\n      2431\n      Henri Eugne Aldebert\n      M\n      43.0\n      NaN\n      NaN\n      France-1\n      FRA\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Bobsleigh\n      Bobsleigh Men's Four/Five\n      NaN\n    \n    \n      8\n      5103\n      5103\n      13\n      7\n      2902\n      Karl Ruben Allinger\n      M\n      32.0\n      NaN\n      NaN\n      Sweden\n      SWE\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Ice Hockey\n      Ice Hockey Men's Ice Hockey\n      NaN\n    \n    \n      9\n      5174\n      5174\n      7\n      7\n      2939\n      Ernst Alm\n      M\n      23.0\n      174.0\n      NaN\n      Sweden\n      SWE\n      1924 Winter\n      1924\n      Winter\n      Chamonix\n      Cross Country Skiing\n      Cross Country Skiing Men's 50 kilometres\n      NaN\n    \n  \n\n\n\n\n\n\n\n\ndf_M_S = df_M_S.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_F_S = df_F_S.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_M_W = df_M_W.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_F_W = df_F_W.drop(columns=['Name','Sex','Season','City','Games','Sport','Event'])\ndf_F_W.head(5)\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Year\n      Medal\n    \n  \n  \n    \n      0\n      30620\n      30620\n      268\n      7\n      15776\n      22.0\n      165.0\n      NaN\n      France\n      FRA\n      1924\n      NaN\n    \n    \n      1\n      30621\n      30621\n      242\n      7\n      15776\n      22.0\n      165.0\n      NaN\n      France-1\n      FRA\n      1924\n      Bronze\n    \n    \n      2\n      63714\n      63714\n      242\n      7\n      32641\n      25.0\n      NaN\n      NaN\n      Austria\n      AUT\n      1924\n      Gold\n    \n    \n      3\n      94058\n      94058\n      268\n      7\n      47618\n      11.0\n      155.0\n      45.0\n      Norway\n      NOR\n      1924\n      NaN\n    \n    \n      4\n      94533\n      94533\n      242\n      7\n      47845\n      NaN\n      NaN\n      NaN\n      Belgium\n      BEL\n      1924\n      NaN\n    \n  \n\n\n\n\n\nSeperate out medals\n\ndf_F_W = pd.get_dummies(df_F_W,columns=['Medal'])\ndf_M_W = pd.get_dummies(df_M_W,columns=['Medal'])\ndf_F_S = pd.get_dummies(df_F_S,columns=['Medal'])\ndf_M_S = pd.get_dummies(df_M_S,columns=['Medal'])\ndf_M_S.head()\n\n\n\n\n\n  \n    \n      \n      event_athlete_ID\n      event_athlete_ID\n      event_id\n      games_id\n      athlete_ID\n      Age\n      Height\n      Weight\n      Team\n      NOC\n      Year\n      Medal_Bronze\n      Medal_Gold\n      Medal_Silver\n    \n  \n  \n    \n      0\n      3079\n      3079\n      191\n      0\n      1724\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      1\n      3080\n      3080\n      92\n      0\n      1724\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      2\n      3081\n      3081\n      191\n      0\n      1725\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      3\n      3082\n      3082\n      92\n      0\n      1725\n      NaN\n      NaN\n      NaN\n      Greece-3\n      CRT\n      1896\n      0\n      0\n      0\n    \n    \n      4\n      7348\n      7348\n      100\n      0\n      4113\n      NaN\n      NaN\n      NaN\n      Greece\n      CRT\n      1896\n      0\n      0\n      0"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_createDFs.html#save-it",
    "href": "posts/2022-07-29-OlympicsSQL_createDFs.html#save-it",
    "title": "ThomasHSimm",
    "section": "Save it",
    "text": "Save it\n\ndf_F_S.to_csv('athlete_F_S')\ndf_F_W.to_csv('athlete_F_W')\ndf_M_S.to_csv('athlete_M_S')\ndf_M_W.to_csv('athlete_M_W')\n\ndf_all_athletes.to_csv('all_athletes')\ndf_country.to_csv('country')\ndf_event.to_csv('event')\ndf_games.to_csv('games')\ndf_population.to_csv('population')"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#introduction",
    "href": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nDue to the global importance of the Olympics, in 2020 there was a broadcast audience of more than 3 billion, I was interested to explore whether countries with the most medals will reflect global politics. And to see if the countries with most influence get more medals.\nThere are two relatively easy to obtain metrics that can be used to define the importance of a nation internationally, GDP and population.\nGross domestic product (GDP) is a monetary measure of the market value of all the final goods and services produced in a specific time period by countries. GDP is often used as a metric for international comparisons as well as a broad measure of economic progress. It is often considered to be the “world’s most powerful statistical indicator of national development and progress”. GDP Wikipedia.\nThe population of a country is an important parameter in assessing the global importance of a nation. Furthermore, the more people in a country the greater the pool of potential athletes.\nIn the final part of this page I will briefly look at how the Cold War was reflected in the Olympics data."
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#pre-analysis",
    "href": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#pre-analysis",
    "title": "ThomasHSimm",
    "section": "Pre-analysis",
    "text": "Pre-analysis\n\nGet medals won by country and year\nWhat we want to end up with is a new table with- - Nation - Number of medals - Event or year of the event - Then the details of nations we’re studying: - GDP - Population - Continent\nTo get a unique medal count for this, we can do a count by grouping on - Nation and Year But also on: - Medal type (Gold, Silver, Bronze) - Event id As we only know if a medal is unique for an athlete if the same medal type does not exist for another athlete in the same event at the same games (year). This is to avoid duplication for team sports. If it is a mixed event then we would need to do the grouping on data of male and female athletes.\nFrom inside out\n\nUse UNION to join the males and female summer athletes\n\nGet NOC, medal types, year, event_id\n\nUse GROUP BY to get unique medals and COUNT\nUse GROUP BY to get medals for countries in each event/year, SUM so we are adding up events\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandasql import sqldf\nimport copy\nimport numpy as np\nimport scipy.stats\n\n\ndf_F_S =pd.read_csv('data/athlete_F_S')\n# df_F_W=pd.read_csv('data/athlete_F_W')\ndf_M_S=pd.read_csv('data/athlete_M_S')\n# df_M_W=pd.read_csv('data/athlete_M_W')\n\ndf_all_athletes= pd.read_csv('data/all_athletes')\ndf_country= pd.read_csv('data/country')\ndf_event= pd.read_csv('data/event')\n# df_games= pd.read_csv('data/games')\n# df_population= pd.read_csv('data/population')\n\ndf_country = df_country.groupby('NOC').max()\ndf_country.head(10)\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      Nation\n      Continent\n      Population\n      GDP\n    \n    \n      NOC\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AFG\n      0\n      Afghanistan\n      Asia\n      32890171\n      19807\n    \n    \n      ALB\n      1\n      Albania\n      Europe\n      2829741\n      14800\n    \n    \n      ALG\n      2\n      Algeria\n      Africa\n      45400000\n      145164\n    \n    \n      AND\n      3\n      Andorra\n      Europe\n      79535\n      3155\n    \n    \n      ANG\n      4\n      Angola\n      Africa\n      33086278\n      62307\n    \n    \n      ANT\n      5\n      Antigua\n      Americas\n      99337\n      1415\n    \n    \n      ANZ\n      7\n      Australia\n      Oceania\n      25921518\n      1330901\n    \n    \n      ARG\n      8\n      Argentina\n      Americas\n      47327407\n      383067\n    \n    \n      ARM\n      9\n      Armenia\n      Asia\n      2963900\n      12645\n    \n    \n      AUT\n      10\n      Austria\n      Europe\n      9027999\n      428965\n    \n  \n\n\n\n\n\ndf_by_year=\\\n     sqldf('SELECT                                                 \\\n              NOC,                                                 \\\n              Year,                                                \\\n              SUM(counta)              AS num_medals               \\\n                FROM(SELECT                                        \\\n                    NOC,                                           \\\n                    Year,                                          \\\n                    event_id,                                      \\\n                    Medal_Bronze, Medal_Gold, Medal_Silver,        \\\n                    COUNT(*) as counta                             \\\n                        FROM(SELECT                                \\\n                            NOC,                                   \\\n                            Year,                                  \\\n                            event_id,                              \\\n                            Medal_Bronze, Medal_Gold, Medal_Silver \\\n                        FROM                                       \\\n                            df_F_S                                 \\\n                        WHERE Medal_Bronze=1 OR Medal_Gold=1 OR Medal_Silver \\\n                        UNION                                      \\\n                        SELECT                                     \\\n                            NOC,                                   \\\n                            Year,                                  \\\n                            event_id,                              \\\n                            Medal_Bronze, Medal_Gold, Medal_Silver \\\n                        FROM                                       \\\n                            df_M_S                                 \\\n                        WHERE Medal_Bronze=1 OR Medal_Gold=1 OR Medal_Silver) as MF                  \\\n                    GROUP BY                                       \\\n                        NOC, Year, event_id, Medal_Bronze, Medal_Gold, Medal_Silver\\\n                    ORDER BY                                       \\\n                        NOC) as inner                              \\\n            GROUP BY                                               \\\n                NOC, Year;',locals()) \n\ndf_by_year[df_by_year.Year==2016].sort_values('num_medals',ascending=False).head(10)\n\n\n\n\n\n  \n    \n      \n      NOC\n      Year\n      num_medals\n    \n  \n  \n    \n      1246\n      USA\n      2016\n      121\n    \n    \n      246\n      CHN\n      2016\n      70\n    \n    \n      527\n      GBR\n      2016\n      67\n    \n    \n      415\n      EUN\n      2016\n      56\n    \n    \n      471\n      FRA\n      2016\n      42\n    \n    \n      497\n      FRG\n      2016\n      42\n    \n    \n      706\n      JPN\n      2016\n      41\n    \n    \n      38\n      ANZ\n      2016\n      29\n    \n    \n      669\n      ITA\n      2016\n      28\n    \n    \n      230\n      CAN\n      2016\n      22\n    \n  \n\n\n\n\n\n\nJoin with the country table\nNow just join to the country table\n\ndf_=\\\n     sqldf('SELECT                              \\\n              NOC,                              \\\n              Nation,                           \\\n              Continent,                        \\\n              SUM(num_medals)  AS number_of_medals,                  \\\n              Population,                       \\\n              GDP                               \\\n            FROM(                               \\\n                SELECT *                        \\\n                FROM                            \\\n                    df_country AS c             \\\n                INNER JOIN                      \\\n                    df_by_year AS d             \\\n                ON                              \\\n                    c.NOC=d.NOC                 \\\n                WHERE                           \\\n                    d.Year>=2008)               \\\n            GROUP BY                            \\\n                NOC,Continent                   \\\n            ORDER BY                            \\\n                num_medals desc;',locals())\n               \ndf_                    \n\n\n\n\n\n  \n    \n      \n      NOC\n      Nation\n      Continent\n      number_of_medals\n      Population\n      GDP\n    \n  \n  \n    \n      0\n      USA\n      USA\n      Americas\n      334\n      332906919\n      20936600\n    \n    \n      1\n      CHN\n      China\n      Asia\n      259\n      1412600000\n      14722731\n    \n    \n      2\n      EUN\n      Russia\n      Europe\n      210\n      147190000\n      1483498\n    \n    \n      3\n      GBR\n      UK\n      Europe\n      180\n      67081234\n      2707744\n    \n    \n      4\n      ANZ\n      Australia\n      Oceania\n      110\n      25921518\n      1330901\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      99\n      TUN\n      Tunisia\n      Africa\n      7\n      11746695\n      39236\n    \n    \n      100\n      UAE\n      United Arab Emirates\n      Asia\n      1\n      9282410\n      421142\n    \n    \n      101\n      UGA\n      Uganda\n      Africa\n      1\n      42885900\n      37372\n    \n    \n      102\n      VEN\n      Venezuela\n      Americas\n      5\n      28705000\n      482359\n    \n    \n      103\n      VIE\n      Vietnam\n      Asia\n      3\n      98505400\n      271158\n    \n  \n\n104 rows × 6 columns"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#correlation-in-population-and-gdp",
    "href": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#correlation-in-population-and-gdp",
    "title": "ThomasHSimm",
    "section": "Correlation in Population and GDP",
    "text": "Correlation in Population and GDP\nFirst create a function to display correlations: - produce scatter plots - find which countries are poor correlation - find some correlation stats\n\ndef modname(string):\n    string=''.join([string[0].upper(),string[1:].lower()])\n    string=string.replace('_',' ')\n    return string\ndef doFigAddOns(nomX,nomY,fontsize):\n        plt.ylabel(modname(nomY), fontsize=fontsize)\n        plt.xlabel(nomX, fontsize=fontsize)\n        plt.grid(True)\n        \ndef scatter_combo(df_temp,xval,yval):\n    \n    df_temp=df_temp.set_index('Nation')\n    fontsize=14\n    \n    df_temp=copy.copy(df_temp)\n    # remove 0 values\n    df_temp=df_temp[df_temp.loc[:,xval]!=0]\n    \n    # drop NaNs \n    df_temp=df_temp.dropna()\n    \n    # values in millions\n    df_temp.loc[:,xval]=df_temp.loc[:,xval]/1e6\n    \n    # the names of the columns\n    nomX=xval#(df_temp.columns[xval])\n    nomY=yval#modname(df_temp.columns[yval])\n    \n    # define the x and y values\n    X=df_temp.loc[:,xval]\n    Y=df_temp.loc[:,yval]\n    \n    # do some plots\n    fig,ax=plt.subplots(figsize=(7,15))\n    plt.rcParams['font.size'] = '13'\n    \n    # Fig A\n    ax1=plt.subplot(3,1,1)\n    ax1.plot(X ,Y,'+b',markeredgewidth=2,ms=10)\n    m,b=np.polyfit(X,Y,1)\n    Ypred=X*m+b\n    plt.plot(X,Ypred, '--k');\n    doFigAddOns(nomX,nomY,fontsize)\n    \n    \n    \n    # Fig B\n    ax3=plt.subplot(3,1,2)\n    ax3.plot(X ,Y,'+b',markeredgewidth=2,ms=10)\n    X=X.sort_values()\n    Ypred=X*m+b\n    plt.plot(X,Ypred, '--k');\n    plt.yscale('log')\n    plt.xscale('log')\n    doFigAddOns(nomX,nomY,fontsize) \n\n    # Fig C\n    diffa = df_temp.loc[:,yval]-Ypred\n    ax2=plt.subplot(3,1,3)\n    ax2.plot(X,diffa, 'xk',markeredgewidth=2,ms=10);\n    plt.xscale('log')\n    doFigAddOns(nomX,'Difference between \\nlinear fit',fontsize)\n\n    plt.subplots_adjust(hspace=0.35)\n    \n    # because sorted x, need to get original x back\n    X=df_temp.loc[:,xval]\n\n    # Get some correlation values, and what are worst countries\n    corr=scipy.stats.pearsonr(X, Y)\n    print('Correlation of  = {:.2f} ({:.0e}) \\n \\\n           And m= {:.3f} b={:.1f}          '.format(corr[0],corr[1],m,b))\n    \n    country_hi_corr=(diffa).sort_values(ascending=False).index[0:10]\n    print('Countries worst correlation where overachive',diffa[country_hi_corr])\n    \n    country_low_corr=(diffa).sort_values().index[0:10]\n    print('Countries worst correlation where unachieve',diffa[country_low_corr])\n\n    d={'Underachieve':country_low_corr,'Overachieve':country_hi_corr}\n    return pd.DataFrame(data=d)\n\ndef getCorr(df_temp, xval,yval):\n    \n    df_temp=copy.copy(df_temp)\n    # remove 0 values\n    df_temp=df_temp[df_temp.loc[:,xval]!=0]\n    \n    # drop NaNs \n    df_temp=df_temp.dropna()\n    \n    # define the x and y values\n    X=df_temp.loc[:,xval]\n    Y=df_temp.loc[:,yval]\n    \n    # Get some correlation values, and what are worst countries\n    corr=scipy.stats.pearsonr(X, Y)\n    print('Pearson Correlation of  = {:.2f} ({:.0e})'.format(corr[0],corr[1]))\n    # Get some correlation values, and what are worst countries\n    corr=scipy.stats.spearmanr(X, Y)\n    print('Spearman Correlation of  = {:.2f} ({:.0e})'.format(corr[0],corr[1]))\n\n\npopCorr=scatter_combo(df_,'GDP','number_of_medals')\npopCorr\n\nCorrelation of  = 0.84 (4e-29) \n            And m= 17.195 b=14.2          \nCountries worst correlation where overachive Nation\nRussia         170.270535\nUK             119.219670\nAustralia       72.894435\nFrance          59.020671\nGermany         47.334168\nUkraine         41.104002\nSouth Korea     37.742411\nItaly           36.341876\nCuba            33.005895\nKazakhstan      26.858922\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia                  -48.322884\nUSA                    -40.224834\nSaudi Arabia           -25.259275\nIndonesia              -22.420333\nUnited Arab Emirates   -20.462293\nPhilippines            -19.436562\nIsrael                 -18.132356\nMexico                 -17.725355\nAustria                -17.596809\nChile                  -17.570066\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      Russia\n    \n    \n      1\n      USA\n      UK\n    \n    \n      2\n      Saudi Arabia\n      Australia\n    \n    \n      3\n      Indonesia\n      France\n    \n    \n      4\n      United Arab Emirates\n      Germany\n    \n    \n      5\n      Philippines\n      Ukraine\n    \n    \n      6\n      Israel\n      South Korea\n    \n    \n      7\n      Mexico\n      Italy\n    \n    \n      8\n      Austria\n      Cuba\n    \n    \n      9\n      Chile\n      Kazakhstan\n    \n  \n\n\n\n\n\n\n\n\nGDPCorr=scatter_combo(df_,'Population','number_of_medals')\nGDPCorr\n\nCorrelation of  = 0.42 (7e-06) \n            And m= 0.113 b=20.6          \nCountries worst correlation where overachive Nation\nUSA            275.692534\nRussia         172.705692\nUK             151.769692\nGermany         96.889859\nFrance          89.679993\nAustralia       86.426756\nChina           78.529401\nJapan           69.159606\nItaly           55.694604\nSouth Korea     53.504928\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia          -165.076115\nIndonesia       -41.444198\nNigeria         -40.164409\nPhilippines     -32.332446\nVietnam         -28.785832\nEgypt           -26.362309\nSudan           -24.687085\nUganda          -24.492699\nSaudi Arabia    -23.601957\nCameroon        -22.395235\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      USA\n    \n    \n      1\n      Indonesia\n      Russia\n    \n    \n      2\n      Nigeria\n      UK\n    \n    \n      3\n      Philippines\n      Germany\n    \n    \n      4\n      Vietnam\n      France\n    \n    \n      5\n      Egypt\n      Australia\n    \n    \n      6\n      Sudan\n      China\n    \n    \n      7\n      Uganda\n      Japan\n    \n    \n      8\n      Saudi Arabia\n      Italy\n    \n    \n      9\n      Cameroon\n      South Korea\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']=='Europe'],'Population','number_of_medals')\n\nCorrelation of  = 0.93 (2e-16) \n            And m= 1.498 b=5.2          \nCountries worst correlation where overachive Nation\nUK                74.302826\nHungary           23.300286\nNetherlands       23.269039\nBelarus           19.808781\nDenmark           17.002417\nFrance            11.114933\nCroatia            9.991807\nCzech Republic     5.060035\nSlovenia           4.658317\nLithuania          4.630427\ndtype: float64\nCountries worst correlation where unachieve Nation\nPoland     -31.142356\nSpain      -24.255647\nPortugal   -16.682378\nRussia     -15.733456\nAustria    -14.709259\nRomania    -12.930475\nBelgium    -11.649525\nItaly      -10.448382\nGreece      -8.813758\nUkraine     -8.812069\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      Poland\n      UK\n    \n    \n      1\n      Spain\n      Hungary\n    \n    \n      2\n      Portugal\n      Netherlands\n    \n    \n      3\n      Russia\n      Belarus\n    \n    \n      4\n      Austria\n      Denmark\n    \n    \n      5\n      Romania\n      France\n    \n    \n      6\n      Belgium\n      Croatia\n    \n    \n      7\n      Italy\n      Czech Republic\n    \n    \n      8\n      Greece\n      Slovenia\n    \n    \n      9\n      Ukraine\n      Lithuania\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']!='Europe'],'Population','number_of_medals')\n\nCorrelation of  = 0.49 (2e-05) \n            And m= 0.109 b=14.0          \nCountries worst correlation where overachive Nation\nUSA            283.666410\nAustralia       93.134297\nChina           90.957076\nJapan           76.277923\nSouth Korea     60.318993\nCanada          40.727568\nCuba            33.748715\nKazakhstan      27.859642\nNew Zealand     25.400672\nAzerbaijan      19.852149\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia          -152.808654\nIndonesia       -33.720543\nNigeria         -32.669700\nPhilippines     -25.269105\nVietnam         -21.778878\nEgypt           -19.334337\nSudan           -17.902477\nUganda          -17.715178\nSaudi Arabia    -16.856911\nCameroon        -15.694183\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      USA\n    \n    \n      1\n      Indonesia\n      Australia\n    \n    \n      2\n      Nigeria\n      China\n    \n    \n      3\n      Philippines\n      Japan\n    \n    \n      4\n      Vietnam\n      South Korea\n    \n    \n      5\n      Egypt\n      Canada\n    \n    \n      6\n      Sudan\n      Cuba\n    \n    \n      7\n      Uganda\n      Kazakhstan\n    \n    \n      8\n      Saudi Arabia\n      New Zealand\n    \n    \n      9\n      Cameroon\n      Azerbaijan\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']=='Europe'],'GDP','number_of_medals')\n\nCorrelation of  = 0.80 (6e-09) \n            And m= 45.027 b=10.1          \nCountries worst correlation where overachive Nation\nRussia            133.114656\nUK                 47.990590\nUkraine            40.906665\nBelarus            26.198814\nHungary            25.932286\nCroatia             8.392025\nCzech Republic      4.946635\nDenmark             4.919196\nNetherlands         3.836572\nSerbia              2.527421\ndtype: float64\nCountries worst correlation where unachieve Nation\nGermany       -54.463232\nSwitzerland   -25.766716\nAustria       -25.402938\nBelgium       -22.291826\nIreland       -18.937224\nPortugal      -16.500704\nSpain         -15.776437\nFinland       -14.300792\nItaly         -12.028820\nSweden        -10.294891\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      Germany\n      Russia\n    \n    \n      1\n      Switzerland\n      UK\n    \n    \n      2\n      Austria\n      Ukraine\n    \n    \n      3\n      Belgium\n      Belarus\n    \n    \n      4\n      Ireland\n      Hungary\n    \n    \n      5\n      Portugal\n      Croatia\n    \n    \n      6\n      Spain\n      Czech Republic\n    \n    \n      7\n      Finland\n      Denmark\n    \n    \n      8\n      Italy\n      Netherlands\n    \n    \n      9\n      Sweden\n      Serbia\n    \n  \n\n\n\n\n\n\n\n\nscatter_combo(df_[df_['Continent']!='Europe'],'GDP','number_of_medals')\n\nCorrelation of  = 0.94 (2e-33) \n            And m= 16.234 b=8.7          \nCountries worst correlation where overachive Nation\nAustralia      79.660038\nSouth Korea    44.796081\nCuba           38.591086\nKazakhstan     32.508245\nKenya          28.660696\nNew Zealand    27.815933\nAzerbaijan     25.573605\nCanada         23.586944\nJamaica        23.041050\nBrazil         19.812142\ndtype: float64\nCountries worst correlation where unachieve Nation\nIndia                  -40.315038\nSaudi Arabia           -19.100124\nIndonesia              -15.916697\nUSA                    -14.609781\nUnited Arab Emirates   -14.571357\nPhilippines            -13.602977\nIsrael                 -12.259868\nChile                  -11.840843\nVenezuela              -11.565125\nMexico                 -11.204664\ndtype: float64\n\n\n\n\n\n\n  \n    \n      \n      Underachieve\n      Overachieve\n    \n  \n  \n    \n      0\n      India\n      Australia\n    \n    \n      1\n      Saudi Arabia\n      South Korea\n    \n    \n      2\n      Indonesia\n      Cuba\n    \n    \n      3\n      USA\n      Kazakhstan\n    \n    \n      4\n      United Arab Emirates\n      Kenya\n    \n    \n      5\n      Philippines\n      New Zealand\n    \n    \n      6\n      Israel\n      Azerbaijan\n    \n    \n      7\n      Chile\n      Canada\n    \n    \n      8\n      Venezuela\n      Jamaica\n    \n    \n      9\n      Mexico\n      Brazil\n    \n  \n\n\n\n\n\n\n\n\ndf_GDP=copy.copy(df_[['Nation','Continent','GDP']])\n\ndf_GDP = df_GDP.sort_values('GDP',ascending=False)\ndf_GDP\nrich_list = df_GDP.head(52).index\n# # index_not_rich=[i for i,country in enumerate(df_.index) if (country not in rich_list) and (df_.iloc[i,2]!='Europe') and (df_.index[i]!='India')]\n# # index_rich=[i for i,country in enumerate(df_.index) if ( (df_.iloc[i,2]!='Europe') )]\nindex_rich=[i for i,country in enumerate(df_.index) if (country in rich_list) ]\nindex_not_rich=[i for i,country in enumerate(df_.index) if (country not in rich_list) ]\n\nprint('         Index Rich- Population')\ngetCorr(df_.iloc[index_rich,:],'Population','number_of_medals')\nprint('         Index Not Rich- Population')\ngetCorr(df_.iloc[index_not_rich,:],'Population','number_of_medals')\nprint('         Index Rich- GDP')\ngetCorr(df_.iloc[index_rich,:],'GDP','number_of_medals')\nprint('         Index Not Rich- GDP')\ngetCorr(df_.iloc[index_not_rich,:],'GDP','number_of_medals')\n\n         Index Rich- Population\nPearson Correlation of  = 0.37 (6e-03)\nSpearman Correlation of  = 0.30 (3e-02)\n         Index Not Rich- Population\nPearson Correlation of  = 0.17 (2e-01)\nSpearman Correlation of  = 0.15 (3e-01)\n         Index Rich- GDP\nPearson Correlation of  = 0.84 (7e-15)\nSpearman Correlation of  = 0.50 (2e-04)\n         Index Not Rich- GDP\nPearson Correlation of  = 0.32 (2e-02)\nSpearman Correlation of  = 0.38 (6e-03)\n\n\n\nprint('         Index Europe- GDP')\ngetCorr(df_[df_['Continent']=='Europe'],'GDP','number_of_medals')\nprint('         Index Not Europe- GDP')\ngetCorr(df_[df_['Continent']!='Europe'],'GDP','number_of_medals')\n\nprint('         Index Europe- Population')\ngetCorr(df_[df_['Continent']=='Europe'],'Population','number_of_medals')\nprint('         Index Not Europe- Population')\ngetCorr(df_[df_['Continent']!='Europe'],'Population','number_of_medals')\n\n         Index Europe- GDP\nPearson Correlation of  = 0.80 (6e-09)\nSpearman Correlation of  = 0.71 (1e-06)\n         Index Not Europe- GDP\nPearson Correlation of  = 0.94 (2e-33)\nSpearman Correlation of  = 0.51 (1e-05)\n         Index Europe- Population\nPearson Correlation of  = 0.93 (2e-16)\nSpearman Correlation of  = 0.81 (3e-09)\n         Index Not Europe- Population\nPearson Correlation of  = 0.49 (2e-05)\nSpearman Correlation of  = 0.42 (3e-04)\n\n\n\nprint('GDP'),getCorr(df_,'GDP','number_of_medals')\nprint('Population'),getCorr(df_,'Population','number_of_medals')\n\nGDP\nPearson Correlation of  = 0.84 (4e-29)\nSpearman Correlation of  = 0.60 (2e-11)\nPopulation\nPearson Correlation of  = 0.42 (7e-06)\nSpearman Correlation of  = 0.41 (1e-05)\n\n\n(None, None)"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#overview-of-gdp-and-population",
    "href": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#overview-of-gdp-and-population",
    "title": "ThomasHSimm",
    "section": "Overview of GDP and population",
    "text": "Overview of GDP and population\n\nHypothesis: GDP is correlated with Medals, and Population is too but less so\n\n\nMethods Used\nLooking at number of medals against GDP and population, for a period from 2008-2016 inclusive. Using population and GDP data from ~2020. - scatter plots - to visualize the relationships between medals and GDP, and medals and population. Both show a correlation - Pearson & Spearman correlation - To quatify the correlation seen. Pearson looks for a linear relationship whereas Spearman considers the ordering of the variables. The Pearson results showed a moderate to strong relationship for GDP and a weak to moderate relationship for population. The Spearman results were similar (more correlation for GDP) but the correlation values were lower. - I considered looking at the changes with time, but there were a lot of factors affecting country participation and the data was harder to obtain easily\n\n\nOverview\nResults were mainly as expected and hence PROVED.\n\nGDP\n\n\nALL = strong AND significant\nEurope = strong AND significant\nNOT Europe = very strong AND significant\n\n\nPopulation\n\n\nALL = moderate AND significant\nEurope = very strong AND significant\nNOT Europe = moderate AND significant\n\nUsing a line fit of the data (GDP or Population to Medals) gives an indication of which countries are reducing the correlation. If the country has more medals than the fit then it is overachieve and if it has less it is underachieveing. The table below shows which countries are under and overachieveing for GDP and population.\n\n\nGDPCorr.rename(columns={'Overachieve':'GDP - Overachieve','Underachieve':'GDP - Underachieve'},inplace=True)\npopCorr.rename(columns={'Overachieve':'Population - Overachieve','Underachieve':'Population - Underachieve'},inplace=True)\n\ncorrComb=pd.concat([GDPCorr,popCorr],axis=1)\ncorrComb\n\n\n\n\n\n  \n    \n      \n      GDP - Underachieve\n      GDP - Overachieve\n      Population - Underachieve\n      Population - Overachieve\n    \n  \n  \n    \n      0\n      India\n      USA\n      India\n      Russia\n    \n    \n      1\n      Indonesia\n      Russia\n      USA\n      UK\n    \n    \n      2\n      Nigeria\n      UK\n      Saudi Arabia\n      Australia\n    \n    \n      3\n      Philippines\n      Germany\n      Indonesia\n      France\n    \n    \n      4\n      Vietnam\n      France\n      United Arab Emirates\n      Germany\n    \n    \n      5\n      Egypt\n      Australia\n      Philippines\n      Ukraine\n    \n    \n      6\n      Sudan\n      China\n      Israel\n      South Korea\n    \n    \n      7\n      Uganda\n      Japan\n      Mexico\n      Italy\n    \n    \n      8\n      Saudi Arabia\n      Italy\n      Austria\n      Cuba\n    \n    \n      9\n      Cameroon\n      South Korea\n      Chile\n      Kazakhstan\n    \n  \n\n\n\n\nSo based on the above it may make sense to group countries based on their GDP, into a rich and poor list. But as shown above this doesn’t increase the correlation for either group.\nThe only useful metric to increase the correlation was to group the countries into those from Europe. This is probably due to the similarity of countries within Europe (and outside): size, GDP but also culturally; and it may be because the European countries have much greater participation at the Olympics (both over currently and historically).\n\n\nGuide on Correlation\n\npd.DataFrame({'Correlation':['1','0.8 - 1.0','0.6 - 0.8','0.4 - 0.6','0.2 - 0.4','0 - 0.2'],\\\n   'Interpretation':['Pefect','Strong to Perfect','Moderate to Very Strong','Moderate to strong','Weak to moderate','Zero to weak']})\n\n\n\n\n\n\n  \n    \n      \n      Correlation\n      Interpretation\n    \n  \n  \n    \n      0\n      1\n      Pefect\n    \n    \n      1\n      0.8 - 1.0\n      Strong to Perfect\n    \n    \n      2\n      0.6 - 0.8\n      Moderate to Very Strong\n    \n    \n      3\n      0.4 - 0.6\n      Moderate to strong\n    \n    \n      4\n      0.2 - 0.4\n      Weak to moderate\n    \n    \n      5\n      0 - 0.2\n      Zero to weak\n    \n  \n\n\n\n\nTo determine whether the correlation between variables is significant, compare the p-value to your significance level. Usually, a significance level (denoted as α or alpha) of 0.05 works well. An α of 0.05 (5e-2) indicates that the risk of concluding that a correlation exists—when, actually, no correlation exists—is 5%. The p-value tells you whether the correlation coefficient is significantly different from 0. (A coefficient of 0 indicates that there is no linear relationship.)\n\n- P-value ≤ α (5e-2): The correlation is statistically significant\n    If the p-value is less than or equal to the significance level, then you can conclude that the correlation is different from 0. \n- P-value > α (5e-2): The correlation is not statistically significant\n    If the p-value is greater than the significance level, then you cannot conclude that the correlation is different from 0. \n    \nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107969/\nhttps://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/correlation/interpret-the-results/"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#number-of-athletes",
    "href": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#number-of-athletes",
    "title": "ThomasHSimm",
    "section": "Number of athletes",
    "text": "Number of athletes\nA metric that would make sense to correlate with medals would be the number of athletes each nation sends to an Olympics. This is because, for the most part, participation is done on merit. That is athletes have to qualify against athletes from other nations.\nSo the metrics we want to look at are: - the number of athletes per nation attending a particular games - the number of medals per nation per games\nNB I will just use male athletes for simplicity\n\nChange in average athletes per continent\nFirst, let us look if the greater number of athletes from Europe is also reflected in the average number of athletes each nation sends within each continent.\nAs shown below European countries send around twice as many athletes per nation as other continents.\n\ntempa= sqldf('SELECT                                     \\\n            Year,                                        \\\n             Continent,                                  \\\n             AVG(numbers)  as ath_per_nation             \\\n        FROM(SELECT                                      \\\n            c.Continent,                                 \\\n            a.Year,\\\n            COUNT(*)           AS numbers                \\\n            FROM                                         \\\n                df_country as c                          \\\n            LEFT JOIN                                    \\\n                df_M_S as a                              \\\n            ON                                           \\\n                a.NOC = c.NOC                            \\\n            GROUP BY                                     \\\n                a.Year,c.Continent,c.Nation              \\\n            ORDER BY                                     \\\n                Year asc) A                              \\\n            GROUP BY                                     \\\n                 Year,Continent;',locals())\n\nplt.subplots(figsize=(8,5))\ncola=['g>--','<r-.','bo-','mv-','kp:']\nfor i,continent in enumerate(tempa.Continent.unique()):\n    x=tempa[tempa.Continent==continent]['Year']\n    y=tempa[tempa.Continent==continent]['ath_per_nation']\n    plt.plot(x,y,cola[i]);\nplt.legend(tempa.Continent.unique());\nplt.ylim([-5,200])\nplt.grid(True)\nplt.xlabel('Year')\nplt.ylabel('Number of male athletes\\n per nation');\n\n\n\n\n\n\nAthletes per nation VS medals per nation\nTo look at this correlation we need to do the following steps: - Join athletes with country tables - Group by Nation and whether they have a medal - Count this, this will give number of events with a medal - Then need to remove nations that didn’t get any medals - Get scatter and correlation of these - Group by continent and do the same\n\ntempa= sqldf('SELECT                                     \\\n             Continent,                                  \\\n             Nation,                                     \\\n             Medal,                                      \\\n             SUM(numbers)   AS numbers                   \\\n        FROM(SELECT                                      \\\n            c.Continent,                                 \\\n            c.Nation,                                    \\\n            a.Medal,                                     \\\n            COUNT(*)           AS numbers                \\\n            FROM                                         \\\n                df_country as c                          \\\n            LEFT JOIN                                    \\\n                df_M_S as a                              \\\n            ON                                           \\\n                a.NOC = c.NOC                            \\\n            WHERE Year>2003                              \\\n            GROUP BY                                     \\\n                c.Continent,c.Nation,a.Medal_Gold,a.Medal_Silver,a.Medal_Bronze) A          \\\n            GROUP BY                                     \\\n                Continent, Nation,Medal;',locals())\n\ntempa2= sqldf('SELECT                                     \\\n             Nation,                                     \\\n             COUNT(numbers)   AS numbers                 \\\n        FROM(SELECT                                      \\\n            a.athlete_ID,                                \\\n            c.Nation,                                    \\\n            COUNT(*)           AS numbers                \\\n            FROM                                         \\\n                df_country as c                          \\\n            LEFT JOIN                                    \\\n                df_F_S as a                              \\\n            ON                                           \\\n                a.NOC = c.NOC                            \\\n            WHERE Year=2016                              \\\n            GROUP BY                                     \\\n                c.NOC,a.athlete_ID,a.Year) A             \\\n            GROUP BY                                     \\\n                Nation;',locals())\n\ntempa3= tempa[tempa.Medal==1]\ntempa4=sqldf('\\\n    SELECT A.Nation,A.numbers as num_medals,B.numbers as num_ath                 \\\n    FROM tempa3 as A                              \\\n    LEFT JOIN tempa2 as B                         \\\n    ON A.Nation=B.Nation                          \\\n;',locals())\ntempa4\n\n\n\n\n\n  \n    \n      \n      Nation\n      num_medals\n      num_ath\n    \n  \n  \n    \n      0\n      Algeria\n      4\n      10.0\n    \n    \n      1\n      Botswana\n      1\n      3.0\n    \n    \n      2\n      Egypt\n      9\n      37.0\n    \n    \n      3\n      Eritrea\n      1\n      1.0\n    \n    \n      4\n      Ethiopia\n      12\n      20.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      UK\n      245\n      159.0\n    \n    \n      96\n      Ukraine\n      51\n      117.0\n    \n    \n      97\n      Australia\n      251\n      212.0\n    \n    \n      98\n      Fiji\n      13\n      17.0\n    \n    \n      99\n      New Zealand\n      44\n      97.0\n    \n  \n\n100 rows × 3 columns\n\n\n\n\ntempa4=tempa4.dropna()\nx=tempa4.num_ath\ny=tempa4.num_medals\n\nplt.subplots(figsize=(8,5))\nplt.scatter(x,y)\na=scipy.stats.spearmanr(x,y)\nb=scipy.stats.pearsonr(x,y)\nprint('Spearman correlation = {:.2f} ({:.0e}) \\nand Pearson correlation= {:.2f} ({:.0e})'\\\n      .format(a[0],a[1],b[0],b[1]))\n\nplt.grid(True)\nplt.xlabel('Athletes per nation')\nplt.ylabel('Medals per nation');\n\np=np.poly1d( np.polyfit(x,y,2) )\nxx=np.arange(0,300,2)\nyy=p(np.arange(0,300,2))\n\nplt.plot(xx,yy);\n\nSpearman correlation = 0.83 (3e-26) \nand Pearson correlation= 0.87 (5e-32)\n\n\n\n\n\n\n\nOverview Medals VS Athletes per nation\nAs was expected there is a good correlation between the number of athletes a nation sends and the number of medals they get\nWhat may also have been expected and shown in the data, is that the relationship is not linear. Instead the more athletes a nation sends the greater the medals/athlete ratio.\ni.e. If a nation sends more athletes it is more likely that a higher proportion of them will win medals"
  },
  {
    "objectID": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#cold-war",
    "href": "posts/2022-07-29-OlympicsSQL_GDPpopulation.html#cold-war",
    "title": "ThomasHSimm",
    "section": "Cold War",
    "text": "Cold War\nThe Cold War was a period of geopolitical tension between the United States and the Soviet Union and their respective allies, the Western Bloc and the Eastern Bloc, which began following World War II and ended in the early 1990s.\nThe conflict was based around the ideological and geopolitical struggle for global influence by these two superpowers.\nThe Soviet Union competed at the Olympics from 1952-1988. The Russian Empire had previously competed at the 1900, 1908 and 1912 Olympics games. In these games the best they ranked was 12th. In contrast the USA competed from the start of the Olympics and all subsequent games. In 1952 they were the most succesful nation, coming 1st in the medals table in 8 out of the previous 11 games (and second in the other 3).\nThe figures below show how during the Cold War period, The Soviet Union was able to compete with USA and in some cases beat them in the medals table. After this Cold War period the medals obtained by both the USA and the Soviet Union fell with respect to the totals from the European nations. Furthermore, USA reasserted it’s dominance after the Cold War period.\nWikipedia Cold War\n\ndef number_of_athletes_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"F\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         group by athlete_ID,Year               \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL               \\\n     UNION ALL                                 \\\n     SELECT                                \\\n        Year,                              \\\n        NOCSMALL,                          \\\n        count(*) AS number_of_athletes,     \\\n        \"M\" AS Sex                          \\\n    FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         group by athlete_ID,Year          \\\n         order by Year asc) A              \\\n     GROUP BY Year, NOCSMALL;',locals()  )\n    return testa2\n\ndef number_of_medals_USA_USSR(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                 \\\n            COUNT(*) AS number_of_medals,\\\n            Year, Sex, NOCSMALL\\\n        FROM \\\n        (SELECT NOCSMALL,Year,Sex,COUNT(*) AS counta\\\n        FROM                                   \\\n         (SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"F\"   AS Sex,                      \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_F_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         UNION ALL                                 \\\n         SELECT                           \\\n         athlete_ID,                        \\\n         event_ID,                          \\\n         \"M\" AS Sex,                       \\\n         Medal_Gold,Medal_Silver,Medal_Bronze,\\\n         Year,                             \\\n         CASE                                \\\n            WHEN NOC IN (\"FRA\",\"ESP\",\"ITA\",\"POR\",\"GBR\",\"IRL\",\"NED\",\"BEL\",\"DEN\",\"SUI\") THEN \"WES\"\\\n            WHEN NOC IN (\"POL\",\"ROU\",\"UKR\",\"LAT\",\"BUL\",\"HUN\",\"LTU\",\"LAT\",\"BLR\",\"ALB\",\"SVK\",\"AUT\",\"EST\",\"BIH\",\"BOH\") THEN \"EST\"\\\n            WHEN NOC=\"USA\" THEN \"USA\"       \\\n            WHEN NOC=\"EUN\" THEN \"EUN\"       \\\n            ELSE \"ROW\"\\\n            END AS NOCSMALL                \\\n         from df_M_S                       \\\n         WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1\\\n         order by Year asc) A\\\n     GROUP BY \\\n         Year, NOCSMALL,event_id,Medal_Gold,Medal_Silver,Medal_Bronze)  AS B\\\n GROUP BY Year, NOCSMALL, Sex\\\n                 ;',locals()  )                                       \n    return testa2\n\n\nUSA_USSR_medals=number_of_medals_USA_USSR(df_F_S,df_M_S)\nUSA_USSR_athletes=number_of_athletes_USA_USSR(df_F_S,df_M_S)\n\n\ndef yrplot(df__,whatplot= 'avg_weight'): \n    \n    countries=['EST', 'EUN' ,'ROW', 'USA' ,'WES']\n    \n#     df__.NOCSMALL.unique()\n#     countries=np.sort(countries)\n    print(countries)\n    cola=['>','o','+','*','<']\n    colur=[[1,0.6,.6],[1,0,0],[.5,.5,.5],[0,0,1],[.6,.6,1]]\n#     ['EST' 'EUN' 'ROW' 'USA' 'WES']\n#     'EST','USA','WES','ROW','EUN'\n\n    fig,ax1=plt.subplots(figsize=(8,5))\n    \n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1.plot(df__[df__.NOCSMALL==country].Year,\\\n                 df__[df__.NOCSMALL==country][whatplot],\\\n                 marker=cola[i],linestyle='None',color=colur[i]\\\n                 ,markersize=10)\n\n\n    def doPlot(df_F,avgNo,whatplot,country,col,lw,ax1):\n        bb = df_F[df__.NOCSMALL==country].Year.rolling(avgNo).mean()\n        cc = df_F[df__.NOCSMALL==country][whatplot]\n        cc = cc.rolling(avgNo).mean()\n        ax1.plot(bb,cc,linewidth=lw,color=col)\n        return ax1\n\n    for i,country in enumerate(countries):\n        if country!='ROW':\n            ax1=doPlot(df__,avgNo=3,whatplot=whatplot,country=country,col=colur[i],lw=3,ax1=ax1)\n    \n    lega = ['East Europe','Russia','USA','West Europe']\n    plt.legend(lega)\n    plt.grid(True)\n    plt.ylabel(modname(whatplot))\n    \n    return ax1\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='F'],whatplot= 'number_of_medals')\n\n\n\nyrplot(USA_USSR_medals[USA_USSR_medals.Sex=='M'],whatplot= 'number_of_medals')"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#overview",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\nThis is part of a project that looks at an Olympics dataset.\nIn this part the hypothesis considered is:\nAt a home Olympic games a nation will on average obtain more medals than at other games\n\nBut can we quantify this effect?\nAre there any residual effects before and after the games?\nWhat about a home continent games?"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#methodology",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#methodology",
    "title": "ThomasHSimm",
    "section": "Methodology",
    "text": "Methodology\nTo be able to answer the question, the steps taken are as follows. Note the data and tables created in a previous page.\n\nCreate table of medal athletes as athlete\n\nMedals\nYear\nNOC\nOthers? Sex, number_of_athletes\n\nJoin athlete table to country table to get the country added to athlete\n\nNow the next step is trickier. There are several ways we could look at the effect of a home game and the nearness to it. The way I like to do this is to visualise the plot(s) I would like and work back from that.\nThe plot I’d like is: - x-axis = year from games (0 = at the games, +ve after and -ve before) - y-axis = number of medals\nIf we normalise the y-axis we can put all the events together to get an effect of games, before and after. We can also pick out individual games or do the averageing on different time-periods.\nSo to achieve this we need a vector for each games of: - Year from games - Number of medals\nThere are a number of potential problems with this: 1. If a nation holds two games close to each other 1. Normally games are every 4 years but how do we deal with exceptions to this? 1. What do we do when there is a lack of data before or after the games? e.g. games at the start of Olympics or current games, or if a nation stops partipation 1. When looking at the effect of continent, the approach would need to be adjusted based on there being fewer continents and most games being in Europe\n\ncan be solved by reducing the times to +- 20 years, and because we are averageing any exceptions should be covered\na way to solve this is to fit the data across the years/medals data we have with a function then use the function to give us values on a set scale (e.g. -20 to 20 in steps of 4 yrs)\na bit trickier, may we fit values that have positive and negative values up to 20 yrs first. Then if an event has a gap in years fill with the average values below and above 0 yrs\nfor this maybe just look at a partcular game based on recent games that are not in the same continent"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#some-starting-code",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#some-starting-code",
    "title": "ThomasHSimm",
    "section": "Some Starting Code",
    "text": "Some Starting Code\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandasql import sqldf\nimport copy\nimport numpy as np\nimport scipy.stats\n\n\ndf_F_S =pd.read_csv('data/athlete_F_S')\ndf_F_W=pd.read_csv('data/athlete_F_W')\ndf_M_S=pd.read_csv('data/athlete_M_S')\ndf_M_W=pd.read_csv('data/athlete_M_W')\n\ndf_all_athletes= pd.read_csv('data/all_athletes')\ndf_country= pd.read_csv('data/country')\n# df_event= pd.read_csv('data/event')\ndf_games= pd.read_csv('data/games')\n# df_population= pd.read_csv('data/population')\n\ndf_country = df_country.groupby('NOC').max()\n# df_country.head(10)\n\n\ndf_games.head()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      games_id\n      City\n      Country\n      Year\n      Region\n      Summer\n      Winter\n      Latitude\n      Longitude\n    \n  \n  \n    \n      0\n      0\n      0\n      Athens\n      Greece\n      1896\n      Europe\n      1\n      0\n      37.9838\n      23.7275\n    \n    \n      1\n      1\n      1\n      Paris\n      France\n      1900\n      Europe\n      1\n      0\n      48.8566\n      2.3522\n    \n    \n      2\n      2\n      2\n      St. Louis\n      USA\n      1904\n      North America\n      1\n      0\n      38.6270\n      90.1994\n    \n    \n      3\n      3\n      3\n      Athens\n      Greece\n      1906\n      Europe\n      1\n      0\n      37.9838\n      23.7275\n    \n    \n      4\n      4\n      4\n      London\n      UK\n      1908\n      Europe\n      1\n      0\n      51.5072\n      0.1276"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#create-a-table-of-country-medals",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#create-a-table-of-country-medals",
    "title": "ThomasHSimm",
    "section": "Create a table of Country & Medals",
    "text": "Create a table of Country & Medals\nThis first step is to create a table of athletes data that includes both women and men athletes from the summer games, we want the following columns: - The Olympic Year - The Nation - The Continent of the Nation - The number of medals the nation got that year\nBasically just UNION to join the male and female athletes- with some additions so we get the total number of medals per country\nFollowed by a JOIN on the country table to get more information about the countries.\n\ndef number_of_medals(df_F_S,df_M_S):\n    testa2=sqldf('\\\n        SELECT                                                         \\\n            COUNT(*)              AS number_of_medals,                 \\\n            Year, NOC                                                  \\\n        FROM                                                           \\\n        (SELECT NOC,Year,COUNT(*) AS counta                            \\\n           FROM                                                        \\\n             (SELECT                                                   \\\n             athlete_ID,                                               \\\n             event_ID,                                                 \\\n             Medal_Gold,Medal_Silver,Medal_Bronze,                     \\\n             Year,                                                     \\\n             NOC                                                       \\\n             from df_F_S                                               \\\n             WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1    \\\n             UNION ALL                                                 \\\n             SELECT                                                    \\\n             athlete_ID,                                               \\\n             event_ID,                                                 \\\n             Medal_Gold,Medal_Silver,Medal_Bronze,                     \\\n             Year,                                                     \\\n             NOC                                                       \\\n             from df_M_S                                               \\\n             WHERE Medal_Gold=1 OR Medal_Silver=1 OR Medal_Bronze=1    \\\n             order by Year asc) A                                      \\\n           GROUP BY                                                    \\\n             Year, NOC,event_id,Medal_Gold,Medal_Silver,Medal_Bronze)  AS B\\\n         GROUP BY Year, NOC                                            \\\n                 ;',locals()  )                                       \n    return testa2\n\ndef join_country(df_,df_country):\n    testa2=sqldf('\\\n        SELECT                             \\\n            c.NOC,c.Nation,c.Continent,    \\\n            a.number_of_medals,            \\\n            a.Year                         \\\n        FROM                               \\\n            df_ AS a                       \\\n        INNER JOIN                         \\\n            df_country AS c                \\\n        ON                                 \\\n            c.NOC=a.NOC                    \\\n        GROUP BY                           \\\n            c.NOC,a.Year                   \\\n     ;',locals()  ) \n    return testa2\n\ndf_medals=number_of_medals(df_F_S,df_M_S)\ndf_medals2=join_country(df_medals,df_country)\ndf_medals2.head()\n\n\n\n\n\n  \n    \n      \n      NOC\n      Nation\n      Continent\n      number_of_medals\n      Year\n    \n  \n  \n    \n      0\n      AFG\n      Afghanistan\n      Asia\n      1\n      2008\n    \n    \n      1\n      AFG\n      Afghanistan\n      Asia\n      1\n      2012\n    \n    \n      2\n      ALG\n      Algeria\n      Africa\n      2\n      1984\n    \n    \n      3\n      ALG\n      Algeria\n      Africa\n      2\n      1992\n    \n    \n      4\n      ALG\n      Algeria\n      Africa\n      3\n      1996"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#find-the-change-in-medals-around-a-home-games",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#find-the-change-in-medals-around-a-home-games",
    "title": "ThomasHSimm",
    "section": "Find the change in medals around a home games",
    "text": "Find the change in medals around a home games\nThe easy solution here would be to take an average of the medals a country obtains obtains at a home games versus non-home games. However, this wouldn’t work mainly due to the changes in medals with time (they increase).\nWe could correct for overall changes in the number of medals by normalising based on the total number of medals in a games. This would be better, but we may need an extra step to account for the lack of diversity of nations in earlier years too.\nBut also we wouldn’t be able to see what effect a home games had before and after the games were held.\nTo observe how medal count is effected before and after a games, and to somewhat reduce the increase in medals with time, the following steps are taken.\n\nScoll through the games table for each summer games\nFor each game add data to the following variables (of length of the number of games) for each particular games\n\nnation the nation hosting the particular games\nmedals the number of medals for each games for the nation hosting the particular games, in all the other games\nyears the difference in years between the particular games and all other games\n\n\nFor example:\nUSA 1984, Los Angeles\n\nnation[20] is ‘USA’\nyears[20] is [-88, -84, -80, -78, -76, -72, -64, -60, -56, -52, -48, -36, -32,-28, -24, -20, -16, -12,  -8,   0,   4,   8,  12,  16,  20,  24, 28,  32]\n\nthe 0 being the 1984 games, and the 32 being the 2016 games\n\nmedals[20] is [ 19,  54, 230,  23,  46,  63,  95,  99,  56, 110,  57,  84,  76, 74,  71,  90, 107,   94,  94, 173,  94, 108, 101,  91, 101, 110, 103, 121]\n\nthe 173 being the number of medals obtained in 1984 and 121 in 2016\n\nCreate a vector for each games of medals against years around the home game.\n\n\nSince not all games are seperated by 4 years and some games can be missed the data needs to be interpolated onto a range in steps of 4 years. Outer bounds of +-28 years ae chosen\nWhen data is missing because the full range of data can’t be obtained (i.e. for recent games or ones near the start of Olympics) replace any missing values with 0\n\n\nAdd up all the vectors for different games\n\n\nignore games where the range isn’t full (-32->32)\nthis gives the average effect of a home games\n\n\n# Step 1 and 2\n\n# Since we just want the summer games\ndf_games=df_games[df_games.Summer==1].reset_index()\n\nmedals=[]\nyears=[]\nnation=[]\nfor i in range(len(df_games)):\n    country=df_games.loc[i,'Country']\n    year=df_games.loc[i,'Year']\n    \n    nation.append(country)\n    medals.append(df_medals2[df_medals2.Nation==country].number_of_medals.values)\n    years.append(df_medals2[df_medals2.Nation==country].Year.values - year)\n    \n\n\n\"\"\"\nStep 3\nFunction to interpolate number of medals in years around a games\nTakes as input x=years and y=number of medals and outputs a new x and y values \nthat have been interpolated between -28 to +28 years in steps of 4 years\nFor games where the full range can't be obtained (e.g. an event close to 2016 \nwill have missing data for years after it) the data is interpolated to the nearest \n4 years and missing data replaced with zeroes.\n\"\"\"\n\ndef do_interp(x,y):\n    from scipy.interpolate import interp1d\n    \n    xx,yy=x,y\n    xhi,xlo=28,-28\n    \n    xnew=np.arange(xlo,xhi+4,4)\n    ynew=np.zeros(np.shape(xnew))\n    # here make adjustments if the whole range doesn't exist to go to nearest 4 yrs\n    # or if inbetween go outside to next one i.e. 11 years->12 years, 8->8,-5->-8\n    # lower years are dealt with separately to later years then combined\n    # and normalised\n    maxx,minx=np.max(x),np.min(x)\n    if maxx<xhi:\n        xhi= 4*(np.ceil(maxx/4))\n        xx=xx[1:]\n        yy=yy[1:]\n    if minx>xlo:\n        xlo= -4*(np.ceil(abs(minx)/4))\n        xx=xx[:-1]\n        yy=yy[:-1]\n        \n    cond =((xnew<=xhi) & (xnew>=xlo))\n    try:\n        f2 = interp1d(x, y, kind='cubic')\n        ynew[cond]=f2(xnew[cond])\n    except:\n        f2 = interp1d(xx, yy, kind='cubic')\n        cond =((xnew<=xhi-4) & (xnew>=xlo+4))\n        ynew[cond]=f2(xnew[cond])\n    \n    ynew=ynew/max(ynew)\n    return xnew,ynew\n\n\n# Step 3\n\nXY=[]\nfor i,year_range in enumerate(years):\n    x=year_range\n    y=medals[i]\n    xnew,ynew=do_interp(x,y)\n    XY.append(np.array(ynew))\n    \n\n\nnp.shape(XY)\n\n(29, 15)\n\n\n\n# If values are less than 0 put as just above zero- can occur when \n\n# make XY a numpy array\nXY = np.array(XY)\n\n# if interpolation is not good\nXY[XY<0]=0\n\n\n\n\n# create vectors for y-data either side of home-event\nyallL = np.zeros((8))\nyallR = np.zeros((8))\n\n# scroll through each games\n# find if the low years or high years have zeros in them\n# if they don't include them in the sum \nfor i,ygames in enumerate(XY):\n    \n    if i>11:\n        if 0 not in ygames[-8:]:\n            yallL[-8:]=yallL[-8:]+ygames[-8:]\n        \n        if 0 not in ygames[0:8]:\n            yallR[0:8]=yallR[0:8]+ygames[0:8]\n            \n\n# normalise\nyallL=yallL/max(yallL)\nyallR=yallR/max(yallR)\n\n# combine low and high years and only use home game year once\nyall=np.concatenate([yallR[0:-1],yallL])\n\n# plot the results\nplt.subplots(figsize=(6,4))\nplt.plot(xnew,yall/max(yall),'ok-')\n\nplt.ylim([0 ,1.05])\nplt.grid(True)\nplt.ylabel('Normalise medals won',fontsize=14)\nplt.xlabel('Years either side of a home games',fontsize=14)\n# plt.plot(xnew,yall2/max(yall2),'m+--')\n\nText(0.5, 0, 'Years either side of a home games')"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#plot-the-effect-of-home-games-for-different-games",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#plot-the-effect-of-home-games-for-different-games",
    "title": "ThomasHSimm",
    "section": "Plot the effect of home games for different games",
    "text": "Plot the effect of home games for different games\nLook at the individual games plots\n\n\nstartnum=11\n\ncola=['mo--','gs:','bv-.']\nfor i2 in range(6):\n    fig,ax=plt.subplots()\n    vals = np.arange(startnum,startnum+3,1,dtype=int)\n    i1=0\n    for i in vals: \n        plt.plot(xnew,XY[i,:],cola[i1])\n        plt.ylim([-.2 ,1])\n        plt.grid(True)\n        plt.legend([ nation[ii] + ' ' + str(df_games.loc[ii,'Year']) for jj,ii in enumerate(vals)]);\n        plt.ylabel('Normalise medals won')\n        plt.xlabel('Years either side of a home games')\n        i1=i1+1\n    startnum=startnum+3"
  },
  {
    "objectID": "posts/2022-07-29-Olympics_HomeEvent.html#continent-home-games",
    "href": "posts/2022-07-29-Olympics_HomeEvent.html#continent-home-games",
    "title": "ThomasHSimm",
    "section": "Continent home games",
    "text": "Continent home games\nThe Olympics have mainly been held in Europe and North America. Because of this it is not possible to do the same analysis as for home country games.\nInstead we can look at the difference if a games is a home continent or not.\n\ncontinentYorN=sqldf('\\\n    SELECT                                     \\\n    home_continent,                            \\\n    Year,                                      \\\n    COUNT(*)         AS num_countries,         \\\n    AVG(avg_medals)  AS avg_medals             \\\n    FROM                                       \\\n      (SELECT                                  \\\n            Nation,home_continent, Year,       \\\n            AVG(number_of_medals)  AS avg_medals\\\n        FROM                                   \\\n            (SELECT                            \\\n               a.*,                            \\\n               CASE WHEN                       \\\n                  c.Region =a.Continent THEN 1 \\\n               ELSE 0 END AS home_continent    \\\n            FROM                               \\\n                df_medals2 AS a                \\\n            INNER JOIN                         \\\n                df_games AS c                  \\\n            ON                                 \\\n                c.Year=a.Year                  \\\n            WHERE c.Year> 1951) as inner       \\\n        GROUP BY                               \\\n            Nation, Year ) as midder           \\\n    GROUP BY home_continent,Year               \\\n     ;',locals()  ) \n\n\ncontinentYorN.head()\n\n\n\n\n\n  \n    \n      \n      home_continent\n      Year\n      num_countries\n      avg_medals\n    \n  \n  \n    \n      0\n      0\n      1952\n      20\n      7.450000\n    \n    \n      1\n      0\n      1956\n      36\n      11.944444\n    \n    \n      2\n      0\n      1960\n      21\n      7.095238\n    \n    \n      3\n      0\n      1964\n      34\n      13.470588\n    \n    \n      4\n      0\n      1968\n      35\n      11.285714\n    \n  \n\n\n\n\n\nfig,ax=plt.subplots(figsize=(8,5))\n\n\n\nplt.plot(continentYorN[continentYorN.home_continent==1].Year,continentYorN[continentYorN.home_continent==1].avg_medals,'rs--')\nplt.plot(continentYorN[continentYorN.home_continent==0].Year,continentYorN[continentYorN.home_continent==0].avg_medals,'ob--')\n\nplt.grid(True)\nplt.ylabel('Average medals')\nplt.xlabel('Games year')\n\n# plt.plot([df_games[df_games.Region=='Asia'].Year.values,df_games[df_games.Region=='Asia'].Year.values],[0,35],color=[1,.8,.8]);\n\nplt.plot([0,0],'m--');\nplt.plot([0,0],'g-.');\n\nplt.plot([df_games[df_games.Region=='Americas'].Year.values,df_games[df_games.Region=='Americas'].Year.values],[0,35],'m--');\n\n\nplt.plot([df_games[df_games.Region=='Europe'].Year.values,df_games[df_games.Region=='Europe'].Year.values],[0,35],'g-.');\n\n\n# plt.plot([df_games[df_games.Region=='Oceania'].Year.values,df_games[df_games.Region=='Oceania'].Year.values],[0,35],color=[0.7,1,.7]);\n\nplt.xlim([1950,2020])\n\nplt.legend(['Home continent','Another continent','Americas','Europe'])\n\n<matplotlib.legend.Legend at 0x1f4339ed580>\n\n\n\n\n\n\nNot a good measure\nInstead need following columns\n\ntotal or average medals per continent\nHome Continent\nYear\n\n\n\n\"\"\"\nA check on the inner part of the SQL  statement\n\n\"\"\"\n\nsqldf('\\\n    SELECT *   FROM                            \\\n        (SELECT                                \\\n               a.*,                            \\\n               CASE WHEN                       \\\n                  c.Region =a.Continent THEN 1 \\\n               ELSE 0 END AS home_continent    \\\n            FROM                               \\\n                df_medals2 AS a                \\\n            INNER JOIN                         \\\n                df_games AS c                  \\\n            ON                                 \\\n                c.Year=a.Year                  \\\n            WHERE c.Year> 1951) as inner       \\\n     ;',locals()  ) \n\n\n\n\n\n\n  \n    \n      \n      NOC\n      Nation\n      Continent\n      number_of_medals\n      Year\n      home_continent\n    \n  \n  \n    \n      0\n      ANZ\n      Australia\n      Oceania\n      11\n      1952\n      0\n    \n    \n      1\n      ARG\n      Argentina\n      Americas\n      5\n      1952\n      0\n    \n    \n      2\n      AUT\n      Austria\n      Europe\n      2\n      1952\n      1\n    \n    \n      3\n      BEL\n      Belgium\n      Europe\n      4\n      1952\n      1\n    \n    \n      4\n      BOH\n      Czech Republic\n      Europe\n      13\n      1952\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      960\n      UKR\n      Ukraine\n      Europe\n      11\n      2016\n      0\n    \n    \n      961\n      USA\n      USA\n      Americas\n      121\n      2016\n      0\n    \n    \n      962\n      UZB\n      Uzbekistan\n      Asia\n      13\n      2016\n      0\n    \n    \n      963\n      VEN\n      Venezuela\n      Americas\n      3\n      2016\n      0\n    \n    \n      964\n      VIE\n      Vietnam\n      Asia\n      2\n      2016\n      0\n    \n  \n\n965 rows × 6 columns\n\n\n\n\n\"\"\"\nThe complete SQL statement\n\n\"\"\"\n\ncontinentYorN2=sqldf('\\\n    SELECT \\\n      Year, sum(number_of_medals) AS num_medals, Continent,home_continent\\\n          FROM                                 \\\n        (SELECT                                \\\n               a.*,                            \\\n               CASE WHEN                       \\\n                  c.Region =a.Continent THEN 1 \\\n               ELSE 0 END AS home_continent    \\\n            FROM                               \\\n                df_medals2 AS a                \\\n            INNER JOIN                         \\\n                df_games AS c                  \\\n            ON                                 \\\n                c.Year=a.Year                  \\\n            WHERE c.Year> 1951) as inner       \\\n        GROUP BY Continent,Year, home_continent\\\n        ORDER BY Year\\\n     ;',locals()  ) \n\ncontinentYorN2.head()\n\n\n\n\n\n  \n    \n      \n      Year\n      num_medals\n      Continent\n      home_continent\n    \n  \n  \n    \n      0\n      1952\n      11\n      Africa\n      0\n    \n    \n      1\n      1952\n      100\n      Americas\n      0\n    \n    \n      2\n      1952\n      24\n      Asia\n      0\n    \n    \n      3\n      1952\n      308\n      Europe\n      1\n    \n    \n      4\n      1952\n      14\n      Oceania\n      0\n    \n  \n\n\n\n\n\nplt.subplots(figsize=(8,5))\nregion='Asia'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'or',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,':or')\n\nregion='Europe'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'bo',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'b--o')\n\nregion='Americas'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'m<',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'m-o')\n\nregion='Oceania'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'cv',markersize=10)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nplt.plot(continentYorN2[cond].Year,continentYorN2[cond].num_medals,'c-o')\n\nplt.legend(['Asia','','Europe','','Americas','','Oceania',''])\nplt.grid(True)\n\n\n\n\n\nregion='Europe'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\n\nregion='Asia'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\nregion='Americas'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\nregion='Oceania'\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==1))\nasum=np.average(continentYorN2[cond].num_medals)\ncond=((continentYorN2.Continent==region)&(continentYorN2.home_continent==0))\nbsum=np.average(continentYorN2[cond].num_medals)\n\nprint('For {} the average medals at home continent = {:.0f} and for away continent = {:.0f}\\n \\\n      With a ratio of {:.2f}'.format(region,asum,bsum,asum/bsum))\n\nFor Europe the average medals at home continent = 420 and for away continent = 396\n       With a ratio of 1.06\nFor Asia the average medals at home continent = 121 and for away continent = 103\n       With a ratio of 1.18\nFor Americas the average medals at home continent = 177 and for away continent = 130\n       With a ratio of 1.36\nFor Oceania the average medals at home continent = 50 and for away continent = 32\n       With a ratio of 1.57\n\n\nAgain the above stats are not really great as\n\ndon’t take account of changes in the average number of medals with time for a nation\ngames in Oceania and Americas are often also home games\n\nThe best metric uses Europe and suggests a less than 6% increase for a home continent"
  },
  {
    "objectID": "posts/2022-07-31-OlympicsSQL-Presentation.html",
    "href": "posts/2022-07-31-OlympicsSQL-Presentation.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "Presentation of Olympics data with SQL and pandas\n\nPresentation of Using SQL and Pandas to understad Olympic data\n\n\ntoc: true\nbadges: true\ncategories: [Presentation,SQL, Pandas, python, Olympics]"
  },
  {
    "objectID": "posts/2022-07-31-OlympicsSQL.html#introduction",
    "href": "posts/2022-07-31-OlympicsSQL.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nThis project looks to understand the changing nature of the Olympics and how it reflects changes in athletes, sporting activities, and global politics. The Olympic Games are considered the world’s foremost sports competition with more than 200 nations participating [1,2], and in Tokyo in 2020 there was a broadcast audience of more than 3 billion with estimates of 3 out of 4 people following the Olympics [3].\nSince it’s inception over 100 years ago many changes have occured. In global politics countries have split and unified, populations have changed and the power distribution across nations fluctuated. In society there have been changes in the rights and roles of women. Finally, in sport there has been a move from amateur atheletes to professionalism and a change in the popularity of different sports.\nDue to it’s global importance, the question this work looks to answer is if data on the Olympics reflect the changes that have occured in the world.\n1.“Overview of Olympic Games”. Encyclopaedia Britannica. Retrieved 4 June 2008\n2.Olympic Games- Wikipedia\n3.Tokyo 2020 audience & insights report December 2021"
  },
  {
    "objectID": "posts/2022-07-31-OlympicsSQL.html#the-data",
    "href": "posts/2022-07-31-OlympicsSQL.html#the-data",
    "title": "ThomasHSimm",
    "section": "The Data",
    "text": "The Data\nThe most important part of any analysis is the data. In Olympics data with SQL and pandas- create the tables I present the data to be analysed and do some initial processing.\nThe main thing here is to seperate the data into useable tables for analysis, as summarised in the entity relationship diagram (ERD) below."
  },
  {
    "objectID": "posts/2022-07-31-OlympicsSQL.html#analysis",
    "href": "posts/2022-07-31-OlympicsSQL.html#analysis",
    "title": "ThomasHSimm",
    "section": "Analysis",
    "text": "Analysis\nBased on a brief analysis of the data three broad questions to be investigated were posed:\n\nWhat are the characteristics of athletes? How does this change with time, and can it be linked with societal or global changes?\nWhat countries do better at the Olympics? Is there a way to quantify this?\nWhat is the influence of a games being a home event?\n\nIn the following parts these are explore in more detail.\n\nAthlete Analysis\nI did some initial plots on the changes in the characteristics of athletes given in the data, height, weight and age, of athletes attending the Olympics by year (see below).\nFrom these plots I was really intrigued as to what may be the cause of these changes.\nMainly what was happening between 1960 and 1980 were there seemed to be changes in each of the parameters?\nMy initial thought was this could be related to some combination of - a switch from amateurs to professionals - the Cold War between USA and USSR - an after effect of WWII\nOlympics data with SQL and pandas- height weight and age\n\n\nNation Analysis\nDue to the global importance of the Olympics, in 2020 there was a broadcast audience of more than 3 billion, I was interested to explore whether countries with the most medals will reflect global politics. And to see if the countries with most influence get more medals.\nOlympics data with SQL and pandas- GDP and population\n\n\nGames Analysis\nIn this part the hypothesis considered is:\nAt a home Olympic games a nation will on average obtain more medals than at other games\n\nBut can we quantify this effect?\nAre there any residual effects before and after the games?\nWhat about a home continent games?\n\nOlympics data with SQL and pandas- home games"
  },
  {
    "objectID": "posts/2022-07-31-OlympicsSQL.html#presentation",
    "href": "posts/2022-07-31-OlympicsSQL.html#presentation",
    "title": "ThomasHSimm",
    "section": "Presentation",
    "text": "Presentation\nTo present this data in a unified form the following presentation was produced.\nThis is a hypothetical presentation:\n\nWho\nThe audience is a fictional research group at Swansea University (UK) called the Sports History Group.\nThis group is a cross-departmental, working across the History and Sports Science department. The group consists of two lecturers (one in each department), three post doctoral researchers, five PhD students and three Masters students.\n\n\nWhy\nThe work I am presenting has overlap with several of the reserachers/students.\nThe main goal is a scoping exercise with one of the post doctoral researchers and the two lecturers who have identified a grant proposal. The Olympics commitee have put out a grant application. The aim of this is to produce a report on the influence the Olympics has had on Geo-Politics and on Athletes and Sport in general. With guidance on what the Olympics can do in the future to maintain and enhance its globally importance, and how it can positively impact Olympic athletes.\n\n\nWhat / How\nMore details are in the presentation"
  },
  {
    "objectID": "posts/2022-08-11-NLPexamples.html#competition-description",
    "href": "posts/2022-08-11-NLPexamples.html#competition-description",
    "title": "ThomasHSimm",
    "section": "Competition Description",
    "text": "Competition Description\nTwitter has become an important communication channel in times of emergency. The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\nBut, it’s not always clear whether a person’s words are actually announcing a disaster.\n\nData\nYou’ll need train.csv, test.csv and sample_submission.csv. What should I expect the data format to be?\nEach sample in the train and test set has the following information:\n\nThe text of a tweet\nA keyword from that tweet (although this may be blank!)\nThe location the tweet was sent from (may also be blank)\n\nWhat am I predicting?\nYou are predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0. Files\n\ntrain.csv - the training set\ntest.csv - the test set\nsample_submission.csv - a sample submission file in the correct format\n\nColumns\n\nid - a unique identifier for each tweet\ntext - the text of the tweet\nlocation - the location the tweet was sent from (may be blank)\nkeyword - a particular keyword from the tweet (may be blank)\ntarget - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)"
  },
  {
    "objectID": "posts/2022-08-11-NLPexamples.html#analysis-methods-used",
    "href": "posts/2022-08-11-NLPexamples.html#analysis-methods-used",
    "title": "ThomasHSimm",
    "section": "Analysis methods used",
    "text": "Analysis methods used\nCode used for the threee methods: - https://www.kaggle.com/code/thomassimm/nlp-disaster-tweets-one-shot - https://www.kaggle.com/code/thomassimm/nlp-disaster-scikit - https://www.kaggle.com/code/thomassimm/nlp-disaster-nn\n\none-shot\nFor the zero shot learning method, the main advantage is no labelled data is needed nor any prior training. But the accuracy will be reduced without any training.\nWhat is zero-shot learning?\n\nTraditionally, zero-shot learning (ZSL) most often referred to a fairly specific type of task: learn a classifier on one set of labels and then evaluate on a different set of labels that the classifier has never seen before. Recently, especially in NLP, it's been used much more broadly to mean get a model to do something that it wasn't explicitly trained to do. A well-known example of this is in the GPT-2 paper where the authors evaluate a language model on downstream tasks like machine translation without fine-tuning on these tasks directly.\nhttps://joeddav.github.io/blog/2020/05/29/ZSL.html\nThe code used here is as follows:\nfrom transformers import pipeline\nclassifier = pipeline(\"zero-shot-classification\", device=0)\nAnd can then be called as follows, where string is what we are classifying (ie. the tweet) and label what we are looking to classify it as (here we use disaster):\nclassout=classifier( TEXT, LABEL, multi_class=True)\n\nThe accuracy is ~60%. But remember no training is done.\n\n\n\nBag of words sci-kit learn\nThis method uses scikit-learn to classify the tweets by using a Bag of Words approach. This example uses a Tf-idf-weighted document-term sparse matrix to encode the features and demonstrates various classifiers that can efficiently handle sparse matrices.\nMethodology taken from here\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nfit_time\nscore_time\ntest_accuracy\ntrain_accuracy\ntest_f1\ntrain_f1\n\n\n\n\nLogistic Regression\n2.349514\n0.006580\n0.739398\n0.977276\n0.639793\n0.973091\n\n\nRidge Classifier\n0.079390\n0.003698\n0.736246\n0.979509\n0.631187\n0.975799\n\n\nkNN\n0.004747\n0.636052\n0.720220\n0.775220\n0.601846\n0.692391\n\n\nRandom Forest\n50.920274\n0.207107\n0.691847\n0.988999\n0.500637\n0.987122\n\n\nLinear SVC\n0.093184\n0.004035\n0.733750\n0.900926\n0.605876\n0.872385\n\n\nlog-loss SGD\n0.002576\n0.000000\nNaN\nNaN\nNaN\nNaN\n\n\nNearestCentroid\n0.008251\n0.005659\n0.664523\n0.772659\n0.658099\n0.751426\n\n\nComplement naive Bayes\n0.008391\n0.003308\n0.690007\n0.979115\n0.676552\n0.975514\n\n\n\n\nResults give ~80% on results file\n\n\n\nNN with fastai\nThe method used here is to do a two step process both of which use a RNN neural network with AWD-LSTM architecture:\n\ncreating a language model for the data\nusing this language model with labelled data to classify different texts\n\nThis method is shown here using fastai for sentiment analysis (i.e. are reviews positive or negative) of IMDB data.\nThe basics of the code for the classifier part are:\ncreate a data loader:\ndls = TextDataLoaders.from_df(df, text_col='text', label_col='target',                                valid_col='is_valid')\ncreate a learner, using text_classifier and AWD_LSTM\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5)\nlearn.metrics = [FBeta(beta=1),accuracy]\nAnd finally add the language model learnt on the tweets in the 1st step\nlearn = learn.load_encoder('finetuned3')\nThen learn by:\nlearn.fit_one_cycle(2, 1e-2)\nWhat surprised me was how low the final accuracy was given the complexity of the model and the time taken (over 8 mins). Maybe some work needs to be done to look at how I implemented this or try other RNN methods?\n\nResults give about 77% accuracy on results file"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#overview",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2022 and 2021 seasons. I will predict whether a result is a win, loss or draw.\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not to use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below.)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who - details of match, limited to those that could be predicted beforehand - referee - captain - formation - attendance\nSome details on the machine learning:\n\nA Random Forest Classifier was used for analysis.\nData is trained on the first 28 game weeks- the other 10 are used for validation\n\n23% validation / 77% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 51.5% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe stats from the last 5 games are the best parameters in predicting results\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nI would say the model probably needs more data to compete and outperform both of the controls consistently.\n\n\nCode- Prepare the data\nData is prepared in a separate page- Predicting Premier League Matches- Prepare the data"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#load-data-and-libraries",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv']\n\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021.csv')\ndfAll\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      0\n      1\n      1\n      13\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      West Ham United\n    \n    \n      1\n      4\n      1\n      12\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n    \n    \n      2\n      5\n      1\n      11\n      NaN\n      NaN\n      NaN\n      Leicester City\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Leicester City\n    \n    \n      3\n      7\n      1\n      12\n      NaN\n      NaN\n      NaN\n      Stoke City\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Stoke City\n    \n    \n      4\n      9\n      1\n      13\n      NaN\n      NaN\n      NaN\n      Tottenham Hotspur\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Tottenham Hotspur\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1895\n      3788\n      38\n      22\n      1.666667\n      2.666667\n      0.333333\n      West Ham United\n      2.666667\n      15.666667\n      6.333333\n      ...\n      12.666667\n      6.666667\n      0.000000\n      0.333333\n      0.333333\n      62.333333\n      14.333333\n      15.000000\n      49.066667\n      West Ham United\n    \n    \n      1896\n      3791\n      38\n      22\n      1.666667\n      1.333333\n      0.666667\n      Manchester United\n      1.333333\n      14.666667\n      5.000000\n      ...\n      19.333333\n      11.333333\n      0.333333\n      0.000000\n      0.000000\n      68.000000\n      17.000000\n      13.333333\n      56.733333\n      Manchester United\n    \n    \n      1897\n      3792\n      38\n      22\n      1.333333\n      2.000000\n      1.666667\n      Leeds United\n      1.666667\n      16.000000\n      5.000000\n      ...\n      12.000000\n      11.666667\n      0.000000\n      0.000000\n      0.000000\n      80.000000\n      12.000000\n      16.333333\n      42.933333\n      Leeds United\n    \n    \n      1898\n      3797\n      38\n      22\n      0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      1899\n      3799\n      38\n      22\n      0.333333\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n1900 rows × 344 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      sot%_x\n      g/sh_x\n      g/sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      xg_x\n      npxg_x\n      npxg/sh_x\n      g-xg_x\n      np:g-xg_x\n      sota_x\n      saves_x\n      save%_x\n      cs_x\n      psxg_x\n      psxg+/-_x\n      pkatt_keeper_x\n      pka_x\n      pksv_x\n      pkm_x\n      cmp_keeper_x\n      att_keeper_x\n      cmp%_keeper_x\n      att_keeper.1_x\n      thr_x\n      launch%_x\n      avglen_x\n      att_keeper.2_x\n      launch%.1_x\n      avglen.1_x\n      opp_x\n      stp_x\n      stp%_x\n      #opa_x\n      avgdist_x\n      cmp_passing_x\n      att_passing_x\n      cmp%_passing_x\n      totdist_passing_x\n      prgdist_passing_x\n      cmp_passing.1_x\n      att_passing.1_x\n      cmp%_passing.1_x\n      cmp_passing.2_x\n      att_passing.2_x\n      cmp%_passing.2_x\n      cmp_passing.3_x\n      att_passing.3_x\n      cmp%_passing.3_x\n      ast_x\n      xa_x\n      kp_x\n      1/3_passing_x\n      ppa_x\n      crspa_x\n      prog_passing_x\n      att_passing_types_x\n      live_passing_types_x\n      dead_x\n      fk_passing_types_x\n      tb_x\n      press_passing_types_x\n      sw_x\n      crs_passing_types_x\n      ck_x\n      in_x\n      out_x\n      str_x\n      ground_x\n      low_x\n      high_x\n      left_x\n      right_x\n      head_x\n      ti_x\n      other_x\n      cmp_passing_types_x\n      off_passing_types_x\n      out.1_x\n      int_passing_types_x\n      blocks_passing_types_x\n      sca_x\n      passlive_x\n      passdead_x\n      drib_x\n      sh_gca_x\n      fld_gca_x\n      def_x\n      gca_x\n      passlive.1_x\n      passdead.1_x\n      drib.1_x\n      sh_gca.1_x\n      fld_gca.1_x\n      def.1_x\n      tkl_x\n      tklw_defense_x\n      def 3rd_defense_x\n      mid 3rd_defense_x\n      att 3rd_defense_x\n      tkl.1_x\n      att_defense_x\n      tkl%_x\n      past_x\n      press_defense_x\n      succ_defense_x\n      %_x\n      def 3rd_defense.1_x\n      mid 3rd_defense.1_x\n      att 3rd_defense.1_x\n      blocks_defense_x\n      sh_defense_x\n      shsv_x\n      pass_x\n      int_defense_x\n      clr_x\n      err_x\n      poss_x\n      touches_x\n      def pen_x\n      def 3rd_possession_x\n      mid 3rd_possession_x\n      att 3rd_possession_x\n      att pen_x\n      live_possession_x\n      succ_possession_x\n      att_possession_x\n      succ%_x\n      #pl_x\n      megs_x\n      carries_x\n      totdist_possession_x\n      prgdist_possession_x\n      prog_possession_x\n      1/3_possession_x\n      cpa_x\n      mis_x\n      dis_x\n      targ_x\n      rec_x\n      rec%_x\n      prog_possession.1_x\n      crdy_x\n      crdr_x\n      2crdy_x\n      fls_x\n      fld_misc_x\n      off_misc_x\n      crs_misc_x\n      int_misc_x\n      tklw_misc_x\n      pkwon_x\n      pkcon_x\n      og_x\n      recov_x\n      won_x\n      lost_x\n      won%_x\n      team_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      result_y\n      gf_y\n      ga_y\n      opponent_y\n      gls_y\n      sh_shooting_y\n      sot_y\n      sot%_y\n      g/sh_y\n      g/sot_y\n      dist_y\n      fk_shooting_y\n      pk_y\n      pkatt_shooting_y\n      xg_y\n      npxg_y\n      npxg/sh_y\n      g-xg_y\n      np:g-xg_y\n      sota_y\n      saves_y\n      save%_y\n      cs_y\n      psxg_y\n      psxg+/-_y\n      pkatt_keeper_y\n      pka_y\n      pksv_y\n      pkm_y\n      cmp_keeper_y\n      att_keeper_y\n      cmp%_keeper_y\n      att_keeper.1_y\n      thr_y\n      launch%_y\n      avglen_y\n      att_keeper.2_y\n      launch%.1_y\n      avglen.1_y\n      opp_y\n      stp_y\n      stp%_y\n      #opa_y\n      avgdist_y\n      cmp_passing_y\n      att_passing_y\n      cmp%_passing_y\n      totdist_passing_y\n      prgdist_passing_y\n      cmp_passing.1_y\n      att_passing.1_y\n      cmp%_passing.1_y\n      cmp_passing.2_y\n      att_passing.2_y\n      cmp%_passing.2_y\n      cmp_passing.3_y\n      att_passing.3_y\n      cmp%_passing.3_y\n      ast_y\n      xa_y\n      kp_y\n      1/3_passing_y\n      ppa_y\n      crspa_y\n      prog_passing_y\n      att_passing_types_y\n      live_passing_types_y\n      dead_y\n      fk_passing_types_y\n      tb_y\n      press_passing_types_y\n      sw_y\n      crs_passing_types_y\n      ck_y\n      in_y\n      out_y\n      str_y\n      ground_y\n      low_y\n      high_y\n      left_y\n      right_y\n      head_y\n      ti_y\n      other_y\n      cmp_passing_types_y\n      off_passing_types_y\n      out.1_y\n      int_passing_types_y\n      blocks_passing_types_y\n      sca_y\n      passlive_y\n      passdead_y\n      drib_y\n      sh_gca_y\n      fld_gca_y\n      def_y\n      gca_y\n      passlive.1_y\n      passdead.1_y\n      drib.1_y\n      sh_gca.1_y\n      fld_gca.1_y\n      def.1_y\n      tkl_y\n      tklw_defense_y\n      def 3rd_defense_y\n      mid 3rd_defense_y\n      att 3rd_defense_y\n      tkl.1_y\n      att_defense_y\n      tkl%_y\n      past_y\n      press_defense_y\n      succ_defense_y\n      %_y\n      def 3rd_defense.1_y\n      mid 3rd_defense.1_y\n      att 3rd_defense.1_y\n      blocks_defense_y\n      sh_defense_y\n      shsv_y\n      pass_y\n      int_defense_y\n      clr_y\n      err_y\n      poss_y\n      touches_y\n      def pen_y\n      def 3rd_possession_y\n      mid 3rd_possession_y\n      att 3rd_possession_y\n      att pen_y\n      live_possession_y\n      succ_possession_y\n      att_possession_y\n      succ%_y\n      #pl_y\n      megs_y\n      carries_y\n      totdist_possession_y\n      prgdist_possession_y\n      prog_possession_y\n      1/3_possession_y\n      cpa_y\n      mis_y\n      dis_y\n      targ_y\n      rec_y\n      rec%_y\n      prog_possession.1_y\n      crdy_y\n      crdr_y\n      2crdy_y\n      fls_y\n      fld_misc_y\n      off_misc_y\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      count\n      1900.000000\n      1900.000000\n      1900.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1900\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1886.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1886.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1900\n      1900.000000\n      1900.000000\n      1900.000000\n      1900.000000\n      1900\n      1885.000000\n      1885.000000\n      1885.000000\n      1900\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1900\n    \n    \n      unique\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n    \n    \n      top\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      W\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n    \n    \n      freq\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      95\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      95\n      NaN\n      NaN\n      NaN\n      NaN\n      833\n      NaN\n      NaN\n      NaN\n      95\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      95\n    \n    \n      mean\n      1899.500000\n      19.500000\n      15.898421\n      0.981275\n      1.348613\n      1.384384\n      NaN\n      1.303745\n      12.114821\n      4.026409\n      33.733678\n      0.103473\n      0.295749\n      17.072311\n      0.449391\n      0.100601\n      0.127628\n      1.298472\n      1.201890\n      0.100960\n      0.005273\n      0.001254\n      4.135223\n      2.855856\n      68.903853\n      0.279456\n      1.345345\n      0.006006\n      0.133899\n      0.104575\n      0.022081\n      0.007243\n      6.758612\n      17.588059\n      41.225057\n      24.244568\n      4.087970\n      51.351016\n      42.636584\n      7.580198\n      67.203542\n      52.586654\n      8.913355\n      0.671524\n      7.550442\n      0.644409\n      14.386937\n      388.891274\n      492.537361\n      77.164414\n      7641.028352\n      2558.818053\n      158.735206\n      180.984897\n      86.644515\n      164.931461\n      192.286169\n      83.897553\n      58.174527\n      100.678237\n      56.828052\n      0.935082\n      0.884941\n      8.780427\n      29.078520\n      8.121092\n      1.944709\n      32.064211\n      492.537361\n      444.751899\n      47.785462\n      11.694135\n      0.920774\n      74.121003\n      14.462197\n      11.809751\n      5.095478\n      2.139286\n      1.731143\n      0.399753\n      321.328211\n      67.803303\n      103.405847\n      135.954425\n      294.845345\n      20.424925\n      21.012365\n      6.499205\n      388.891274\n      1.642731\n      8.930136\n      11.704469\n      12.023582\n      18.906289\n      13.642908\n      1.663929\n      1.160661\n      0.968998\n      1.045487\n      0.424307\n      2.121798\n      1.457781\n      0.142024\n      0.143879\n      0.175146\n      0.154213\n      0.048755\n      17.752694\n      10.716570\n      8.989313\n      6.634164\n      2.129217\n      6.005211\n      16.475534\n      36.579765\n      10.470323\n      150.920155\n      43.718248\n      29.466393\n      53.042219\n      65.075075\n      32.802862\n      15.953100\n      3.864335\n      0.080639\n      12.088765\n      12.303568\n      25.391715\n      0.277778\n      49.794471\n      613.384473\n      66.492316\n      200.964671\n      289.074545\n      160.185921\n      23.606077\n      566.688571\n      9.590178\n      16.423688\n      58.240761\n      10.422893\n      0.710564\n      381.649620\n      1946.036213\n      1046.398075\n      42.419007\n      12.752164\n      4.159424\n      12.226020\n      11.763911\n      463.668610\n      388.891274\n      82.442943\n      34.198816\n      1.649709\n      0.059883\n      0.025349\n      12.391892\n      11.972178\n      1.849585\n      11.809751\n      12.303568\n      10.716570\n      0.106783\n      0.127363\n      0.045398\n      89.831832\n      19.251016\n      19.192457\n      50.053021\n      NaN\n      2019.000000\n      6.783684\n      2019.502105\n      4.369474\n      NaN\n      1.019452\n      1.394164\n      1.357913\n      NaN\n      1.350928\n      12.542794\n      4.147126\n      33.628974\n      0.103412\n      0.296049\n      17.005402\n      0.465252\n      0.106720\n      0.134483\n      1.343775\n      1.241813\n      0.101071\n      0.007153\n      0.002396\n      4.028559\n      2.772679\n      68.942476\n      0.294518\n      1.318400\n      0.003899\n      0.133245\n      0.103714\n      0.021751\n      0.007781\n      6.664633\n      17.180460\n      41.582263\n      24.047303\n      4.079222\n      50.730752\n      42.360955\n      7.347834\n      66.706225\n      52.362776\n      8.600973\n      0.653935\n      7.557745\n      0.655615\n      14.457374\n      393.315915\n      497.116092\n      77.334757\n      7716.688859\n      2578.746154\n      160.743148\n      183.147303\n      86.690531\n      166.674713\n      194.160389\n      83.990256\n      58.696375\n      100.996286\n      57.213572\n      0.958886\n      0.912387\n      9.089567\n      29.760743\n      8.403890\n      2.037577\n      32.761362\n      497.116092\n      449.316888\n      47.799204\n      11.632361\n      0.939346\n      74.330416\n      14.539257\n      12.193280\n      5.269231\n      2.218744\n      1.782405\n      0.397436\n      325.532007\n      67.987710\n      103.596375\n      137.411229\n      297.718479\n      20.550663\n      21.171530\n      6.524138\n      393.315915\n      1.669938\n      8.890097\n      11.775950\n      12.071176\n      19.572944\n      14.123784\n      1.717241\n      1.208488\n      1.018214\n      1.069850\n      0.435367\n      2.188329\n      1.490363\n      0.143767\n      0.150663\n      0.187798\n      0.165429\n      0.050309\n      17.783466\n      10.777542\n      8.864633\n      6.707339\n      2.211494\n      5.972944\n      16.418568\n      36.510177\n      10.445623\n      150.598320\n      43.888240\n      29.662538\n      51.744209\n      65.314943\n      33.539169\n      15.756322\n      3.754907\n      0.081698\n      12.001415\n      12.301503\n      24.903271\n      0.268789\n      50.256852\n      617.632449\n      64.989744\n      198.262511\n      292.036251\n      164.680195\n      24.284085\n      570.912290\n      9.664898\n      16.536693\n      58.282299\n      10.489567\n      0.719629\n      385.818391\n      1975.821751\n      1064.124050\n      43.414147\n      13.084085\n      4.244828\n      12.209372\n      11.802122\n      468.212025\n      393.315915\n      82.592440\n      34.972679\n      1.617860\n      0.057913\n      0.022812\n      12.375066\n      11.976835\n      1.889390\n      12.193280\n      12.301503\n      10.777542\n      0.112555\n      0.128647\n      0.043590\n      90.371618\n      19.201503\n      19.248806\n      49.947038\n      NaN\n    \n    \n      std\n      1097.253898\n      10.968743\n      9.032951\n      0.562990\n      0.821883\n      0.785860\n      NaN\n      0.804609\n      3.604429\n      1.602244\n      9.903141\n      0.065570\n      0.165471\n      1.924068\n      0.400656\n      0.186497\n      0.210009\n      0.539552\n      0.501255\n      0.028464\n      0.559989\n      0.556278\n      1.552937\n      1.210365\n      17.491508\n      0.271230\n      0.629407\n      0.438295\n      0.217505\n      0.189225\n      0.088425\n      0.052120\n      2.660282\n      6.832762\n      11.726573\n      5.616292\n      1.715115\n      19.941490\n      9.586412\n      2.184880\n      24.470953\n      13.806232\n      2.816386\n      0.539412\n      6.476357\n      0.572101\n      3.176210\n      119.229069\n      116.071850\n      6.144141\n      2168.848871\n      445.699643\n      50.744911\n      52.013891\n      3.643398\n      59.005557\n      59.215437\n      5.401759\n      14.684347\n      13.592733\n      8.982522\n      0.666895\n      0.399544\n      2.870647\n      10.251511\n      3.403934\n      0.983293\n      10.231721\n      116.071850\n      116.835035\n      5.205801\n      2.417642\n      0.819581\n      19.067863\n      4.485810\n      3.426532\n      1.843978\n      1.226782\n      1.228117\n      0.563332\n      117.228523\n      14.824503\n      17.732367\n      49.991609\n      89.158574\n      5.061035\n      3.878356\n      2.018556\n      119.229069\n      0.906005\n      2.228578\n      4.818136\n      2.640678\n      6.149121\n      5.048727\n      0.842950\n      0.764914\n      0.690645\n      0.595341\n      0.404329\n      1.403242\n      1.128908\n      0.214357\n      0.251739\n      0.249517\n      0.235028\n      0.132418\n      3.486760\n      2.321194\n      2.604811\n      1.869853\n      1.015222\n      1.928814\n      3.932232\n      8.482969\n      2.871477\n      28.004395\n      8.310211\n      4.019124\n      15.206973\n      13.690141\n      8.566743\n      3.450404\n      1.723662\n      0.172795\n      2.669393\n      4.950353\n      7.901514\n      0.338057\n      9.654077\n      112.185015\n      11.791488\n      29.665480\n      73.462201\n      47.891499\n      8.135065\n      112.874321\n      2.904043\n      4.134119\n      9.007144\n      3.056041\n      0.574513\n      108.474565\n      555.165722\n      343.059723\n      16.988892\n      4.900100\n      2.137224\n      2.450544\n      2.720636\n      118.818312\n      119.229069\n      5.176446\n      10.821910\n      0.744174\n      0.139770\n      0.091251\n      2.557418\n      2.618130\n      0.965104\n      3.426532\n      4.950353\n      2.321194\n      0.192593\n      0.209222\n      0.122086\n      11.271895\n      5.651655\n      5.762810\n      6.334482\n      NaN\n      1.414586\n      3.941522\n      1.534060\n      1.790301\n      NaN\n      0.552615\n      0.807042\n      0.773021\n      NaN\n      0.797606\n      3.627001\n      1.623645\n      9.439212\n      0.062460\n      0.158243\n      1.854209\n      0.408448\n      0.192914\n      0.217812\n      0.542758\n      0.500615\n      0.028187\n      0.548397\n      0.546242\n      1.531216\n      1.180476\n      17.188190\n      0.275738\n      0.618038\n      0.420442\n      0.219380\n      0.189636\n      0.089879\n      0.051501\n      2.703961\n      6.855387\n      11.862575\n      5.541456\n      1.641207\n      20.175225\n      9.649619\n      2.115403\n      24.974972\n      13.990437\n      2.787519\n      0.525688\n      6.332470\n      0.567261\n      3.141355\n      120.349836\n      116.921562\n      6.151168\n      2170.967839\n      444.312969\n      51.702598\n      52.846013\n      3.671086\n      59.408668\n      59.649384\n      5.348855\n      14.399394\n      13.379318\n      8.932960\n      0.670045\n      0.405043\n      2.929930\n      10.425809\n      3.474786\n      0.996109\n      10.419660\n      116.921562\n      117.856119\n      5.108167\n      2.394477\n      0.837783\n      18.926442\n      4.461939\n      3.465959\n      1.852495\n      1.273013\n      1.253528\n      0.555805\n      119.017408\n      14.350673\n      17.779460\n      50.632261\n      89.905177\n      5.074563\n      3.824267\n      1.953636\n      120.349836\n      0.905120\n      2.222899\n      4.840289\n      2.638053\n      6.235966\n      5.138590\n      0.855581\n      0.774006\n      0.707101\n      0.609149\n      0.411871\n      1.389641\n      1.130901\n      0.220694\n      0.251019\n      0.263766\n      0.243332\n      0.135716\n      3.497036\n      2.283436\n      2.575933\n      1.880128\n      1.026761\n      1.903147\n      3.991825\n      8.613304\n      2.975346\n      27.787039\n      8.192015\n      3.904190\n      14.934585\n      13.454384\n      8.855899\n      3.427076\n      1.641214\n      0.176925\n      2.692379\n      4.848354\n      7.741390\n      0.326118\n      9.582076\n      113.150911\n      11.346986\n      29.170312\n      75.558722\n      47.850712\n      8.148257\n      113.983664\n      2.935263\n      4.119026\n      8.891462\n      3.069472\n      0.559645\n      110.104248\n      567.762012\n      352.252975\n      17.649311\n      5.005604\n      2.101465\n      2.442809\n      2.752240\n      119.845963\n      120.349836\n      5.157349\n      10.905252\n      0.753974\n      0.145882\n      0.090107\n      2.516177\n      2.584682\n      0.962440\n      3.465959\n      4.848354\n      2.283436\n      0.198533\n      0.213166\n      0.119223\n      11.291527\n      5.667756\n      5.856177\n      6.246339\n      NaN\n    \n    \n      min\n      1.000000\n      1.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.200000\n      0.030000\n      -2.100000\n      -2.100000\n      0.000000\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      1.000000\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.666667\n      0.000000\n      11.400000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      5.500000\n      157.000000\n      251.666667\n      58.200000\n      3334.666667\n      1419.000000\n      58.000000\n      70.000000\n      68.133333\n      55.666667\n      78.000000\n      63.566667\n      26.333333\n      68.000000\n      33.233333\n      0.000000\n      0.133333\n      1.666667\n      10.333333\n      0.333333\n      0.000000\n      8.000000\n      251.666667\n      212.000000\n      32.333333\n      4.333333\n      0.000000\n      32.000000\n      4.333333\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      88.000000\n      31.333333\n      57.666667\n      37.000000\n      118.500000\n      7.666667\n      7.000000\n      0.666667\n      157.000000\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      4.666667\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      4.000000\n      2.000000\n      1.333333\n      0.000000\n      1.000000\n      6.000000\n      9.166667\n      2.666667\n      80.333333\n      19.333333\n      13.700000\n      15.666667\n      31.333333\n      12.666667\n      6.000000\n      0.000000\n      0.000000\n      5.000000\n      1.666667\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      25.000000\n      116.000000\n      140.666667\n      54.666667\n      5.666667\n      324.333333\n      2.666667\n      5.000000\n      28.600000\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      348.666667\n      12.000000\n      1.000000\n      0.000000\n      5.000000\n      4.000000\n      219.333333\n      157.000000\n      63.700000\n      11.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      4.666667\n      0.000000\n      3.000000\n      1.666667\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      0.000000\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      4.000000\n      0.333333\n      5.000000\n      0.000000\n      0.000000\n      11.766667\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.700000\n      -1.700000\n      0.666667\n      0.000000\n      -8.333333\n      0.000000\n      0.000000\n      -1.800000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      11.100000\n      10.000000\n      0.333333\n      8.200000\n      22.500000\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      137.000000\n      235.000000\n      58.300000\n      3027.000000\n      1359.000000\n      53.000000\n      68.000000\n      71.333333\n      51.000000\n      72.000000\n      64.733333\n      27.000000\n      65.666667\n      32.133333\n      0.000000\n      0.100000\n      2.000000\n      9.000000\n      0.000000\n      0.000000\n      6.000000\n      235.000000\n      190.000000\n      29.666667\n      3.000000\n      0.000000\n      34.000000\n      4.666667\n      3.333333\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      103.666667\n      27.666667\n      54.333333\n      42.000000\n      112.000000\n      7.000000\n      10.000000\n      1.000000\n      137.000000\n      0.000000\n      2.666667\n      1.666667\n      5.000000\n      5.500000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      8.000000\n      4.333333\n      1.666667\n      1.000000\n      0.000000\n      1.333333\n      6.000000\n      11.666667\n      2.000000\n      66.000000\n      17.333333\n      16.966667\n      12.000000\n      30.666667\n      9.500000\n      6.333333\n      0.000000\n      0.000000\n      4.666667\n      1.333333\n      6.666667\n      0.000000\n      23.000000\n      346.000000\n      32.000000\n      112.000000\n      124.000000\n      55.000000\n      6.000000\n      303.000000\n      2.000000\n      6.000000\n      22.333333\n      3.000000\n      0.000000\n      142.000000\n      780.000000\n      356.000000\n      9.000000\n      2.000000\n      0.000000\n      5.000000\n      3.666667\n      203.000000\n      137.000000\n      61.866667\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.333333\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      51.666667\n      5.000000\n      6.000000\n      28.633333\n      NaN\n    \n    \n      25%\n      950.750000\n      10.000000\n      8.000000\n      0.666667\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.150000\n      0.056667\n      0.170000\n      15.733333\n      0.000000\n      0.000000\n      0.000000\n      0.900000\n      0.833333\n      0.080000\n      -0.400000\n      -0.400000\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.333333\n      33.100000\n      20.333333\n      3.000000\n      34.716667\n      34.866667\n      6.000000\n      48.900000\n      41.616667\n      7.000000\n      0.333333\n      2.766667\n      0.333333\n      12.233333\n      299.833333\n      406.666667\n      73.000000\n      6008.666667\n      2243.166667\n      121.666667\n      143.000000\n      84.400000\n      119.333333\n      146.666667\n      80.400000\n      47.333333\n      91.333333\n      50.250000\n      0.333333\n      0.600000\n      6.666667\n      22.000000\n      5.666667\n      1.333333\n      24.666667\n      406.666667\n      358.333333\n      44.333333\n      10.000000\n      0.333333\n      61.000000\n      11.000000\n      9.333333\n      4.000000\n      1.333333\n      0.666667\n      0.000000\n      232.833333\n      57.333333\n      90.666667\n      102.666667\n      227.666667\n      17.000000\n      18.333333\n      5.000000\n      299.833333\n      1.000000\n      7.333333\n      8.000000\n      10.000000\n      14.666667\n      10.000000\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.000000\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.000000\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.650000\n      8.333333\n      130.333333\n      38.000000\n      26.766667\n      42.333333\n      55.000000\n      26.666667\n      13.333333\n      2.666667\n      0.000000\n      10.333333\n      8.333333\n      20.000000\n      0.000000\n      42.666667\n      530.166667\n      58.333333\n      179.333333\n      235.666667\n      127.666667\n      17.666667\n      483.333333\n      7.666667\n      13.666667\n      52.583333\n      8.333333\n      0.333333\n      301.666667\n      1526.500000\n      788.166667\n      30.333333\n      9.333333\n      2.666667\n      10.666667\n      9.833333\n      374.333333\n      299.833333\n      79.116667\n      26.333333\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.000000\n      1.000000\n      9.333333\n      8.333333\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      82.000000\n      15.333333\n      15.000000\n      46.066667\n      NaN\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      0.666667\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      10.000000\n      3.000000\n      27.266667\n      0.060000\n      0.183333\n      15.766667\n      0.000000\n      0.000000\n      0.000000\n      0.966667\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.566667\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      11.666667\n      33.333333\n      20.000000\n      3.000000\n      34.466667\n      34.500000\n      6.000000\n      46.800000\n      40.966667\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.300000\n      305.000000\n      411.666667\n      73.033333\n      6110.666667\n      2265.000000\n      123.333333\n      145.000000\n      84.366667\n      121.333333\n      149.333333\n      80.600000\n      48.000000\n      91.333333\n      50.400000\n      0.333333\n      0.633333\n      7.000000\n      22.333333\n      6.000000\n      1.333333\n      25.333333\n      411.666667\n      362.333333\n      44.333333\n      10.000000\n      0.333333\n      60.666667\n      11.333333\n      9.666667\n      4.000000\n      1.333333\n      1.000000\n      0.000000\n      235.000000\n      57.333333\n      91.000000\n      105.333333\n      230.666667\n      17.000000\n      18.666667\n      5.333333\n      305.000000\n      1.000000\n      7.333333\n      8.000000\n      10.333333\n      15.333333\n      10.333333\n      1.000000\n      0.666667\n      0.666667\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.333333\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.533333\n      8.333333\n      131.000000\n      38.333333\n      27.066667\n      41.333333\n      56.000000\n      27.000000\n      13.333333\n      2.666667\n      0.000000\n      10.000000\n      8.333333\n      19.333333\n      0.000000\n      43.333333\n      535.666667\n      57.000000\n      178.000000\n      238.000000\n      132.000000\n      18.333333\n      489.000000\n      7.333333\n      13.666667\n      52.466667\n      8.333333\n      0.333333\n      303.000000\n      1534.333333\n      796.666667\n      30.333333\n      9.666667\n      2.666667\n      10.333333\n      10.000000\n      379.666667\n      305.000000\n      79.166667\n      27.000000\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.333333\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.833333\n      NaN\n    \n    \n      50%\n      1898.500000\n      19.500000\n      16.000000\n      1.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      11.666667\n      3.666667\n      33.333333\n      0.096667\n      0.276667\n      16.966667\n      0.333333\n      0.000000\n      0.000000\n      1.200000\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      71.133333\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.666667\n      17.666667\n      39.766667\n      23.666667\n      4.000000\n      51.300000\n      42.100000\n      7.666667\n      70.933333\n      53.866667\n      8.666667\n      0.666667\n      6.466667\n      0.666667\n      14.133333\n      366.666667\n      472.666667\n      77.433333\n      7265.333333\n      2498.333333\n      150.000000\n      172.666667\n      87.000000\n      154.000000\n      182.333333\n      84.700000\n      56.000000\n      100.000000\n      56.366667\n      0.666667\n      0.833333\n      8.333333\n      26.666667\n      7.333333\n      1.666667\n      30.333333\n      472.666667\n      423.000000\n      47.666667\n      11.666667\n      0.666667\n      71.333333\n      14.000000\n      11.333333\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      300.000000\n      66.333333\n      102.333333\n      126.000000\n      282.000000\n      20.000000\n      20.666667\n      6.333333\n      366.666667\n      1.666667\n      9.000000\n      11.333333\n      12.000000\n      18.333333\n      12.666667\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      9.000000\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.333333\n      10.333333\n      148.666667\n      43.333333\n      29.433333\n      51.666667\n      64.000000\n      32.000000\n      16.000000\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.666667\n      0.333333\n      49.333333\n      596.333333\n      65.666667\n      199.333333\n      278.333333\n      150.000000\n      22.333333\n      547.666667\n      9.333333\n      16.333333\n      58.300000\n      10.333333\n      0.666667\n      361.666667\n      1874.000000\n      995.666667\n      39.000000\n      12.000000\n      3.666667\n      12.000000\n      11.666667\n      444.000000\n      366.666667\n      82.866667\n      32.333333\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      11.666667\n      1.666667\n      11.333333\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.333333\n      18.666667\n      18.666667\n      49.966667\n      NaN\n      2019.000000\n      7.000000\n      2019.000000\n      5.000000\n      NaN\n      1.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.333333\n      4.000000\n      33.233333\n      0.096667\n      0.280000\n      16.933333\n      0.333333\n      0.000000\n      0.000000\n      1.266667\n      1.166667\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.333333\n      40.400000\n      23.666667\n      4.000000\n      51.200000\n      41.866667\n      7.333333\n      71.166667\n      54.000000\n      8.333333\n      0.666667\n      6.533333\n      0.666667\n      14.266667\n      372.333333\n      478.666667\n      77.666667\n      7365.333333\n      2526.333333\n      151.666667\n      174.333333\n      87.100000\n      157.000000\n      184.000000\n      84.800000\n      57.000000\n      100.333333\n      56.766667\n      1.000000\n      0.833333\n      8.666667\n      27.333333\n      7.666667\n      2.000000\n      31.000000\n      478.666667\n      429.333333\n      48.000000\n      11.666667\n      0.666667\n      72.000000\n      14.000000\n      12.000000\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      306.000000\n      67.000000\n      102.333333\n      127.000000\n      284.000000\n      20.333333\n      21.000000\n      6.333333\n      372.333333\n      1.666667\n      8.666667\n      11.666667\n      12.000000\n      19.000000\n      13.333333\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      8.666667\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.366667\n      10.333333\n      148.666667\n      43.333333\n      29.533333\n      51.000000\n      64.000000\n      32.666667\n      15.666667\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.333333\n      0.333333\n      49.666667\n      599.666667\n      64.333333\n      195.666667\n      279.666667\n      155.333333\n      23.000000\n      551.666667\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      369.333333\n      1916.666667\n      1013.666667\n      40.000000\n      12.000000\n      4.000000\n      12.333333\n      11.666667\n      448.666667\n      372.333333\n      83.133333\n      33.666667\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      12.000000\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      90.000000\n      18.666667\n      18.666667\n      49.800000\n      NaN\n    \n    \n      75%\n      2853.500000\n      29.000000\n      23.000000\n      1.333333\n      1.666667\n      2.000000\n      NaN\n      1.666667\n      14.333333\n      5.000000\n      40.300000\n      0.140000\n      0.400000\n      18.233333\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.466667\n      0.116667\n      0.366667\n      0.333333\n      5.000000\n      3.666667\n      80.966667\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.666667\n      47.883333\n      27.666667\n      5.000000\n      66.800000\n      50.016667\n      9.000000\n      88.900000\n      63.683333\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.100000\n      461.250000\n      566.166667\n      81.783333\n      8979.000000\n      2816.833333\n      186.000000\n      210.000000\n      89.250000\n      202.666667\n      230.500000\n      88.016667\n      67.000000\n      109.333333\n      63.116667\n      1.333333\n      1.100000\n      10.666667\n      33.666667\n      10.000000\n      2.666667\n      37.500000\n      566.166667\n      517.500000\n      51.333333\n      13.333333\n      1.333333\n      85.000000\n      17.000000\n      14.000000\n      6.000000\n      3.000000\n      2.333333\n      0.666667\n      396.000000\n      76.666667\n      115.333333\n      155.500000\n      350.500000\n      23.666667\n      23.333333\n      7.666667\n      461.250000\n      2.000000\n      10.333333\n      15.000000\n      13.666667\n      22.666667\n      16.666667\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      7.666667\n      2.666667\n      7.333333\n      18.666667\n      42.083333\n      12.333333\n      168.333333\n      49.000000\n      32.100000\n      62.000000\n      73.666667\n      38.000000\n      18.000000\n      5.000000\n      0.000000\n      14.000000\n      15.833333\n      30.000000\n      0.333333\n      56.333333\n      683.666667\n      73.666667\n      220.000000\n      328.333333\n      182.333333\n      28.000000\n      637.666667\n      11.333333\n      19.000000\n      64.150000\n      12.333333\n      1.000000\n      448.833333\n      2302.166667\n      1252.000000\n      51.666667\n      15.333333\n      5.333333\n      13.666667\n      13.333333\n      537.333333\n      461.250000\n      86.233333\n      40.333333\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.833333\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.333333\n      22.666667\n      23.000000\n      54.050000\n      NaN\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      1.333333\n      2.000000\n      2.000000\n      NaN\n      1.666667\n      14.666667\n      5.333333\n      39.433333\n      0.136667\n      0.396667\n      18.166667\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.566667\n      0.333333\n      1.700000\n      0.266667\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.200000\n      27.333333\n      5.000000\n      66.400000\n      49.666667\n      8.666667\n      88.900000\n      63.933333\n      10.333333\n      1.000000\n      11.100000\n      1.000000\n      16.333333\n      465.666667\n      566.666667\n      82.000000\n      8991.000000\n      2841.666667\n      190.000000\n      213.666667\n      89.366667\n      203.666667\n      229.666667\n      88.066667\n      68.000000\n      109.333333\n      63.766667\n      1.333333\n      1.133333\n      11.000000\n      34.333333\n      10.333333\n      2.666667\n      38.000000\n      566.666667\n      519.666667\n      51.333333\n      13.000000\n      1.333333\n      85.000000\n      17.333333\n      14.333333\n      6.333333\n      3.000000\n      2.333333\n      0.666667\n      397.666667\n      77.333333\n      115.666667\n      156.000000\n      355.000000\n      23.666667\n      23.666667\n      7.666667\n      465.666667\n      2.333333\n      10.333333\n      15.000000\n      13.666667\n      23.333333\n      17.333333\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      8.000000\n      3.000000\n      7.000000\n      18.666667\n      42.133333\n      12.000000\n      167.666667\n      49.000000\n      32.266667\n      60.666667\n      74.000000\n      39.333333\n      18.000000\n      4.666667\n      0.000000\n      14.000000\n      15.666667\n      29.333333\n      0.333333\n      56.666667\n      686.000000\n      72.000000\n      217.333333\n      334.000000\n      187.666667\n      28.666667\n      639.333333\n      11.333333\n      19.000000\n      64.300000\n      12.333333\n      1.000000\n      452.333333\n      2354.000000\n      1290.000000\n      53.000000\n      15.666667\n      5.333333\n      13.666667\n      13.666667\n      539.000000\n      465.666667\n      86.433333\n      41.000000\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.333333\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      98.000000\n      23.000000\n      23.000000\n      53.933333\n      NaN\n    \n    \n      max\n      3799.000000\n      38.000000\n      31.000000\n      2.000000\n      4.666667\n      5.666667\n      NaN\n      4.666667\n      28.000000\n      10.000000\n      66.966667\n      0.500000\n      1.000000\n      25.600000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.233333\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.000000\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      37.333333\n      90.000000\n      47.333333\n      10.666667\n      98.933333\n      71.100000\n      22.000000\n      100.000000\n      85.850000\n      19.666667\n      3.333333\n      44.766667\n      3.666667\n      40.666667\n      841.666667\n      927.333333\n      90.833333\n      15066.666667\n      4280.333333\n      392.666667\n      416.000000\n      94.600000\n      366.666667\n      397.000000\n      94.266667\n      117.666667\n      164.000000\n      83.633333\n      4.333333\n      2.833333\n      22.000000\n      71.000000\n      24.333333\n      8.000000\n      76.666667\n      927.333333\n      884.000000\n      67.000000\n      20.000000\n      5.333333\n      171.333333\n      31.000000\n      26.666667\n      14.000000\n      8.000000\n      8.000000\n      5.000000\n      786.000000\n      141.333333\n      169.000000\n      400.333333\n      609.333333\n      42.333333\n      36.333333\n      14.333333\n      841.666667\n      7.000000\n      16.333333\n      32.666667\n      22.333333\n      45.000000\n      38.000000\n      5.000000\n      5.666667\n      5.666667\n      3.666667\n      2.000000\n      8.666667\n      8.000000\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      18.666667\n      21.000000\n      14.000000\n      6.666667\n      17.666667\n      36.333333\n      66.700000\n      24.000000\n      268.333333\n      83.000000\n      43.100000\n      122.666667\n      122.000000\n      76.666667\n      30.666667\n      14.666667\n      1.000000\n      22.666667\n      31.666667\n      62.666667\n      2.666667\n      77.666667\n      1023.666667\n      141.000000\n      363.000000\n      598.333333\n      367.666667\n      63.333333\n      981.333333\n      24.333333\n      36.333333\n      90.000000\n      25.666667\n      4.666667\n      746.333333\n      3773.333333\n      2269.666667\n      109.666667\n      35.666667\n      14.333333\n      23.000000\n      23.000000\n      912.000000\n      841.666667\n      94.300000\n      76.666667\n      4.333333\n      1.000000\n      0.666667\n      21.000000\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      18.666667\n      1.666667\n      2.000000\n      1.000000\n      126.000000\n      50.333333\n      43.000000\n      75.766667\n      NaN\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      2.000000\n      5.666667\n      4.666667\n      NaN\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.426667\n      1.000000\n      25.033333\n      3.000000\n      1.000000\n      1.000000\n      3.666667\n      3.300000\n      0.240000\n      2.366667\n      2.366667\n      10.333333\n      8.000000\n      100.000000\n      1.333333\n      3.766667\n      1.500000\n      1.500000\n      1.500000\n      1.000000\n      0.666667\n      16.333333\n      42.000000\n      95.233333\n      50.333333\n      10.333333\n      100.000000\n      71.666667\n      16.000000\n      100.000000\n      81.833333\n      21.333333\n      3.666667\n      42.933333\n      3.333333\n      40.266667\n      846.333333\n      930.666667\n      91.066667\n      14734.333333\n      4056.666667\n      406.333333\n      429.333333\n      95.100000\n      356.666667\n      385.000000\n      94.633333\n      114.666667\n      164.000000\n      80.666667\n      5.000000\n      2.700000\n      25.000000\n      79.333333\n      25.333333\n      6.333333\n      76.333333\n      930.666667\n      890.666667\n      66.333333\n      20.500000\n      5.333333\n      162.333333\n      35.000000\n      25.666667\n      12.666667\n      7.000000\n      9.333333\n      3.666667\n      772.666667\n      126.000000\n      165.666667\n      362.000000\n      620.000000\n      40.000000\n      33.666667\n      14.666667\n      846.333333\n      6.000000\n      16.666667\n      32.666667\n      21.333333\n      50.000000\n      39.000000\n      5.333333\n      5.000000\n      5.666667\n      3.333333\n      2.333333\n      10.666667\n      8.666667\n      1.000000\n      2.000000\n      2.000000\n      1.333333\n      0.666667\n      31.333333\n      19.666667\n      17.666667\n      16.000000\n      6.000000\n      15.000000\n      39.000000\n      71.400000\n      27.000000\n      259.333333\n      79.333333\n      45.566667\n      125.000000\n      123.666667\n      75.666667\n      29.333333\n      11.666667\n      1.333333\n      21.000000\n      31.666667\n      57.666667\n      2.333333\n      78.333333\n      1024.000000\n      114.666667\n      311.333333\n      651.666667\n      382.333333\n      67.000000\n      984.666667\n      26.000000\n      39.000000\n      84.433333\n      27.000000\n      4.000000\n      737.666667\n      4209.000000\n      2418.333333\n      116.000000\n      37.000000\n      14.666667\n      23.000000\n      25.333333\n      914.666667\n      846.333333\n      93.333333\n      78.333333\n      5.000000\n      2.000000\n      1.000000\n      22.333333\n      22.000000\n      6.666667\n      25.666667\n      31.666667\n      19.666667\n      1.000000\n      1.500000\n      1.000000\n      126.666667\n      43.000000\n      45.333333\n      72.166667\n      NaN\n    \n  \n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom dtreeviz.trees import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\n\nfrom sklearn.experimental import enable_halving_search_cv  # noqa\nfrom sklearn.model_selection import HalvingRandomSearchCV\n\n\nTrain / Valid split\nIn this case valid is actually test as train will be split by fits into train and valid\n\nimport copy\ndf=copy.copy(dfAll)\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\n\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/len(df)\n\n0.2\n\n\n\nwant_binary=0\nif want_binary==1:\n    df.loc[df['Win_x']=='D','Win_x']='L'\n\n\n\nCreate tabular pandas & x and y values\n\ndep_var='Win_x'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\ncat\n\n['opponent_x', 'team_x', 'opponent_y', 'team_y']\n\n\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#fit-the-data",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#fit-the-data",
    "title": "ThomasHSimm",
    "section": "Fit the data",
    "text": "Fit the data\n\nclf=RandomForestClassifier(random_state=42)\nclf.fit(xs,y)\n\nRandomForestClassifier(random_state=42)\n\n\n\nclf.score(xs,y),clf.score(valid_xs,valid_y)\n\n(1.0, 0.4921052631578947)\n\n\n\nclf.get_params()\n\n{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'gini',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': 42,\n 'verbose': 0,\n 'warm_start': False}\n\n\n\nImprove hyperparameters\nHalvingRandomSearchCV, RandomizedSearchCV and GridSearchCV can be used to search for the best hyperparameters.\nThe random ones don’t go through all the options, but pick combinations randomly. So they will be quicker but may not get the best result. You may want to do the random ones to get a rough idea of parameters followed by grid search on a reduced range.\nThe most important arguments are - cv which is the number of folds to use for cross validation (we use the default values for cv of 5). - factor the halving parameter (2 is used) - (or n_iter for RandomizedSearchCV, which controls the number of different combinations to try)\nMore iterations or lower factor will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time.\n\n# Number of trees in random forest\nn_estimators=[20,50,150,400,700]\n\n# Number of features to consider at every split\nmax_features = ['log2','sqrt',None]\n\n# Maximum number of levels in tree\nmax_depth=[10,  30,  70,  200, None]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [1.,2, 10,50]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,10]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Weights associated with classes \nclass_weight=[\"balanced\", \"balanced_subsample\",None]\n\n#Complexity parameter used for Minimal Cost-Complexity Pruning.\nccp_alpha=[0., 0.1, 0.5]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap,\n               'class_weight':class_weight,\n               'ccp_alpha' : ccp_alpha\n\n              }\n\nrsh = HalvingRandomSearchCV(estimator = clf, param_distributions = random_grid, \\\n                              random_state=42, factor = 6)# Fit the random search model\nrsh.fit(xs, y)\n\nHalvingRandomSearchCV(estimator=RandomForestClassifier(random_state=42),\n                      factor=6,\n                      param_distributions={'bootstrap': [True, False],\n                                           'ccp_alpha': [0.0, 0.1, 0.5],\n                                           'class_weight': ['balanced',\n                                                            'balanced_subsample',\n                                                            None],\n                                           'max_depth': [10, 30, 70, 200, None],\n                                           'max_features': ['log2', 'sqrt',\n                                                            None],\n                                           'min_samples_leaf': [1, 2, 4, 10],\n                                           'min_samples_split': [1.0, 2, 10,\n                                                                 50],\n                                           'n_estimators': [20, 50, 150, 400,\n                                                            700]},\n                      random_state=42)\n\n\n\nresults = pd.DataFrame(rsh.cv_results_)\nresults[\"params_str\"] = results.params.apply(str)\nresults.drop_duplicates(subset=(\"params_str\", \"iter\"), inplace=True)\nmean_scores = results.pivot(\n    index=\"iter\", columns=\"params_str\", values=\"mean_test_score\"\n)\nax = mean_scores.plot(legend=False, alpha=0.6)\n\nlabels = [\n    f\"iter={i}\\nn_samples={rsh.n_resources_[i]}\\nn_candidates={rsh.n_candidates_[i]}\"\n    for i in range(rsh.n_iterations_)\n]\n\nax.set_xticks(range(rsh.n_iterations_))\nax.set_xticklabels(labels, rotation=45, multialignment=\"left\")\nax.set_title(\"Scores of candidates over iterations\")\nax.set_ylabel(\"mean test score\", fontsize=15)\nax.set_xlabel(\"iterations\", fontsize=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nprint(rsh.best_params_)\ndef evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors / test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy\nbest_random = rsh.best_estimator_\n\nmm = best_random.predict(valid_xs)\n\n\n\nprint(best_random.get_params())\n\n\n\nprint(\"\\nThe score for predictions on the 2021 season (not shown to training data) is:\\n\\\n      {:.3f}\\n\\\n\\nThe predictions for the training data is:\\n\\\n      {:.3f}\".format(best_random.score(valid_xs, valid_y),best_random.score(xs, y)) )\n\n{'n_estimators': 50, 'min_samples_split': 50, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': None, 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n\nThe score for predictions on the 2021 season (not shown to training data) is:\n      0.532\n\nThe predictions for the training data is:\n      0.853"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#look-at-the-predictions",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#look-at-the-predictions",
    "title": "ThomasHSimm",
    "section": "Look at the predictions",
    "text": "Look at the predictions\n\n#clf rsh\npred=clf.predict(xs)\npred_valid=clf.predict(valid_xs)\n\n# [(y[i],df['Win_x'].iloc[i]) for i in range(5)]\n[(y[i],df['Win_x'].iloc[i],pred[i]) for i in range(5)]\n\n[(2, 'W', 2), (1, 'L', 1), (2, 'W', 2), (2, 'W', 2), (1, 'L', 1)]\n\n\n\nplt.hist(pred[y==1]-1,width=.1,align='left',linewidth=2,linestyle='-.',\n         facecolor='none',edgecolor='b')#loss\nplt.hist(pred[y==0],width=.1,align='mid',linewidth=2,linestyle='-',\n         facecolor='none',edgecolor='r')#draw\nplt.hist(pred[y==2]-2,width=.1,align='left',linewidth=2,linestyle='--',\n         facecolor='none',edgecolor='k')#win\n\n# Draw=0\n# Win=2\n# Loss=1\nplt.legend(['Loss','Draw','Win'])\npc_loss=int(100*len(y[y==1])/len(pred))\npc_win=int(100*len(y[y==2])/len(pred))\npc_draw=int(100*len(y[y==0])/len(pred))\n\npc_lossP=int(100*len(pred[pred==1])/len(pred))\npc_winP=int(100*len(pred[pred==2])/len(pred))\npc_drawP=int(100*len(pred[pred==0])/len(pred))\n\nprint('win PC actual {} pred {}\\n\\\nloss PC actual {} pred {}\\n\\\ndraw PC actual {} pred {}'.format(pc_loss,pc_lossP,pc_win,pc_winP,pc_draw,pc_drawP))\n\nwin PC actual 33 pred 33\nloss PC actual 44 pred 44\ndraw PC actual 22 pred 22\n\n\n\n\n\n\nplt.hist(pred_valid[valid_y==1]-1,width=.1,align='left',linewidth=2,linestyle='-.',\n         facecolor='none',edgecolor='b')#loss\nplt.hist(pred_valid[valid_y==0],width=.1,align='mid',linewidth=2,linestyle='-',\n         facecolor='none',edgecolor='r')#draw\nplt.hist(pred_valid[valid_y==2]-2,width=.1,align='left',linewidth=2,linestyle='--',\n         facecolor='none',edgecolor='k')#win\n\n# Draw=0\n# Win=2\n# Loss=1\nplt.legend(['Loss','Draw','Win'])\n\n\npc_loss=int(100*len(valid_y[valid_y==1])/len(pred_valid))\npc_win=int(100*len(valid_y[valid_y==2])/len(pred_valid))\npc_draw=int(100*len(valid_y[valid_y==0])/len(pred_valid))\n\npc_lossP=int(100*len(pred_valid[pred_valid==1])/len(pred_valid))\npc_winP=int(100*len(pred_valid[pred_valid==2])/len(pred_valid))\npc_drawP=int(100*len(pred_valid[pred_valid==0])/len(pred_valid))\n\nprint('win PC actual {} pred {}\\n\\\nloss PC actual {} pred {}\\n\\\ndraw PC actual {} pred {}'.format(pc_loss,pc_lossP,pc_win,pc_winP,pc_draw,pc_drawP))\n\nwin PC actual 33 pred 35\nloss PC actual 42 pred 61\ndraw PC actual 23 pred 3\n\n\n\n\n\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#try-with-a-binary-question-does-the-team-win",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#try-with-a-binary-question-does-the-team-win",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import Ridge\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\ncolsextraX=[x for x in df.columns if  x[-2:]!='_y']\ncolsextraY=[x for x in df.columns if  x[-2:]!='_x']\n\n#collapse-hide\n\nimport copy\ndf=copy.copy(dfAll)\n\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\n\ndf=df.rename(columns={'Win_x':'Win'})\ndf=df.loc[( ((df['round']>1) & (df['season']==2017)) | (df['season']>2017)  ) ]\n\n#     df=df.loc[:,colsextra]\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n#############\nwant_binary=1\nif want_binary==1:\n    df.loc[df['Win']=='D','Win']='L'\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\ndef do_RF():\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n    ppred_valid=clf.predict_proba(valid_xs)\n    ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,ppred,ppred_valid\n\ndef do_XGB(n_estimators=1000, learning_rate=0.0001, n_jobs=100):\n    # !pip install xgboost\n    \n\n    # Define the model\n    my_model_2 = XGBClassifier(n_estimators=1000, learning_rate=0.01) # Your code here\n\n    # Fit the model\n    my_model_2.fit(xs, y) \n\n    # Get predictions\n    ppred = my_model_2.predict_proba(xs)\n    ppred_valid = my_model_2.predict_proba(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n\n    return pred,pred_valid,ppred,ppred_valid \n\ndef do_ridge():\n    my_model_2 = Ridge(alpha=21)\n    my_model_2.fit(xs, y)\n    \n    # Get predictions\n    ppred = my_model_2.predict(xs)\n    ppred_valid = my_model_2.predict(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n    \n    pred[pred>0.5]=1\n    pred[pred<=0.5]=0\n    \n    pred_valid[pred_valid>0.5]=1\n    pred_valid[pred_valid<=0.5]=0\n\n    return pred,pred_valid , ppred,ppred_valid\n    \n    \n\n\npred_RF,pred_valid_RF, ppred_RF,ppred_valid_RF  = do_RF()\npred_XGB,pred_valid_XGB,ppred_XGB,ppred_valid_XGB = do_XGB()\npred_rdg,pred_valid_rdg,ppred_rdg,ppred_valid_rdg = do_ridge()\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.35191e-10): result may not be accurate.\n  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n\n\n\n\n\n10      0\n11      0\n12      1\n13      0\n14      1\n       ..\n1515    1\n1516    1\n1517    0\n1518    0\n1519    1\nName: Win, Length: 1510, dtype: int8\n\n\n\npred_combo=(ppred_valid_RF[:,1]+ppred_valid_XGB[:,1])\npred_combo[pred_combo>=1]=1\npred_combo[pred_combo<1] =0\n\n\ndef get_scores(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.2f} and precision = {:.2f}\".format(nom,acc,prec))\n\nget_scores('RF train',pred_RF, y)\nget_scores('RF valid',pred_valid_RF, valid_y)\nprint('-----')\nget_scores('XGB train',pred_XGB, y)\nget_scores('XGB valid',pred_valid_XGB, valid_y)\nprint('-----')\nget_scores('Ridge train',pred_rdg, y)\nget_scores('Ridge valid',pred_valid_rdg, valid_y)\nprint('-----')\nget_scores('Combined valid',pred_combo, valid_y)\n\nRF train: accuracy = 1.00 and precision = 1.00\nRF valid: accuracy = 0.62 and precision = 0.40\n-----\nXGB train: accuracy = 1.00 and precision = 1.00\nXGB valid: accuracy = 0.61 and precision = 0.36\n-----\nRidge train: accuracy = 0.74 and precision = 0.68\nRidge valid: accuracy = 0.59 and precision = 0.44\n-----\nCombined valid: accuracy = 0.59 and precision = 0.33\n\n\n\n# prec=precision_score(pred_valid, np.array(valid_y))\n# print(\"USING WIN versus DRAW/LOSS\\n\\\n#       \\nThe score for predictions on the 2021 season (not shown to training data) is:\\n\\\n#       {:.3f}   and precision {:.3f}\\n\\\n# \\nThe predictions for the training data is:\\n\\\n#       {:.3f}\".format(clf.score(valid_xs, valid_y),prec,clf.score(xs, y)) )\n\n\n\n#collapse-hide\n# Number of trees in random forest\nn_estimators=[20,50,150,400,700]\n\n# Number of features to consider at every split\nmax_features = ['log2','sqrt',None]\n\n# Maximum number of levels in tree\nmax_depth=[10,  30,  70,  200, None]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [1.,2, 10,50]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,10]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Weights associated with classes \nclass_weight=[\"balanced\", \"balanced_subsample\",None]\n\n#Complexity parameter used for Minimal Cost-Complexity Pruning.\nccp_alpha=[0., 0.1, 0.5]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap,\n               'class_weight':class_weight,\n               'ccp_alpha' : ccp_alpha\n\n              }\n\nrsh = HalvingRandomSearchCV(estimator = clf, param_distributions = random_grid, \\\n                              random_state=42, factor = 2)# Fit the random search model\nrsh.fit(xs, y)\n\n\nHalvingRandomSearchCV(estimator=RandomForestClassifier(random_state=42),\n                      factor=2,\n                      param_distributions={'bootstrap': [True, False],\n                                           'ccp_alpha': [0.0, 0.1, 0.5],\n                                           'class_weight': ['balanced',\n                                                            'balanced_subsample',\n                                                            None],\n                                           'max_depth': [10, 30, 70, 200, None],\n                                           'max_features': ['log2', 'sqrt',\n                                                            None],\n                                           'min_samples_leaf': [1, 2, 4, 10],\n                                           'min_samples_split': [1.0, 2, 10,\n                                                                 50],\n                                           'n_estimators': [20, 50, 150, 400,\n                                                            700]},\n                      random_state=42)\n\n\n\nprint(rsh.best_params_)\ndef evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors / test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy\nbest_random = rsh.best_estimator_\n\nmm = best_random.predict(valid_xs)\n\n\n\nprint(best_random.get_params())\n\n\n\nprint(\"\\nThe score for predictions on the 2021 season (not shown to training data) is:\\n\\\n      {:.3f}\\n\\\n\\nThe predictions for the training data is:\\n\\\n      {:.3f}\".format(best_random.score(valid_xs, valid_y),best_random.score(xs, y)) )\n\n{'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 10, 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n\nThe score for predictions on the 2021 season (not shown to training data) is:\n      0.624\n\nThe predictions for the training data is:\n      0.976\n\n\n\nfrom sklearn.metrics import precision_score\n\npred=best_random.predict(xs)\npred_valid=best_random.predict(valid_xs)\n\nprecision_score(pred_valid, np.array(valid_y))\n\n\n# precision_score(test[\"target\"], pred)\n\n0.3496932515337423\n\n\n\ncombined = pd.DataFrame(dict(actual = valid_y, prediction = pred_valid ))\npd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\n\n\n\n\n\n  \n    \n      prediction\n      0\n      1\n    \n    \n      actual\n      \n      \n    \n  \n  \n    \n      0\n      180\n      37\n    \n    \n      1\n      106\n      57\n    \n  \n\n\n\n\n\n[(y[i],df['Win_x'].iloc[i],pred[i]) for i in range(5)]\n\n[(1, 'W', 0), (0, 'L', 0), (1, 'W', 0), (1, 'W', 0), (0, 'L', 0)]\n\n\n\nplt.hist(pred_valid[valid_y==0],width=.1,align='left',linewidth=2,linestyle='-.',\n         facecolor='none',edgecolor='b')#\nplt.hist(pred_valid[valid_y==1]-1,width=.1,align='mid',linewidth=2,linestyle='--',\n         facecolor='none',edgecolor='k')#\n# plt.hist(pred_valid[valid_y==2]-2,width=.1,align='left',linewidth=2,linestyle='--',\n#          facecolor='none',edgecolor='k')#\n\n# Loss=0\n# Win=1\n\nplt.legend(['Loss','Win'])\n\n\n<matplotlib.legend.Legend at 0x1f8c4cd6640>\n\n\n\n\n\n\nprint(\"USING WIN versus DRAW/LOSS\\n\\\n      \\nThe score for predictions on the 2021 season (not shown to training data) is:\\n\\\n      {:.3f}\\n\\\n\\nThe predictions for the training data is:\\n\\\n      {:.3f}\".format(rsh.score(valid_xs, valid_y),rsh.score(xs, y)) )\n\n\nUSING WIN versus DRAW/LOSS\n      \nThe score for predictions on the 2021 season (not shown to training data) is:\n      0.761\n\nThe predictions for the training data is:\n      0.999"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#look-at-what-parameters-matter-in-match-results",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#look-at-what-parameters-matter-in-match-results",
    "title": "ThomasHSimm",
    "section": "Look at what parameters matter in match results",
    "text": "Look at what parameters matter in match results\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\npred=best_random.predict(xs)\npred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(best_random, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n\n\n\ndf.loc[10:,:]\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      10\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      ...\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n      L\n    \n    \n      11\n      22\n      2\n      20\n      2.0\n      2.0\n      0.0\n      Chelsea\n      2.0\n      18.0\n      6.0\n      ...\n      9.0\n      8.0\n      0.0\n      0.0\n      0.0\n      92.0\n      21.0\n      31.0\n      40.4\n      Chelsea\n    \n    \n      12\n      23\n      2\n      19\n      1.0\n      3.0\n      3.0\n      Crystal Palace\n      3.0\n      13.0\n      4.0\n      ...\n      21.0\n      13.0\n      0.0\n      0.0\n      1.0\n      100.0\n      19.0\n      19.0\n      50.0\n      Crystal Palace\n    \n    \n      13\n      26\n      2\n      19\n      2.0\n      3.0\n      2.0\n      West Bromwich Albion\n      3.0\n      10.0\n      5.0\n      ...\n      19.0\n      12.0\n      0.0\n      0.0\n      0.0\n      81.0\n      21.0\n      21.0\n      50.0\n      West Bromwich Albion\n    \n    \n      14\n      28\n      2\n      19\n      0.0\n      3.0\n      4.0\n      Brighton and Hove Albion\n      3.0\n      6.0\n      4.0\n      ...\n      19.0\n      8.0\n      0.0\n      0.0\n      1.0\n      65.0\n      17.0\n      19.0\n      47.2\n      Brighton and Hove Albion\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1895\n      3788\n      38\n      22\n      1.666667\n      2.666667\n      0.333333\n      West Ham United\n      2.666667\n      15.666667\n      6.333333\n      ...\n      12.666667\n      6.666667\n      0.0\n      0.333333\n      0.333333\n      62.333333\n      14.333333\n      15.0\n      49.066667\n      West Ham United\n    \n    \n      1896\n      3791\n      38\n      22\n      1.666667\n      1.333333\n      0.666667\n      Manchester United\n      1.333333\n      14.666667\n      5.0\n      ...\n      19.333333\n      11.333333\n      0.333333\n      0.0\n      0.0\n      68.0\n      17.0\n      13.333333\n      56.733333\n      Manchester United\n    \n    \n      1897\n      3792\n      38\n      22\n      1.333333\n      2.0\n      1.666667\n      Leeds United\n      1.666667\n      16.0\n      5.0\n      ...\n      12.0\n      11.666667\n      0.0\n      0.0\n      0.0\n      80.0\n      12.0\n      16.333333\n      42.933333\n      Leeds United\n    \n    \n      1898\n      3797\n      38\n      22\n      0.666667\n      1.0\n      1.666667\n      Newcastle United\n      1.0\n      13.0\n      4.333333\n      ...\n      14.666667\n      13.0\n      0.0\n      0.0\n      0.0\n      64.333333\n      20.0\n      19.0\n      48.766667\n      Newcastle United\n    \n    \n      1899\n      3799\n      38\n      22\n      0.333333\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.0\n      9.666667\n      0.0\n      0.0\n      0.0\n      81.666667\n      23.666667\n      17.0\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n1890 rows × 344 columns"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#try-as-a-regression-problem",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy1.html#try-as-a-regression-problem",
    "title": "ThomasHSimm",
    "section": "Try as a regression problem",
    "text": "Try as a regression problem\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\ndfAll\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n      NetScore_y\n    \n  \n  \n    \n      0\n      1\n      1\n      13\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      West Ham United\n      -4\n    \n    \n      1\n      4\n      1\n      12\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      1\n    \n    \n      2\n      5\n      1\n      11\n      NaN\n      NaN\n      NaN\n      Leicester City\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Leicester City\n      -1\n    \n    \n      3\n      7\n      1\n      12\n      NaN\n      NaN\n      NaN\n      Stoke City\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Stoke City\n      -1\n    \n    \n      4\n      9\n      1\n      13\n      NaN\n      NaN\n      NaN\n      Tottenham Hotspur\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Tottenham Hotspur\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1895\n      3788\n      38\n      22\n      2.333333\n      2.666667\n      0.333333\n      West Ham United\n      2.666667\n      15.666667\n      6.333333\n      ...\n      6.666667\n      0.000000\n      0.333333\n      0.333333\n      62.333333\n      14.333333\n      15.000000\n      49.066667\n      West Ham United\n      -2\n    \n    \n      1896\n      3791\n      38\n      22\n      0.666667\n      1.333333\n      0.666667\n      Manchester United\n      1.333333\n      14.666667\n      5.000000\n      ...\n      11.333333\n      0.333333\n      0.000000\n      0.000000\n      68.000000\n      17.000000\n      13.333333\n      56.733333\n      Manchester United\n      -1\n    \n    \n      1897\n      3792\n      38\n      22\n      0.333333\n      2.000000\n      1.666667\n      Leeds United\n      1.666667\n      16.000000\n      5.000000\n      ...\n      11.666667\n      0.000000\n      0.000000\n      0.000000\n      80.000000\n      12.000000\n      16.333333\n      42.933333\n      Leeds United\n      1\n    \n    \n      1898\n      3797\n      38\n      22\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n      1\n    \n    \n      1899\n      3799\n      38\n      22\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n      5\n    \n  \n\n1900 rows × 346 columns\n\n\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'NetScore_x':'NetScore'})\ndf=df.drop(columns=['Win_x','NetScore_y'])\n\ndf=df.loc[( ((df['round']>1) & (df['season']==2017)) | (df['season']>2017)  ) ]\n\n#     df=df.loc[:,colsextra]\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n##############\n\ndep_var='NetScore'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\n[x for x in df.columns]\n# df[['NetScore_y','NetScore']]\n\n['round',\n 'day',\n 'result_x',\n 'gf_x',\n 'ga_x',\n 'opponent_x',\n 'gls_x',\n 'sh_shooting_x',\n 'sot_x',\n 'sot%_x',\n 'g/sh_x',\n 'g/sot_x',\n 'dist_x',\n 'fk_shooting_x',\n 'pk_x',\n 'pkatt_shooting_x',\n 'xg_x',\n 'npxg_x',\n 'npxg/sh_x',\n 'g-xg_x',\n 'np:g-xg_x',\n 'sota_x',\n 'saves_x',\n 'save%_x',\n 'cs_x',\n 'psxg_x',\n 'psxg+/-_x',\n 'pkatt_keeper_x',\n 'pka_x',\n 'pksv_x',\n 'pkm_x',\n 'cmp_keeper_x',\n 'att_keeper_x',\n 'cmp%_keeper_x',\n 'att_keeper.1_x',\n 'thr_x',\n 'launch%_x',\n 'avglen_x',\n 'att_keeper.2_x',\n 'launch%.1_x',\n 'avglen.1_x',\n 'opp_x',\n 'stp_x',\n 'stp%_x',\n '#opa_x',\n 'avgdist_x',\n 'cmp_passing_x',\n 'att_passing_x',\n 'cmp%_passing_x',\n 'totdist_passing_x',\n 'prgdist_passing_x',\n 'cmp_passing.1_x',\n 'att_passing.1_x',\n 'cmp%_passing.1_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'cmp%_passing.2_x',\n 'cmp_passing.3_x',\n 'att_passing.3_x',\n 'cmp%_passing.3_x',\n 'ast_x',\n 'xa_x',\n 'kp_x',\n '1/3_passing_x',\n 'ppa_x',\n 'crspa_x',\n 'prog_passing_x',\n 'att_passing_types_x',\n 'live_passing_types_x',\n 'dead_x',\n 'fk_passing_types_x',\n 'tb_x',\n 'press_passing_types_x',\n 'sw_x',\n 'crs_passing_types_x',\n 'ck_x',\n 'in_x',\n 'out_x',\n 'str_x',\n 'ground_x',\n 'low_x',\n 'high_x',\n 'left_x',\n 'right_x',\n 'head_x',\n 'ti_x',\n 'other_x',\n 'cmp_passing_types_x',\n 'off_passing_types_x',\n 'out.1_x',\n 'int_passing_types_x',\n 'blocks_passing_types_x',\n 'sca_x',\n 'passlive_x',\n 'passdead_x',\n 'drib_x',\n 'sh_gca_x',\n 'fld_gca_x',\n 'def_x',\n 'gca_x',\n 'passlive.1_x',\n 'passdead.1_x',\n 'drib.1_x',\n 'sh_gca.1_x',\n 'fld_gca.1_x',\n 'def.1_x',\n 'tkl_x',\n 'tklw_defense_x',\n 'def 3rd_defense_x',\n 'mid 3rd_defense_x',\n 'att 3rd_defense_x',\n 'tkl.1_x',\n 'att_defense_x',\n 'tkl%_x',\n 'past_x',\n 'press_defense_x',\n 'succ_defense_x',\n '%_x',\n 'def 3rd_defense.1_x',\n 'mid 3rd_defense.1_x',\n 'att 3rd_defense.1_x',\n 'blocks_defense_x',\n 'sh_defense_x',\n 'shsv_x',\n 'pass_x',\n 'int_defense_x',\n 'clr_x',\n 'err_x',\n 'poss_x',\n 'touches_x',\n 'def pen_x',\n 'def 3rd_possession_x',\n 'mid 3rd_possession_x',\n 'att 3rd_possession_x',\n 'att pen_x',\n 'live_possession_x',\n 'succ_possession_x',\n 'att_possession_x',\n 'succ%_x',\n '#pl_x',\n 'megs_x',\n 'carries_x',\n 'totdist_possession_x',\n 'prgdist_possession_x',\n 'prog_possession_x',\n '1/3_possession_x',\n 'cpa_x',\n 'mis_x',\n 'dis_x',\n 'targ_x',\n 'rec_x',\n 'rec%_x',\n 'prog_possession.1_x',\n 'crdy_x',\n 'crdr_x',\n '2crdy_x',\n 'fls_x',\n 'fld_misc_x',\n 'off_misc_x',\n 'crs_misc_x',\n 'int_misc_x',\n 'tklw_misc_x',\n 'pkwon_x',\n 'pkcon_x',\n 'og_x',\n 'recov_x',\n 'won_x',\n 'lost_x',\n 'won%_x',\n 'team_x',\n 'season',\n 'month',\n 'year',\n 'weekday',\n 'NetScore',\n 'result_y',\n 'gf_y',\n 'ga_y',\n 'opponent_y',\n 'gls_y',\n 'sh_shooting_y',\n 'sot_y',\n 'sot%_y',\n 'g/sh_y',\n 'g/sot_y',\n 'dist_y',\n 'fk_shooting_y',\n 'pk_y',\n 'pkatt_shooting_y',\n 'xg_y',\n 'npxg_y',\n 'npxg/sh_y',\n 'g-xg_y',\n 'np:g-xg_y',\n 'sota_y',\n 'saves_y',\n 'save%_y',\n 'cs_y',\n 'psxg_y',\n 'psxg+/-_y',\n 'pkatt_keeper_y',\n 'pka_y',\n 'pksv_y',\n 'pkm_y',\n 'cmp_keeper_y',\n 'att_keeper_y',\n 'cmp%_keeper_y',\n 'att_keeper.1_y',\n 'thr_y',\n 'launch%_y',\n 'avglen_y',\n 'att_keeper.2_y',\n 'launch%.1_y',\n 'avglen.1_y',\n 'opp_y',\n 'stp_y',\n 'stp%_y',\n '#opa_y',\n 'avgdist_y',\n 'cmp_passing_y',\n 'att_passing_y',\n 'cmp%_passing_y',\n 'totdist_passing_y',\n 'prgdist_passing_y',\n 'cmp_passing.1_y',\n 'att_passing.1_y',\n 'cmp%_passing.1_y',\n 'cmp_passing.2_y',\n 'att_passing.2_y',\n 'cmp%_passing.2_y',\n 'cmp_passing.3_y',\n 'att_passing.3_y',\n 'cmp%_passing.3_y',\n 'ast_y',\n 'xa_y',\n 'kp_y',\n '1/3_passing_y',\n 'ppa_y',\n 'crspa_y',\n 'prog_passing_y',\n 'att_passing_types_y',\n 'live_passing_types_y',\n 'dead_y',\n 'fk_passing_types_y',\n 'tb_y',\n 'press_passing_types_y',\n 'sw_y',\n 'crs_passing_types_y',\n 'ck_y',\n 'in_y',\n 'out_y',\n 'str_y',\n 'ground_y',\n 'low_y',\n 'high_y',\n 'left_y',\n 'right_y',\n 'head_y',\n 'ti_y',\n 'other_y',\n 'cmp_passing_types_y',\n 'off_passing_types_y',\n 'out.1_y',\n 'int_passing_types_y',\n 'blocks_passing_types_y',\n 'sca_y',\n 'passlive_y',\n 'passdead_y',\n 'drib_y',\n 'sh_gca_y',\n 'fld_gca_y',\n 'def_y',\n 'gca_y',\n 'passlive.1_y',\n 'passdead.1_y',\n 'drib.1_y',\n 'sh_gca.1_y',\n 'fld_gca.1_y',\n 'def.1_y',\n 'tkl_y',\n 'tklw_defense_y',\n 'def 3rd_defense_y',\n 'mid 3rd_defense_y',\n 'att 3rd_defense_y',\n 'tkl.1_y',\n 'att_defense_y',\n 'tkl%_y',\n 'past_y',\n 'press_defense_y',\n 'succ_defense_y',\n '%_y',\n 'def 3rd_defense.1_y',\n 'mid 3rd_defense.1_y',\n 'att 3rd_defense.1_y',\n 'blocks_defense_y',\n 'sh_defense_y',\n 'shsv_y',\n 'pass_y',\n 'int_defense_y',\n 'clr_y',\n 'err_y',\n 'poss_y',\n 'touches_y',\n 'def pen_y',\n 'def 3rd_possession_y',\n 'mid 3rd_possession_y',\n 'att 3rd_possession_y',\n 'att pen_y',\n 'live_possession_y',\n 'succ_possession_y',\n 'att_possession_y',\n 'succ%_y',\n '#pl_y',\n 'megs_y',\n 'carries_y',\n 'totdist_possession_y',\n 'prgdist_possession_y',\n 'prog_possession_y',\n '1/3_possession_y',\n 'cpa_y',\n 'mis_y',\n 'dis_y',\n 'targ_y',\n 'rec_y',\n 'rec%_y',\n 'prog_possession.1_y',\n 'crdy_y',\n 'crdr_y',\n '2crdy_y',\n 'fls_y',\n 'fld_misc_y',\n 'off_misc_y',\n 'crs_misc_y',\n 'int_misc_y',\n 'tklw_misc_y',\n 'pkwon_y',\n 'pkcon_y',\n 'og_y',\n 'recov_y',\n 'won_y',\n 'lost_y',\n 'won%_y',\n 'team_y']\n\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef do_RF(xs,y,valid_xs):\n##############\n    clf=RandomForestRegressor(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n#     ppred_valid=clf.predict_proba(valid_xs)\n#     ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid#,ppred,ppred_valid\n\n   \ndef get_scores2(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.3f} and precision = {:.3f}\".format(nom,acc,prec))\n    \ndef get_reg_scores(yy,preds,XX):\n    yy=copy.copy(yy)\n    preds=copy.copy(preds)\n    \n    \n    yy[yy>0] = 1\n    yy[yy<=0] = 0\n#     yy[yy==0]=0\n#     yy[yy<0]=-1\n    \n    preds[preds>=XX]=1\n    preds[preds<XX]=0\n    \n#     preds[preds<-XX]=-1\n#     preds[( (preds>=-XX) & (preds<XX) )]=0\n    \n\n    get_scores2('Regression RF',preds, yy)\n#     preds_yy=preds-yy\n#     print( len(preds_yy[preds_yy==0])/len(yy) )\n\n    return preds,yy\n\n\n\npred,pred_val=do_RF(xs,y,valid_xs)\n\n\nnew_preds,new_y=get_reg_scores(valid_y,pred_val,.5)\n\nRegression RF: accuracy = 0.626 and precision = 0.368\n\n\n\nto.show()\n\n\n\n  \n    \n      \n      opponent_x\n      team_x\n      opponent_y\n      team_y\n      result_x_na\n      gf_x_na\n      ga_x_na\n      gls_x_na\n      sh_shooting_x_na\n      sot_x_na\n      sot%_x_na\n      g/sh_x_na\n      g/sot_x_na\n      dist_x_na\n      fk_shooting_x_na\n      pk_x_na\n      pkatt_shooting_x_na\n      xg_x_na\n      npxg_x_na\n      npxg/sh_x_na\n      g-xg_x_na\n      np:g-xg_x_na\n      sota_x_na\n      saves_x_na\n      save%_x_na\n      cs_x_na\n      psxg_x_na\n      psxg+/-_x_na\n      pkatt_keeper_x_na\n      pka_x_na\n      pksv_x_na\n      pkm_x_na\n      cmp_keeper_x_na\n      att_keeper_x_na\n      cmp%_keeper_x_na\n      att_keeper.1_x_na\n      thr_x_na\n      launch%_x_na\n      avglen_x_na\n      att_keeper.2_x_na\n      launch%.1_x_na\n      avglen.1_x_na\n      opp_x_na\n      stp_x_na\n      stp%_x_na\n      #opa_x_na\n      avgdist_x_na\n      cmp_passing_x_na\n      att_passing_x_na\n      cmp%_passing_x_na\n      totdist_passing_x_na\n      prgdist_passing_x_na\n      cmp_passing.1_x_na\n      att_passing.1_x_na\n      cmp%_passing.1_x_na\n      cmp_passing.2_x_na\n      att_passing.2_x_na\n      cmp%_passing.2_x_na\n      cmp_passing.3_x_na\n      att_passing.3_x_na\n      cmp%_passing.3_x_na\n      ast_x_na\n      xa_x_na\n      kp_x_na\n      1/3_passing_x_na\n      ppa_x_na\n      crspa_x_na\n      prog_passing_x_na\n      att_passing_types_x_na\n      live_passing_types_x_na\n      dead_x_na\n      fk_passing_types_x_na\n      tb_x_na\n      press_passing_types_x_na\n      sw_x_na\n      crs_passing_types_x_na\n      ck_x_na\n      in_x_na\n      out_x_na\n      str_x_na\n      ground_x_na\n      low_x_na\n      high_x_na\n      left_x_na\n      right_x_na\n      head_x_na\n      ti_x_na\n      other_x_na\n      cmp_passing_types_x_na\n      off_passing_types_x_na\n      out.1_x_na\n      int_passing_types_x_na\n      blocks_passing_types_x_na\n      sca_x_na\n      passlive_x_na\n      passdead_x_na\n      drib_x_na\n      sh_gca_x_na\n      fld_gca_x_na\n      def_x_na\n      gca_x_na\n      passlive.1_x_na\n      passdead.1_x_na\n      drib.1_x_na\n      sh_gca.1_x_na\n      fld_gca.1_x_na\n      def.1_x_na\n      tkl_x_na\n      tklw_defense_x_na\n      def 3rd_defense_x_na\n      mid 3rd_defense_x_na\n      att 3rd_defense_x_na\n      tkl.1_x_na\n      att_defense_x_na\n      tkl%_x_na\n      past_x_na\n      press_defense_x_na\n      succ_defense_x_na\n      %_x_na\n      def 3rd_defense.1_x_na\n      mid 3rd_defense.1_x_na\n      att 3rd_defense.1_x_na\n      blocks_defense_x_na\n      sh_defense_x_na\n      shsv_x_na\n      pass_x_na\n      int_defense_x_na\n      clr_x_na\n      err_x_na\n      poss_x_na\n      touches_x_na\n      def pen_x_na\n      def 3rd_possession_x_na\n      mid 3rd_possession_x_na\n      att 3rd_possession_x_na\n      att pen_x_na\n      live_possession_x_na\n      succ_possession_x_na\n      att_possession_x_na\n      succ%_x_na\n      #pl_x_na\n      megs_x_na\n      carries_x_na\n      totdist_possession_x_na\n      prgdist_possession_x_na\n      prog_possession_x_na\n      1/3_possession_x_na\n      cpa_x_na\n      mis_x_na\n      dis_x_na\n      targ_x_na\n      rec_x_na\n      rec%_x_na\n      prog_possession.1_x_na\n      crdy_x_na\n      crdr_x_na\n      2crdy_x_na\n      fls_x_na\n      fld_misc_x_na\n      off_misc_x_na\n      crs_misc_x_na\n      int_misc_x_na\n      tklw_misc_x_na\n      pkwon_x_na\n      pkcon_x_na\n      og_x_na\n      recov_x_na\n      won_x_na\n      lost_x_na\n      won%_x_na\n      result_y_na\n      gf_y_na\n      ga_y_na\n      gls_y_na\n      sh_shooting_y_na\n      sot_y_na\n      sot%_y_na\n      g/sh_y_na\n      g/sot_y_na\n      dist_y_na\n      fk_shooting_y_na\n      pk_y_na\n      pkatt_shooting_y_na\n      xg_y_na\n      npxg_y_na\n      npxg/sh_y_na\n      g-xg_y_na\n      np:g-xg_y_na\n      sota_y_na\n      saves_y_na\n      save%_y_na\n      cs_y_na\n      psxg_y_na\n      psxg+/-_y_na\n      pkatt_keeper_y_na\n      pka_y_na\n      pksv_y_na\n      pkm_y_na\n      cmp_keeper_y_na\n      att_keeper_y_na\n      cmp%_keeper_y_na\n      att_keeper.1_y_na\n      thr_y_na\n      launch%_y_na\n      avglen_y_na\n      att_keeper.2_y_na\n      launch%.1_y_na\n      avglen.1_y_na\n      opp_y_na\n      stp_y_na\n      stp%_y_na\n      #opa_y_na\n      avgdist_y_na\n      cmp_passing_y_na\n      att_passing_y_na\n      cmp%_passing_y_na\n      totdist_passing_y_na\n      prgdist_passing_y_na\n      cmp_passing.1_y_na\n      att_passing.1_y_na\n      cmp%_passing.1_y_na\n      cmp_passing.2_y_na\n      att_passing.2_y_na\n      cmp%_passing.2_y_na\n      cmp_passing.3_y_na\n      att_passing.3_y_na\n      cmp%_passing.3_y_na\n      ast_y_na\n      xa_y_na\n      kp_y_na\n      1/3_passing_y_na\n      ppa_y_na\n      crspa_y_na\n      prog_passing_y_na\n      att_passing_types_y_na\n      live_passing_types_y_na\n      dead_y_na\n      fk_passing_types_y_na\n      tb_y_na\n      press_passing_types_y_na\n      sw_y_na\n      crs_passing_types_y_na\n      ck_y_na\n      in_y_na\n      out_y_na\n      str_y_na\n      ground_y_na\n      low_y_na\n      high_y_na\n      left_y_na\n      right_y_na\n      head_y_na\n      ti_y_na\n      other_y_na\n      cmp_passing_types_y_na\n      off_passing_types_y_na\n      out.1_y_na\n      int_passing_types_y_na\n      blocks_passing_types_y_na\n      sca_y_na\n      passlive_y_na\n      passdead_y_na\n      drib_y_na\n      sh_gca_y_na\n      fld_gca_y_na\n      def_y_na\n      gca_y_na\n      passlive.1_y_na\n      passdead.1_y_na\n      drib.1_y_na\n      sh_gca.1_y_na\n      fld_gca.1_y_na\n      def.1_y_na\n      tkl_y_na\n      tklw_defense_y_na\n      def 3rd_defense_y_na\n      mid 3rd_defense_y_na\n      att 3rd_defense_y_na\n      tkl.1_y_na\n      att_defense_y_na\n      tkl%_y_na\n      past_y_na\n      press_defense_y_na\n      succ_defense_y_na\n      %_y_na\n      def 3rd_defense.1_y_na\n      mid 3rd_defense.1_y_na\n      att 3rd_defense.1_y_na\n      blocks_defense_y_na\n      sh_defense_y_na\n      shsv_y_na\n      pass_y_na\n      int_defense_y_na\n      clr_y_na\n      err_y_na\n      poss_y_na\n      touches_y_na\n      def pen_y_na\n      def 3rd_possession_y_na\n      mid 3rd_possession_y_na\n      att 3rd_possession_y_na\n      att pen_y_na\n      live_possession_y_na\n      succ_possession_y_na\n      att_possession_y_na\n      succ%_y_na\n      #pl_y_na\n      megs_y_na\n      carries_y_na\n      totdist_possession_y_na\n      prgdist_possession_y_na\n      prog_possession_y_na\n      1/3_possession_y_na\n      cpa_y_na\n      mis_y_na\n      dis_y_na\n      targ_y_na\n      rec_y_na\n      rec%_y_na\n      prog_possession.1_y_na\n      crdy_y_na\n      crdr_y_na\n      2crdy_y_na\n      fls_y_na\n      fld_misc_y_na\n      off_misc_y_na\n      crs_misc_y_na\n      int_misc_y_na\n      tklw_misc_y_na\n      pkwon_y_na\n      pkcon_y_na\n      og_y_na\n      recov_y_na\n      won_y_na\n      lost_y_na\n      won%_y_na\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      sot%_x\n      g/sh_x\n      g/sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      xg_x\n      npxg_x\n      npxg/sh_x\n      g-xg_x\n      np:g-xg_x\n      sota_x\n      saves_x\n      save%_x\n      cs_x\n      psxg_x\n      psxg+/-_x\n      pkatt_keeper_x\n      pka_x\n      pksv_x\n      pkm_x\n      cmp_keeper_x\n      att_keeper_x\n      cmp%_keeper_x\n      att_keeper.1_x\n      thr_x\n      launch%_x\n      avglen_x\n      att_keeper.2_x\n      launch%.1_x\n      avglen.1_x\n      opp_x\n      stp_x\n      stp%_x\n      #opa_x\n      avgdist_x\n      cmp_passing_x\n      att_passing_x\n      cmp%_passing_x\n      totdist_passing_x\n      prgdist_passing_x\n      cmp_passing.1_x\n      att_passing.1_x\n      cmp%_passing.1_x\n      cmp_passing.2_x\n      att_passing.2_x\n      cmp%_passing.2_x\n      cmp_passing.3_x\n      att_passing.3_x\n      cmp%_passing.3_x\n      ast_x\n      xa_x\n      kp_x\n      1/3_passing_x\n      ppa_x\n      crspa_x\n      prog_passing_x\n      att_passing_types_x\n      live_passing_types_x\n      dead_x\n      fk_passing_types_x\n      tb_x\n      press_passing_types_x\n      sw_x\n      crs_passing_types_x\n      ck_x\n      in_x\n      out_x\n      str_x\n      ground_x\n      low_x\n      high_x\n      left_x\n      right_x\n      head_x\n      ti_x\n      other_x\n      cmp_passing_types_x\n      off_passing_types_x\n      out.1_x\n      int_passing_types_x\n      blocks_passing_types_x\n      sca_x\n      passlive_x\n      passdead_x\n      drib_x\n      sh_gca_x\n      fld_gca_x\n      def_x\n      gca_x\n      passlive.1_x\n      passdead.1_x\n      drib.1_x\n      sh_gca.1_x\n      fld_gca.1_x\n      def.1_x\n      tkl_x\n      tklw_defense_x\n      def 3rd_defense_x\n      mid 3rd_defense_x\n      att 3rd_defense_x\n      tkl.1_x\n      att_defense_x\n      tkl%_x\n      past_x\n      press_defense_x\n      succ_defense_x\n      %_x\n      def 3rd_defense.1_x\n      mid 3rd_defense.1_x\n      att 3rd_defense.1_x\n      blocks_defense_x\n      sh_defense_x\n      shsv_x\n      pass_x\n      int_defense_x\n      clr_x\n      err_x\n      poss_x\n      touches_x\n      def pen_x\n      def 3rd_possession_x\n      mid 3rd_possession_x\n      att 3rd_possession_x\n      att pen_x\n      live_possession_x\n      succ_possession_x\n      att_possession_x\n      succ%_x\n      #pl_x\n      megs_x\n      carries_x\n      totdist_possession_x\n      prgdist_possession_x\n      prog_possession_x\n      1/3_possession_x\n      cpa_x\n      mis_x\n      dis_x\n      targ_x\n      rec_x\n      rec%_x\n      prog_possession.1_x\n      crdy_x\n      crdr_x\n      2crdy_x\n      fls_x\n      fld_misc_x\n      off_misc_x\n      crs_misc_x\n      int_misc_x\n      tklw_misc_x\n      pkwon_x\n      pkcon_x\n      og_x\n      recov_x\n      won_x\n      lost_x\n      won%_x\n      season\n      month\n      year\n      weekday\n      result_y\n      gf_y\n      ga_y\n      gls_y\n      sh_shooting_y\n      sot_y\n      sot%_y\n      g/sh_y\n      g/sot_y\n      dist_y\n      fk_shooting_y\n      pk_y\n      pkatt_shooting_y\n      xg_y\n      npxg_y\n      npxg/sh_y\n      g-xg_y\n      np:g-xg_y\n      sota_y\n      saves_y\n      save%_y\n      cs_y\n      psxg_y\n      psxg+/-_y\n      pkatt_keeper_y\n      pka_y\n      pksv_y\n      pkm_y\n      cmp_keeper_y\n      att_keeper_y\n      cmp%_keeper_y\n      att_keeper.1_y\n      thr_y\n      launch%_y\n      avglen_y\n      att_keeper.2_y\n      launch%.1_y\n      avglen.1_y\n      opp_y\n      stp_y\n      stp%_y\n      #opa_y\n      avgdist_y\n      cmp_passing_y\n      att_passing_y\n      cmp%_passing_y\n      totdist_passing_y\n      prgdist_passing_y\n      cmp_passing.1_y\n      att_passing.1_y\n      cmp%_passing.1_y\n      cmp_passing.2_y\n      att_passing.2_y\n      cmp%_passing.2_y\n      cmp_passing.3_y\n      att_passing.3_y\n      cmp%_passing.3_y\n      ast_y\n      xa_y\n      kp_y\n      1/3_passing_y\n      ppa_y\n      crspa_y\n      prog_passing_y\n      att_passing_types_y\n      live_passing_types_y\n      dead_y\n      fk_passing_types_y\n      tb_y\n      press_passing_types_y\n      sw_y\n      crs_passing_types_y\n      ck_y\n      in_y\n      out_y\n      str_y\n      ground_y\n      low_y\n      high_y\n      left_y\n      right_y\n      head_y\n      ti_y\n      other_y\n      cmp_passing_types_y\n      off_passing_types_y\n      out.1_y\n      int_passing_types_y\n      blocks_passing_types_y\n      sca_y\n      passlive_y\n      passdead_y\n      drib_y\n      sh_gca_y\n      fld_gca_y\n      def_y\n      gca_y\n      passlive.1_y\n      passdead.1_y\n      drib.1_y\n      sh_gca.1_y\n      fld_gca.1_y\n      def.1_y\n      tkl_y\n      tklw_defense_y\n      def 3rd_defense_y\n      mid 3rd_defense_y\n      att 3rd_defense_y\n      tkl.1_y\n      att_defense_y\n      tkl%_y\n      past_y\n      press_defense_y\n      succ_defense_y\n      %_y\n      def 3rd_defense.1_y\n      mid 3rd_defense.1_y\n      att 3rd_defense.1_y\n      blocks_defense_y\n      sh_defense_y\n      shsv_y\n      pass_y\n      int_defense_y\n      clr_y\n      err_y\n      poss_y\n      touches_y\n      def pen_y\n      def 3rd_possession_y\n      mid 3rd_possession_y\n      att 3rd_possession_y\n      att pen_y\n      live_possession_y\n      succ_possession_y\n      att_possession_y\n      succ%_y\n      #pl_y\n      megs_y\n      carries_y\n      totdist_possession_y\n      prgdist_possession_y\n      prog_possession_y\n      1/3_possession_y\n      cpa_y\n      mis_y\n      dis_y\n      targ_y\n      rec_y\n      rec%_y\n      prog_possession.1_y\n      crdy_y\n      crdr_y\n      2crdy_y\n      fls_y\n      fld_misc_y\n      off_misc_y\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      NetScore\n    \n  \n  \n    \n      10\n      Everton\n      Manchester City\n      Manchester City\n      Everton\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      21\n      2.0\n      2.0\n      0.0\n      1.0\n      14.0\n      4.0\n      28.600000\n      0.07\n      0.250000\n      19.400000\n      2.0\n      0.0\n      0.0\n      1.8\n      1.8\n      0.14\n      -0.8\n      -0.8\n      2.0\n      2.0\n      100.000000\n      1.0\n      0.4\n      0.4\n      0.0\n      0.0\n      0.0\n      0.0\n      2.0\n      5.0\n      40.000000\n      20.0\n      7.0\n      10.000000\n      22.500000\n      4.0\n      75.000000\n      56.799999\n      3.0\n      0.0\n      0.0\n      1.0\n      24.200001\n      712.0\n      808.0\n      88.099998\n      13422.0\n      3465.0\n      297.0\n      320.0\n      92.800003\n      315.0\n      346.0\n      91.000000\n      89.0\n      117.0\n      76.099998\n      1.0\n      1.1\n      9.0\n      69.0\n      15.0\n      1.0\n      60.0\n      808.0\n      766.0\n      42.0\n      10.0\n      2.0\n      63.0\n      28.0\n      16.0\n      10.0\n      1.0\n      5.0\n      0.0\n      612.0\n      105.0\n      91.0\n      182.0\n      570.0\n      20.0\n      17.0\n      10.0\n      712.0\n      1.0\n      8.0\n      19.0\n      17.0\n      22.0\n      17.0\n      1.0\n      0.0\n      1.0\n      2.0\n      1.0\n      2.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      4.0\n      5.0\n      6.0\n      0.0\n      4.0\n      14.0\n      28.600000\n      10.0\n      104.0\n      28.0\n      26.900000\n      25.0\n      42.0\n      37.0\n      7.0\n      2.0\n      0.0\n      5.0\n      13.0\n      15.0\n      0.0\n      77.0\n      902.0\n      30.0\n      146.0\n      484.0\n      329.0\n      31.0\n      858.0\n      8.0\n      15.0\n      53.299999\n      9.0\n      1.0\n      646.0\n      3346.0\n      1924.0\n      91.0\n      27.0\n      3.0\n      15.0\n      4.0\n      794.0\n      712.0\n      89.699997\n      60.0\n      2.0\n      0.0\n      0.0\n      9.0\n      8.0\n      1.0\n      16.0\n      13.0\n      4.0\n      0.0\n      0.0\n      0.0\n      85.0\n      19.0\n      17.0\n      52.799999\n      2017\n      8\n      2017\n      0\n      1.0\n      1.0\n      0.0\n      1.0\n      9.0\n      4.0\n      44.400002\n      0.11\n      0.25\n      18.200001\n      0.0\n      0.0\n      0.0\n      0.5\n      0.5\n      0.05\n      0.5\n      0.5\n      1.0\n      1.0\n      100.000000\n      1.0\n      0.1\n      0.1\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      23.0\n      39.099998\n      22.0\n      4.0\n      68.199997\n      51.500000\n      10.0\n      80.000000\n      65.699997\n      8.0\n      1.0\n      12.500000\n      1.0\n      15.000000\n      429.0\n      550.0\n      78.000000\n      8656.0\n      2742.0\n      157.0\n      185.0\n      84.900002\n      191.0\n      222.0\n      86.000000\n      68.0\n      117.0\n      58.099998\n      1.0\n      0.3\n      6.0\n      28.0\n      8.0\n      4.0\n      24.0\n      550.0\n      494.0\n      56.0\n      15.0\n      0.0\n      67.0\n      17.0\n      12.0\n      6.0\n      3.0\n      2.0\n      0.0\n      378.0\n      68.0\n      104.0\n      106.0\n      377.0\n      25.0\n      24.0\n      4.0\n      429.0\n      2.0\n      13.0\n      24.0\n      15.0\n      14.0\n      11.0\n      1.0\n      1.0\n      0.0\n      0.0\n      1.0\n      2.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      19.0\n      9.0\n      9.0\n      4.0\n      6.0\n      2.0\n      13.0\n      15.400000\n      11.0\n      165.0\n      48.0\n      29.100000\n      70.0\n      65.0\n      30.0\n      12.0\n      3.0\n      0.0\n      9.0\n      16.0\n      28.0\n      0.0\n      60.0\n      686.0\n      78.0\n      239.0\n      331.0\n      155.0\n      22.0\n      632.0\n      4.0\n      12.0\n      33.299999\n      4.0\n      2.0\n      430.0\n      2051.0\n      1008.0\n      30.0\n      8.0\n      5.0\n      15.0\n      14.0\n      516.0\n      429.0\n      83.099998\n      24.0\n      1.0\n      0.0\n      0.0\n      15.0\n      10.0\n      3.0\n      12.0\n      16.0\n      9.0\n      0.0\n      0.0\n      0.0\n      101.0\n      25.0\n      26.0\n      49.000000\n      0\n    \n    \n      11\n      Chelsea\n      Tottenham Hotspur\n      Tottenham Hotspur\n      Chelsea\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      20\n      2.0\n      2.0\n      0.0\n      2.0\n      18.0\n      6.0\n      33.299999\n      0.11\n      0.330000\n      18.400000\n      0.0\n      0.0\n      0.0\n      1.9\n      1.9\n      0.10\n      0.1\n      0.1\n      3.0\n      3.0\n      100.000000\n      1.0\n      0.8\n      0.8\n      0.0\n      0.0\n      0.0\n      0.0\n      2.0\n      6.0\n      33.299999\n      28.0\n      10.0\n      14.300000\n      29.400000\n      5.0\n      40.000000\n      30.799999\n      8.0\n      2.0\n      25.0\n      2.0\n      19.100000\n      665.0\n      757.0\n      87.800003\n      12334.0\n      3240.0\n      266.0\n      285.0\n      93.300003\n      307.0\n      330.0\n      93.000000\n      81.0\n      116.0\n      69.800003\n      2.0\n      1.4\n      12.0\n      51.0\n      10.0\n      1.0\n      44.0\n      757.0\n      710.0\n      47.0\n      8.0\n      1.0\n      105.0\n      10.0\n      14.0\n      7.0\n      1.0\n      1.0\n      1.0\n      546.0\n      123.0\n      88.0\n      295.0\n      396.0\n      12.0\n      26.0\n      13.0\n      665.0\n      1.0\n      12.0\n      6.0\n      13.0\n      26.0\n      18.0\n      3.0\n      1.0\n      1.0\n      2.0\n      1.0\n      4.0\n      4.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      12.0\n      6.0\n      7.0\n      4.0\n      1.0\n      3.0\n      14.0\n      21.400000\n      11.0\n      131.0\n      50.0\n      38.200001\n      52.0\n      43.0\n      36.0\n      10.0\n      0.0\n      0.0\n      10.0\n      17.0\n      17.0\n      0.0\n      72.0\n      870.0\n      57.0\n      227.0\n      420.0\n      280.0\n      27.0\n      823.0\n      11.0\n      19.0\n      57.900002\n      13.0\n      0.0\n      598.0\n      2996.0\n      1679.0\n      72.0\n      21.0\n      3.0\n      17.0\n      8.0\n      747.0\n      665.0\n      89.000000\n      44.0\n      2.0\n      0.0\n      0.0\n      12.0\n      9.0\n      1.0\n      14.0\n      17.0\n      6.0\n      0.0\n      0.0\n      0.0\n      75.0\n      21.0\n      19.0\n      52.500000\n      2017\n      8\n      2017\n      6\n      -1.0\n      2.0\n      3.0\n      2.0\n      19.0\n      6.0\n      31.600000\n      0.11\n      0.33\n      21.600000\n      1.0\n      0.0\n      0.0\n      1.3\n      1.3\n      0.07\n      0.7\n      0.7\n      5.0\n      2.0\n      40.000000\n      0.0\n      1.2\n      -1.8\n      0.0\n      0.0\n      0.0\n      0.0\n      4.0\n      17.0\n      23.500000\n      34.0\n      6.0\n      41.200001\n      39.799999\n      4.0\n      75.000000\n      62.500000\n      6.0\n      0.0\n      0.000000\n      3.0\n      27.799999\n      466.0\n      569.0\n      81.900002\n      9046.0\n      2581.0\n      199.0\n      220.0\n      90.500000\n      185.0\n      211.0\n      87.699997\n      74.0\n      117.0\n      63.200001\n      2.0\n      1.1\n      14.0\n      34.0\n      6.0\n      1.0\n      36.0\n      569.0\n      529.0\n      40.0\n      11.0\n      1.0\n      43.0\n      14.0\n      14.0\n      8.0\n      3.0\n      4.0\n      0.0\n      407.0\n      62.0\n      100.0\n      105.0\n      411.0\n      20.0\n      13.0\n      7.0\n      466.0\n      2.0\n      6.0\n      12.0\n      11.0\n      28.0\n      22.0\n      2.0\n      2.0\n      0.0\n      2.0\n      0.0\n      4.0\n      4.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      13.0\n      8.0\n      6.0\n      5.0\n      2.0\n      4.0\n      9.0\n      44.400002\n      5.0\n      97.0\n      40.0\n      41.200001\n      28.0\n      44.0\n      25.0\n      8.0\n      2.0\n      0.0\n      6.0\n      9.0\n      20.0\n      0.0\n      63.0\n      668.0\n      55.0\n      211.0\n      303.0\n      207.0\n      24.0\n      628.0\n      10.0\n      13.0\n      76.900002\n      10.0\n      1.0\n      431.0\n      2658.0\n      1577.0\n      82.0\n      20.0\n      4.0\n      20.0\n      5.0\n      536.0\n      466.0\n      86.900002\n      36.0\n      4.0\n      2.0\n      1.0\n      15.0\n      13.0\n      3.0\n      14.0\n      9.0\n      8.0\n      0.0\n      0.0\n      0.0\n      92.0\n      21.0\n      31.0\n      40.400002\n      -1\n    \n    \n      12\n      Crystal Palace\n      Liverpool\n      Liverpool\n      Crystal Palace\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      0.0\n      3.0\n      3.0\n      3.0\n      13.0\n      4.0\n      30.799999\n      0.15\n      0.500000\n      13.500000\n      0.0\n      1.0\n      1.0\n      3.1\n      2.4\n      0.20\n      -0.1\n      -0.4\n      5.0\n      1.0\n      40.000000\n      0.0\n      2.8\n      -0.2\n      0.0\n      0.0\n      0.0\n      0.0\n      3.0\n      15.0\n      20.000000\n      34.0\n      8.0\n      32.400002\n      34.299999\n      7.0\n      57.099998\n      44.900002\n      11.0\n      1.0\n      9.1\n      0.0\n      15.000000\n      388.0\n      515.0\n      75.300003\n      8070.0\n      2952.0\n      129.0\n      146.0\n      88.400002\n      183.0\n      218.0\n      83.900002\n      67.0\n      121.0\n      55.400002\n      2.0\n      1.0\n      8.0\n      26.0\n      12.0\n      1.0\n      32.0\n      515.0\n      458.0\n      57.0\n      16.0\n      3.0\n      90.0\n      15.0\n      9.0\n      3.0\n      1.0\n      1.0\n      1.0\n      291.0\n      78.0\n      146.0\n      123.0\n      305.0\n      32.0\n      27.0\n      9.0\n      388.0\n      1.0\n      9.0\n      20.0\n      12.0\n      19.0\n      13.0\n      3.0\n      0.0\n      2.0\n      1.0\n      0.0\n      5.0\n      3.0\n      0.0\n      0.0\n      1.0\n      1.0\n      0.0\n      17.0\n      11.0\n      14.0\n      3.0\n      0.0\n      4.0\n      13.0\n      30.799999\n      9.0\n      158.0\n      62.0\n      39.200001\n      48.0\n      83.0\n      27.0\n      13.0\n      1.0\n      0.0\n      12.0\n      23.0\n      29.0\n      0.0\n      54.0\n      658.0\n      66.0\n      244.0\n      323.0\n      136.0\n      27.0\n      603.0\n      9.0\n      13.0\n      69.199997\n      10.0\n      0.0\n      349.0\n      1809.0\n      1049.0\n      35.0\n      10.0\n      4.0\n      23.0\n      13.0\n      505.0\n      388.0\n      76.800003\n      32.0\n      3.0\n      0.0\n      0.0\n      10.0\n      15.0\n      1.0\n      9.0\n      23.0\n      11.0\n      1.0\n      0.0\n      0.0\n      105.0\n      35.0\n      21.0\n      62.500000\n      2017\n      8\n      2017\n      5\n      -3.0\n      0.0\n      3.0\n      0.0\n      14.0\n      4.0\n      28.600000\n      0.00\n      0.00\n      16.700001\n      3.0\n      0.0\n      0.0\n      1.1\n      1.1\n      0.08\n      -1.1\n      -1.1\n      6.0\n      4.0\n      50.000000\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      6.0\n      15.0\n      40.000000\n      29.0\n      7.0\n      44.799999\n      40.099998\n      3.0\n      66.699997\n      56.700001\n      4.0\n      0.0\n      0.000000\n      0.0\n      15.700000\n      335.0\n      446.0\n      75.099998\n      7410.0\n      2978.0\n      102.0\n      117.0\n      87.199997\n      161.0\n      196.0\n      82.099998\n      66.0\n      112.0\n      58.900002\n      0.0\n      0.5\n      7.0\n      35.0\n      8.0\n      2.0\n      34.0\n      446.0\n      390.0\n      56.0\n      18.0\n      1.0\n      82.0\n      19.0\n      13.0\n      12.0\n      3.0\n      8.0\n      1.0\n      287.0\n      59.0\n      100.0\n      162.0\n      221.0\n      19.0\n      19.0\n      10.0\n      335.0\n      0.0\n      12.0\n      12.0\n      13.0\n      17.0\n      4.0\n      5.0\n      3.0\n      0.0\n      3.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      25.0\n      13.0\n      17.0\n      7.0\n      1.0\n      6.0\n      10.0\n      60.000000\n      4.0\n      122.0\n      49.0\n      40.200001\n      47.0\n      53.0\n      22.0\n      15.0\n      0.0\n      0.0\n      15.0\n      21.0\n      19.0\n      1.0\n      56.0\n      589.0\n      56.0\n      206.0\n      273.0\n      150.0\n      25.0\n      533.0\n      16.0\n      24.0\n      66.699997\n      18.0\n      0.0\n      366.0\n      1825.0\n      966.0\n      33.0\n      17.0\n      7.0\n      18.0\n      20.0\n      435.0\n      335.0\n      77.000000\n      34.0\n      1.0\n      0.0\n      0.0\n      7.0\n      20.0\n      0.0\n      13.0\n      21.0\n      13.0\n      0.0\n      0.0\n      1.0\n      100.0\n      19.0\n      19.0\n      50.000000\n      1\n    \n    \n      13\n      West Bromwich Albion\n      Burnley\n      Burnley\n      West Bromwich Albion\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      1.0\n      3.0\n      2.0\n      3.0\n      10.0\n      5.0\n      50.000000\n      0.30\n      0.600000\n      12.600000\n      1.0\n      0.0\n      0.0\n      0.8\n      0.8\n      0.08\n      2.2\n      2.2\n      6.0\n      4.0\n      66.699997\n      0.0\n      1.8\n      -0.2\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      31.0\n      35.500000\n      30.0\n      4.0\n      73.300003\n      57.299999\n      10.0\n      90.000000\n      69.000000\n      11.0\n      1.0\n      9.1\n      0.0\n      6.800000\n      251.0\n      331.0\n      75.800003\n      6011.0\n      2283.0\n      72.0\n      88.0\n      81.800003\n      118.0\n      135.0\n      87.400002\n      60.0\n      102.0\n      58.799999\n      3.0\n      0.5\n      8.0\n      16.0\n      8.0\n      3.0\n      27.0\n      331.0\n      289.0\n      42.0\n      17.0\n      0.0\n      44.0\n      12.0\n      7.0\n      5.0\n      2.0\n      2.0\n      0.0\n      201.0\n      34.0\n      96.0\n      107.0\n      187.0\n      15.0\n      7.0\n      6.0\n      251.0\n      1.0\n      6.0\n      9.0\n      6.0\n      15.0\n      6.0\n      5.0\n      1.0\n      1.0\n      2.0\n      0.0\n      6.0\n      4.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      8.0\n      4.0\n      6.0\n      2.0\n      0.0\n      3.0\n      13.0\n      23.100000\n      10.0\n      124.0\n      20.0\n      16.100000\n      59.0\n      44.0\n      21.0\n      18.0\n      7.0\n      0.0\n      11.0\n      13.0\n      55.0\n      0.0\n      37.0\n      469.0\n      74.0\n      169.0\n      232.0\n      83.0\n      14.0\n      428.0\n      4.0\n      9.0\n      44.400002\n      5.0\n      1.0\n      259.0\n      1018.0\n      487.0\n      16.0\n      8.0\n      0.0\n      10.0\n      9.0\n      322.0\n      251.0\n      78.000000\n      27.0\n      3.0\n      0.0\n      0.0\n      13.0\n      16.0\n      1.0\n      7.0\n      13.0\n      4.0\n      0.0\n      0.0\n      0.0\n      68.0\n      31.0\n      21.0\n      59.599998\n      2017\n      8\n      2017\n      5\n      1.0\n      1.0\n      0.0\n      1.0\n      17.0\n      6.0\n      35.299999\n      0.06\n      0.17\n      16.000000\n      0.0\n      0.0\n      0.0\n      1.2\n      1.2\n      0.07\n      -0.2\n      -0.2\n      2.0\n      2.0\n      100.000000\n      1.0\n      0.2\n      0.2\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      20.0\n      25.000000\n      13.0\n      1.0\n      92.300003\n      57.700001\n      8.0\n      100.000000\n      76.400002\n      15.0\n      0.0\n      0.000000\n      0.0\n      13.500000\n      178.0\n      291.0\n      61.200001\n      4057.0\n      1826.0\n      62.0\n      68.0\n      91.199997\n      71.0\n      102.0\n      69.599998\n      39.0\n      102.0\n      38.200001\n      1.0\n      1.0\n      14.0\n      19.0\n      5.0\n      1.0\n      14.0\n      291.0\n      241.0\n      50.0\n      3.0\n      0.0\n      54.0\n      11.0\n      8.0\n      8.0\n      6.0\n      1.0\n      0.0\n      114.0\n      54.0\n      123.0\n      78.0\n      145.0\n      18.0\n      30.0\n      3.0\n      178.0\n      2.0\n      6.0\n      4.0\n      15.0\n      23.0\n      16.0\n      4.0\n      0.0\n      2.0\n      1.0\n      0.0\n      2.0\n      0.0\n      1.0\n      0.0\n      0.0\n      1.0\n      0.0\n      16.0\n      12.0\n      9.0\n      6.0\n      1.0\n      7.0\n      15.0\n      46.700001\n      8.0\n      154.0\n      41.0\n      26.600000\n      67.0\n      60.0\n      27.0\n      16.0\n      5.0\n      0.0\n      11.0\n      19.0\n      29.0\n      0.0\n      31.0\n      405.0\n      66.0\n      152.0\n      158.0\n      123.0\n      19.0\n      356.0\n      4.0\n      10.0\n      40.000000\n      4.0\n      1.0\n      194.0\n      1161.0\n      580.0\n      17.0\n      10.0\n      1.0\n      9.0\n      10.0\n      264.0\n      178.0\n      67.400002\n      14.0\n      3.0\n      0.0\n      0.0\n      19.0\n      4.0\n      2.0\n      8.0\n      19.0\n      12.0\n      0.0\n      0.0\n      0.0\n      81.0\n      21.0\n      21.0\n      50.000000\n      -1\n    \n    \n      14\n      Brighton and Hove Albion\n      Leicester City\n      Leicester City\n      Brighton and Hove Albion\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      -1.0\n      3.0\n      4.0\n      3.0\n      6.0\n      4.0\n      66.699997\n      0.50\n      0.750000\n      10.300000\n      0.0\n      0.0\n      0.0\n      1.3\n      1.3\n      0.22\n      1.7\n      1.7\n      10.0\n      6.0\n      60.000000\n      0.0\n      3.0\n      -1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      15.0\n      37.0\n      40.500000\n      26.0\n      0.0\n      96.199997\n      65.300003\n      12.0\n      100.000000\n      73.099998\n      10.0\n      0.0\n      0.0\n      1.0\n      27.700001\n      181.0\n      299.0\n      60.500000\n      4126.0\n      2019.0\n      77.0\n      94.0\n      81.900002\n      56.0\n      79.0\n      70.900002\n      41.0\n      104.0\n      39.400002\n      3.0\n      1.2\n      4.0\n      19.0\n      3.0\n      3.0\n      12.0\n      299.0\n      232.0\n      67.0\n      15.0\n      0.0\n      49.0\n      23.0\n      19.0\n      4.0\n      2.0\n      0.0\n      0.0\n      110.0\n      53.0\n      136.0\n      73.0\n      149.0\n      27.0\n      31.0\n      3.0\n      181.0\n      3.0\n      9.0\n      20.0\n      10.0\n      7.0\n      4.0\n      1.0\n      0.0\n      1.0\n      0.0\n      1.0\n      6.0\n      3.0\n      1.0\n      0.0\n      1.0\n      0.0\n      1.0\n      18.0\n      8.0\n      5.0\n      8.0\n      5.0\n      4.0\n      17.0\n      23.500000\n      13.0\n      139.0\n      31.0\n      22.299999\n      49.0\n      52.0\n      38.0\n      20.0\n      11.0\n      0.0\n      9.0\n      19.0\n      34.0\n      0.0\n      31.0\n      435.0\n      73.0\n      163.0\n      169.0\n      116.0\n      13.0\n      370.0\n      4.0\n      14.0\n      28.600000\n      4.0\n      0.0\n      202.0\n      832.0\n      400.0\n      22.0\n      1.0\n      1.0\n      16.0\n      12.0\n      284.0\n      181.0\n      63.700001\n      12.0\n      1.0\n      0.0\n      0.0\n      13.0\n      10.0\n      3.0\n      19.0\n      19.0\n      8.0\n      0.0\n      0.0\n      0.0\n      80.0\n      18.0\n      18.0\n      50.000000\n      2017\n      8\n      2017\n      5\n      -2.0\n      0.0\n      2.0\n      0.0\n      6.0\n      2.0\n      33.299999\n      0.00\n      0.00\n      16.299999\n      0.0\n      0.0\n      0.0\n      0.3\n      0.3\n      0.06\n      -0.3\n      -0.3\n      4.0\n      3.0\n      50.000000\n      0.0\n      1.6\n      0.6\n      0.0\n      0.0\n      0.0\n      0.0\n      8.0\n      26.0\n      30.799999\n      19.0\n      3.0\n      78.900002\n      55.599998\n      11.0\n      100.000000\n      70.300003\n      12.0\n      1.0\n      8.300000\n      0.0\n      7.600000\n      137.0\n      235.0\n      58.299999\n      3027.0\n      1359.0\n      53.0\n      68.0\n      77.900002\n      51.0\n      72.0\n      70.800003\n      30.0\n      82.0\n      36.599998\n      0.0\n      0.1\n      2.0\n      9.0\n      0.0\n      0.0\n      6.0\n      235.0\n      190.0\n      45.0\n      10.0\n      0.0\n      46.0\n      7.0\n      4.0\n      3.0\n      2.0\n      1.0\n      0.0\n      110.0\n      38.0\n      87.0\n      51.0\n      137.0\n      12.0\n      18.0\n      4.0\n      137.0\n      6.0\n      12.0\n      13.0\n      5.0\n      7.0\n      1.0\n      1.0\n      0.0\n      4.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      10.0\n      8.0\n      7.0\n      3.0\n      0.0\n      6.0\n      15.0\n      40.000000\n      9.0\n      144.0\n      40.0\n      27.799999\n      84.0\n      46.0\n      14.0\n      22.0\n      5.0\n      0.0\n      17.0\n      19.0\n      40.0\n      0.0\n      23.0\n      346.0\n      84.0\n      188.0\n      124.0\n      55.0\n      6.0\n      303.0\n      9.0\n      14.0\n      64.300003\n      10.0\n      0.0\n      142.0\n      780.0\n      356.0\n      9.0\n      2.0\n      0.0\n      5.0\n      7.0\n      203.0\n      137.0\n      67.500000\n      6.0\n      0.0\n      0.0\n      0.0\n      8.0\n      8.0\n      6.0\n      4.0\n      19.0\n      8.0\n      0.0\n      0.0\n      1.0\n      65.0\n      17.0\n      19.0\n      47.200001\n      2\n    \n    \n      15\n      Watford\n      Bournemouth\n      Bournemouth\n      Watford\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      -1.0\n      0.0\n      1.0\n      0.0\n      9.0\n      2.0\n      22.200001\n      0.00\n      0.000000\n      20.100000\n      0.0\n      0.0\n      0.0\n      0.4\n      0.4\n      0.05\n      -0.4\n      -0.4\n      6.0\n      5.0\n      83.300003\n      0.0\n      1.4\n      0.4\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      12.0\n      41.700001\n      22.0\n      8.0\n      31.799999\n      33.299999\n      10.0\n      50.000000\n      46.700001\n      7.0\n      0.0\n      0.0\n      0.0\n      15.300000\n      556.0\n      653.0\n      85.099998\n      10183.0\n      2639.0\n      222.0\n      238.0\n      93.300003\n      270.0\n      296.0\n      91.199997\n      55.0\n      99.0\n      55.599998\n      0.0\n      0.4\n      8.0\n      38.0\n      11.0\n      3.0\n      40.0\n      653.0\n      608.0\n      45.0\n      17.0\n      0.0\n      68.0\n      11.0\n      18.0\n      2.0\n      0.0\n      0.0\n      1.0\n      514.0\n      54.0\n      85.0\n      287.0\n      313.0\n      14.0\n      14.0\n      13.0\n      556.0\n      0.0\n      9.0\n      19.0\n      11.0\n      14.0\n      12.0\n      1.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      16.0\n      7.0\n      13.0\n      3.0\n      0.0\n      6.0\n      10.0\n      60.000000\n      4.0\n      109.0\n      28.0\n      25.700001\n      40.0\n      41.0\n      28.0\n      16.0\n      1.0\n      0.0\n      15.0\n      4.0\n      36.0\n      0.0\n      69.0\n      770.0\n      66.0\n      216.0\n      378.0\n      233.0\n      22.0\n      729.0\n      8.0\n      15.0\n      53.299999\n      8.0\n      1.0\n      575.0\n      2932.0\n      1517.0\n      57.0\n      19.0\n      1.0\n      12.0\n      10.0\n      624.0\n      556.0\n      89.099998\n      40.0\n      1.0\n      0.0\n      0.0\n      5.0\n      19.0\n      0.0\n      18.0\n      4.0\n      7.0\n      0.0\n      0.0\n      0.0\n      97.0\n      21.0\n      21.0\n      50.000000\n      2017\n      8\n      2017\n      5\n      0.0\n      3.0\n      3.0\n      3.0\n      9.0\n      5.0\n      55.599998\n      0.33\n      0.60\n      16.100000\n      0.0\n      0.0\n      0.0\n      2.1\n      2.1\n      0.23\n      0.9\n      0.9\n      4.0\n      2.0\n      50.000000\n      0.0\n      3.1\n      0.1\n      1.0\n      1.0\n      0.0\n      0.0\n      13.0\n      32.0\n      40.599998\n      32.0\n      8.0\n      68.800003\n      48.900002\n      12.0\n      83.300003\n      64.599998\n      6.0\n      0.0\n      0.000000\n      2.0\n      14.900000\n      304.0\n      432.0\n      70.400002\n      6790.0\n      2541.0\n      111.0\n      133.0\n      83.500000\n      121.0\n      160.0\n      75.599998\n      66.0\n      120.0\n      55.000000\n      1.0\n      0.6\n      4.0\n      27.0\n      3.0\n      1.0\n      25.0\n      432.0\n      378.0\n      54.0\n      9.0\n      0.0\n      79.0\n      12.0\n      13.0\n      3.0\n      3.0\n      0.0\n      0.0\n      239.0\n      64.0\n      129.0\n      79.0\n      278.0\n      27.0\n      26.0\n      9.0\n      304.0\n      3.0\n      11.0\n      22.0\n      12.0\n      11.0\n      6.0\n      1.0\n      1.0\n      2.0\n      1.0\n      0.0\n      3.0\n      0.0\n      1.0\n      0.0\n      2.0\n      0.0\n      0.0\n      16.0\n      10.0\n      6.0\n      10.0\n      0.0\n      3.0\n      13.0\n      23.100000\n      10.0\n      189.0\n      67.0\n      35.400002\n      57.0\n      92.0\n      40.0\n      13.0\n      1.0\n      0.0\n      12.0\n      22.0\n      42.0\n      0.0\n      46.0\n      571.0\n      62.0\n      197.0\n      280.0\n      125.0\n      12.0\n      518.0\n      9.0\n      13.0\n      69.199997\n      9.0\n      2.0\n      260.0\n      1374.0\n      724.0\n      24.0\n      10.0\n      2.0\n      15.0\n      13.0\n      396.0\n      304.0\n      76.800003\n      25.0\n      0.0\n      0.0\n      0.0\n      16.0\n      10.0\n      3.0\n      13.0\n      22.0\n      10.0\n      0.0\n      1.0\n      0.0\n      92.0\n      21.0\n      35.0\n      37.500000\n      -2\n    \n    \n      16\n      Newcastle United\n      Huddersfield Town\n      Huddersfield Town\n      Newcastle United\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      20\n      3.0\n      3.0\n      0.0\n      2.0\n      9.0\n      6.0\n      66.699997\n      0.22\n      0.330000\n      15.600000\n      0.0\n      0.0\n      0.0\n      1.7\n      1.7\n      0.18\n      0.3\n      0.3\n      4.0\n      4.0\n      100.000000\n      1.0\n      1.5\n      1.5\n      0.0\n      0.0\n      0.0\n      0.0\n      12.0\n      28.0\n      42.900002\n      22.0\n      3.0\n      81.800003\n      62.400002\n      10.0\n      100.000000\n      78.699997\n      9.0\n      0.0\n      0.0\n      1.0\n      16.200001\n      236.0\n      357.0\n      66.099998\n      4951.0\n      2224.0\n      97.0\n      116.0\n      83.599998\n      85.0\n      121.0\n      70.199997\n      45.0\n      96.0\n      46.900002\n      2.0\n      1.3\n      6.0\n      16.0\n      3.0\n      1.0\n      15.0\n      357.0\n      301.0\n      56.0\n      7.0\n      1.0\n      63.0\n      9.0\n      5.0\n      9.0\n      6.0\n      0.0\n      0.0\n      175.0\n      56.0\n      126.0\n      96.0\n      173.0\n      28.0\n      29.0\n      5.0\n      236.0\n      2.0\n      11.0\n      19.0\n      15.0\n      12.0\n      6.0\n      4.0\n      1.0\n      1.0\n      0.0\n      0.0\n      4.0\n      3.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      26.0\n      13.0\n      11.0\n      10.0\n      5.0\n      6.0\n      24.0\n      25.000000\n      18.0\n      208.0\n      67.0\n      32.200001\n      73.0\n      95.0\n      40.0\n      17.0\n      4.0\n      0.0\n      13.0\n      13.0\n      29.0\n      0.0\n      44.0\n      486.0\n      70.0\n      179.0\n      196.0\n      138.0\n      16.0\n      430.0\n      3.0\n      10.0\n      30.000000\n      4.0\n      0.0\n      216.0\n      1093.0\n      493.0\n      22.0\n      10.0\n      2.0\n      10.0\n      19.0\n      342.0\n      236.0\n      69.000000\n      15.0\n      3.0\n      0.0\n      0.0\n      20.0\n      7.0\n      2.0\n      5.0\n      13.0\n      13.0\n      0.0\n      0.0\n      0.0\n      83.0\n      19.0\n      19.0\n      50.000000\n      2017\n      8\n      2017\n      6\n      -2.0\n      0.0\n      2.0\n      0.0\n      6.0\n      3.0\n      50.000000\n      0.00\n      0.00\n      12.000000\n      0.0\n      0.0\n      0.0\n      0.6\n      0.6\n      0.10\n      -0.6\n      -0.6\n      6.0\n      4.0\n      66.699997\n      0.0\n      1.0\n      -1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      8.0\n      29.0\n      27.600000\n      27.0\n      4.0\n      81.500000\n      58.099998\n      7.0\n      100.000000\n      68.599998\n      10.0\n      0.0\n      0.000000\n      0.0\n      7.200000\n      189.0\n      290.0\n      65.199997\n      4133.0\n      1725.0\n      72.0\n      90.0\n      80.000000\n      72.0\n      96.0\n      75.000000\n      40.0\n      87.0\n      46.000000\n      0.0\n      0.1\n      3.0\n      13.0\n      5.0\n      1.0\n      14.0\n      290.0\n      238.0\n      52.0\n      11.0\n      1.0\n      54.0\n      10.0\n      10.0\n      5.0\n      3.0\n      1.0\n      0.0\n      146.0\n      56.0\n      88.0\n      117.0\n      112.0\n      12.0\n      26.0\n      5.0\n      189.0\n      2.0\n      13.0\n      14.0\n      10.0\n      7.0\n      6.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      14.0\n      8.0\n      13.0\n      1.0\n      0.0\n      6.0\n      19.0\n      31.600000\n      13.0\n      173.0\n      50.0\n      28.900000\n      79.0\n      57.0\n      37.0\n      20.0\n      7.0\n      0.0\n      13.0\n      7.0\n      32.0\n      0.0\n      28.0\n      409.0\n      69.0\n      188.0\n      132.0\n      106.0\n      13.0\n      357.0\n      9.0\n      14.0\n      64.300003\n      11.0\n      1.0\n      216.0\n      1060.0\n      586.0\n      13.0\n      6.0\n      3.0\n      13.0\n      9.0\n      261.0\n      189.0\n      72.400002\n      14.0\n      1.0\n      1.0\n      0.0\n      9.0\n      11.0\n      2.0\n      10.0\n      7.0\n      8.0\n      0.0\n      0.0\n      0.0\n      73.0\n      19.0\n      21.0\n      47.500000\n      1\n    \n    \n      17\n      West Ham United\n      Southampton\n      Southampton\n      West Ham United\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      0.0\n      0.0\n      0.0\n      0.0\n      28.0\n      2.0\n      7.100000\n      0.00\n      0.000000\n      17.900000\n      1.0\n      0.0\n      0.0\n      2.1\n      2.1\n      0.07\n      -2.1\n      -2.1\n      0.0\n      0.0\n      71.033333\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      2.0\n      9.0\n      22.200001\n      11.0\n      1.0\n      54.500000\n      41.599998\n      4.0\n      75.000000\n      65.500000\n      4.0\n      0.0\n      0.0\n      1.0\n      19.000000\n      471.0\n      573.0\n      82.199997\n      8520.0\n      2727.0\n      219.0\n      237.0\n      92.400002\n      191.0\n      216.0\n      88.400002\n      53.0\n      93.0\n      57.000000\n      0.0\n      1.8\n      22.0\n      41.0\n      21.0\n      8.0\n      52.0\n      573.0\n      516.0\n      57.0\n      13.0\n      0.0\n      80.0\n      19.0\n      22.0\n      13.0\n      8.0\n      2.0\n      0.0\n      366.0\n      99.0\n      108.0\n      173.0\n      338.0\n      18.0\n      26.0\n      2.0\n      471.0\n      0.0\n      6.0\n      13.0\n      18.0\n      45.0\n      38.0\n      2.0\n      1.0\n      1.0\n      1.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      15.0\n      13.0\n      6.0\n      8.0\n      1.0\n      3.0\n      8.0\n      37.500000\n      5.0\n      109.0\n      42.0\n      38.500000\n      19.0\n      57.0\n      33.0\n      10.0\n      2.0\n      0.0\n      8.0\n      9.0\n      18.0\n      0.0\n      59.0\n      679.0\n      25.0\n      116.0\n      328.0\n      280.0\n      44.0\n      624.0\n      9.0\n      10.0\n      90.000000\n      9.0\n      1.0\n      483.0\n      2398.0\n      1319.0\n      61.0\n      22.0\n      2.0\n      17.0\n      9.0\n      558.0\n      471.0\n      84.400002\n      52.0\n      2.0\n      0.0\n      0.0\n      11.0\n      13.0\n      0.0\n      22.0\n      9.0\n      13.0\n      0.0\n      0.0\n      0.0\n      91.0\n      24.0\n      20.0\n      54.500000\n      2017\n      8\n      2017\n      5\n      -4.0\n      0.0\n      4.0\n      0.0\n      9.0\n      1.0\n      11.100000\n      0.00\n      0.00\n      16.400000\n      0.0\n      0.0\n      0.0\n      0.6\n      0.6\n      0.07\n      -0.6\n      -0.6\n      5.0\n      1.0\n      20.000000\n      0.0\n      2.4\n      -1.6\n      0.0\n      0.0\n      0.0\n      0.0\n      6.0\n      20.0\n      30.000000\n      22.0\n      5.0\n      31.799999\n      37.099998\n      13.0\n      100.000000\n      71.199997\n      9.0\n      2.0\n      22.200001\n      0.0\n      17.000000\n      322.0\n      419.0\n      76.800003\n      6664.0\n      2169.0\n      119.0\n      140.0\n      85.000000\n      143.0\n      169.0\n      84.599998\n      58.0\n      105.0\n      55.200001\n      0.0\n      0.5\n      6.0\n      18.0\n      7.0\n      0.0\n      33.0\n      419.0\n      367.0\n      52.0\n      20.0\n      0.0\n      83.0\n      10.0\n      11.0\n      1.0\n      0.0\n      1.0\n      0.0\n      273.0\n      56.0\n      90.0\n      125.0\n      238.0\n      26.0\n      13.0\n      7.0\n      322.0\n      3.0\n      8.0\n      11.0\n      8.0\n      12.0\n      8.0\n      1.0\n      2.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      23.0\n      12.0\n      13.0\n      8.0\n      2.0\n      12.0\n      39.0\n      30.799999\n      27.0\n      158.0\n      45.0\n      28.500000\n      62.0\n      84.0\n      12.0\n      16.0\n      9.0\n      0.0\n      7.0\n      14.0\n      28.0\n      0.0\n      45.0\n      557.0\n      79.0\n      180.0\n      297.0\n      108.0\n      15.0\n      507.0\n      6.0\n      11.0\n      54.500000\n      6.0\n      0.0\n      342.0\n      1574.0\n      736.0\n      19.0\n      9.0\n      0.0\n      14.0\n      11.0\n      413.0\n      322.0\n      78.000000\n      33.0\n      2.0\n      0.0\n      0.0\n      10.0\n      18.0\n      4.0\n      11.0\n      14.0\n      12.0\n      0.0\n      0.0\n      0.0\n      79.0\n      19.0\n      30.0\n      38.799999\n      1\n    \n    \n      18\n      Manchester United\n      Swansea City\n      Swansea City\n      Manchester United\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      True\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      0.0\n      0.0\n      0.0\n      0.0\n      4.0\n      0.0\n      0.000000\n      0.00\n      0.283333\n      14.800000\n      0.0\n      0.0\n      0.0\n      0.5\n      0.5\n      0.12\n      -0.5\n      -0.5\n      2.0\n      2.0\n      100.000000\n      1.0\n      0.3\n      0.3\n      0.0\n      0.0\n      0.0\n      0.0\n      14.0\n      29.0\n      48.299999\n      22.0\n      3.0\n      54.500000\n      41.700001\n      22.0\n      77.300003\n      59.900002\n      18.0\n      2.0\n      11.1\n      0.0\n      5.500000\n      310.0\n      398.0\n      77.900002\n      6621.0\n      2209.0\n      112.0\n      125.0\n      89.599998\n      137.0\n      164.0\n      83.500000\n      57.0\n      98.0\n      58.200001\n      0.0\n      0.4\n      3.0\n      16.0\n      3.0\n      1.0\n      17.0\n      398.0\n      350.0\n      48.0\n      10.0\n      0.0\n      45.0\n      14.0\n      5.0\n      0.0\n      0.0\n      0.0\n      0.0\n      257.0\n      48.0\n      93.0\n      104.0\n      244.0\n      18.0\n      15.0\n      7.0\n      310.0\n      1.0\n      13.0\n      9.0\n      8.0\n      7.0\n      4.0\n      0.0\n      1.0\n      1.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      10.0\n      5.0\n      4.0\n      2.0\n      4.0\n      1.0\n      10.0\n      10.000000\n      9.0\n      145.0\n      35.0\n      24.100000\n      70.0\n      52.0\n      23.0\n      29.0\n      11.0\n      0.0\n      18.0\n      14.0\n      35.0\n      0.0\n      41.0\n      515.0\n      97.0\n      217.0\n      252.0\n      76.0\n      8.0\n      469.0\n      5.0\n      8.0\n      62.500000\n      5.0\n      0.0\n      282.0\n      1263.0\n      643.0\n      16.0\n      3.0\n      0.0\n      13.0\n      12.0\n      381.0\n      310.0\n      81.400002\n      17.0\n      1.0\n      0.0\n      0.0\n      14.0\n      11.0\n      1.0\n      5.0\n      14.0\n      5.0\n      0.0\n      0.0\n      0.0\n      55.0\n      20.0\n      24.0\n      45.500000\n      2017\n      8\n      2017\n      5\n      4.0\n      4.0\n      0.0\n      4.0\n      20.0\n      5.0\n      25.000000\n      0.20\n      0.80\n      18.600000\n      0.0\n      0.0\n      0.0\n      2.1\n      2.1\n      0.11\n      1.9\n      1.9\n      1.0\n      1.0\n      100.000000\n      1.0\n      0.1\n      0.1\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      18.0\n      61.099998\n      22.0\n      3.0\n      54.500000\n      42.700001\n      7.0\n      85.699997\n      61.000000\n      10.0\n      2.0\n      20.000000\n      0.0\n      7.500000\n      434.0\n      520.0\n      83.500000\n      8579.0\n      2888.0\n      170.0\n      192.0\n      88.500000\n      185.0\n      206.0\n      89.800003\n      69.0\n      105.0\n      65.699997\n      4.0\n      2.0\n      15.0\n      33.0\n      10.0\n      2.0\n      39.0\n      520.0\n      471.0\n      49.0\n      11.0\n      5.0\n      56.0\n      15.0\n      10.0\n      10.0\n      1.0\n      6.0\n      0.0\n      367.0\n      65.0\n      88.0\n      169.0\n      290.0\n      17.0\n      20.0\n      5.0\n      434.0\n      2.0\n      3.0\n      13.0\n      7.0\n      31.0\n      23.0\n      2.0\n      3.0\n      1.0\n      1.0\n      1.0\n      7.0\n      5.0\n      1.0\n      0.0\n      0.0\n      1.0\n      0.0\n      16.0\n      8.0\n      4.0\n      10.0\n      2.0\n      5.0\n      11.0\n      45.500000\n      6.0\n      157.0\n      32.0\n      20.400000\n      36.0\n      93.0\n      28.0\n      10.0\n      2.0\n      0.0\n      8.0\n      12.0\n      31.0\n      0.0\n      55.0\n      659.0\n      51.0\n      165.0\n      363.0\n      169.0\n      32.0\n      611.0\n      26.0\n      39.0\n      66.699997\n      27.0\n      2.0\n      476.0\n      2115.0\n      1230.0\n      53.0\n      16.0\n      6.0\n      12.0\n      11.0\n      478.0\n      434.0\n      90.800003\n      39.0\n      2.0\n      0.0\n      0.0\n      18.0\n      10.0\n      1.0\n      10.0\n      12.0\n      8.0\n      0.0\n      0.0\n      0.0\n      86.0\n      30.0\n      19.0\n      61.200001\n      -4\n    \n    \n      19\n      Arsenal\n      Stoke City\n      Stoke City\n      Arsenal\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      2\n      19\n      -1.0\n      0.0\n      1.0\n      0.0\n      9.0\n      1.0\n      11.100000\n      0.00\n      0.000000\n      22.200001\n      0.0\n      0.0\n      0.0\n      0.3\n      0.3\n      0.03\n      -0.3\n      -0.3\n      4.0\n      3.0\n      75.000000\n      0.0\n      0.3\n      -0.7\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      20.0\n      55.000000\n      22.0\n      3.0\n      63.599998\n      45.400002\n      8.0\n      75.000000\n      60.799999\n      9.0\n      0.0\n      0.0\n      0.0\n      15.000000\n      241.0\n      360.0\n      66.900002\n      5019.0\n      2192.0\n      92.0\n      112.0\n      82.099998\n      96.0\n      125.0\n      76.800003\n      48.0\n      109.0\n      44.000000\n      0.0\n      0.2\n      6.0\n      25.0\n      9.0\n      1.0\n      29.0\n      360.0\n      301.0\n      59.0\n      15.0\n      0.0\n      86.0\n      9.0\n      9.0\n      7.0\n      3.0\n      3.0\n      1.0\n      167.0\n      57.0\n      136.0\n      94.0\n      186.0\n      23.0\n      27.0\n      9.0\n      241.0\n      5.0\n      8.0\n      15.0\n      9.0\n      12.0\n      10.0\n      0.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      22.0\n      12.0\n      9.0\n      9.0\n      4.0\n      8.0\n      12.0\n      66.699997\n      4.0\n      138.0\n      42.0\n      30.400000\n      43.0\n      66.0\n      29.0\n      17.0\n      2.0\n      0.0\n      15.0\n      25.0\n      26.0\n      1.0\n      40.0\n      495.0\n      55.0\n      164.0\n      219.0\n      148.0\n      17.0\n      438.0\n      11.0\n      13.0\n      84.599998\n      11.0\n      0.0\n      265.0\n      1701.0\n      897.0\n      36.0\n      12.0\n      3.0\n      18.0\n      17.0\n      349.0\n      241.0\n      69.099998\n      29.0\n      1.0\n      0.0\n      0.0\n      11.0\n      14.0\n      6.0\n      9.0\n      25.0\n      12.0\n      0.0\n      0.0\n      0.0\n      91.0\n      26.0\n      25.0\n      51.000000\n      2017\n      8\n      2017\n      5\n      1.0\n      4.0\n      3.0\n      4.0\n      27.0\n      10.0\n      37.000000\n      0.15\n      0.40\n      19.400000\n      0.0\n      0.0\n      0.0\n      2.3\n      2.3\n      0.09\n      1.7\n      1.7\n      4.0\n      1.0\n      25.000000\n      0.0\n      2.4\n      -0.6\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      8.0\n      62.500000\n      16.0\n      3.0\n      37.500000\n      34.599998\n      6.0\n      33.299999\n      32.200001\n      17.0\n      1.0\n      5.900000\n      2.0\n      23.000000\n      564.0\n      675.0\n      83.599998\n      11212.0\n      3316.0\n      231.0\n      267.0\n      86.500000\n      234.0\n      262.0\n      89.300003\n      88.0\n      122.0\n      72.099998\n      4.0\n      2.3\n      25.0\n      56.0\n      15.0\n      3.0\n      48.0\n      675.0\n      620.0\n      55.0\n      15.0\n      3.0\n      42.0\n      33.0\n      14.0\n      9.0\n      3.0\n      3.0\n      0.0\n      487.0\n      90.0\n      98.0\n      318.0\n      291.0\n      28.0\n      21.0\n      8.0\n      564.0\n      5.0\n      12.0\n      19.0\n      9.0\n      50.0\n      39.0\n      4.0\n      2.0\n      3.0\n      2.0\n      0.0\n      7.0\n      4.0\n      1.0\n      0.0\n      2.0\n      0.0\n      0.0\n      22.0\n      14.0\n      10.0\n      9.0\n      3.0\n      10.0\n      14.0\n      71.400002\n      4.0\n      92.0\n      36.0\n      39.099998\n      32.0\n      40.0\n      20.0\n      10.0\n      0.0\n      0.0\n      10.0\n      20.0\n      31.0\n      0.0\n      69.0\n      808.0\n      56.0\n      216.0\n      394.0\n      249.0\n      32.0\n      753.0\n      12.0\n      17.0\n      70.599998\n      13.0\n      0.0\n      526.0\n      2837.0\n      1584.0\n      67.0\n      23.0\n      5.0\n      11.0\n      14.0\n      669.0\n      564.0\n      84.300003\n      48.0\n      0.0\n      0.0\n      0.0\n      10.0\n      13.0\n      5.0\n      14.0\n      20.0\n      14.0\n      0.0\n      0.0\n      0.0\n      93.0\n      18.0\n      18.0\n      50.000000\n      1\n    \n  \n\n\n\n\n\ndef do_XGB(n_estimators=1000, learning_rate=0.0001, n_jobs=100):\n    from xgboost import XGBRegressor\n    # !pip install xgboost\n    \n\n    # Define the model\n    my_model_2 = XGBRegressor(n_estimators=1000, learning_rate=0.01) # Your code here\n\n    # Fit the model\n    my_model_2.fit(xs, y) \n\n    # Get predictions\n#     ppred = my_model_2.predict_proba(xs)\n#     ppred_valid = my_model_2.predict_probab(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n    XX=0.5\n    pred[pred>=XX]=1\n    pred[pred<XX]=0\n\n    return pred,pred_valid \n\n   \n\n\n# pred_RF,pred_valid_RF, ppred_RF,ppred_valid_RF  = do_RF()\npred_XGB,pred_valid_XGB = do_XGB()\n# pred_rdg,pred_valid_rdg,ppred_rdg,ppred_valid_rdg = do_ridge()\n\n\nget_reg_scores(valid_y,0.5*(pred_valid_XGB+pred_val),.5);\n# len(pred_XGB),len(valid_y)\n# precision_score(valid_y,pred_val)\n\nRegression RF: accuracy = 0.624 and precision = 0.368\n\n\n\nclf=RandomForestRegressor(random_state=42)\nclf.get_params()\n\n{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'criterion': 'squared_error',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': 42,\n 'verbose': 0,\n 'warm_start': False}\n\n\n\n#collapse-hide\n# Number of trees in random forest\nn_estimators=[20,50,150,400,700]\n\n# Number of features to consider at every split\n# max_features = ['log2','sqrt',None]\n\n# Maximum number of levels in tree\nmax_depth=[10,  30,  70,  200, None]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [1.,2, 10,50]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,10]\n\n# Method of selecting samples for training each tree\n# bootstrap = [True, False]\n\n# Weights associated with classes \nclass_weight=[\"balanced\", \"balanced_subsample\",None]\n\n#Complexity parameter used for Minimal Cost-Complexity Pruning.\nccp_alpha=[0., 0.1, 0.5]\n\nrandom_grid = {'n_estimators': n_estimators,\n#                'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n#                'bootstrap': bootstrap,\n#                'class_weight':class_weight,\n               'ccp_alpha' : ccp_alpha\n\n              }\n\nrsh = HalvingRandomSearchCV(estimator = clf, param_distributions = random_grid, \\\n                              random_state=42, factor = 3)# Fit the random search model\nrsh.fit(xs, y)\n\n\nHalvingRandomSearchCV(estimator=RandomForestRegressor(random_state=42),\n                      param_distributions={'ccp_alpha': [0.0, 0.1, 0.5],\n                                           'max_depth': [10, 30, 70, 200, None],\n                                           'min_samples_leaf': [1, 2, 4, 10],\n                                           'min_samples_split': [1.0, 2, 10,\n                                                                 50],\n                                           'n_estimators': [20, 50, 150, 400,\n                                                            700]},\n                      random_state=42)\n\n\n\npred=rsh.predict(xs)\npred_valid=rsh.predict(valid_xs)\n\nget_reg_scores(valid_y,pred_valid,.5);\n\nget_reg_scores(valid_y,0.5*(pred_valid_XGB+pred_valid),.5);\n\n# valid_y,pred_valid\n\n# pred = rsh.predict(xs)\n# pred_valid = my_model_2.predict(valid_xs)\n# XX=0.5\n# pred[pred>=XX]=1\n# pred[pred<XX]=0\n\nRegression RF: accuracy = 0.626 and precision = 0.350\nRegression RF: accuracy = 0.621 and precision = 0.350\n\n\n\ndf.loc[:,'Win']\n\nKeyError: 'Win'\n\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\nXuse=list(Xuse[-15:-1].category.values)\nXuse\n\n['att_passing.2_x',\n 'totdist_passing_x',\n 'touches_x',\n 'cmp_passing_types_x',\n 'cmp_passing_x',\n 'rec_x',\n 'targ_x',\n 'live_possession_x',\n 'prog_possession_x',\n 'att_passing_types_x',\n 'att_passing_x',\n 'carries_x',\n 'live_passing_types_x',\n 'mid 3rd_possession_x']\n\n\n\nimport pandas as pd\n\n\ndf_=pd.read_csv(folda+'epl2017-2021.csv')\n\ndf_=df_.iloc[10:,:]\ncols = [\"gf\",\"ga\",\"sh_shooting\",\"sot\",\"dist\",\"fk_shooting\",\"pk\",\"pkatt_shooting\"]\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\npredictors = [x+'_x' for x in cols ]\n\npredictors=Xuse.copy()\n\npredictors_=['day','opponent_x','team_x','weekday']\n\n[predictors.append(x) for x in predictors_]\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\npredictors.append('Win_x')\npredictors.append('season')\n# df.loc[:,cola]\n\n# [x for x in df.columns if x[0]=='W']\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint(len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier()#n_estimators = 40, min_samples_split =10, random_state = 1)\nprint(predictors[0:-2])\npredictors=predictors[0:-2]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\n\nprint(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) )\n\nNameError: name 'folda' is not defined\n\n\n\ndf=df_.copy()\ndf=df.dropna()\ntrain = df[df[\"season\"] <= 2020]\ntest = df[df[\"season\"] > 2020]\n\n[predictors.append(x) for x in predictors_]\npredictors.append('Win_x')\npredictors.append('season')\npredictors=predictors[0:-2]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\naccuracy_score(test['Win_x'], pred)\n\n\n0.6464379947229552\n\n\n\n\n\n['rec_x',\n 'targ_x',\n 'live_possession_x',\n 'prog_possession_x',\n 'att_passing_types_x',\n 'att_passing_x',\n 'carries_x',\n 'live_passing_types_x',\n 'mid 3rd_possession_x',\n 'day',\n 'opponent_x',\n 'team_x',\n 'weekday',\n 'day',\n 'opponent_x',\n 'team_x',\n 'weekday']\n\n\n\ndf=pd.read_csv(folda+'epl2017-2021.csv')\ncola=['day','opponent_x','team_x','weekday','season']\ndf.loc[:,cola[3]]\n[x for x in df.columns]\n\n['Unnamed: 0',\n 'round',\n 'day',\n 'result_x',\n 'gf_x',\n 'ga_x',\n 'opponent_x',\n 'gls_x',\n 'sh_shooting_x',\n 'sot_x',\n 'sot%_x',\n 'g/sh_x',\n 'g/sot_x',\n 'dist_x',\n 'fk_shooting_x',\n 'pk_x',\n 'pkatt_shooting_x',\n 'xg_x',\n 'npxg_x',\n 'npxg/sh_x',\n 'g-xg_x',\n 'np:g-xg_x',\n 'sota_x',\n 'saves_x',\n 'save%_x',\n 'cs_x',\n 'psxg_x',\n 'psxg+/-_x',\n 'pkatt_keeper_x',\n 'pka_x',\n 'pksv_x',\n 'pkm_x',\n 'cmp_keeper_x',\n 'att_keeper_x',\n 'cmp%_keeper_x',\n 'att_keeper.1_x',\n 'thr_x',\n 'launch%_x',\n 'avglen_x',\n 'att_keeper.2_x',\n 'launch%.1_x',\n 'avglen.1_x',\n 'opp_x',\n 'stp_x',\n 'stp%_x',\n '#opa_x',\n 'avgdist_x',\n 'cmp_passing_x',\n 'att_passing_x',\n 'cmp%_passing_x',\n 'totdist_passing_x',\n 'prgdist_passing_x',\n 'cmp_passing.1_x',\n 'att_passing.1_x',\n 'cmp%_passing.1_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'cmp%_passing.2_x',\n 'cmp_passing.3_x',\n 'att_passing.3_x',\n 'cmp%_passing.3_x',\n 'ast_x',\n 'xa_x',\n 'kp_x',\n '1/3_passing_x',\n 'ppa_x',\n 'crspa_x',\n 'prog_passing_x',\n 'att_passing_types_x',\n 'live_passing_types_x',\n 'dead_x',\n 'fk_passing_types_x',\n 'tb_x',\n 'press_passing_types_x',\n 'sw_x',\n 'crs_passing_types_x',\n 'ck_x',\n 'in_x',\n 'out_x',\n 'str_x',\n 'ground_x',\n 'low_x',\n 'high_x',\n 'left_x',\n 'right_x',\n 'head_x',\n 'ti_x',\n 'other_x',\n 'cmp_passing_types_x',\n 'off_passing_types_x',\n 'out.1_x',\n 'int_passing_types_x',\n 'blocks_passing_types_x',\n 'sca_x',\n 'passlive_x',\n 'passdead_x',\n 'drib_x',\n 'sh_gca_x',\n 'fld_gca_x',\n 'def_x',\n 'gca_x',\n 'passlive.1_x',\n 'passdead.1_x',\n 'drib.1_x',\n 'sh_gca.1_x',\n 'fld_gca.1_x',\n 'def.1_x',\n 'tkl_x',\n 'tklw_defense_x',\n 'def 3rd_defense_x',\n 'mid 3rd_defense_x',\n 'att 3rd_defense_x',\n 'tkl.1_x',\n 'att_defense_x',\n 'tkl%_x',\n 'past_x',\n 'press_defense_x',\n 'succ_defense_x',\n '%_x',\n 'def 3rd_defense.1_x',\n 'mid 3rd_defense.1_x',\n 'att 3rd_defense.1_x',\n 'blocks_defense_x',\n 'sh_defense_x',\n 'shsv_x',\n 'pass_x',\n 'int_defense_x',\n 'clr_x',\n 'err_x',\n 'poss_x',\n 'touches_x',\n 'def pen_x',\n 'def 3rd_possession_x',\n 'mid 3rd_possession_x',\n 'att 3rd_possession_x',\n 'att pen_x',\n 'live_possession_x',\n 'succ_possession_x',\n 'att_possession_x',\n 'succ%_x',\n '#pl_x',\n 'megs_x',\n 'carries_x',\n 'totdist_possession_x',\n 'prgdist_possession_x',\n 'prog_possession_x',\n '1/3_possession_x',\n 'cpa_x',\n 'mis_x',\n 'dis_x',\n 'targ_x',\n 'rec_x',\n 'rec%_x',\n 'prog_possession.1_x',\n 'crdy_x',\n 'crdr_x',\n '2crdy_x',\n 'fls_x',\n 'fld_misc_x',\n 'off_misc_x',\n 'crs_misc_x',\n 'int_misc_x',\n 'tklw_misc_x',\n 'pkwon_x',\n 'pkcon_x',\n 'og_x',\n 'recov_x',\n 'won_x',\n 'lost_x',\n 'won%_x',\n 'team_x',\n 'season',\n 'month',\n 'year',\n 'weekday',\n 'Win_x',\n 'result_y',\n 'gf_y',\n 'ga_y',\n 'opponent_y',\n 'gls_y',\n 'sh_shooting_y',\n 'sot_y',\n 'sot%_y',\n 'g/sh_y',\n 'g/sot_y',\n 'dist_y',\n 'fk_shooting_y',\n 'pk_y',\n 'pkatt_shooting_y',\n 'xg_y',\n 'npxg_y',\n 'npxg/sh_y',\n 'g-xg_y',\n 'np:g-xg_y',\n 'sota_y',\n 'saves_y',\n 'save%_y',\n 'cs_y',\n 'psxg_y',\n 'psxg+/-_y',\n 'pkatt_keeper_y',\n 'pka_y',\n 'pksv_y',\n 'pkm_y',\n 'cmp_keeper_y',\n 'att_keeper_y',\n 'cmp%_keeper_y',\n 'att_keeper.1_y',\n 'thr_y',\n 'launch%_y',\n 'avglen_y',\n 'att_keeper.2_y',\n 'launch%.1_y',\n 'avglen.1_y',\n 'opp_y',\n 'stp_y',\n 'stp%_y',\n '#opa_y',\n 'avgdist_y',\n 'cmp_passing_y',\n 'att_passing_y',\n 'cmp%_passing_y',\n 'totdist_passing_y',\n 'prgdist_passing_y',\n 'cmp_passing.1_y',\n 'att_passing.1_y',\n 'cmp%_passing.1_y',\n 'cmp_passing.2_y',\n 'att_passing.2_y',\n 'cmp%_passing.2_y',\n 'cmp_passing.3_y',\n 'att_passing.3_y',\n 'cmp%_passing.3_y',\n 'ast_y',\n 'xa_y',\n 'kp_y',\n '1/3_passing_y',\n 'ppa_y',\n 'crspa_y',\n 'prog_passing_y',\n 'att_passing_types_y',\n 'live_passing_types_y',\n 'dead_y',\n 'fk_passing_types_y',\n 'tb_y',\n 'press_passing_types_y',\n 'sw_y',\n 'crs_passing_types_y',\n 'ck_y',\n 'in_y',\n 'out_y',\n 'str_y',\n 'ground_y',\n 'low_y',\n 'high_y',\n 'left_y',\n 'right_y',\n 'head_y',\n 'ti_y',\n 'other_y',\n 'cmp_passing_types_y',\n 'off_passing_types_y',\n 'out.1_y',\n 'int_passing_types_y',\n 'blocks_passing_types_y',\n 'sca_y',\n 'passlive_y',\n 'passdead_y',\n 'drib_y',\n 'sh_gca_y',\n 'fld_gca_y',\n 'def_y',\n 'gca_y',\n 'passlive.1_y',\n 'passdead.1_y',\n 'drib.1_y',\n 'sh_gca.1_y',\n 'fld_gca.1_y',\n 'def.1_y',\n 'tkl_y',\n 'tklw_defense_y',\n 'def 3rd_defense_y',\n 'mid 3rd_defense_y',\n 'att 3rd_defense_y',\n 'tkl.1_y',\n 'att_defense_y',\n 'tkl%_y',\n 'past_y',\n 'press_defense_y',\n 'succ_defense_y',\n '%_y',\n 'def 3rd_defense.1_y',\n 'mid 3rd_defense.1_y',\n 'att 3rd_defense.1_y',\n 'blocks_defense_y',\n 'sh_defense_y',\n 'shsv_y',\n 'pass_y',\n 'int_defense_y',\n 'clr_y',\n 'err_y',\n 'poss_y',\n 'touches_y',\n 'def pen_y',\n 'def 3rd_possession_y',\n 'mid 3rd_possession_y',\n 'att 3rd_possession_y',\n 'att pen_y',\n 'live_possession_y',\n 'succ_possession_y',\n 'att_possession_y',\n 'succ%_y',\n '#pl_y',\n 'megs_y',\n 'carries_y',\n 'totdist_possession_y',\n 'prgdist_possession_y',\n 'prog_possession_y',\n '1/3_possession_y',\n 'cpa_y',\n 'mis_y',\n 'dis_y',\n 'targ_y',\n 'rec_y',\n 'rec%_y',\n 'prog_possession.1_y',\n 'crdy_y',\n 'crdr_y',\n '2crdy_y',\n 'fls_y',\n 'fld_misc_y',\n 'off_misc_y',\n 'crs_misc_y',\n 'int_misc_y',\n 'tklw_misc_y',\n 'pkwon_y',\n 'pkcon_y',\n 'og_y',\n 'recov_y',\n 'won_y',\n 'lost_y',\n 'won%_y',\n 'team_y']\n\n\n\nmg = df.groupby('team_x').mean()\nmg\n# df\n\n\n\n\n\n  \n    \n      \n      day\n      opponent_x\n      weekday\n      gf_x\n      ga_x\n      sh_shooting_x\n      sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      Win_x\n      season\n    \n    \n      team_x\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      0\n      15.148936\n      14.117021\n      4.638298\n      1.602837\n      1.248227\n      12.836879\n      4.393617\n      16.712766\n      0.542553\n      0.099291\n      0.120567\n      0.627660\n      2019.021277\n    \n    \n      1\n      16.578947\n      14.000000\n      4.350877\n      1.245614\n      1.511696\n      12.248538\n      4.108187\n      17.098830\n      0.470760\n      0.081871\n      0.116959\n      0.350877\n      2020.000000\n    \n    \n      2\n      15.719298\n      14.052632\n      4.526316\n      1.192982\n      1.809942\n      11.023392\n      3.652047\n      16.854094\n      0.380117\n      0.116959\n      0.128655\n      0.350877\n      2018.000000\n    \n    \n      3\n      16.888889\n      14.388889\n      4.888889\n      1.222222\n      1.592593\n      11.185185\n      3.555556\n      16.381481\n      0.277778\n      0.129630\n      0.129630\n      0.333333\n      2021.000000\n    \n    \n      4\n      16.340426\n      13.882979\n      4.148936\n      0.996454\n      1.322695\n      11.234043\n      3.258865\n      17.318440\n      0.301418\n      0.099291\n      0.152482\n      0.287234\n      2019.021277\n    \n    \n      5\n      15.610526\n      13.842105\n      4.168421\n      1.000000\n      1.414035\n      9.796491\n      3.059649\n      16.143860\n      0.414035\n      0.045614\n      0.052632\n      0.326316\n      2019.000000\n    \n    \n      6\n      15.421053\n      13.210526\n      4.684211\n      0.807018\n      1.894737\n      10.701754\n      2.912281\n      16.559649\n      0.385965\n      0.052632\n      0.087719\n      0.315789\n      2018.000000\n    \n    \n      7\n      15.489362\n      13.829787\n      4.202128\n      1.744681\n      1.099291\n      15.320922\n      5.099291\n      16.919681\n      0.609929\n      0.152482\n      0.170213\n      0.553191\n      2019.021277\n    \n    \n      8\n      16.882979\n      13.712766\n      4.234043\n      1.141844\n      1.446809\n      10.615248\n      3.317376\n      16.727482\n      0.407801\n      0.166667\n      0.195035\n      0.329787\n      2019.021277\n    \n    \n      9\n      13.829787\n      13.553191\n      4.287234\n      1.187943\n      1.418440\n      11.085106\n      3.563830\n      16.581915\n      0.414894\n      0.099291\n      0.131206\n      0.446809\n      2019.021277\n    \n    \n      10\n      16.945946\n      13.513514\n      4.216216\n      0.752252\n      1.779279\n      11.157658\n      3.355856\n      18.388288\n      0.238739\n      0.081081\n      0.126126\n      0.216216\n      2019.027027\n    \n    \n      11\n      16.710526\n      13.605263\n      4.421053\n      0.675439\n      1.745614\n      9.850877\n      2.969298\n      18.506140\n      0.333333\n      0.035088\n      0.035088\n      0.210526\n      2017.500000\n    \n    \n      12\n      15.289474\n      13.394737\n      4.236842\n      1.385965\n      1.859649\n      12.885965\n      4.464912\n      17.216667\n      0.280702\n      0.096491\n      0.096491\n      0.315789\n      2020.500000\n    \n    \n      13\n      16.326316\n      13.421053\n      4.463158\n      1.592982\n      1.392982\n      12.312281\n      4.361404\n      17.383860\n      0.431579\n      0.143860\n      0.178947\n      0.473684\n      2019.000000\n    \n    \n      14\n      16.947368\n      13.368421\n      4.684211\n      2.136842\n      0.875439\n      15.980702\n      5.682456\n      16.283333\n      0.470175\n      0.145614\n      0.156140\n      0.757895\n      2019.000000\n    \n    \n      15\n      15.463158\n      13.315789\n      4.368421\n      2.515789\n      0.743860\n      17.364912\n      6.280702\n      16.438596\n      0.635088\n      0.133333\n      0.214035\n      0.810526\n      2019.000000\n    \n    \n      16\n      16.340426\n      13.127660\n      4.255319\n      1.737589\n      1.230496\n      13.576241\n      5.037234\n      17.644681\n      0.618794\n      0.163121\n      0.223404\n      0.563830\n      2019.021277\n    \n    \n      17\n      16.319149\n      13.106383\n      4.521277\n      1.053191\n      1.445035\n      10.927305\n      3.528369\n      18.350355\n      0.460993\n      0.053191\n      0.081560\n      0.382979\n      2019.021277\n    \n    \n      18\n      16.052632\n      13.000000\n      4.736842\n      0.684211\n      2.048246\n      10.324561\n      3.157895\n      17.771930\n      0.486842\n      0.052632\n      0.052632\n      0.184211\n      2020.000000\n    \n    \n      19\n      15.473684\n      13.184211\n      4.210526\n      0.771930\n      1.390351\n      8.478070\n      2.578947\n      15.800877\n      0.096491\n      0.043860\n      0.061404\n      0.394737\n      2019.500000\n    \n    \n      20\n      16.670213\n      12.957447\n      4.436170\n      1.173759\n      1.634752\n      12.216312\n      4.039007\n      17.598936\n      0.524823\n      0.099291\n      0.127660\n      0.308511\n      2019.021277\n    \n    \n      21\n      15.842105\n      13.736842\n      4.210526\n      0.807018\n      1.929825\n      10.140351\n      3.175439\n      18.054386\n      0.263158\n      0.000000\n      0.035088\n      0.263158\n      2017.000000\n    \n    \n      22\n      15.315789\n      13.684211\n      4.052632\n      0.736842\n      1.350877\n      7.754386\n      2.035088\n      17.620175\n      0.333333\n      0.017544\n      0.017544\n      0.315789\n      2017.000000\n    \n    \n      23\n      15.157895\n      12.894737\n      4.557895\n      1.749123\n      1.101754\n      13.117544\n      4.654386\n      17.540351\n      0.642105\n      0.098246\n      0.108772\n      0.631579\n      2019.000000\n    \n    \n      24\n      16.000000\n      12.786667\n      4.360000\n      1.122222\n      1.713333\n      11.108889\n      3.448889\n      17.028444\n      0.462222\n      0.075556\n      0.111111\n      0.306667\n      2018.773333\n    \n    \n      25\n      17.459459\n      13.540541\n      4.297297\n      0.801802\n      1.675676\n      9.099099\n      2.635135\n      17.706306\n      0.400901\n      0.072072\n      0.072072\n      0.135135\n      2018.540541\n    \n    \n      26\n      15.894737\n      12.736842\n      4.284211\n      1.350877\n      1.452632\n      11.063158\n      3.842105\n      16.130877\n      0.396491\n      0.084211\n      0.115789\n      0.431579\n      2019.000000\n    \n    \n      27\n      15.080000\n      12.546667\n      4.026667\n      1.080000\n      1.191111\n      11.582222\n      3.697778\n      17.282222\n      0.308889\n      0.071111\n      0.071111\n      0.426667\n      2019.520000\n    \n  \n\n\n\n\n\n# plt.plot(mg.Win_x,mg.dist_x,'ok')\n[x for x in df_.columns if x[-1]!='y']\n\n['Unnamed: 0',\n 'round',\n 'result_x',\n 'gf_x',\n 'ga_x',\n 'opponent_x',\n 'gls_x',\n 'sh_shooting_x',\n 'sot_x',\n 'sot%_x',\n 'g/sh_x',\n 'g/sot_x',\n 'dist_x',\n 'fk_shooting_x',\n 'pk_x',\n 'pkatt_shooting_x',\n 'xg_x',\n 'npxg_x',\n 'npxg/sh_x',\n 'g-xg_x',\n 'np:g-xg_x',\n 'sota_x',\n 'saves_x',\n 'save%_x',\n 'cs_x',\n 'psxg_x',\n 'psxg+/-_x',\n 'pkatt_keeper_x',\n 'pka_x',\n 'pksv_x',\n 'pkm_x',\n 'cmp_keeper_x',\n 'att_keeper_x',\n 'cmp%_keeper_x',\n 'att_keeper.1_x',\n 'thr_x',\n 'launch%_x',\n 'avglen_x',\n 'att_keeper.2_x',\n 'launch%.1_x',\n 'avglen.1_x',\n 'opp_x',\n 'stp_x',\n 'stp%_x',\n '#opa_x',\n 'avgdist_x',\n 'cmp_passing_x',\n 'att_passing_x',\n 'cmp%_passing_x',\n 'totdist_passing_x',\n 'prgdist_passing_x',\n 'cmp_passing.1_x',\n 'att_passing.1_x',\n 'cmp%_passing.1_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'cmp%_passing.2_x',\n 'cmp_passing.3_x',\n 'att_passing.3_x',\n 'cmp%_passing.3_x',\n 'ast_x',\n 'xa_x',\n 'kp_x',\n '1/3_passing_x',\n 'ppa_x',\n 'crspa_x',\n 'prog_passing_x',\n 'att_passing_types_x',\n 'live_passing_types_x',\n 'dead_x',\n 'fk_passing_types_x',\n 'tb_x',\n 'press_passing_types_x',\n 'sw_x',\n 'crs_passing_types_x',\n 'ck_x',\n 'in_x',\n 'out_x',\n 'str_x',\n 'ground_x',\n 'low_x',\n 'high_x',\n 'left_x',\n 'right_x',\n 'head_x',\n 'ti_x',\n 'other_x',\n 'cmp_passing_types_x',\n 'off_passing_types_x',\n 'out.1_x',\n 'int_passing_types_x',\n 'blocks_passing_types_x',\n 'sca_x',\n 'passlive_x',\n 'passdead_x',\n 'drib_x',\n 'sh_gca_x',\n 'fld_gca_x',\n 'def_x',\n 'gca_x',\n 'passlive.1_x',\n 'passdead.1_x',\n 'drib.1_x',\n 'sh_gca.1_x',\n 'fld_gca.1_x',\n 'def.1_x',\n 'tkl_x',\n 'tklw_defense_x',\n 'def 3rd_defense_x',\n 'mid 3rd_defense_x',\n 'att 3rd_defense_x',\n 'tkl.1_x',\n 'att_defense_x',\n 'tkl%_x',\n 'past_x',\n 'press_defense_x',\n 'succ_defense_x',\n '%_x',\n 'def 3rd_defense.1_x',\n 'mid 3rd_defense.1_x',\n 'att 3rd_defense.1_x',\n 'blocks_defense_x',\n 'sh_defense_x',\n 'shsv_x',\n 'pass_x',\n 'int_defense_x',\n 'clr_x',\n 'err_x',\n 'poss_x',\n 'touches_x',\n 'def pen_x',\n 'def 3rd_possession_x',\n 'mid 3rd_possession_x',\n 'att 3rd_possession_x',\n 'att pen_x',\n 'live_possession_x',\n 'succ_possession_x',\n 'att_possession_x',\n 'succ%_x',\n '#pl_x',\n 'megs_x',\n 'carries_x',\n 'totdist_possession_x',\n 'prgdist_possession_x',\n 'prog_possession_x',\n '1/3_possession_x',\n 'cpa_x',\n 'mis_x',\n 'dis_x',\n 'targ_x',\n 'rec_x',\n 'rec%_x',\n 'prog_possession.1_x',\n 'crdy_x',\n 'crdr_x',\n '2crdy_x',\n 'fls_x',\n 'fld_misc_x',\n 'off_misc_x',\n 'crs_misc_x',\n 'int_misc_x',\n 'tklw_misc_x',\n 'pkwon_x',\n 'pkcon_x',\n 'og_x',\n 'recov_x',\n 'won_x',\n 'lost_x',\n 'won%_x',\n 'team_x',\n 'season',\n 'month',\n 'year',\n 'Win_x']\n\n\n\nplt.plot(df.Win_x\n\n\n\n\n\n  \n    \n      \n      gf_x\n      ga_x\n      sh_shooting_x\n      sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      Win_x\n      season\n    \n  \n  \n    \n      10\n      2.000000\n      0.000000\n      14.000000\n      4.000000\n      19.400000\n      2.000000\n      0.000000\n      0.000000\n      0\n      2017\n    \n    \n      11\n      2.000000\n      0.000000\n      18.000000\n      6.000000\n      18.400000\n      0.000000\n      0.000000\n      0.000000\n      0\n      2017\n    \n    \n      12\n      3.000000\n      3.000000\n      13.000000\n      4.000000\n      13.500000\n      0.000000\n      1.000000\n      1.000000\n      1\n      2017\n    \n    \n      13\n      3.000000\n      2.000000\n      10.000000\n      5.000000\n      12.600000\n      1.000000\n      0.000000\n      0.000000\n      0\n      2017\n    \n    \n      14\n      3.000000\n      4.000000\n      6.000000\n      4.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      1\n      2017\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1895\n      2.666667\n      0.333333\n      15.666667\n      6.333333\n      16.300000\n      0.000000\n      0.333333\n      0.666667\n      1\n      2021\n    \n    \n      1896\n      1.333333\n      0.666667\n      14.666667\n      5.000000\n      15.300000\n      0.333333\n      0.333333\n      0.333333\n      1\n      2021\n    \n    \n      1897\n      2.000000\n      1.666667\n      16.000000\n      5.000000\n      16.400000\n      1.000000\n      0.000000\n      0.000000\n      0\n      2021\n    \n    \n      1898\n      1.000000\n      1.666667\n      13.000000\n      4.333333\n      15.066667\n      0.333333\n      0.000000\n      0.000000\n      0\n      2021\n    \n    \n      1899\n      0.333333\n      2.333333\n      9.666667\n      2.333333\n      18.533333\n      0.333333\n      0.000000\n      0.000000\n      0\n      2021\n    \n  \n\n1887 rows × 10 columns"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#overview",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2022 and 2021 seasons. I will predict whether a result is a win, loss or draw.\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not to use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below.)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who - details of match, limited to those that could be predicted beforehand - referee - captain - formation - attendance\nSome details on the machine learning:\n\nA Random Forest Classifier was used for analysis.\nData is trained on the first 28 game weeks- the other 10 are used for validation\n\n23% validation / 77% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 51.5% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe stats from the last 5 games are the best parameters in predicting results\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nI would say the model probably needs more data to compete and outperform both of the controls consistently.\n\n\nCode- Prepare the data\nData is prepared in a separate page- Predicting Premier League Matches- Prepare the data"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#load-data-and-libraries",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv']\n\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021.csv')\ndfAll\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      0\n      1\n      1\n      13\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      West Ham United\n    \n    \n      1\n      4\n      1\n      12\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n    \n    \n      2\n      5\n      1\n      11\n      NaN\n      NaN\n      NaN\n      Leicester City\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Leicester City\n    \n    \n      3\n      7\n      1\n      12\n      NaN\n      NaN\n      NaN\n      Stoke City\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Stoke City\n    \n    \n      4\n      9\n      1\n      13\n      NaN\n      NaN\n      NaN\n      Tottenham Hotspur\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Tottenham Hotspur\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1895\n      3788\n      38\n      22\n      1.666667\n      2.666667\n      0.333333\n      West Ham United\n      2.666667\n      15.666667\n      6.333333\n      ...\n      12.666667\n      6.666667\n      0.000000\n      0.333333\n      0.333333\n      62.333333\n      14.333333\n      15.000000\n      49.066667\n      West Ham United\n    \n    \n      1896\n      3791\n      38\n      22\n      1.666667\n      1.333333\n      0.666667\n      Manchester United\n      1.333333\n      14.666667\n      5.000000\n      ...\n      19.333333\n      11.333333\n      0.333333\n      0.000000\n      0.000000\n      68.000000\n      17.000000\n      13.333333\n      56.733333\n      Manchester United\n    \n    \n      1897\n      3792\n      38\n      22\n      1.333333\n      2.000000\n      1.666667\n      Leeds United\n      1.666667\n      16.000000\n      5.000000\n      ...\n      12.000000\n      11.666667\n      0.000000\n      0.000000\n      0.000000\n      80.000000\n      12.000000\n      16.333333\n      42.933333\n      Leeds United\n    \n    \n      1898\n      3797\n      38\n      22\n      0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      1899\n      3799\n      38\n      22\n      0.333333\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n1900 rows × 344 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      sot%_x\n      g/sh_x\n      g/sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      xg_x\n      npxg_x\n      npxg/sh_x\n      g-xg_x\n      np:g-xg_x\n      sota_x\n      saves_x\n      save%_x\n      cs_x\n      psxg_x\n      psxg+/-_x\n      pkatt_keeper_x\n      pka_x\n      pksv_x\n      pkm_x\n      cmp_keeper_x\n      att_keeper_x\n      cmp%_keeper_x\n      att_keeper.1_x\n      thr_x\n      launch%_x\n      avglen_x\n      att_keeper.2_x\n      launch%.1_x\n      avglen.1_x\n      opp_x\n      stp_x\n      stp%_x\n      #opa_x\n      avgdist_x\n      cmp_passing_x\n      att_passing_x\n      cmp%_passing_x\n      totdist_passing_x\n      prgdist_passing_x\n      cmp_passing.1_x\n      att_passing.1_x\n      cmp%_passing.1_x\n      cmp_passing.2_x\n      att_passing.2_x\n      cmp%_passing.2_x\n      cmp_passing.3_x\n      att_passing.3_x\n      cmp%_passing.3_x\n      ast_x\n      xa_x\n      kp_x\n      1/3_passing_x\n      ppa_x\n      crspa_x\n      prog_passing_x\n      att_passing_types_x\n      live_passing_types_x\n      dead_x\n      fk_passing_types_x\n      tb_x\n      press_passing_types_x\n      sw_x\n      crs_passing_types_x\n      ck_x\n      in_x\n      out_x\n      str_x\n      ground_x\n      low_x\n      high_x\n      left_x\n      right_x\n      head_x\n      ti_x\n      other_x\n      cmp_passing_types_x\n      off_passing_types_x\n      out.1_x\n      int_passing_types_x\n      blocks_passing_types_x\n      sca_x\n      passlive_x\n      passdead_x\n      drib_x\n      sh_gca_x\n      fld_gca_x\n      def_x\n      gca_x\n      passlive.1_x\n      passdead.1_x\n      drib.1_x\n      sh_gca.1_x\n      fld_gca.1_x\n      def.1_x\n      tkl_x\n      tklw_defense_x\n      def 3rd_defense_x\n      mid 3rd_defense_x\n      att 3rd_defense_x\n      tkl.1_x\n      att_defense_x\n      tkl%_x\n      past_x\n      press_defense_x\n      succ_defense_x\n      %_x\n      def 3rd_defense.1_x\n      mid 3rd_defense.1_x\n      att 3rd_defense.1_x\n      blocks_defense_x\n      sh_defense_x\n      shsv_x\n      pass_x\n      int_defense_x\n      clr_x\n      err_x\n      poss_x\n      touches_x\n      def pen_x\n      def 3rd_possession_x\n      mid 3rd_possession_x\n      att 3rd_possession_x\n      att pen_x\n      live_possession_x\n      succ_possession_x\n      att_possession_x\n      succ%_x\n      #pl_x\n      megs_x\n      carries_x\n      totdist_possession_x\n      prgdist_possession_x\n      prog_possession_x\n      1/3_possession_x\n      cpa_x\n      mis_x\n      dis_x\n      targ_x\n      rec_x\n      rec%_x\n      prog_possession.1_x\n      crdy_x\n      crdr_x\n      2crdy_x\n      fls_x\n      fld_misc_x\n      off_misc_x\n      crs_misc_x\n      int_misc_x\n      tklw_misc_x\n      pkwon_x\n      pkcon_x\n      og_x\n      recov_x\n      won_x\n      lost_x\n      won%_x\n      team_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      result_y\n      gf_y\n      ga_y\n      opponent_y\n      gls_y\n      sh_shooting_y\n      sot_y\n      sot%_y\n      g/sh_y\n      g/sot_y\n      dist_y\n      fk_shooting_y\n      pk_y\n      pkatt_shooting_y\n      xg_y\n      npxg_y\n      npxg/sh_y\n      g-xg_y\n      np:g-xg_y\n      sota_y\n      saves_y\n      save%_y\n      cs_y\n      psxg_y\n      psxg+/-_y\n      pkatt_keeper_y\n      pka_y\n      pksv_y\n      pkm_y\n      cmp_keeper_y\n      att_keeper_y\n      cmp%_keeper_y\n      att_keeper.1_y\n      thr_y\n      launch%_y\n      avglen_y\n      att_keeper.2_y\n      launch%.1_y\n      avglen.1_y\n      opp_y\n      stp_y\n      stp%_y\n      #opa_y\n      avgdist_y\n      cmp_passing_y\n      att_passing_y\n      cmp%_passing_y\n      totdist_passing_y\n      prgdist_passing_y\n      cmp_passing.1_y\n      att_passing.1_y\n      cmp%_passing.1_y\n      cmp_passing.2_y\n      att_passing.2_y\n      cmp%_passing.2_y\n      cmp_passing.3_y\n      att_passing.3_y\n      cmp%_passing.3_y\n      ast_y\n      xa_y\n      kp_y\n      1/3_passing_y\n      ppa_y\n      crspa_y\n      prog_passing_y\n      att_passing_types_y\n      live_passing_types_y\n      dead_y\n      fk_passing_types_y\n      tb_y\n      press_passing_types_y\n      sw_y\n      crs_passing_types_y\n      ck_y\n      in_y\n      out_y\n      str_y\n      ground_y\n      low_y\n      high_y\n      left_y\n      right_y\n      head_y\n      ti_y\n      other_y\n      cmp_passing_types_y\n      off_passing_types_y\n      out.1_y\n      int_passing_types_y\n      blocks_passing_types_y\n      sca_y\n      passlive_y\n      passdead_y\n      drib_y\n      sh_gca_y\n      fld_gca_y\n      def_y\n      gca_y\n      passlive.1_y\n      passdead.1_y\n      drib.1_y\n      sh_gca.1_y\n      fld_gca.1_y\n      def.1_y\n      tkl_y\n      tklw_defense_y\n      def 3rd_defense_y\n      mid 3rd_defense_y\n      att 3rd_defense_y\n      tkl.1_y\n      att_defense_y\n      tkl%_y\n      past_y\n      press_defense_y\n      succ_defense_y\n      %_y\n      def 3rd_defense.1_y\n      mid 3rd_defense.1_y\n      att 3rd_defense.1_y\n      blocks_defense_y\n      sh_defense_y\n      shsv_y\n      pass_y\n      int_defense_y\n      clr_y\n      err_y\n      poss_y\n      touches_y\n      def pen_y\n      def 3rd_possession_y\n      mid 3rd_possession_y\n      att 3rd_possession_y\n      att pen_y\n      live_possession_y\n      succ_possession_y\n      att_possession_y\n      succ%_y\n      #pl_y\n      megs_y\n      carries_y\n      totdist_possession_y\n      prgdist_possession_y\n      prog_possession_y\n      1/3_possession_y\n      cpa_y\n      mis_y\n      dis_y\n      targ_y\n      rec_y\n      rec%_y\n      prog_possession.1_y\n      crdy_y\n      crdr_y\n      2crdy_y\n      fls_y\n      fld_misc_y\n      off_misc_y\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      count\n      1900.000000\n      1900.000000\n      1900.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1900\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1886.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1886.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1887.000000\n      1900\n      1900.000000\n      1900.000000\n      1900.000000\n      1900.000000\n      1900\n      1885.000000\n      1885.000000\n      1885.000000\n      1900\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1885.000000\n      1900\n    \n    \n      unique\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n    \n    \n      top\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      W\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n    \n    \n      freq\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      95\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      95\n      NaN\n      NaN\n      NaN\n      NaN\n      833\n      NaN\n      NaN\n      NaN\n      95\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      95\n    \n    \n      mean\n      1899.500000\n      19.500000\n      15.898421\n      0.981275\n      1.348613\n      1.384384\n      NaN\n      1.303745\n      12.114821\n      4.026409\n      33.733678\n      0.103473\n      0.295749\n      17.072311\n      0.449391\n      0.100601\n      0.127628\n      1.298472\n      1.201890\n      0.100960\n      0.005273\n      0.001254\n      4.135223\n      2.855856\n      68.903853\n      0.279456\n      1.345345\n      0.006006\n      0.133899\n      0.104575\n      0.022081\n      0.007243\n      6.758612\n      17.588059\n      41.225057\n      24.244568\n      4.087970\n      51.351016\n      42.636584\n      7.580198\n      67.203542\n      52.586654\n      8.913355\n      0.671524\n      7.550442\n      0.644409\n      14.386937\n      388.891274\n      492.537361\n      77.164414\n      7641.028352\n      2558.818053\n      158.735206\n      180.984897\n      86.644515\n      164.931461\n      192.286169\n      83.897553\n      58.174527\n      100.678237\n      56.828052\n      0.935082\n      0.884941\n      8.780427\n      29.078520\n      8.121092\n      1.944709\n      32.064211\n      492.537361\n      444.751899\n      47.785462\n      11.694135\n      0.920774\n      74.121003\n      14.462197\n      11.809751\n      5.095478\n      2.139286\n      1.731143\n      0.399753\n      321.328211\n      67.803303\n      103.405847\n      135.954425\n      294.845345\n      20.424925\n      21.012365\n      6.499205\n      388.891274\n      1.642731\n      8.930136\n      11.704469\n      12.023582\n      18.906289\n      13.642908\n      1.663929\n      1.160661\n      0.968998\n      1.045487\n      0.424307\n      2.121798\n      1.457781\n      0.142024\n      0.143879\n      0.175146\n      0.154213\n      0.048755\n      17.752694\n      10.716570\n      8.989313\n      6.634164\n      2.129217\n      6.005211\n      16.475534\n      36.579765\n      10.470323\n      150.920155\n      43.718248\n      29.466393\n      53.042219\n      65.075075\n      32.802862\n      15.953100\n      3.864335\n      0.080639\n      12.088765\n      12.303568\n      25.391715\n      0.277778\n      49.794471\n      613.384473\n      66.492316\n      200.964671\n      289.074545\n      160.185921\n      23.606077\n      566.688571\n      9.590178\n      16.423688\n      58.240761\n      10.422893\n      0.710564\n      381.649620\n      1946.036213\n      1046.398075\n      42.419007\n      12.752164\n      4.159424\n      12.226020\n      11.763911\n      463.668610\n      388.891274\n      82.442943\n      34.198816\n      1.649709\n      0.059883\n      0.025349\n      12.391892\n      11.972178\n      1.849585\n      11.809751\n      12.303568\n      10.716570\n      0.106783\n      0.127363\n      0.045398\n      89.831832\n      19.251016\n      19.192457\n      50.053021\n      NaN\n      2019.000000\n      6.783684\n      2019.502105\n      4.369474\n      NaN\n      1.019452\n      1.394164\n      1.357913\n      NaN\n      1.350928\n      12.542794\n      4.147126\n      33.628974\n      0.103412\n      0.296049\n      17.005402\n      0.465252\n      0.106720\n      0.134483\n      1.343775\n      1.241813\n      0.101071\n      0.007153\n      0.002396\n      4.028559\n      2.772679\n      68.942476\n      0.294518\n      1.318400\n      0.003899\n      0.133245\n      0.103714\n      0.021751\n      0.007781\n      6.664633\n      17.180460\n      41.582263\n      24.047303\n      4.079222\n      50.730752\n      42.360955\n      7.347834\n      66.706225\n      52.362776\n      8.600973\n      0.653935\n      7.557745\n      0.655615\n      14.457374\n      393.315915\n      497.116092\n      77.334757\n      7716.688859\n      2578.746154\n      160.743148\n      183.147303\n      86.690531\n      166.674713\n      194.160389\n      83.990256\n      58.696375\n      100.996286\n      57.213572\n      0.958886\n      0.912387\n      9.089567\n      29.760743\n      8.403890\n      2.037577\n      32.761362\n      497.116092\n      449.316888\n      47.799204\n      11.632361\n      0.939346\n      74.330416\n      14.539257\n      12.193280\n      5.269231\n      2.218744\n      1.782405\n      0.397436\n      325.532007\n      67.987710\n      103.596375\n      137.411229\n      297.718479\n      20.550663\n      21.171530\n      6.524138\n      393.315915\n      1.669938\n      8.890097\n      11.775950\n      12.071176\n      19.572944\n      14.123784\n      1.717241\n      1.208488\n      1.018214\n      1.069850\n      0.435367\n      2.188329\n      1.490363\n      0.143767\n      0.150663\n      0.187798\n      0.165429\n      0.050309\n      17.783466\n      10.777542\n      8.864633\n      6.707339\n      2.211494\n      5.972944\n      16.418568\n      36.510177\n      10.445623\n      150.598320\n      43.888240\n      29.662538\n      51.744209\n      65.314943\n      33.539169\n      15.756322\n      3.754907\n      0.081698\n      12.001415\n      12.301503\n      24.903271\n      0.268789\n      50.256852\n      617.632449\n      64.989744\n      198.262511\n      292.036251\n      164.680195\n      24.284085\n      570.912290\n      9.664898\n      16.536693\n      58.282299\n      10.489567\n      0.719629\n      385.818391\n      1975.821751\n      1064.124050\n      43.414147\n      13.084085\n      4.244828\n      12.209372\n      11.802122\n      468.212025\n      393.315915\n      82.592440\n      34.972679\n      1.617860\n      0.057913\n      0.022812\n      12.375066\n      11.976835\n      1.889390\n      12.193280\n      12.301503\n      10.777542\n      0.112555\n      0.128647\n      0.043590\n      90.371618\n      19.201503\n      19.248806\n      49.947038\n      NaN\n    \n    \n      std\n      1097.253898\n      10.968743\n      9.032951\n      0.562990\n      0.821883\n      0.785860\n      NaN\n      0.804609\n      3.604429\n      1.602244\n      9.903141\n      0.065570\n      0.165471\n      1.924068\n      0.400656\n      0.186497\n      0.210009\n      0.539552\n      0.501255\n      0.028464\n      0.559989\n      0.556278\n      1.552937\n      1.210365\n      17.491508\n      0.271230\n      0.629407\n      0.438295\n      0.217505\n      0.189225\n      0.088425\n      0.052120\n      2.660282\n      6.832762\n      11.726573\n      5.616292\n      1.715115\n      19.941490\n      9.586412\n      2.184880\n      24.470953\n      13.806232\n      2.816386\n      0.539412\n      6.476357\n      0.572101\n      3.176210\n      119.229069\n      116.071850\n      6.144141\n      2168.848871\n      445.699643\n      50.744911\n      52.013891\n      3.643398\n      59.005557\n      59.215437\n      5.401759\n      14.684347\n      13.592733\n      8.982522\n      0.666895\n      0.399544\n      2.870647\n      10.251511\n      3.403934\n      0.983293\n      10.231721\n      116.071850\n      116.835035\n      5.205801\n      2.417642\n      0.819581\n      19.067863\n      4.485810\n      3.426532\n      1.843978\n      1.226782\n      1.228117\n      0.563332\n      117.228523\n      14.824503\n      17.732367\n      49.991609\n      89.158574\n      5.061035\n      3.878356\n      2.018556\n      119.229069\n      0.906005\n      2.228578\n      4.818136\n      2.640678\n      6.149121\n      5.048727\n      0.842950\n      0.764914\n      0.690645\n      0.595341\n      0.404329\n      1.403242\n      1.128908\n      0.214357\n      0.251739\n      0.249517\n      0.235028\n      0.132418\n      3.486760\n      2.321194\n      2.604811\n      1.869853\n      1.015222\n      1.928814\n      3.932232\n      8.482969\n      2.871477\n      28.004395\n      8.310211\n      4.019124\n      15.206973\n      13.690141\n      8.566743\n      3.450404\n      1.723662\n      0.172795\n      2.669393\n      4.950353\n      7.901514\n      0.338057\n      9.654077\n      112.185015\n      11.791488\n      29.665480\n      73.462201\n      47.891499\n      8.135065\n      112.874321\n      2.904043\n      4.134119\n      9.007144\n      3.056041\n      0.574513\n      108.474565\n      555.165722\n      343.059723\n      16.988892\n      4.900100\n      2.137224\n      2.450544\n      2.720636\n      118.818312\n      119.229069\n      5.176446\n      10.821910\n      0.744174\n      0.139770\n      0.091251\n      2.557418\n      2.618130\n      0.965104\n      3.426532\n      4.950353\n      2.321194\n      0.192593\n      0.209222\n      0.122086\n      11.271895\n      5.651655\n      5.762810\n      6.334482\n      NaN\n      1.414586\n      3.941522\n      1.534060\n      1.790301\n      NaN\n      0.552615\n      0.807042\n      0.773021\n      NaN\n      0.797606\n      3.627001\n      1.623645\n      9.439212\n      0.062460\n      0.158243\n      1.854209\n      0.408448\n      0.192914\n      0.217812\n      0.542758\n      0.500615\n      0.028187\n      0.548397\n      0.546242\n      1.531216\n      1.180476\n      17.188190\n      0.275738\n      0.618038\n      0.420442\n      0.219380\n      0.189636\n      0.089879\n      0.051501\n      2.703961\n      6.855387\n      11.862575\n      5.541456\n      1.641207\n      20.175225\n      9.649619\n      2.115403\n      24.974972\n      13.990437\n      2.787519\n      0.525688\n      6.332470\n      0.567261\n      3.141355\n      120.349836\n      116.921562\n      6.151168\n      2170.967839\n      444.312969\n      51.702598\n      52.846013\n      3.671086\n      59.408668\n      59.649384\n      5.348855\n      14.399394\n      13.379318\n      8.932960\n      0.670045\n      0.405043\n      2.929930\n      10.425809\n      3.474786\n      0.996109\n      10.419660\n      116.921562\n      117.856119\n      5.108167\n      2.394477\n      0.837783\n      18.926442\n      4.461939\n      3.465959\n      1.852495\n      1.273013\n      1.253528\n      0.555805\n      119.017408\n      14.350673\n      17.779460\n      50.632261\n      89.905177\n      5.074563\n      3.824267\n      1.953636\n      120.349836\n      0.905120\n      2.222899\n      4.840289\n      2.638053\n      6.235966\n      5.138590\n      0.855581\n      0.774006\n      0.707101\n      0.609149\n      0.411871\n      1.389641\n      1.130901\n      0.220694\n      0.251019\n      0.263766\n      0.243332\n      0.135716\n      3.497036\n      2.283436\n      2.575933\n      1.880128\n      1.026761\n      1.903147\n      3.991825\n      8.613304\n      2.975346\n      27.787039\n      8.192015\n      3.904190\n      14.934585\n      13.454384\n      8.855899\n      3.427076\n      1.641214\n      0.176925\n      2.692379\n      4.848354\n      7.741390\n      0.326118\n      9.582076\n      113.150911\n      11.346986\n      29.170312\n      75.558722\n      47.850712\n      8.148257\n      113.983664\n      2.935263\n      4.119026\n      8.891462\n      3.069472\n      0.559645\n      110.104248\n      567.762012\n      352.252975\n      17.649311\n      5.005604\n      2.101465\n      2.442809\n      2.752240\n      119.845963\n      120.349836\n      5.157349\n      10.905252\n      0.753974\n      0.145882\n      0.090107\n      2.516177\n      2.584682\n      0.962440\n      3.465959\n      4.848354\n      2.283436\n      0.198533\n      0.213166\n      0.119223\n      11.291527\n      5.667756\n      5.856177\n      6.246339\n      NaN\n    \n    \n      min\n      1.000000\n      1.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.200000\n      0.030000\n      -2.100000\n      -2.100000\n      0.000000\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      1.000000\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.666667\n      0.000000\n      11.400000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      5.500000\n      157.000000\n      251.666667\n      58.200000\n      3334.666667\n      1419.000000\n      58.000000\n      70.000000\n      68.133333\n      55.666667\n      78.000000\n      63.566667\n      26.333333\n      68.000000\n      33.233333\n      0.000000\n      0.133333\n      1.666667\n      10.333333\n      0.333333\n      0.000000\n      8.000000\n      251.666667\n      212.000000\n      32.333333\n      4.333333\n      0.000000\n      32.000000\n      4.333333\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      88.000000\n      31.333333\n      57.666667\n      37.000000\n      118.500000\n      7.666667\n      7.000000\n      0.666667\n      157.000000\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      4.666667\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      4.000000\n      2.000000\n      1.333333\n      0.000000\n      1.000000\n      6.000000\n      9.166667\n      2.666667\n      80.333333\n      19.333333\n      13.700000\n      15.666667\n      31.333333\n      12.666667\n      6.000000\n      0.000000\n      0.000000\n      5.000000\n      1.666667\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      25.000000\n      116.000000\n      140.666667\n      54.666667\n      5.666667\n      324.333333\n      2.666667\n      5.000000\n      28.600000\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      348.666667\n      12.000000\n      1.000000\n      0.000000\n      5.000000\n      4.000000\n      219.333333\n      157.000000\n      63.700000\n      11.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      4.666667\n      0.000000\n      3.000000\n      1.666667\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      0.000000\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      4.000000\n      0.333333\n      5.000000\n      0.000000\n      0.000000\n      11.766667\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.700000\n      -1.700000\n      0.666667\n      0.000000\n      -8.333333\n      0.000000\n      0.000000\n      -1.800000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      11.100000\n      10.000000\n      0.333333\n      8.200000\n      22.500000\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      137.000000\n      235.000000\n      58.300000\n      3027.000000\n      1359.000000\n      53.000000\n      68.000000\n      71.333333\n      51.000000\n      72.000000\n      64.733333\n      27.000000\n      65.666667\n      32.133333\n      0.000000\n      0.100000\n      2.000000\n      9.000000\n      0.000000\n      0.000000\n      6.000000\n      235.000000\n      190.000000\n      29.666667\n      3.000000\n      0.000000\n      34.000000\n      4.666667\n      3.333333\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      103.666667\n      27.666667\n      54.333333\n      42.000000\n      112.000000\n      7.000000\n      10.000000\n      1.000000\n      137.000000\n      0.000000\n      2.666667\n      1.666667\n      5.000000\n      5.500000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      8.000000\n      4.333333\n      1.666667\n      1.000000\n      0.000000\n      1.333333\n      6.000000\n      11.666667\n      2.000000\n      66.000000\n      17.333333\n      16.966667\n      12.000000\n      30.666667\n      9.500000\n      6.333333\n      0.000000\n      0.000000\n      4.666667\n      1.333333\n      6.666667\n      0.000000\n      23.000000\n      346.000000\n      32.000000\n      112.000000\n      124.000000\n      55.000000\n      6.000000\n      303.000000\n      2.000000\n      6.000000\n      22.333333\n      3.000000\n      0.000000\n      142.000000\n      780.000000\n      356.000000\n      9.000000\n      2.000000\n      0.000000\n      5.000000\n      3.666667\n      203.000000\n      137.000000\n      61.866667\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.333333\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      51.666667\n      5.000000\n      6.000000\n      28.633333\n      NaN\n    \n    \n      25%\n      950.750000\n      10.000000\n      8.000000\n      0.666667\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.150000\n      0.056667\n      0.170000\n      15.733333\n      0.000000\n      0.000000\n      0.000000\n      0.900000\n      0.833333\n      0.080000\n      -0.400000\n      -0.400000\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.333333\n      33.100000\n      20.333333\n      3.000000\n      34.716667\n      34.866667\n      6.000000\n      48.900000\n      41.616667\n      7.000000\n      0.333333\n      2.766667\n      0.333333\n      12.233333\n      299.833333\n      406.666667\n      73.000000\n      6008.666667\n      2243.166667\n      121.666667\n      143.000000\n      84.400000\n      119.333333\n      146.666667\n      80.400000\n      47.333333\n      91.333333\n      50.250000\n      0.333333\n      0.600000\n      6.666667\n      22.000000\n      5.666667\n      1.333333\n      24.666667\n      406.666667\n      358.333333\n      44.333333\n      10.000000\n      0.333333\n      61.000000\n      11.000000\n      9.333333\n      4.000000\n      1.333333\n      0.666667\n      0.000000\n      232.833333\n      57.333333\n      90.666667\n      102.666667\n      227.666667\n      17.000000\n      18.333333\n      5.000000\n      299.833333\n      1.000000\n      7.333333\n      8.000000\n      10.000000\n      14.666667\n      10.000000\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.000000\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.000000\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.650000\n      8.333333\n      130.333333\n      38.000000\n      26.766667\n      42.333333\n      55.000000\n      26.666667\n      13.333333\n      2.666667\n      0.000000\n      10.333333\n      8.333333\n      20.000000\n      0.000000\n      42.666667\n      530.166667\n      58.333333\n      179.333333\n      235.666667\n      127.666667\n      17.666667\n      483.333333\n      7.666667\n      13.666667\n      52.583333\n      8.333333\n      0.333333\n      301.666667\n      1526.500000\n      788.166667\n      30.333333\n      9.333333\n      2.666667\n      10.666667\n      9.833333\n      374.333333\n      299.833333\n      79.116667\n      26.333333\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.000000\n      1.000000\n      9.333333\n      8.333333\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      82.000000\n      15.333333\n      15.000000\n      46.066667\n      NaN\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      0.666667\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      10.000000\n      3.000000\n      27.266667\n      0.060000\n      0.183333\n      15.766667\n      0.000000\n      0.000000\n      0.000000\n      0.966667\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.566667\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      11.666667\n      33.333333\n      20.000000\n      3.000000\n      34.466667\n      34.500000\n      6.000000\n      46.800000\n      40.966667\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.300000\n      305.000000\n      411.666667\n      73.033333\n      6110.666667\n      2265.000000\n      123.333333\n      145.000000\n      84.366667\n      121.333333\n      149.333333\n      80.600000\n      48.000000\n      91.333333\n      50.400000\n      0.333333\n      0.633333\n      7.000000\n      22.333333\n      6.000000\n      1.333333\n      25.333333\n      411.666667\n      362.333333\n      44.333333\n      10.000000\n      0.333333\n      60.666667\n      11.333333\n      9.666667\n      4.000000\n      1.333333\n      1.000000\n      0.000000\n      235.000000\n      57.333333\n      91.000000\n      105.333333\n      230.666667\n      17.000000\n      18.666667\n      5.333333\n      305.000000\n      1.000000\n      7.333333\n      8.000000\n      10.333333\n      15.333333\n      10.333333\n      1.000000\n      0.666667\n      0.666667\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.333333\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.533333\n      8.333333\n      131.000000\n      38.333333\n      27.066667\n      41.333333\n      56.000000\n      27.000000\n      13.333333\n      2.666667\n      0.000000\n      10.000000\n      8.333333\n      19.333333\n      0.000000\n      43.333333\n      535.666667\n      57.000000\n      178.000000\n      238.000000\n      132.000000\n      18.333333\n      489.000000\n      7.333333\n      13.666667\n      52.466667\n      8.333333\n      0.333333\n      303.000000\n      1534.333333\n      796.666667\n      30.333333\n      9.666667\n      2.666667\n      10.333333\n      10.000000\n      379.666667\n      305.000000\n      79.166667\n      27.000000\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.333333\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.833333\n      NaN\n    \n    \n      50%\n      1898.500000\n      19.500000\n      16.000000\n      1.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      11.666667\n      3.666667\n      33.333333\n      0.096667\n      0.276667\n      16.966667\n      0.333333\n      0.000000\n      0.000000\n      1.200000\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      71.133333\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.666667\n      17.666667\n      39.766667\n      23.666667\n      4.000000\n      51.300000\n      42.100000\n      7.666667\n      70.933333\n      53.866667\n      8.666667\n      0.666667\n      6.466667\n      0.666667\n      14.133333\n      366.666667\n      472.666667\n      77.433333\n      7265.333333\n      2498.333333\n      150.000000\n      172.666667\n      87.000000\n      154.000000\n      182.333333\n      84.700000\n      56.000000\n      100.000000\n      56.366667\n      0.666667\n      0.833333\n      8.333333\n      26.666667\n      7.333333\n      1.666667\n      30.333333\n      472.666667\n      423.000000\n      47.666667\n      11.666667\n      0.666667\n      71.333333\n      14.000000\n      11.333333\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      300.000000\n      66.333333\n      102.333333\n      126.000000\n      282.000000\n      20.000000\n      20.666667\n      6.333333\n      366.666667\n      1.666667\n      9.000000\n      11.333333\n      12.000000\n      18.333333\n      12.666667\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      9.000000\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.333333\n      10.333333\n      148.666667\n      43.333333\n      29.433333\n      51.666667\n      64.000000\n      32.000000\n      16.000000\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.666667\n      0.333333\n      49.333333\n      596.333333\n      65.666667\n      199.333333\n      278.333333\n      150.000000\n      22.333333\n      547.666667\n      9.333333\n      16.333333\n      58.300000\n      10.333333\n      0.666667\n      361.666667\n      1874.000000\n      995.666667\n      39.000000\n      12.000000\n      3.666667\n      12.000000\n      11.666667\n      444.000000\n      366.666667\n      82.866667\n      32.333333\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      11.666667\n      1.666667\n      11.333333\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.333333\n      18.666667\n      18.666667\n      49.966667\n      NaN\n      2019.000000\n      7.000000\n      2019.000000\n      5.000000\n      NaN\n      1.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.333333\n      4.000000\n      33.233333\n      0.096667\n      0.280000\n      16.933333\n      0.333333\n      0.000000\n      0.000000\n      1.266667\n      1.166667\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.333333\n      40.400000\n      23.666667\n      4.000000\n      51.200000\n      41.866667\n      7.333333\n      71.166667\n      54.000000\n      8.333333\n      0.666667\n      6.533333\n      0.666667\n      14.266667\n      372.333333\n      478.666667\n      77.666667\n      7365.333333\n      2526.333333\n      151.666667\n      174.333333\n      87.100000\n      157.000000\n      184.000000\n      84.800000\n      57.000000\n      100.333333\n      56.766667\n      1.000000\n      0.833333\n      8.666667\n      27.333333\n      7.666667\n      2.000000\n      31.000000\n      478.666667\n      429.333333\n      48.000000\n      11.666667\n      0.666667\n      72.000000\n      14.000000\n      12.000000\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      306.000000\n      67.000000\n      102.333333\n      127.000000\n      284.000000\n      20.333333\n      21.000000\n      6.333333\n      372.333333\n      1.666667\n      8.666667\n      11.666667\n      12.000000\n      19.000000\n      13.333333\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      8.666667\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.366667\n      10.333333\n      148.666667\n      43.333333\n      29.533333\n      51.000000\n      64.000000\n      32.666667\n      15.666667\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.333333\n      0.333333\n      49.666667\n      599.666667\n      64.333333\n      195.666667\n      279.666667\n      155.333333\n      23.000000\n      551.666667\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      369.333333\n      1916.666667\n      1013.666667\n      40.000000\n      12.000000\n      4.000000\n      12.333333\n      11.666667\n      448.666667\n      372.333333\n      83.133333\n      33.666667\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      12.000000\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      90.000000\n      18.666667\n      18.666667\n      49.800000\n      NaN\n    \n    \n      75%\n      2853.500000\n      29.000000\n      23.000000\n      1.333333\n      1.666667\n      2.000000\n      NaN\n      1.666667\n      14.333333\n      5.000000\n      40.300000\n      0.140000\n      0.400000\n      18.233333\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.466667\n      0.116667\n      0.366667\n      0.333333\n      5.000000\n      3.666667\n      80.966667\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.666667\n      47.883333\n      27.666667\n      5.000000\n      66.800000\n      50.016667\n      9.000000\n      88.900000\n      63.683333\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.100000\n      461.250000\n      566.166667\n      81.783333\n      8979.000000\n      2816.833333\n      186.000000\n      210.000000\n      89.250000\n      202.666667\n      230.500000\n      88.016667\n      67.000000\n      109.333333\n      63.116667\n      1.333333\n      1.100000\n      10.666667\n      33.666667\n      10.000000\n      2.666667\n      37.500000\n      566.166667\n      517.500000\n      51.333333\n      13.333333\n      1.333333\n      85.000000\n      17.000000\n      14.000000\n      6.000000\n      3.000000\n      2.333333\n      0.666667\n      396.000000\n      76.666667\n      115.333333\n      155.500000\n      350.500000\n      23.666667\n      23.333333\n      7.666667\n      461.250000\n      2.000000\n      10.333333\n      15.000000\n      13.666667\n      22.666667\n      16.666667\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      7.666667\n      2.666667\n      7.333333\n      18.666667\n      42.083333\n      12.333333\n      168.333333\n      49.000000\n      32.100000\n      62.000000\n      73.666667\n      38.000000\n      18.000000\n      5.000000\n      0.000000\n      14.000000\n      15.833333\n      30.000000\n      0.333333\n      56.333333\n      683.666667\n      73.666667\n      220.000000\n      328.333333\n      182.333333\n      28.000000\n      637.666667\n      11.333333\n      19.000000\n      64.150000\n      12.333333\n      1.000000\n      448.833333\n      2302.166667\n      1252.000000\n      51.666667\n      15.333333\n      5.333333\n      13.666667\n      13.333333\n      537.333333\n      461.250000\n      86.233333\n      40.333333\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.833333\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.333333\n      22.666667\n      23.000000\n      54.050000\n      NaN\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      1.333333\n      2.000000\n      2.000000\n      NaN\n      1.666667\n      14.666667\n      5.333333\n      39.433333\n      0.136667\n      0.396667\n      18.166667\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.566667\n      0.333333\n      1.700000\n      0.266667\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.200000\n      27.333333\n      5.000000\n      66.400000\n      49.666667\n      8.666667\n      88.900000\n      63.933333\n      10.333333\n      1.000000\n      11.100000\n      1.000000\n      16.333333\n      465.666667\n      566.666667\n      82.000000\n      8991.000000\n      2841.666667\n      190.000000\n      213.666667\n      89.366667\n      203.666667\n      229.666667\n      88.066667\n      68.000000\n      109.333333\n      63.766667\n      1.333333\n      1.133333\n      11.000000\n      34.333333\n      10.333333\n      2.666667\n      38.000000\n      566.666667\n      519.666667\n      51.333333\n      13.000000\n      1.333333\n      85.000000\n      17.333333\n      14.333333\n      6.333333\n      3.000000\n      2.333333\n      0.666667\n      397.666667\n      77.333333\n      115.666667\n      156.000000\n      355.000000\n      23.666667\n      23.666667\n      7.666667\n      465.666667\n      2.333333\n      10.333333\n      15.000000\n      13.666667\n      23.333333\n      17.333333\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      8.000000\n      3.000000\n      7.000000\n      18.666667\n      42.133333\n      12.000000\n      167.666667\n      49.000000\n      32.266667\n      60.666667\n      74.000000\n      39.333333\n      18.000000\n      4.666667\n      0.000000\n      14.000000\n      15.666667\n      29.333333\n      0.333333\n      56.666667\n      686.000000\n      72.000000\n      217.333333\n      334.000000\n      187.666667\n      28.666667\n      639.333333\n      11.333333\n      19.000000\n      64.300000\n      12.333333\n      1.000000\n      452.333333\n      2354.000000\n      1290.000000\n      53.000000\n      15.666667\n      5.333333\n      13.666667\n      13.666667\n      539.000000\n      465.666667\n      86.433333\n      41.000000\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.333333\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      98.000000\n      23.000000\n      23.000000\n      53.933333\n      NaN\n    \n    \n      max\n      3799.000000\n      38.000000\n      31.000000\n      2.000000\n      4.666667\n      5.666667\n      NaN\n      4.666667\n      28.000000\n      10.000000\n      66.966667\n      0.500000\n      1.000000\n      25.600000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.233333\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.000000\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      37.333333\n      90.000000\n      47.333333\n      10.666667\n      98.933333\n      71.100000\n      22.000000\n      100.000000\n      85.850000\n      19.666667\n      3.333333\n      44.766667\n      3.666667\n      40.666667\n      841.666667\n      927.333333\n      90.833333\n      15066.666667\n      4280.333333\n      392.666667\n      416.000000\n      94.600000\n      366.666667\n      397.000000\n      94.266667\n      117.666667\n      164.000000\n      83.633333\n      4.333333\n      2.833333\n      22.000000\n      71.000000\n      24.333333\n      8.000000\n      76.666667\n      927.333333\n      884.000000\n      67.000000\n      20.000000\n      5.333333\n      171.333333\n      31.000000\n      26.666667\n      14.000000\n      8.000000\n      8.000000\n      5.000000\n      786.000000\n      141.333333\n      169.000000\n      400.333333\n      609.333333\n      42.333333\n      36.333333\n      14.333333\n      841.666667\n      7.000000\n      16.333333\n      32.666667\n      22.333333\n      45.000000\n      38.000000\n      5.000000\n      5.666667\n      5.666667\n      3.666667\n      2.000000\n      8.666667\n      8.000000\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      18.666667\n      21.000000\n      14.000000\n      6.666667\n      17.666667\n      36.333333\n      66.700000\n      24.000000\n      268.333333\n      83.000000\n      43.100000\n      122.666667\n      122.000000\n      76.666667\n      30.666667\n      14.666667\n      1.000000\n      22.666667\n      31.666667\n      62.666667\n      2.666667\n      77.666667\n      1023.666667\n      141.000000\n      363.000000\n      598.333333\n      367.666667\n      63.333333\n      981.333333\n      24.333333\n      36.333333\n      90.000000\n      25.666667\n      4.666667\n      746.333333\n      3773.333333\n      2269.666667\n      109.666667\n      35.666667\n      14.333333\n      23.000000\n      23.000000\n      912.000000\n      841.666667\n      94.300000\n      76.666667\n      4.333333\n      1.000000\n      0.666667\n      21.000000\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      18.666667\n      1.666667\n      2.000000\n      1.000000\n      126.000000\n      50.333333\n      43.000000\n      75.766667\n      NaN\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      2.000000\n      5.666667\n      4.666667\n      NaN\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.426667\n      1.000000\n      25.033333\n      3.000000\n      1.000000\n      1.000000\n      3.666667\n      3.300000\n      0.240000\n      2.366667\n      2.366667\n      10.333333\n      8.000000\n      100.000000\n      1.333333\n      3.766667\n      1.500000\n      1.500000\n      1.500000\n      1.000000\n      0.666667\n      16.333333\n      42.000000\n      95.233333\n      50.333333\n      10.333333\n      100.000000\n      71.666667\n      16.000000\n      100.000000\n      81.833333\n      21.333333\n      3.666667\n      42.933333\n      3.333333\n      40.266667\n      846.333333\n      930.666667\n      91.066667\n      14734.333333\n      4056.666667\n      406.333333\n      429.333333\n      95.100000\n      356.666667\n      385.000000\n      94.633333\n      114.666667\n      164.000000\n      80.666667\n      5.000000\n      2.700000\n      25.000000\n      79.333333\n      25.333333\n      6.333333\n      76.333333\n      930.666667\n      890.666667\n      66.333333\n      20.500000\n      5.333333\n      162.333333\n      35.000000\n      25.666667\n      12.666667\n      7.000000\n      9.333333\n      3.666667\n      772.666667\n      126.000000\n      165.666667\n      362.000000\n      620.000000\n      40.000000\n      33.666667\n      14.666667\n      846.333333\n      6.000000\n      16.666667\n      32.666667\n      21.333333\n      50.000000\n      39.000000\n      5.333333\n      5.000000\n      5.666667\n      3.333333\n      2.333333\n      10.666667\n      8.666667\n      1.000000\n      2.000000\n      2.000000\n      1.333333\n      0.666667\n      31.333333\n      19.666667\n      17.666667\n      16.000000\n      6.000000\n      15.000000\n      39.000000\n      71.400000\n      27.000000\n      259.333333\n      79.333333\n      45.566667\n      125.000000\n      123.666667\n      75.666667\n      29.333333\n      11.666667\n      1.333333\n      21.000000\n      31.666667\n      57.666667\n      2.333333\n      78.333333\n      1024.000000\n      114.666667\n      311.333333\n      651.666667\n      382.333333\n      67.000000\n      984.666667\n      26.000000\n      39.000000\n      84.433333\n      27.000000\n      4.000000\n      737.666667\n      4209.000000\n      2418.333333\n      116.000000\n      37.000000\n      14.666667\n      23.000000\n      25.333333\n      914.666667\n      846.333333\n      93.333333\n      78.333333\n      5.000000\n      2.000000\n      1.000000\n      22.333333\n      22.000000\n      6.666667\n      25.666667\n      31.666667\n      19.666667\n      1.000000\n      1.500000\n      1.000000\n      126.666667\n      43.000000\n      45.333333\n      72.166667\n      NaN\n    \n  \n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom dtreeviz.trees import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\n\nfrom sklearn.experimental import enable_halving_search_cv  # noqa\nfrom sklearn.model_selection import HalvingRandomSearchCV\n\n\nTrain / Valid split\nIn this case valid is actually test as train will be split by fits into train and valid\n\nimport copy\ndf=copy.copy(dfAll)\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\n\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/len(df)\n\n0.2\n\n\n\nwant_binary=0\nif want_binary==1:\n    df.loc[df['Win_x']=='D','Win_x']='L'\n\n\n\nCreate tabular pandas & x and y values\n\ndep_var='Win_x'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\ncat\n\n['opponent_x', 'team_x', 'opponent_y', 'team_y']\n\n\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#fit-the-data",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#fit-the-data",
    "title": "ThomasHSimm",
    "section": "Fit the data",
    "text": "Fit the data\n\nclf=RandomForestClassifier(random_state=42)\nclf.fit(xs,y)\n\nRandomForestClassifier(random_state=42)\n\n\n\nclf.score(xs,y),clf.score(valid_xs,valid_y)\n\n(1.0, 0.4921052631578947)\n\n\n\nclf.get_params()\n\n{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'gini',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': 42,\n 'verbose': 0,\n 'warm_start': False}\n\n\n\nImprove hyperparameters\nHalvingRandomSearchCV, RandomizedSearchCV and GridSearchCV can be used to search for the best hyperparameters.\nThe random ones don’t go through all the options, but pick combinations randomly. So they will be quicker but may not get the best result. You may want to do the random ones to get a rough idea of parameters followed by grid search on a reduced range.\nThe most important arguments are - cv which is the number of folds to use for cross validation (we use the default values for cv of 5). - factor the halving parameter (2 is used) - (or n_iter for RandomizedSearchCV, which controls the number of different combinations to try)\nMore iterations or lower factor will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time.\n\n# Number of trees in random forest\nn_estimators=[20,50,150,400,700]\n\n# Number of features to consider at every split\nmax_features = ['log2','sqrt',None]\n\n# Maximum number of levels in tree\nmax_depth=[10,  30,  70,  200, None]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [1.,2, 10,50]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,10]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Weights associated with classes \nclass_weight=[\"balanced\", \"balanced_subsample\",None]\n\n#Complexity parameter used for Minimal Cost-Complexity Pruning.\nccp_alpha=[0., 0.1, 0.5]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap,\n               'class_weight':class_weight,\n               'ccp_alpha' : ccp_alpha\n\n              }\n\nrsh = HalvingRandomSearchCV(estimator = clf, param_distributions = random_grid, \\\n                              random_state=42, factor = 6)# Fit the random search model\nrsh.fit(xs, y)\n\nHalvingRandomSearchCV(estimator=RandomForestClassifier(random_state=42),\n                      factor=6,\n                      param_distributions={'bootstrap': [True, False],\n                                           'ccp_alpha': [0.0, 0.1, 0.5],\n                                           'class_weight': ['balanced',\n                                                            'balanced_subsample',\n                                                            None],\n                                           'max_depth': [10, 30, 70, 200, None],\n                                           'max_features': ['log2', 'sqrt',\n                                                            None],\n                                           'min_samples_leaf': [1, 2, 4, 10],\n                                           'min_samples_split': [1.0, 2, 10,\n                                                                 50],\n                                           'n_estimators': [20, 50, 150, 400,\n                                                            700]},\n                      random_state=42)\n\n\n\nresults = pd.DataFrame(rsh.cv_results_)\nresults[\"params_str\"] = results.params.apply(str)\nresults.drop_duplicates(subset=(\"params_str\", \"iter\"), inplace=True)\nmean_scores = results.pivot(\n    index=\"iter\", columns=\"params_str\", values=\"mean_test_score\"\n)\nax = mean_scores.plot(legend=False, alpha=0.6)\n\nlabels = [\n    f\"iter={i}\\nn_samples={rsh.n_resources_[i]}\\nn_candidates={rsh.n_candidates_[i]}\"\n    for i in range(rsh.n_iterations_)\n]\n\nax.set_xticks(range(rsh.n_iterations_))\nax.set_xticklabels(labels, rotation=45, multialignment=\"left\")\nax.set_title(\"Scores of candidates over iterations\")\nax.set_ylabel(\"mean test score\", fontsize=15)\nax.set_xlabel(\"iterations\", fontsize=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nprint(rsh.best_params_)\ndef evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors / test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy\nbest_random = rsh.best_estimator_\n\nmm = best_random.predict(valid_xs)\n\n\n\nprint(best_random.get_params())\n\n\n\nprint(\"\\nThe score for predictions on the 2021 season (not shown to training data) is:\\n\\\n      {:.3f}\\n\\\n\\nThe predictions for the training data is:\\n\\\n      {:.3f}\".format(best_random.score(valid_xs, valid_y),best_random.score(xs, y)) )\n\n{'n_estimators': 50, 'min_samples_split': 50, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': None, 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n\nThe score for predictions on the 2021 season (not shown to training data) is:\n      0.532\n\nThe predictions for the training data is:\n      0.853"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#look-at-the-predictions",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#look-at-the-predictions",
    "title": "ThomasHSimm",
    "section": "Look at the predictions",
    "text": "Look at the predictions\n\n#clf rsh\npred=clf.predict(xs)\npred_valid=clf.predict(valid_xs)\n\n# [(y[i],df['Win_x'].iloc[i]) for i in range(5)]\n[(y[i],df['Win_x'].iloc[i],pred[i]) for i in range(5)]\n\n[(2, 'W', 2), (1, 'L', 1), (2, 'W', 2), (2, 'W', 2), (1, 'L', 1)]\n\n\n\nplt.hist(pred[y==1]-1,width=.1,align='left',linewidth=2,linestyle='-.',\n         facecolor='none',edgecolor='b')#loss\nplt.hist(pred[y==0],width=.1,align='mid',linewidth=2,linestyle='-',\n         facecolor='none',edgecolor='r')#draw\nplt.hist(pred[y==2]-2,width=.1,align='left',linewidth=2,linestyle='--',\n         facecolor='none',edgecolor='k')#win\n\n# Draw=0\n# Win=2\n# Loss=1\nplt.legend(['Loss','Draw','Win'])\npc_loss=int(100*len(y[y==1])/len(pred))\npc_win=int(100*len(y[y==2])/len(pred))\npc_draw=int(100*len(y[y==0])/len(pred))\n\npc_lossP=int(100*len(pred[pred==1])/len(pred))\npc_winP=int(100*len(pred[pred==2])/len(pred))\npc_drawP=int(100*len(pred[pred==0])/len(pred))\n\nprint('win PC actual {} pred {}\\n\\\nloss PC actual {} pred {}\\n\\\ndraw PC actual {} pred {}'.format(pc_loss,pc_lossP,pc_win,pc_winP,pc_draw,pc_drawP))\n\nwin PC actual 33 pred 33\nloss PC actual 44 pred 44\ndraw PC actual 22 pred 22\n\n\n\n\n\n\nplt.hist(pred_valid[valid_y==1]-1,width=.1,align='left',linewidth=2,linestyle='-.',\n         facecolor='none',edgecolor='b')#loss\nplt.hist(pred_valid[valid_y==0],width=.1,align='mid',linewidth=2,linestyle='-',\n         facecolor='none',edgecolor='r')#draw\nplt.hist(pred_valid[valid_y==2]-2,width=.1,align='left',linewidth=2,linestyle='--',\n         facecolor='none',edgecolor='k')#win\n\n# Draw=0\n# Win=2\n# Loss=1\nplt.legend(['Loss','Draw','Win'])\n\n\npc_loss=int(100*len(valid_y[valid_y==1])/len(pred_valid))\npc_win=int(100*len(valid_y[valid_y==2])/len(pred_valid))\npc_draw=int(100*len(valid_y[valid_y==0])/len(pred_valid))\n\npc_lossP=int(100*len(pred_valid[pred_valid==1])/len(pred_valid))\npc_winP=int(100*len(pred_valid[pred_valid==2])/len(pred_valid))\npc_drawP=int(100*len(pred_valid[pred_valid==0])/len(pred_valid))\n\nprint('win PC actual {} pred {}\\n\\\nloss PC actual {} pred {}\\n\\\ndraw PC actual {} pred {}'.format(pc_loss,pc_lossP,pc_win,pc_winP,pc_draw,pc_drawP))\n\nwin PC actual 33 pred 35\nloss PC actual 42 pred 61\ndraw PC actual 23 pred 3\n\n\n\n\n\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#try-with-a-binary-question-does-the-team-win",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#try-with-a-binary-question-does-the-team-win",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import Ridge\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\ncolsextraX=[x for x in df.columns if  x[-2:]!='_y']\ncolsextraY=[x for x in df.columns if  x[-2:]!='_x']\n\n#collapse-hide\n\nimport copy\ndf=copy.copy(dfAll)\n\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\n\ndf=df.rename(columns={'Win_x':'Win'})\ndf=df.loc[( ((df['round']>1) & (df['season']==2017)) | (df['season']>2017)  ) ]\n\n#     df=df.loc[:,colsextra]\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n#############\nwant_binary=1\nif want_binary==1:\n    df.loc[df['Win']=='D','Win']='L'\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\ndef do_RF():\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n    ppred_valid=clf.predict_proba(valid_xs)\n    ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,ppred,ppred_valid\n\ndef do_XGB(n_estimators=1000, learning_rate=0.0001, n_jobs=100):\n    # !pip install xgboost\n    \n\n    # Define the model\n    my_model_2 = XGBClassifier(n_estimators=1000, learning_rate=0.01) # Your code here\n\n    # Fit the model\n    my_model_2.fit(xs, y) \n\n    # Get predictions\n    ppred = my_model_2.predict_proba(xs)\n    ppred_valid = my_model_2.predict_proba(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n\n    return pred,pred_valid,ppred,ppred_valid \n\ndef do_ridge():\n    my_model_2 = Ridge(alpha=21)\n    my_model_2.fit(xs, y)\n    \n    # Get predictions\n    ppred = my_model_2.predict(xs)\n    ppred_valid = my_model_2.predict(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n    \n    pred[pred>0.5]=1\n    pred[pred<=0.5]=0\n    \n    pred_valid[pred_valid>0.5]=1\n    pred_valid[pred_valid<=0.5]=0\n\n    return pred,pred_valid , ppred,ppred_valid\n    \n    \n\n\npred_RF,pred_valid_RF, ppred_RF,ppred_valid_RF  = do_RF()\npred_XGB,pred_valid_XGB,ppred_XGB,ppred_valid_XGB = do_XGB()\npred_rdg,pred_valid_rdg,ppred_rdg,ppred_valid_rdg = do_ridge()\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.35191e-10): result may not be accurate.\n  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n\n\n\n\n\n10      0\n11      0\n12      1\n13      0\n14      1\n       ..\n1515    1\n1516    1\n1517    0\n1518    0\n1519    1\nName: Win, Length: 1510, dtype: int8\n\n\n\npred_combo=(ppred_valid_RF[:,1]+ppred_valid_XGB[:,1])\npred_combo[pred_combo>=1]=1\npred_combo[pred_combo<1] =0\n\n\ndef get_scores(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.2f} and precision = {:.2f}\".format(nom,acc,prec))\n\nget_scores('RF train',pred_RF, y)\nget_scores('RF valid',pred_valid_RF, valid_y)\nprint('-----')\nget_scores('XGB train',pred_XGB, y)\nget_scores('XGB valid',pred_valid_XGB, valid_y)\nprint('-----')\nget_scores('Ridge train',pred_rdg, y)\nget_scores('Ridge valid',pred_valid_rdg, valid_y)\nprint('-----')\nget_scores('Combined valid',pred_combo, valid_y)\n\nRF train: accuracy = 1.00 and precision = 1.00\nRF valid: accuracy = 0.62 and precision = 0.40\n-----\nXGB train: accuracy = 1.00 and precision = 1.00\nXGB valid: accuracy = 0.61 and precision = 0.36\n-----\nRidge train: accuracy = 0.74 and precision = 0.68\nRidge valid: accuracy = 0.59 and precision = 0.44\n-----\nCombined valid: accuracy = 0.59 and precision = 0.33"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#try-reducing-the-predictors",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy2.html#try-reducing-the-predictors",
    "title": "ThomasHSimm",
    "section": "Try reducing the predictors",
    "text": "Try reducing the predictors\nThere is a lot of variance, do we need all the columns and what accuracy do we get with just a few basic ones?\n\n##hide\ndf_=pd.read_csv(folda+'epl2017-2021.csv')\ndf_=df_.iloc[10:,:]\n\npredictors=['day','opponent_x','team_x','weekday']\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\n\npredictors.append('Win_x')\npredictors.append('season')\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint('Length of training and test data: ',len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier()#n_estimators = 40, min_samples_split =10, random_state = 1)\nprint('The predictors ', predictors[0:-2])\npredictors=predictors[0:-2]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\npred_train = rf.predict(train[predictors])\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the training data\".format(accuracy_score(train['Win_x'], pred_train),precision_score(train['Win_x'], pred_train) ) )\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".format(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) ) )\n\nLength of training and test data:  1510 380\nThe predictors  ['day', 'opponent_x', 'team_x', 'weekday']\nThe accuracy 0.996 and precision 0.997 of the training data\nThe accuracy 0.621 and precision 0.565 of the test data\n\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\n\n\n\n  \n    \n      \n      category\n      NetScore_x\n    \n  \n  \n    \n      0\n      NetScore_y\n      -1.000000\n    \n    \n      1\n      ground_y\n      -0.264919\n    \n    \n      2\n      cmp_passing.2_y\n      -0.264773\n    \n    \n      3\n      cmp_passing_y\n      -0.263268\n    \n    \n      4\n      rec_y\n      -0.263268\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336\n      att_passing_x\n      0.307719\n    \n    \n      337\n      carries_x\n      0.307754\n    \n    \n      338\n      live_passing_types_x\n      0.307866\n    \n    \n      339\n      mid 3rd_possession_x\n      0.309859\n    \n    \n      340\n      NetScore_x\n      1.000000\n    \n  \n\n341 rows × 2 columns\n\n\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.26) )]]\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.24) )]]\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\n\nXuse=list(Xuse[-20:-1].category.values)\nXuse\n\n['att_passing.1_x',\n '1/3_passing_x',\n 'prgdist_possession_x',\n 'ground_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'totdist_passing_x',\n 'touches_x',\n 'cmp_passing_types_x',\n 'cmp_passing_x',\n 'rec_x',\n 'targ_x',\n 'live_possession_x',\n 'prog_possession_x',\n 'att_passing_types_x',\n 'att_passing_x',\n 'carries_x',\n 'live_passing_types_x',\n 'mid 3rd_possession_x']\n\n\n\n##hide\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndf_=df_.iloc[10:,:]\n\npredictors_=['round','opponent_x','team_x','weekday']\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\n\ndf_=df_[df_['Win_x']!='D']\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\n\npredictors=Xuse.copy()\n\n[predictors.append(x) for x in predictors_]\n\n\npredictors.append('season')\npredictors.append('Win_x')\n\n\n\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint('Length of training and test data: ',len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier(n_estimators = 200, min_samples_split =4, random_state = 1)\nprint('The predictors ', predictors[0:-2])\npredictors=predictors[0:-1]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\npred_train = rf.predict(train[predictors])\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the training data\".\\\nformat(accuracy_score(train['Win_x'], pred_train),precision_score(train['Win_x'], pred_train) ) )\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) ) )\n\nLength of training and test data:  2329 583\nThe predictors  ['att_passing.1_x', '1/3_passing_x', 'prgdist_possession_x', 'ground_x', 'cmp_passing.2_x', 'att_passing.2_x', 'totdist_passing_x', 'touches_x', 'cmp_passing_types_x', 'cmp_passing_x', 'rec_x', 'targ_x', 'live_possession_x', 'prog_possession_x', 'att_passing_types_x', 'att_passing_x', 'carries_x', 'live_passing_types_x', 'mid 3rd_possession_x', 'round', 'opponent_x', 'team_x', 'weekday']\nThe accuracy 1.000 and precision 1.000 of the training data\nThe accuracy 0.633 and precision 0.651 of the test data\n\n\n\ncombined = pd.DataFrame(dict(actual = test['Win_x'], prediction = pred ))\ncrosstab=pd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\ncrosstab\n# crosstab=np.array(crosstab)\n\n# # sum(crosstab.diagonal())/\n# crosstab,np.sum(crosstab),np.sum(crosstab, axis=1)\n# # crosstab\n\n\n\n\n\n  \n    \n      prediction\n      0\n      1\n    \n    \n      actual\n      \n      \n    \n  \n  \n    \n      0\n      180\n      111\n    \n    \n      1\n      88\n      204\n    \n  \n\n\n\n\n\n# df.groupby(columns=['season','round',])\n\ndfnew=df.copy()\n\ndfnew = dfnew.loc[df[\"season\"] > 2020,:]\ndef team_combo_unq(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    return stra \ndef team_combo2(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    if np.array_equal(a,a2):\n        return  'te'\n    else:\n        return  'op'\n\nteam_combo_unq(2,3)\n\ndfnew['team_unq']=dfnew.apply(lambda x: team_combo_unq(x['team_x'],x['opponent_x']), axis=1)\ndfnew['team_opp']=dfnew.apply(lambda x: team_combo2(x['team_x'],x['opponent_x']), axis=1)\n\npred__=rf.predict_proba(dfnew[predictors])\npred__2=rf.predict(dfnew[predictors])\ndfnew['pred']= pred__[:,1]\ndfnew['predAct']= pred__2\n\n\ndfnew.loc[dfnew.team_opp=='op','pred']=1-dfnew.loc[dfnew.team_opp=='op','pred']\ndfnew.loc[dfnew.team_opp=='op','predAct']=1-dfnew.loc[dfnew.team_opp=='op','predAct']\n\ndfnew.loc[dfnew.team_opp=='op','Win_x']=1-dfnew.loc[dfnew.team_opp=='op','Win_x']\n# a=np.array([1 ,3])\n# a\n\n\nA=dfnew['Win_x']\nB=dfnew[['predAct']]\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\nThe accuracy 0.633 and precision 0.647 of the test data\n\n\n\n\npred_df=dfnew.loc[:,['Win_x','team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct']].groupby(by=['season','round','team_unq']).mean()\n\ndef bina(numa):\n    if numa<0.5:\n        return 0\n    else:\n        return 1\n\npred_df['pred_bin']=pred_df['pred'].apply(bina)\npred_df['predAct']=pred_df['predAct'].apply(bina)\n\nA=np.array(pred_df['Win_x'])\nB=pred_df['pred_bin']\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\nA=pred_df['Win_x']\nB=np.array(pred_df[['predAct']])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\npred_df\n\nThe accuracy 0.647 and precision 0.671 of the test data\nThe accuracy 0.651 and precision 0.619 of the test data\n\n\n\n\n\n\n  \n    \n      \n      \n      \n      Win_x\n      team_x\n      opponent_x\n      pred\n      predAct\n      pred_bin\n    \n    \n      season\n      round\n      team_unq\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2021\n      1\n      0 3\n      0.0\n      0.0\n      3.0\n      0.614917\n      1\n      1\n    \n    \n      1 24\n      0.0\n      12.5\n      12.5\n      0.483089\n      1\n      0\n    \n    \n      12 16\n      0.0\n      14.0\n      14.0\n      0.364101\n      0\n      0\n    \n    \n      13 27\n      1.0\n      20.0\n      20.0\n      0.492810\n      1\n      0\n    \n    \n      14 18\n      1.0\n      16.0\n      16.0\n      0.712417\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      38\n      3 12\n      0.0\n      7.5\n      7.5\n      0.535958\n      1\n      1\n    \n    \n      4 26\n      1.0\n      15.0\n      15.0\n      0.490208\n      1\n      0\n    \n    \n      5 17\n      0.0\n      11.0\n      11.0\n      0.536071\n      1\n      1\n    \n    \n      7 24\n      1.0\n      15.5\n      15.5\n      0.604250\n      1\n      1\n    \n    \n      8 16\n      1.0\n      12.0\n      12.0\n      0.431250\n      0\n      0\n    \n  \n\n292 rows × 6 columns\n\n\n\n\n# dfnew[['Win_x','team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct']]\naccuracy_score(np.array(dfnew[['predAct']]), dfnew[['Win_x']] ) \n\n0.501717032967033\n\n\n\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndf_=df_.iloc[10:,:]\nprint(len(df_.loc[df_.Win_x=='W']),len(df_.loc[df_.Win_x=='L']) )\n\ndf_[['team_x','team_y','round','Win_x']].iloc[0:11]\n\n1461 1464\n\n\n\n\n\n\n  \n    \n      \n      team_x\n      team_y\n      round\n      Win_x\n    \n  \n  \n    \n      10\n      Crystal Palace\n      Huddersfield Town\n      1\n      L\n    \n    \n      11\n      Bournemouth\n      West Bromwich Albion\n      1\n      L\n    \n    \n      12\n      West Ham United\n      Manchester United\n      1\n      L\n    \n    \n      13\n      Watford\n      Liverpool\n      1\n      D\n    \n    \n      14\n      Brighton and Hove Albion\n      Manchester City\n      1\n      L\n    \n    \n      15\n      Huddersfield Town\n      Crystal Palace\n      1\n      W\n    \n    \n      16\n      Southampton\n      Swansea City\n      1\n      D\n    \n    \n      17\n      Swansea City\n      Southampton\n      1\n      D\n    \n    \n      18\n      Stoke City\n      Everton\n      1\n      L\n    \n    \n      19\n      West Bromwich Albion\n      Bournemouth\n      1\n      W\n    \n    \n      20\n      Manchester City\n      Everton\n      2\n      D\n    \n  \n\n\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(rf, train[predictors])\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n\n\n\n#collapse-output\npredictors2=predictors.copy()\npredictors2.append('season')\npredictors2.append('Win_x')\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\ndfAll=dfAll.loc[10:,predictors2]\ndfAll\n\n\n\n\n\n  \n    \n      \n      att_passing.2_x\n      totdist_passing_x\n      touches_x\n      cmp_passing_types_x\n      cmp_passing_x\n      rec_x\n      targ_x\n      live_possession_x\n      prog_possession_x\n      att_passing_types_x\n      att_passing_x\n      carries_x\n      live_passing_types_x\n      mid 3rd_possession_x\n      day\n      opponent_x\n      team_x\n      weekday\n      season\n      Win_x\n    \n  \n  \n    \n      10\n      346.000000\n      13422.000000\n      902.000000\n      712.000000\n      712.000000\n      712.000000\n      794.000000\n      858.000000\n      91.000000\n      808.000000\n      808.000000\n      646.000000\n      766.000000\n      484.000000\n      21\n      Everton\n      Manchester City\n      0\n      2017\n      D\n    \n    \n      11\n      330.000000\n      12334.000000\n      870.000000\n      665.000000\n      665.000000\n      665.000000\n      747.000000\n      823.000000\n      72.000000\n      757.000000\n      757.000000\n      598.000000\n      710.000000\n      420.000000\n      20\n      Chelsea\n      Tottenham Hotspur\n      6\n      2017\n      L\n    \n    \n      12\n      218.000000\n      8070.000000\n      658.000000\n      388.000000\n      388.000000\n      388.000000\n      505.000000\n      603.000000\n      35.000000\n      515.000000\n      515.000000\n      349.000000\n      458.000000\n      323.000000\n      19\n      Crystal Palace\n      Liverpool\n      5\n      2017\n      W\n    \n    \n      13\n      135.000000\n      6011.000000\n      469.000000\n      251.000000\n      251.000000\n      251.000000\n      322.000000\n      428.000000\n      16.000000\n      331.000000\n      331.000000\n      259.000000\n      289.000000\n      232.000000\n      19\n      West Bromwich Albion\n      Burnley\n      5\n      2017\n      L\n    \n    \n      14\n      79.000000\n      4126.000000\n      435.000000\n      181.000000\n      181.000000\n      181.000000\n      284.000000\n      370.000000\n      22.000000\n      299.000000\n      299.000000\n      202.000000\n      232.000000\n      169.000000\n      19\n      Brighton and Hove Albion\n      Leicester City\n      5\n      2017\n      W\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1895\n      167.000000\n      7080.666667\n      572.666667\n      353.666667\n      353.666667\n      353.666667\n      428.333333\n      529.666667\n      42.000000\n      453.000000\n      453.000000\n      327.333333\n      410.000000\n      236.000000\n      22\n      West Ham United\n      Brighton and Hove Albion\n      6\n      2021\n      W\n    \n    \n      1896\n      233.000000\n      9669.333333\n      672.000000\n      457.666667\n      457.666667\n      457.666667\n      512.333333\n      622.666667\n      36.333333\n      556.000000\n      556.000000\n      462.666667\n      505.000000\n      295.333333\n      22\n      Manchester United\n      Crystal Palace\n      6\n      2021\n      W\n    \n    \n      1897\n      171.000000\n      7650.000000\n      552.666667\n      359.000000\n      359.000000\n      359.000000\n      413.666667\n      510.333333\n      39.666667\n      457.000000\n      457.000000\n      333.666667\n      415.000000\n      220.666667\n      22\n      Leeds United\n      Brentford\n      6\n      2021\n      L\n    \n    \n      1898\n      148.666667\n      6493.333333\n      524.333333\n      295.666667\n      295.666667\n      295.666667\n      362.333333\n      478.333333\n      30.333333\n      407.333333\n      407.333333\n      310.333333\n      360.000000\n      259.333333\n      22\n      Newcastle United\n      Burnley\n      6\n      2021\n      L\n    \n    \n      1899\n      165.666667\n      6556.000000\n      534.333333\n      344.666667\n      344.666667\n      344.666667\n      401.000000\n      487.333333\n      37.333333\n      429.666667\n      429.666667\n      316.000000\n      381.333333\n      214.666667\n      22\n      Tottenham Hotspur\n      Norwich City\n      6\n      2021\n      L\n    \n  \n\n1890 rows × 20 columns\n\n\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf['Win']=df['Win'].apply(dowin)\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef do_RF(xs,y,valid_xs):\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n#     ppred_valid=clf.predict_proba(valid_xs)\n#     ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,clf#,ppred,ppred_valid\n\n   \npred,pred_val,clf=do_RF(xs,y,valid_xs)\n\n\n# new_preds,new_y=get_reg_scores(valid_y,pred_val,.5)\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the train data\".format(\\\n  accuracy_score(y, pred),precision_score(y, pred) ) )\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".format(\\\n  accuracy_score(valid_y, pred_val),precision_score(valid_y, pred_val) ) )\n\nThe accuracy 1.000 and precision 1.000 of the train data\nThe accuracy 0.637 and precision 0.662 of the test data\n\n\n\ncombined = pd.DataFrame(dict(actual = valid_y, prediction = pred_val ))\ncrosstab=pd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\ncrosstab\n# crosstab=np.array(crosstab)\n\n# sum(crosstab.diagonal())/sum(sum(crosstab))\n# # crosstab\n\n\n\n\n\n  \n    \n      prediction\n      0\n      1\n    \n    \n      actual\n      \n      \n    \n  \n  \n    \n      0\n      191\n      26\n    \n    \n      1\n      112\n      51\n    \n  \n\n\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#overview",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2022 and 2021 seasons. I will predict whether a result is a win, loss or draw.\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not to use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below.)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who - details of match, limited to those that could be predicted beforehand - referee - captain - formation - attendance\nSome details on the machine learning:\n\nA Random Forest Classifier was used for analysis.\nData is trained on the first 28 game weeks- the other 10 are used for validation\n\n23% validation / 77% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 51.5% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe stats from the last 5 games are the best parameters in predicting results\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nI would say the model probably needs more data to compete and outperform both of the controls consistently.\n\n\nCode- Prepare the data\nData is prepared in a separate page- Predicting Premier League Matches- Prepare the data"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#load-data-and-libraries",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv',\n 'epl2017-2021_wivnetscore_both-HA.csv']\n\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndfAll=dfAll.iloc[20:,:]\ndfAll\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      20\n      20\n      2\n      21\n      2.000000\n      2.000000\n      0.000000\n      Everton\n      1.000000\n      14.000000\n      4.000000\n      ...\n      16.000000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      101.000000\n      25.000000\n      26.000000\n      49.000000\n      Everton\n    \n    \n      21\n      21\n      2\n      19\n      4.000000\n      4.000000\n      0.000000\n      Swansea City\n      4.000000\n      20.000000\n      5.000000\n      ...\n      14.000000\n      5.000000\n      0.000000\n      0.000000\n      0.000000\n      55.000000\n      20.000000\n      24.000000\n      45.500000\n      Swansea City\n    \n    \n      22\n      22\n      2\n      20\n      2.000000\n      2.000000\n      0.000000\n      Chelsea\n      2.000000\n      18.000000\n      6.000000\n      ...\n      9.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      92.000000\n      21.000000\n      31.000000\n      40.400000\n      Chelsea\n    \n    \n      23\n      23\n      2\n      19\n      0.000000\n      3.000000\n      3.000000\n      Crystal Palace\n      3.000000\n      13.000000\n      4.000000\n      ...\n      21.000000\n      13.000000\n      0.000000\n      0.000000\n      1.000000\n      100.000000\n      19.000000\n      19.000000\n      50.000000\n      Crystal Palace\n    \n    \n      24\n      24\n      2\n      20\n      -1.000000\n      2.000000\n      3.000000\n      Tottenham Hotspur\n      2.000000\n      19.000000\n      6.000000\n      ...\n      17.000000\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      75.000000\n      21.000000\n      19.000000\n      52.500000\n      Tottenham Hotspur\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      3795\n      38\n      22\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n    \n    \n      3796\n      3796\n      38\n      22\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n    \n    \n      3797\n      3797\n      38\n      22\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      3798\n      3798\n      38\n      22\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n    \n    \n      3799\n      3799\n      38\n      22\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n3780 rows × 345 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      sot%_x\n      g/sh_x\n      g/sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      xg_x\n      npxg_x\n      npxg/sh_x\n      g-xg_x\n      np:g-xg_x\n      sota_x\n      saves_x\n      save%_x\n      cs_x\n      psxg_x\n      psxg+/-_x\n      pkatt_keeper_x\n      pka_x\n      pksv_x\n      pkm_x\n      cmp_keeper_x\n      att_keeper_x\n      cmp%_keeper_x\n      att_keeper.1_x\n      thr_x\n      launch%_x\n      avglen_x\n      att_keeper.2_x\n      launch%.1_x\n      avglen.1_x\n      opp_x\n      stp_x\n      stp%_x\n      #opa_x\n      avgdist_x\n      cmp_passing_x\n      att_passing_x\n      cmp%_passing_x\n      totdist_passing_x\n      prgdist_passing_x\n      cmp_passing.1_x\n      att_passing.1_x\n      cmp%_passing.1_x\n      cmp_passing.2_x\n      att_passing.2_x\n      cmp%_passing.2_x\n      cmp_passing.3_x\n      att_passing.3_x\n      cmp%_passing.3_x\n      ast_x\n      xa_x\n      kp_x\n      1/3_passing_x\n      ppa_x\n      crspa_x\n      prog_passing_x\n      att_passing_types_x\n      live_passing_types_x\n      dead_x\n      fk_passing_types_x\n      tb_x\n      press_passing_types_x\n      sw_x\n      crs_passing_types_x\n      ck_x\n      in_x\n      out_x\n      str_x\n      ground_x\n      low_x\n      high_x\n      left_x\n      right_x\n      head_x\n      ti_x\n      other_x\n      cmp_passing_types_x\n      off_passing_types_x\n      out.1_x\n      int_passing_types_x\n      blocks_passing_types_x\n      sca_x\n      passlive_x\n      passdead_x\n      drib_x\n      sh_gca_x\n      fld_gca_x\n      def_x\n      gca_x\n      passlive.1_x\n      passdead.1_x\n      drib.1_x\n      sh_gca.1_x\n      fld_gca.1_x\n      def.1_x\n      tkl_x\n      tklw_defense_x\n      def 3rd_defense_x\n      mid 3rd_defense_x\n      att 3rd_defense_x\n      tkl.1_x\n      att_defense_x\n      tkl%_x\n      past_x\n      press_defense_x\n      succ_defense_x\n      %_x\n      def 3rd_defense.1_x\n      mid 3rd_defense.1_x\n      att 3rd_defense.1_x\n      blocks_defense_x\n      sh_defense_x\n      shsv_x\n      pass_x\n      int_defense_x\n      clr_x\n      err_x\n      poss_x\n      touches_x\n      def pen_x\n      def 3rd_possession_x\n      mid 3rd_possession_x\n      att 3rd_possession_x\n      att pen_x\n      live_possession_x\n      succ_possession_x\n      att_possession_x\n      succ%_x\n      #pl_x\n      megs_x\n      carries_x\n      totdist_possession_x\n      prgdist_possession_x\n      prog_possession_x\n      1/3_possession_x\n      cpa_x\n      mis_x\n      dis_x\n      targ_x\n      rec_x\n      rec%_x\n      prog_possession.1_x\n      crdy_x\n      crdr_x\n      2crdy_x\n      fls_x\n      fld_misc_x\n      off_misc_x\n      crs_misc_x\n      int_misc_x\n      tklw_misc_x\n      pkwon_x\n      pkcon_x\n      og_x\n      recov_x\n      won_x\n      lost_x\n      won%_x\n      team_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      NetScore_x\n      result_y\n      gf_y\n      ga_y\n      opponent_y\n      gls_y\n      sh_shooting_y\n      sot_y\n      sot%_y\n      g/sh_y\n      g/sot_y\n      dist_y\n      fk_shooting_y\n      pk_y\n      pkatt_shooting_y\n      xg_y\n      npxg_y\n      npxg/sh_y\n      g-xg_y\n      np:g-xg_y\n      sota_y\n      saves_y\n      save%_y\n      cs_y\n      psxg_y\n      psxg+/-_y\n      pkatt_keeper_y\n      pka_y\n      pksv_y\n      pkm_y\n      cmp_keeper_y\n      att_keeper_y\n      cmp%_keeper_y\n      att_keeper.1_y\n      thr_y\n      launch%_y\n      avglen_y\n      att_keeper.2_y\n      launch%.1_y\n      avglen.1_y\n      opp_y\n      stp_y\n      stp%_y\n      #opa_y\n      avgdist_y\n      cmp_passing_y\n      att_passing_y\n      cmp%_passing_y\n      totdist_passing_y\n      prgdist_passing_y\n      cmp_passing.1_y\n      att_passing.1_y\n      cmp%_passing.1_y\n      cmp_passing.2_y\n      att_passing.2_y\n      cmp%_passing.2_y\n      cmp_passing.3_y\n      att_passing.3_y\n      cmp%_passing.3_y\n      ast_y\n      xa_y\n      kp_y\n      1/3_passing_y\n      ppa_y\n      crspa_y\n      prog_passing_y\n      att_passing_types_y\n      live_passing_types_y\n      dead_y\n      fk_passing_types_y\n      tb_y\n      press_passing_types_y\n      sw_y\n      crs_passing_types_y\n      ck_y\n      in_y\n      out_y\n      str_y\n      ground_y\n      low_y\n      high_y\n      left_y\n      right_y\n      head_y\n      ti_y\n      other_y\n      cmp_passing_types_y\n      off_passing_types_y\n      out.1_y\n      int_passing_types_y\n      blocks_passing_types_y\n      sca_y\n      passlive_y\n      passdead_y\n      drib_y\n      sh_gca_y\n      fld_gca_y\n      def_y\n      gca_y\n      passlive.1_y\n      passdead.1_y\n      drib.1_y\n      sh_gca.1_y\n      fld_gca.1_y\n      def.1_y\n      tkl_y\n      tklw_defense_y\n      def 3rd_defense_y\n      mid 3rd_defense_y\n      att 3rd_defense_y\n      tkl.1_y\n      att_defense_y\n      tkl%_y\n      past_y\n      press_defense_y\n      succ_defense_y\n      %_y\n      def 3rd_defense.1_y\n      mid 3rd_defense.1_y\n      att 3rd_defense.1_y\n      blocks_defense_y\n      sh_defense_y\n      shsv_y\n      pass_y\n      int_defense_y\n      clr_y\n      err_y\n      poss_y\n      touches_y\n      def pen_y\n      def 3rd_possession_y\n      mid 3rd_possession_y\n      att 3rd_possession_y\n      att pen_y\n      live_possession_y\n      succ_possession_y\n      att_possession_y\n      succ%_y\n      #pl_y\n      megs_y\n      carries_y\n      totdist_possession_y\n      prgdist_possession_y\n      prog_possession_y\n      1/3_possession_y\n      cpa_y\n      mis_y\n      dis_y\n      targ_y\n      rec_y\n      rec%_y\n      prog_possession.1_y\n      crdy_y\n      crdr_y\n      2crdy_y\n      fls_y\n      fld_misc_y\n      off_misc_y\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      count\n      3780.000000\n      3780.000000\n      3780.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n      3780.000000\n      3780.000000\n      3780.000000\n      3780.000000\n      3780\n      3780.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n    \n    \n      unique\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n    \n    \n      top\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      W\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Everton\n    \n    \n      freq\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n      NaN\n      NaN\n      NaN\n      NaN\n      1459\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n    \n    \n      mean\n      1909.500000\n      19.597884\n      15.918519\n      0.000221\n      1.371377\n      1.371156\n      NaN\n      1.327324\n      12.328694\n      4.086736\n      33.681354\n      0.103442\n      0.295899\n      17.038874\n      0.457317\n      0.103659\n      0.131053\n      1.321112\n      1.221841\n      0.101015\n      0.006212\n      0.001825\n      4.081919\n      2.814290\n      68.923159\n      0.286983\n      1.331880\n      0.004953\n      0.133572\n      0.104145\n      0.021916\n      0.007511\n      6.711647\n      17.384367\n      41.403566\n      24.145988\n      4.083598\n      51.041048\n      42.498842\n      7.464077\n      66.955015\n      52.474775\n      8.757246\n      0.662734\n      7.554092\n      0.650009\n      14.422137\n      391.102421\n      494.825513\n      77.249540\n      7678.838547\n      2568.776820\n      159.738644\n      182.065527\n      86.667511\n      165.802625\n      193.222782\n      83.943880\n      58.435313\n      100.837177\n      57.020710\n      0.946978\n      0.898657\n      8.934915\n      29.419450\n      8.262416\n      1.991119\n      32.412602\n      494.825513\n      447.033183\n      47.792329\n      11.663264\n      0.930055\n      74.225654\n      14.500707\n      12.001414\n      5.182308\n      2.178994\n      1.756760\n      0.398595\n      323.428994\n      67.895458\n      103.501060\n      136.682441\n      296.281151\n      20.487761\n      21.091905\n      6.511665\n      391.102421\n      1.656327\n      8.910127\n      11.740191\n      12.047367\n      19.239440\n      13.883218\n      1.690571\n      1.184562\n      0.993593\n      1.057662\n      0.429834\n      2.155046\n      1.474063\n      0.142895\n      0.147269\n      0.181469\n      0.159818\n      0.049532\n      17.768072\n      10.747040\n      8.927006\n      6.670732\n      2.170334\n      5.989086\n      16.447066\n      36.544989\n      10.457980\n      150.759323\n      43.803199\n      29.564413\n      52.393558\n      65.194945\n      33.170820\n      15.854763\n      3.809650\n      0.081168\n      12.045113\n      12.302536\n      25.147623\n      0.273286\n      50.025539\n      615.507335\n      65.741428\n      199.614307\n      290.554613\n      162.431866\n      23.944901\n      568.799311\n      9.627519\n      16.480161\n      58.261519\n      10.456212\n      0.715094\n      383.732900\n      1960.921085\n      1055.256363\n      42.916313\n      12.918036\n      4.202103\n      12.217701\n      11.783006\n      465.939113\n      391.102421\n      82.517652\n      34.585543\n      1.633793\n      0.058899\n      0.024081\n      12.383484\n      11.974505\n      1.869477\n      12.001414\n      12.302536\n      10.747040\n      0.109668\n      0.128005\n      0.044495\n      90.101582\n      19.226273\n      19.220617\n      50.000057\n      NaN\n      2019.010582\n      6.777249\n      2019.515344\n      4.365608\n      NaN\n      0.000000\n      0.000221\n      1.371377\n      1.371156\n      NaN\n      1.327324\n      12.328694\n      4.086736\n      33.681354\n      0.103442\n      0.295899\n      17.038874\n      0.457317\n      0.103659\n      0.131053\n      1.321112\n      1.221841\n      0.101015\n      0.006212\n      0.001825\n      4.081919\n      2.814290\n      68.923159\n      0.286983\n      1.331880\n      0.004953\n      0.133572\n      0.104145\n      0.021916\n      0.007511\n      6.711647\n      17.384367\n      41.403566\n      24.145988\n      4.083598\n      51.041048\n      42.498842\n      7.464077\n      66.955015\n      52.474775\n      8.757246\n      0.662734\n      7.554092\n      0.650009\n      14.422137\n      391.102421\n      494.825513\n      77.249540\n      7678.838547\n      2568.776820\n      159.738644\n      182.065527\n      86.667511\n      165.802625\n      193.222782\n      83.943880\n      58.435313\n      100.837177\n      57.020710\n      0.946978\n      0.898657\n      8.934915\n      29.419450\n      8.262416\n      1.991119\n      32.412602\n      494.825513\n      447.033183\n      47.792329\n      11.663264\n      0.930055\n      74.225654\n      14.500707\n      12.001414\n      5.182308\n      2.178994\n      1.756760\n      0.398595\n      323.428994\n      67.895458\n      103.501060\n      136.682441\n      296.281151\n      20.487761\n      21.091905\n      6.511665\n      391.102421\n      1.656327\n      8.910127\n      11.740191\n      12.047367\n      19.239440\n      13.883218\n      1.690571\n      1.184562\n      0.993593\n      1.057662\n      0.429834\n      2.155046\n      1.474063\n      0.142895\n      0.147269\n      0.181469\n      0.159818\n      0.049532\n      17.768072\n      10.747040\n      8.927006\n      6.670732\n      2.170334\n      5.989086\n      16.447066\n      36.544989\n      10.457980\n      150.759323\n      43.803199\n      29.564413\n      52.393558\n      65.194945\n      33.170820\n      15.854763\n      3.809650\n      0.081168\n      12.045113\n      12.302536\n      25.147623\n      0.273286\n      50.025539\n      615.507335\n      65.741428\n      199.614307\n      290.554613\n      162.431866\n      23.944901\n      568.799311\n      9.627519\n      16.480161\n      58.261519\n      10.456212\n      0.715094\n      383.732900\n      1960.921085\n      1055.256363\n      42.916313\n      12.918036\n      4.202103\n      12.217701\n      11.783006\n      465.939113\n      391.102421\n      82.517652\n      34.585543\n      1.633793\n      0.058899\n      0.024081\n      12.383484\n      11.974505\n      1.869477\n      12.001414\n      12.302536\n      10.747040\n      0.109668\n      0.128005\n      0.044495\n      90.101582\n      19.226273\n      19.220617\n      50.000057\n      NaN\n    \n    \n      std\n      1091.336337\n      10.913172\n      9.051306\n      1.267149\n      0.814710\n      0.779479\n      NaN\n      0.801358\n      3.621576\n      1.613890\n      9.672940\n      0.064026\n      0.161877\n      1.889526\n      0.404593\n      0.189731\n      0.213943\n      0.541559\n      0.501267\n      0.028322\n      0.554154\n      0.551213\n      1.542838\n      1.196087\n      17.338263\n      0.273559\n      0.623814\n      0.429410\n      0.218415\n      0.189406\n      0.089143\n      0.051805\n      2.682255\n      6.846205\n      11.794523\n      5.579152\n      1.678371\n      20.058375\n      9.617763\n      2.153293\n      24.722086\n      13.897199\n      2.805977\n      0.532600\n      6.404008\n      0.569639\n      3.158617\n      119.795017\n      116.504310\n      6.147428\n      2169.950196\n      445.059788\n      51.228787\n      52.435581\n      3.656848\n      59.205916\n      59.432201\n      5.374873\n      14.543057\n      13.485654\n      8.958675\n      0.668489\n      0.402482\n      2.904157\n      10.343238\n      3.441974\n      0.990676\n      10.330583\n      116.504310\n      117.353062\n      5.156562\n      2.405973\n      0.828669\n      18.995091\n      4.473470\n      3.451168\n      1.850036\n      1.250564\n      1.240981\n      0.559510\n      118.128920\n      14.587994\n      17.753818\n      50.311388\n      89.532113\n      5.067518\n      3.851733\n      1.986154\n      119.795017\n      0.905545\n      2.225536\n      4.828711\n      2.639124\n      6.200819\n      5.098831\n      0.849591\n      0.769741\n      0.699258\n      0.602324\n      0.408099\n      1.396673\n      1.129872\n      0.217520\n      0.251369\n      0.256781\n      0.239248\n      0.134061\n      3.491470\n      2.302299\n      2.590827\n      1.875103\n      1.021698\n      1.915844\n      3.961702\n      8.547288\n      2.923483\n      27.892752\n      8.250700\n      3.962793\n      15.083441\n      13.571567\n      8.719067\n      3.439718\n      1.683631\n      0.174849\n      2.680905\n      4.898996\n      7.824680\n      0.332131\n      9.619667\n      112.673828\n      11.594328\n      29.446189\n      74.522116\n      47.917507\n      8.147638\n      113.434679\n      2.919538\n      4.126423\n      8.948358\n      3.062536\n      0.567075\n      109.297402\n      561.618942\n      347.751186\n      17.326925\n      4.955229\n      2.119579\n      2.446371\n      2.736179\n      119.338777\n      119.795017\n      5.166767\n      10.869089\n      0.749157\n      0.142842\n      0.090678\n      2.536570\n      2.601125\n      0.963851\n      3.451168\n      4.898996\n      2.302299\n      0.195579\n      0.211175\n      0.120651\n      11.283443\n      5.659011\n      5.808954\n      6.289977\n      NaN\n      1.410614\n      3.950422\n      1.527044\n      1.793577\n      NaN\n      1.945813\n      1.267149\n      0.814710\n      0.779479\n      NaN\n      0.801358\n      3.621576\n      1.613890\n      9.672940\n      0.064026\n      0.161877\n      1.889526\n      0.404593\n      0.189731\n      0.213943\n      0.541559\n      0.501267\n      0.028322\n      0.554154\n      0.551213\n      1.542838\n      1.196087\n      17.338263\n      0.273559\n      0.623814\n      0.429410\n      0.218415\n      0.189406\n      0.089143\n      0.051805\n      2.682255\n      6.846205\n      11.794523\n      5.579152\n      1.678371\n      20.058375\n      9.617763\n      2.153293\n      24.722086\n      13.897199\n      2.805977\n      0.532600\n      6.404008\n      0.569639\n      3.158617\n      119.795017\n      116.504310\n      6.147428\n      2169.950196\n      445.059788\n      51.228787\n      52.435581\n      3.656848\n      59.205916\n      59.432201\n      5.374873\n      14.543057\n      13.485654\n      8.958675\n      0.668489\n      0.402482\n      2.904157\n      10.343238\n      3.441974\n      0.990676\n      10.330583\n      116.504310\n      117.353062\n      5.156562\n      2.405973\n      0.828669\n      18.995091\n      4.473470\n      3.451168\n      1.850036\n      1.250564\n      1.240981\n      0.559510\n      118.128920\n      14.587994\n      17.753818\n      50.311388\n      89.532113\n      5.067518\n      3.851733\n      1.986154\n      119.795017\n      0.905545\n      2.225536\n      4.828711\n      2.639124\n      6.200819\n      5.098831\n      0.849591\n      0.769741\n      0.699258\n      0.602324\n      0.408099\n      1.396673\n      1.129872\n      0.217520\n      0.251369\n      0.256781\n      0.239248\n      0.134061\n      3.491470\n      2.302299\n      2.590827\n      1.875103\n      1.021698\n      1.915844\n      3.961702\n      8.547288\n      2.923483\n      27.892752\n      8.250700\n      3.962793\n      15.083441\n      13.571567\n      8.719067\n      3.439718\n      1.683631\n      0.174849\n      2.680905\n      4.898996\n      7.824680\n      0.332131\n      9.619667\n      112.673828\n      11.594328\n      29.446189\n      74.522116\n      47.917507\n      8.147638\n      113.434679\n      2.919538\n      4.126423\n      8.948358\n      3.062536\n      0.567075\n      109.297402\n      561.618942\n      347.751186\n      17.326925\n      4.955229\n      2.119579\n      2.446371\n      2.736179\n      119.338777\n      119.795017\n      5.166767\n      10.869089\n      0.749157\n      0.142842\n      0.090678\n      2.536570\n      2.601125\n      0.963851\n      3.451168\n      4.898996\n      2.302299\n      0.195579\n      0.211175\n      0.120651\n      11.283443\n      5.659011\n      5.808954\n      6.289977\n      NaN\n    \n    \n      min\n      20.000000\n      1.000000\n      1.000000\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.030000\n      -2.100000\n      -2.100000\n      0.000000\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      137.000000\n      235.000000\n      58.200000\n      3027.000000\n      1359.000000\n      53.000000\n      68.000000\n      68.133333\n      51.000000\n      72.000000\n      63.566667\n      26.333333\n      65.666667\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      9.000000\n      0.000000\n      0.000000\n      6.000000\n      235.000000\n      190.000000\n      29.666667\n      3.000000\n      0.000000\n      32.000000\n      4.333333\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      88.000000\n      27.666667\n      54.333333\n      37.000000\n      112.000000\n      7.000000\n      7.000000\n      0.666667\n      137.000000\n      0.000000\n      2.666667\n      1.333333\n      4.333333\n      4.666667\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      4.000000\n      1.666667\n      1.000000\n      0.000000\n      1.000000\n      6.000000\n      9.166667\n      2.000000\n      66.000000\n      17.333333\n      13.700000\n      12.000000\n      30.666667\n      9.500000\n      6.000000\n      0.000000\n      0.000000\n      4.666667\n      1.333333\n      6.333333\n      0.000000\n      23.000000\n      346.000000\n      25.000000\n      112.000000\n      124.000000\n      54.666667\n      5.666667\n      303.000000\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      142.000000\n      778.000000\n      348.666667\n      9.000000\n      1.000000\n      0.000000\n      5.000000\n      3.666667\n      203.000000\n      137.000000\n      61.866667\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      -9.000000\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.030000\n      -2.100000\n      -2.100000\n      0.000000\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      137.000000\n      235.000000\n      58.200000\n      3027.000000\n      1359.000000\n      53.000000\n      68.000000\n      68.133333\n      51.000000\n      72.000000\n      63.566667\n      26.333333\n      65.666667\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      9.000000\n      0.000000\n      0.000000\n      6.000000\n      235.000000\n      190.000000\n      29.666667\n      3.000000\n      0.000000\n      32.000000\n      4.333333\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      88.000000\n      27.666667\n      54.333333\n      37.000000\n      112.000000\n      7.000000\n      7.000000\n      0.666667\n      137.000000\n      0.000000\n      2.666667\n      1.333333\n      4.333333\n      4.666667\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      4.000000\n      1.666667\n      1.000000\n      0.000000\n      1.000000\n      6.000000\n      9.166667\n      2.000000\n      66.000000\n      17.333333\n      13.700000\n      12.000000\n      30.666667\n      9.500000\n      6.000000\n      0.000000\n      0.000000\n      4.666667\n      1.333333\n      6.333333\n      0.000000\n      23.000000\n      346.000000\n      25.000000\n      112.000000\n      124.000000\n      54.666667\n      5.666667\n      303.000000\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      142.000000\n      778.000000\n      348.666667\n      9.000000\n      1.000000\n      0.000000\n      5.000000\n      3.666667\n      203.000000\n      137.000000\n      61.866667\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n    \n    \n      25%\n      964.750000\n      10.000000\n      8.000000\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.233333\n      0.060000\n      0.176667\n      15.766667\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.225000\n      20.333333\n      3.000000\n      34.566667\n      34.658333\n      6.000000\n      48.100000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      408.666667\n      73.000000\n      6061.833333\n      2253.000000\n      122.250000\n      144.333333\n      84.366667\n      120.666667\n      148.333333\n      80.466667\n      47.666667\n      91.333333\n      50.333333\n      0.333333\n      0.600000\n      6.916667\n      22.000000\n      6.000000\n      1.333333\n      25.000000\n      408.666667\n      360.000000\n      44.333333\n      10.000000\n      0.333333\n      61.000000\n      11.333333\n      9.666667\n      4.000000\n      1.333333\n      1.000000\n      0.000000\n      233.333333\n      57.333333\n      90.666667\n      104.000000\n      229.000000\n      17.000000\n      18.666667\n      5.000000\n      302.000000\n      1.000000\n      7.333333\n      8.000000\n      10.333333\n      14.666667\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.333333\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.600000\n      8.333333\n      130.666667\n      38.000000\n      26.900000\n      41.666667\n      55.666667\n      27.000000\n      13.333333\n      2.666667\n      0.000000\n      10.000000\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      57.666667\n      178.333333\n      236.333333\n      129.333333\n      18.000000\n      486.000000\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      790.916667\n      30.333333\n      9.333333\n      2.666667\n      10.666667\n      10.000000\n      377.333333\n      302.000000\n      79.133333\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.333333\n      15.000000\n      45.933333\n      NaN\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      -1.000000\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.233333\n      0.060000\n      0.176667\n      15.766667\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.225000\n      20.333333\n      3.000000\n      34.566667\n      34.658333\n      6.000000\n      48.100000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      408.666667\n      73.000000\n      6061.833333\n      2253.000000\n      122.250000\n      144.333333\n      84.366667\n      120.666667\n      148.333333\n      80.466667\n      47.666667\n      91.333333\n      50.333333\n      0.333333\n      0.600000\n      6.916667\n      22.000000\n      6.000000\n      1.333333\n      25.000000\n      408.666667\n      360.000000\n      44.333333\n      10.000000\n      0.333333\n      61.000000\n      11.333333\n      9.666667\n      4.000000\n      1.333333\n      1.000000\n      0.000000\n      233.333333\n      57.333333\n      90.666667\n      104.000000\n      229.000000\n      17.000000\n      18.666667\n      5.000000\n      302.000000\n      1.000000\n      7.333333\n      8.000000\n      10.333333\n      14.666667\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.333333\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.600000\n      8.333333\n      130.666667\n      38.000000\n      26.900000\n      41.666667\n      55.666667\n      27.000000\n      13.333333\n      2.666667\n      0.000000\n      10.000000\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      57.666667\n      178.333333\n      236.333333\n      129.333333\n      18.000000\n      486.000000\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      790.916667\n      30.333333\n      9.333333\n      2.666667\n      10.666667\n      10.000000\n      377.333333\n      302.000000\n      79.133333\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.333333\n      15.000000\n      45.933333\n      NaN\n    \n    \n      50%\n      1909.500000\n      20.000000\n      16.000000\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.300000\n      0.096667\n      0.276667\n      16.966667\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.333333\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      71.000000\n      53.933333\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.833333\n      475.666667\n      77.533333\n      7296.500000\n      2514.500000\n      151.000000\n      173.500000\n      87.033333\n      155.333333\n      183.000000\n      84.733333\n      56.500000\n      100.000000\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      27.000000\n      7.666667\n      2.000000\n      30.666667\n      475.666667\n      427.000000\n      47.666667\n      11.666667\n      0.666667\n      71.666667\n      14.000000\n      11.666667\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      303.000000\n      66.666667\n      102.333333\n      126.666667\n      283.000000\n      20.000000\n      21.000000\n      6.333333\n      369.833333\n      1.666667\n      8.666667\n      11.333333\n      12.000000\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      8.666667\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.333333\n      10.333333\n      148.666667\n      43.333333\n      29.500000\n      51.333333\n      64.000000\n      32.333333\n      16.000000\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.666667\n      0.333333\n      49.333333\n      598.333333\n      65.000000\n      197.333333\n      279.000000\n      153.000000\n      22.666667\n      550.000000\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      1007.000000\n      39.333333\n      12.000000\n      4.000000\n      12.000000\n      11.666667\n      447.000000\n      369.833333\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.900000\n      NaN\n      2019.000000\n      7.000000\n      2019.000000\n      5.000000\n      NaN\n      0.000000\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.300000\n      0.096667\n      0.276667\n      16.966667\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.333333\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      71.000000\n      53.933333\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.833333\n      475.666667\n      77.533333\n      7296.500000\n      2514.500000\n      151.000000\n      173.500000\n      87.033333\n      155.333333\n      183.000000\n      84.733333\n      56.500000\n      100.000000\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      27.000000\n      7.666667\n      2.000000\n      30.666667\n      475.666667\n      427.000000\n      47.666667\n      11.666667\n      0.666667\n      71.666667\n      14.000000\n      11.666667\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      303.000000\n      66.666667\n      102.333333\n      126.666667\n      283.000000\n      20.000000\n      21.000000\n      6.333333\n      369.833333\n      1.666667\n      8.666667\n      11.333333\n      12.000000\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      8.666667\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.333333\n      10.333333\n      148.666667\n      43.333333\n      29.500000\n      51.333333\n      64.000000\n      32.333333\n      16.000000\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.666667\n      0.333333\n      49.333333\n      598.333333\n      65.000000\n      197.333333\n      279.000000\n      153.000000\n      22.666667\n      550.000000\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      1007.000000\n      39.333333\n      12.000000\n      4.000000\n      12.000000\n      11.666667\n      447.000000\n      369.833333\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.900000\n      NaN\n    \n    \n      75%\n      2854.250000\n      29.000000\n      23.000000\n      0.666667\n      2.000000\n      2.000000\n      NaN\n      1.666667\n      14.666667\n      5.000000\n      39.841667\n      0.140000\n      0.400000\n      18.200000\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.883333\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.866667\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      566.333333\n      81.900000\n      8987.750000\n      2830.833333\n      188.000000\n      211.666667\n      89.308333\n      203.083333\n      230.333333\n      88.033333\n      67.416667\n      109.333333\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      34.000000\n      10.000000\n      2.666667\n      37.750000\n      566.333333\n      519.000000\n      51.333333\n      13.333333\n      1.333333\n      85.000000\n      17.333333\n      14.000000\n      6.333333\n      3.000000\n      2.333333\n      0.666667\n      397.000000\n      77.000000\n      115.666667\n      155.750000\n      352.083333\n      23.666667\n      23.666667\n      7.666667\n      463.000000\n      2.333333\n      10.333333\n      15.000000\n      13.666667\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      8.000000\n      2.666667\n      7.333333\n      18.666667\n      42.133333\n      12.333333\n      168.000000\n      49.000000\n      32.200000\n      61.333333\n      73.666667\n      38.666667\n      18.000000\n      5.000000\n      0.000000\n      14.000000\n      15.666667\n      30.000000\n      0.333333\n      56.666667\n      685.000000\n      73.000000\n      218.666667\n      331.666667\n      184.666667\n      28.333333\n      638.333333\n      11.333333\n      19.000000\n      64.266667\n      12.333333\n      1.000000\n      450.666667\n      2323.083333\n      1273.750000\n      52.333333\n      15.333333\n      5.333333\n      13.666667\n      13.666667\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      1.000000\n      0.666667\n      2.000000\n      2.000000\n      NaN\n      1.666667\n      14.666667\n      5.000000\n      39.841667\n      0.140000\n      0.400000\n      18.200000\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.883333\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.866667\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      566.333333\n      81.900000\n      8987.750000\n      2830.833333\n      188.000000\n      211.666667\n      89.308333\n      203.083333\n      230.333333\n      88.033333\n      67.416667\n      109.333333\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      34.000000\n      10.000000\n      2.666667\n      37.750000\n      566.333333\n      519.000000\n      51.333333\n      13.333333\n      1.333333\n      85.000000\n      17.333333\n      14.000000\n      6.333333\n      3.000000\n      2.333333\n      0.666667\n      397.000000\n      77.000000\n      115.666667\n      155.750000\n      352.083333\n      23.666667\n      23.666667\n      7.666667\n      463.000000\n      2.333333\n      10.333333\n      15.000000\n      13.666667\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      8.000000\n      2.666667\n      7.333333\n      18.666667\n      42.133333\n      12.333333\n      168.000000\n      49.000000\n      32.200000\n      61.333333\n      73.666667\n      38.666667\n      18.000000\n      5.000000\n      0.000000\n      14.000000\n      15.666667\n      30.000000\n      0.333333\n      56.666667\n      685.000000\n      73.000000\n      218.666667\n      331.666667\n      184.666667\n      28.333333\n      638.333333\n      11.333333\n      19.000000\n      64.266667\n      12.333333\n      1.000000\n      450.666667\n      2323.083333\n      1273.750000\n      52.333333\n      15.333333\n      5.333333\n      13.666667\n      13.666667\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n    \n    \n      max\n      3799.000000\n      38.000000\n      31.000000\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      28.000000\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      25.600000\n      3.000000\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      22.000000\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      930.666667\n      91.066667\n      15066.666667\n      4280.333333\n      406.333333\n      429.333333\n      95.100000\n      366.666667\n      397.000000\n      94.633333\n      117.666667\n      164.000000\n      83.633333\n      5.000000\n      2.833333\n      25.000000\n      79.333333\n      25.333333\n      8.000000\n      76.666667\n      930.666667\n      890.666667\n      67.000000\n      20.500000\n      5.333333\n      171.333333\n      35.000000\n      26.666667\n      14.000000\n      8.000000\n      9.333333\n      5.000000\n      786.000000\n      141.333333\n      169.000000\n      400.333333\n      620.000000\n      42.333333\n      36.333333\n      14.666667\n      846.333333\n      7.000000\n      16.666667\n      32.666667\n      22.333333\n      50.000000\n      39.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      2.000000\n      1.666667\n      1.000000\n      32.000000\n      19.666667\n      21.000000\n      16.000000\n      6.666667\n      17.666667\n      39.000000\n      71.400000\n      27.000000\n      268.333333\n      83.000000\n      45.566667\n      125.000000\n      123.666667\n      76.666667\n      30.666667\n      14.666667\n      1.333333\n      22.666667\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      141.000000\n      363.000000\n      651.666667\n      382.333333\n      67.000000\n      984.666667\n      26.000000\n      39.000000\n      90.000000\n      27.000000\n      4.666667\n      746.333333\n      4209.000000\n      2418.333333\n      116.000000\n      37.000000\n      14.666667\n      23.000000\n      25.333333\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      2.000000\n      1.000000\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      9.000000\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      28.000000\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      25.600000\n      3.000000\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      22.000000\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      930.666667\n      91.066667\n      15066.666667\n      4280.333333\n      406.333333\n      429.333333\n      95.100000\n      366.666667\n      397.000000\n      94.633333\n      117.666667\n      164.000000\n      83.633333\n      5.000000\n      2.833333\n      25.000000\n      79.333333\n      25.333333\n      8.000000\n      76.666667\n      930.666667\n      890.666667\n      67.000000\n      20.500000\n      5.333333\n      171.333333\n      35.000000\n      26.666667\n      14.000000\n      8.000000\n      9.333333\n      5.000000\n      786.000000\n      141.333333\n      169.000000\n      400.333333\n      620.000000\n      42.333333\n      36.333333\n      14.666667\n      846.333333\n      7.000000\n      16.666667\n      32.666667\n      22.333333\n      50.000000\n      39.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      2.000000\n      1.666667\n      1.000000\n      32.000000\n      19.666667\n      21.000000\n      16.000000\n      6.666667\n      17.666667\n      39.000000\n      71.400000\n      27.000000\n      268.333333\n      83.000000\n      45.566667\n      125.000000\n      123.666667\n      76.666667\n      30.666667\n      14.666667\n      1.333333\n      22.666667\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      141.000000\n      363.000000\n      651.666667\n      382.333333\n      67.000000\n      984.666667\n      26.000000\n      39.000000\n      90.000000\n      27.000000\n      4.666667\n      746.333333\n      4209.000000\n      2418.333333\n      116.000000\n      37.000000\n      14.666667\n      23.000000\n      25.333333\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      2.000000\n      1.000000\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN\n    \n  \n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom dtreeviz.trees import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\n\nfrom sklearn.experimental import enable_halving_search_cv  # noqa\nfrom sklearn.model_selection import HalvingRandomSearchCV\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\n\n\nTrain / Valid split\nIn this case valid is actually test as train will be split by fits into train and valid\n\nimport copy\ndf=copy.copy(dfAll)\n\n## if want to do randomly\n# sza=np.shape(df)[0]\n# randAr=np.random.randint(0,100, size=sza)\n# cond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\n\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/len(df)\n\n0.20105820105820105\n\n\n\ndf=df.drop(columns=['Unnamed: 0','NetScore_x','opponent_y','team_y'])\n\n\nwant_binary=0\nif want_binary==1:\n    df.loc[df['Win_x']=='D','Win_x']='L'\n\n\n\nCreate tabular pandas & x and y values\n\ndep_var='Win_x'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\ncat\n\n['opponent_x', 'team_x']\n\n\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#fit-the-data",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#fit-the-data",
    "title": "ThomasHSimm",
    "section": "Fit the data",
    "text": "Fit the data\n\nclf=RandomForestClassifier(random_state=42)\nclf.fit(xs,y)\n\nRandomForestClassifier(random_state=42)\n\n\n\nclf.score(xs,y),clf.score(valid_xs,valid_y)\n\n(1.0, 0.4921052631578947)\n\n\n\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n      2\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      0\n      6\n      83\n      87\n    \n    \n      1\n      8\n      187\n      97\n    \n    \n      2\n      9\n      102\n      181\n    \n  \n\n\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n\n\n\nlen(fi[fi['imp']>0.0043])\n\n27\n\n\n\ncol_use = fi[fi['imp']>0.004].cols.values\n\n\n# xs,y = to.train.xs,to.train.y\n# valid_xs,valid_y = to.valid.xs,to.valid.y\n\ndef do_fit_red_col(xs,valid_xs,y,valid_y,col_use,class_weight=None):\n    xs_imp= xs[col_use]\n    valid_xs_imp =valid_xs[col_use]\n    clf_imp=RandomForestClassifier(random_state=42,class_weight=class_weight)\n    clf_imp.fit(xs_imp,y)\n\n    print('Accuracy scores of train {:.3f} and validation {:.3f} sets'.format(\\\n    clf_imp.score(xs_imp,y),clf_imp.score(valid_xs_imp,valid_y)))\n    \n    return clf_imp\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use)\npred=clf.predict(valid_xs[col_use])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\nAccuracy scores of train 1.000 and validation 0.476 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n      2\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      0\n      14\n      77\n      85\n    \n    \n      1\n      12\n      173\n      107\n    \n    \n      2\n      13\n      104\n      175\n    \n  \n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 0.994 and validation 0.468 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n      2\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      0\n      28\n      74\n      74\n    \n    \n      1\n      46\n      163\n      83\n    \n    \n      2\n      45\n      82\n      165\n    \n  \n\n\n\n\nChnage amount of draws weight\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,'balanced')\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 0.994 and validation 0.475 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n      2\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      0\n      34\n      70\n      72\n    \n    \n      1\n      42\n      165\n      85\n    \n    \n      2\n      43\n      87\n      162\n    \n  \n\n\n\n\n\nXX=[1, 10, 100, 1e3, 1e6, 1e9,1e100]\nfor Draw_weght in XX:\n    clf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use,{0:Draw_weght,1:1,2:1})\n    pred=clf.predict(valid_xs[col_use])\n    crosstab=pd.crosstab(index = valid_y, columns = pred)\n    ratio_draw_good=100*crosstab.iloc[0,0]/sum(crosstab.iloc[0,:])\n    print('weight draw = {}, how many draws predicted {:.1f}%'.format(Draw_weght,ratio_draw_good))\n    \n\n\nAccuracy scores of train 1.000 and validation 0.476 sets\nweight draw = 1, how many draws predicted 8.0%\nAccuracy scores of train 1.000 and validation 0.487 sets\nweight draw = 10, how many draws predicted 5.7%\nAccuracy scores of train 1.000 and validation 0.482 sets\nweight draw = 100, how many draws predicted 9.1%\nAccuracy scores of train 1.000 and validation 0.491 sets\nweight draw = 1000.0, how many draws predicted 6.8%\nAccuracy scores of train 1.000 and validation 0.495 sets\nweight draw = 1000000.0, how many draws predicted 6.2%\nAccuracy scores of train 1.000 and validation 0.491 sets\nweight draw = 1000000000.0, how many draws predicted 4.5%\nAccuracy scores of train 0.227 and validation 0.232 sets\nweight draw = 1e+100, how many draws predicted 100.0%"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#try-with-a-binary-question-does-the-team-win",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#try-with-a-binary-question-does-the-team-win",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one\n\n#hide\nimport copy\ndf=copy.copy(dfAll)\nsza=np.shape(df)[0]\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\ndf=df.drop(columns=['Unnamed: 0','NetScore_x','opponent_y','team_y'])\n\nwant_binary=1\nif want_binary==1:\n    df.loc[df['Win_x']=='D','Win_x']='L'\n\ndep_var='Win_x'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\ncol_use = xs.columns\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use)\npred=clf.predict(valid_xs[col_use])\nprint('Length of predictors is: ',len(col_use))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.655 sets\nLength of predictors is:  672\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      396\n      72\n    \n    \n      1\n      190\n      102\n    \n  \n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\nprint('Length of predictors is: ',len(predictors_))\ncrosstab\n\nAccuracy scores of train 0.995 and validation 0.647 sets\nLength of predictors is:  4\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      356\n      112\n    \n    \n      1\n      156\n      136\n    \n  \n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, xs.columns)\nfi = rf_feat_importance(clf, xs)\ncol_use = fi[fi['imp']>0.004].cols.values\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use)\npred=clf.predict(valid_xs[col_use])\nprint('Length of predictors is: ',len(col_use))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.655 sets\nAccuracy scores of train 1.000 and validation 0.645 sets\nLength of predictors is:  64\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      382\n      86\n    \n    \n      1\n      184\n      108\n    \n  \n\n\n\n\n\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,'balanced')\npred=clf.predict(valid_xs[predictors_])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\nprint('Length of predictors is: ',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.651 sets\nThe accuracy 0.651 and precision 0.584 of the validation data\nLength of predictors is:  68\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      401\n      67\n    \n    \n      1\n      198\n      94\n    \n  \n\n\n\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\n\n\n\n  \n    \n      \n      category\n      NetScore_x\n    \n  \n  \n    \n      0\n      NetScore_y\n      -1.000000\n    \n    \n      1\n      ground_y\n      -0.264919\n    \n    \n      2\n      cmp_passing.2_y\n      -0.264773\n    \n    \n      3\n      cmp_passing_y\n      -0.263268\n    \n    \n      4\n      rec_y\n      -0.263268\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336\n      att_passing_x\n      0.307719\n    \n    \n      337\n      carries_x\n      0.307754\n    \n    \n      338\n      live_passing_types_x\n      0.307866\n    \n    \n      339\n      mid 3rd_possession_x\n      0.309859\n    \n    \n      340\n      NetScore_x\n      1.000000\n    \n  \n\n341 rows × 2 columns\n\n\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.26) )]]\n# Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.24) )]]\n\n# Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\n\nXuse=list(Xuse[-20:-1].category.values)\nXuse\n\n\n['att_passing.1_x',\n '1/3_passing_x',\n 'prgdist_possession_x',\n 'ground_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'totdist_passing_x',\n 'touches_x',\n 'cmp_passing_types_x',\n 'cmp_passing_x',\n 'rec_x',\n 'targ_x',\n 'live_possession_x',\n 'prog_possession_x',\n 'att_passing_types_x',\n 'att_passing_x',\n 'carries_x',\n 'live_passing_types_x',\n 'mid 3rd_possession_x']\n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, Xuse)\npred=clf.predict(valid_xs[Xuse])\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\n\nprint('Length of predictors is: ',len(Xuse))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.633 sets\nThe accuracy 0.633 and precision 0.541 of the validation data\nLength of predictors is:  19\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      395\n      73\n    \n    \n      1\n      206\n      86\n    \n  \n\n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[predictors_.append(x) for x in Xuse]\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\nprint('number of predictors =',len(predictors_))\n\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.645 sets\nThe accuracy 0.645 and precision 0.580 of the validation data\nnumber of predictors = 23\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      410\n      58\n    \n    \n      1\n      212\n      80\n    \n  \n\n\n\n\n\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\n\nprint('number of predictors =',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.653 sets\nThe accuracy 0.653 and precision 0.572 of the validation data\nnumber of predictors = 87\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      385\n      83\n    \n    \n      1\n      181\n      111\n    \n  \n\n\n\n\n\ndfnew\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n      team_unq\n      team_opp\n      pred\n      predAct\n    \n  \n  \n    \n      3040\n      3040\n      1\n      15\n      1.666667\n      3.666667\n      2.000000\n      23\n      3.666667\n      14.666667\n      7.000000\n      ...\n      0.333333\n      80.666667\n      14.000000\n      14.000000\n      50.166667\n      Tottenham Hotspur\n      15 23\n      te\n      0.59\n      1\n    \n    \n      3041\n      3041\n      1\n      14\n      2.000000\n      2.333333\n      0.333333\n      18\n      2.333333\n      21.666667\n      4.666667\n      ...\n      0.333333\n      69.666667\n      12.333333\n      18.333333\n      40.733333\n      Norwich City\n      14 18\n      te\n      0.65\n      1\n    \n    \n      3042\n      3042\n      1\n      14\n      -0.333333\n      1.000000\n      1.333333\n      8\n      1.000000\n      19.333333\n      5.000000\n      ...\n      0.000000\n      82.000000\n      20.333333\n      18.666667\n      51.400000\n      Crystal Palace\n      7 8\n      te\n      0.71\n      1\n    \n    \n      3043\n      3043\n      1\n      15\n      1.000000\n      2.333333\n      1.333333\n      15\n      2.000000\n      15.000000\n      6.333333\n      ...\n      0.000000\n      69.333333\n      9.333333\n      12.000000\n      43.900000\n      Manchester City\n      15 23\n      op\n      0.73\n      1\n    \n    \n      3045\n      3045\n      1\n      14\n      0.000000\n      1.333333\n      1.333333\n      12\n      1.333333\n      8.666667\n      3.333333\n      ...\n      0.000000\n      86.666667\n      17.333333\n      18.000000\n      50.400000\n      Leeds United\n      12 16\n      op\n      0.50\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      3795\n      38\n      22\n      0.333333\n      1.666667\n      1.333333\n      0\n      1.666667\n      9.333333\n      4.000000\n      ...\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n      0 9\n      op\n      0.76\n      1\n    \n    \n      3796\n      3796\n      38\n      22\n      -1.666667\n      0.666667\n      2.333333\n      3\n      0.666667\n      9.666667\n      2.333333\n      ...\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n      3 12\n      op\n      0.56\n      1\n    \n    \n      3797\n      3797\n      38\n      22\n      -0.666667\n      1.000000\n      1.666667\n      17\n      1.000000\n      13.000000\n      4.333333\n      ...\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n      5 17\n      te\n      0.46\n      0\n    \n    \n      3798\n      3798\n      38\n      22\n      -2.000000\n      0.666667\n      2.666667\n      7\n      0.333333\n      10.666667\n      2.666667\n      ...\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n      7 24\n      op\n      0.88\n      1\n    \n    \n      3799\n      3799\n      38\n      22\n      -2.000000\n      0.333333\n      2.333333\n      23\n      0.333333\n      9.666667\n      2.333333\n      ...\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n      18 23\n      te\n      0.36\n      0\n    \n  \n\n758 rows × 349 columns\n\n\n\n\n# df.groupby(columns=['season','round',])\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndfnew=df_.copy()\nrf=copy.copy(clf)\npredictors=copy.copy(predictors_)\ndfnew[\"opponent_x\"] = dfnew[\"opponent_x\"].astype(\"category\").cat.codes\ndfnew[\"team_x\"] = dfnew[\"team_x\"].astype(\"category\").cat.codes\n\n# dfnew = dfnew.loc[dfnew[\"season\"] > 2020,:]\ndfnew=dfnew.dropna()\ndef team_combo_unq(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    return stra \ndef team_combo2(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    if np.array_equal(a,a2):\n        return  'te'\n    else:\n        return  'op'\n\n# team_combo_unq(2,3)\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndfnew.loc[dfnew.Win_x!='D','Win_x']=dfnew.loc[dfnew.Win_x!='D','Win_x'].apply(dowin)\n\ndfnew['team_unq']=dfnew.apply(lambda x: team_combo_unq(x['team_x'],x['opponent_x']), axis=1)\ndfnew['team_opp']=dfnew.apply(lambda x: team_combo2(x['team_x'],x['opponent_x']), axis=1)\n\npred__=rf.predict_proba(dfnew[predictors])\npred__2=rf.predict(dfnew[predictors])\ndfnew['pred']= pred__[:,1]\ndfnew['predAct']= pred__2\n\n\ndfnew.loc[dfnew.team_opp=='op','pred']=1-dfnew.loc[dfnew.team_opp=='op','pred']\ndfnew.loc[dfnew.team_opp=='op','predAct']=1-dfnew.loc[dfnew.team_opp=='op','predAct']\n\ndfnew.loc[( (dfnew.Win_x!='D') & (dfnew.team_opp=='op') ),'Win_x']=1-dfnew.loc[( (dfnew.Win_x!='D') & (dfnew.team_opp=='op') ),'Win_x']\n# # a=np.array([1 ,3])\ndfnew.loc[dfnew.Win_x=='D','Win_x']=0\ndfnew['Win_x'] = dfnew['Win_x'].astype('int')\ndfnew.loc[3060:3080,['Win_x','opponent_x','round','team_unq','predAct']].sort_values(by=['team_unq'])\n\n\n\n\n\n  \n    \n      \n      Win_x\n      opponent_x\n      round\n      team_unq\n      predAct\n    \n  \n  \n    \n      3080\n      0\n      0\n      3\n      0 15\n      0\n    \n    \n      3062\n      0\n      0\n      2\n      0 7\n      1\n    \n    \n      3064\n      0\n      7\n      2\n      0 7\n      0\n    \n    \n      3073\n      1\n      17\n      2\n      1 17\n      0\n    \n    \n      3070\n      1\n      1\n      2\n      1 17\n      1\n    \n    \n      3066\n      0\n      13\n      2\n      13 26\n      1\n    \n    \n      3067\n      0\n      26\n      2\n      13 26\n      0\n    \n    \n      3079\n      1\n      15\n      2\n      15 18\n      1\n    \n    \n      3060\n      1\n      18\n      2\n      15 18\n      1\n    \n    \n      3065\n      0\n      20\n      2\n      16 20\n      0\n    \n    \n      3074\n      0\n      16\n      2\n      16 20\n      1\n    \n    \n      3069\n      1\n      23\n      2\n      23 27\n      1\n    \n    \n      3063\n      1\n      27\n      2\n      23 27\n      0\n    \n    \n      3071\n      0\n      3\n      2\n      3 8\n      0\n    \n    \n      3072\n      0\n      8\n      2\n      3 8\n      0\n    \n    \n      3068\n      1\n      24\n      2\n      4 24\n      0\n    \n    \n      3078\n      1\n      4\n      2\n      4 24\n      1\n    \n    \n      3061\n      0\n      5\n      2\n      5 14\n      1\n    \n    \n      3077\n      0\n      14\n      2\n      5 14\n      0\n    \n    \n      3075\n      0\n      12\n      2\n      9 12\n      0\n    \n    \n      3076\n      0\n      9\n      2\n      9 12\n      1\n    \n  \n\n\n\n\n\nA=np.array(dfnew[['Win_x']])\nB=np.array(dfnew[['predAct']])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),1 ) )\n\n\nThe accuracy 0.828 and precision 1.000 of the test data\n\n\n\n\npred_df=dfnew.loc[:,['team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct','Win_x']].groupby(by=['season','round','team_unq','Win_x'],observed=True).mean()\npred_df=pred_df.reset_index()\ndef bina(numa):\n    if numa<0.5:\n        return 0\n    else:\n        return 1\n\npred_df['pred_bin']=pred_df['pred'].apply(bina)\npred_df['predAct']=pred_df['predAct'].apply(bina)\n\nA=np.array(pred_df['Win_x'])\nB=np.array(pred_df['pred_bin'])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\nA=pred_df['Win_x']\nB=np.array(pred_df[['predAct']])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\n# A,B\n\n# pred_df.iloc[0:20]\n\nThe accuracy 0.817 and precision 0.699 of the test data\nThe accuracy 0.729 and precision 0.590 of the test data\n\n\n\npred_df\n\n\n\n\n\n  \n    \n      \n      season\n      round\n      team_unq\n      Win_x\n      team_x\n      opponent_x\n      pred\n      predAct\n      pred_bin\n    \n  \n  \n    \n      0\n      2017\n      2\n      0 21\n      0\n      10.5\n      10.5\n      0.250\n      0\n      0\n    \n    \n      1\n      2017\n      2\n      11 17\n      1\n      14.0\n      14.0\n      0.765\n      1\n      1\n    \n    \n      2\n      2017\n      2\n      2 24\n      0\n      13.0\n      13.0\n      0.170\n      0\n      0\n    \n    \n      3\n      2017\n      2\n      4 13\n      0\n      8.5\n      8.5\n      0.210\n      0\n      0\n    \n    \n      4\n      2017\n      2\n      5 25\n      0\n      15.0\n      15.0\n      0.225\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1875\n      2021\n      38\n      3 12\n      0\n      7.5\n      7.5\n      0.500\n      1\n      1\n    \n    \n      1876\n      2021\n      38\n      4 26\n      1\n      15.0\n      15.0\n      0.525\n      1\n      1\n    \n    \n      1877\n      2021\n      38\n      5 17\n      0\n      11.0\n      11.0\n      0.605\n      1\n      1\n    \n    \n      1878\n      2021\n      38\n      7 24\n      1\n      15.5\n      15.5\n      0.800\n      1\n      1\n    \n    \n      1879\n      2021\n      38\n      8 16\n      1\n      12.0\n      12.0\n      0.515\n      1\n      1\n    \n  \n\n1880 rows × 9 columns\n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors)\npred=clf.predict(valid_xs[predictors])\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\n\nprint('number of predictors =',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.653 sets\nThe accuracy 0.653 and precision 0.572 of the validation data\nnumber of predictors = 87\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      385\n      83\n    \n    \n      1\n      181\n      111\n    \n  \n\n\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs[predictors])\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[Xuse.append(x) for x in predictors_]\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, Xuse)\npred=clf.predict(valid_xs)\n\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.492 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n      2\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      0\n      7\n      85\n      84\n    \n    \n      1\n      12\n      190\n      90\n    \n    \n      2\n      2\n      98\n      192"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#look-at-the-predictions",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#look-at-the-predictions",
    "title": "ThomasHSimm",
    "section": "Look at the predictions",
    "text": "Look at the predictions\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#try-with-a-binary-question-does-the-team-win-1",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#try-with-a-binary-question-does-the-team-win-1",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import Ridge\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\ncolsextraX=[x for x in df.columns if  x[-2:]!='_y']\ncolsextraY=[x for x in df.columns if  x[-2:]!='_x']\n\n#collapse-hide\n\nimport copy\ndf=copy.copy(dfAll)\n\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\n\ndf=df.rename(columns={'Win_x':'Win'})\ndf=df.loc[( ((df['round']>1) & (df['season']==2017)) | (df['season']>2017)  ) ]\n\n#     df=df.loc[:,colsextra]\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n#############\nwant_binary=1\nif want_binary==1:\n    df.loc[df['Win']=='D','Win']='L'\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\ndef do_RF():\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n    ppred_valid=clf.predict_proba(valid_xs)\n    ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,ppred,ppred_valid\n\ndef do_XGB(n_estimators=1000, learning_rate=0.0001, n_jobs=100):\n    # !pip install xgboost\n    \n\n    # Define the model\n    my_model_2 = XGBClassifier(n_estimators=1000, learning_rate=0.01) # Your code here\n\n    # Fit the model\n    my_model_2.fit(xs, y) \n\n    # Get predictions\n    ppred = my_model_2.predict_proba(xs)\n    ppred_valid = my_model_2.predict_proba(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n\n    return pred,pred_valid,ppred,ppred_valid \n\ndef do_ridge():\n    my_model_2 = Ridge(alpha=21)\n    my_model_2.fit(xs, y)\n    \n    # Get predictions\n    ppred = my_model_2.predict(xs)\n    ppred_valid = my_model_2.predict(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n    \n    pred[pred>0.5]=1\n    pred[pred<=0.5]=0\n    \n    pred_valid[pred_valid>0.5]=1\n    pred_valid[pred_valid<=0.5]=0\n\n    return pred,pred_valid , ppred,ppred_valid\n    \n    \n\n\npred_RF,pred_valid_RF, ppred_RF,ppred_valid_RF  = do_RF()\npred_XGB,pred_valid_XGB,ppred_XGB,ppred_valid_XGB = do_XGB()\npred_rdg,pred_valid_rdg,ppred_rdg,ppred_valid_rdg = do_ridge()\n\n\npred_combo=(ppred_valid_RF[:,1]+ppred_valid_XGB[:,1])\npred_combo[pred_combo>=1]=1\npred_combo[pred_combo<1] =0\n\n\ndef get_scores(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.2f} and precision = {:.2f}\".format(nom,acc,prec))\n\nget_scores('RF train',pred_RF, y)\nget_scores('RF valid',pred_valid_RF, valid_y)\nprint('-----')\nget_scores('XGB train',pred_XGB, y)\nget_scores('XGB valid',pred_valid_XGB, valid_y)\nprint('-----')\nget_scores('Ridge train',pred_rdg, y)\nget_scores('Ridge valid',pred_valid_rdg, valid_y)\nprint('-----')\nget_scores('Combined valid',pred_combo, valid_y)"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#try-reducing-the-predictors",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy3.html#try-reducing-the-predictors",
    "title": "ThomasHSimm",
    "section": "Try reducing the predictors",
    "text": "Try reducing the predictors\nThere is a lot of variance, do we need all the columns and what accuracy do we get with just a few basic ones?\n\n##hide\ndf_=pd.read_csv(folda+'epl2017-2021.csv')\ndf_=df_.iloc[10:,:]\n\npredictors=['day','opponent_x','team_x','weekday']\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\n\npredictors.append('Win_x')\npredictors.append('season')\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint('Length of training and test data: ',len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier()#n_estimators = 40, min_samples_split =10, random_state = 1)\nprint('The predictors ', predictors[0:-2])\npredictors=predictors[0:-2]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\npred_train = rf.predict(train[predictors])\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the training data\".format(accuracy_score(train['Win_x'], pred_train),precision_score(train['Win_x'], pred_train) ) )\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".format(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) ) )\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.26) )]]\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.24) )]]\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\n\nXuse=list(Xuse[-20:-1].category.values)\nXuse\n\n\n##hide\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndf_=df_.iloc[10:,:]\n\npredictors_=['round','opponent_x','team_x','weekday']\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\n\ndf_=df_[df_['Win_x']!='D']\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\n\npredictors=Xuse.copy()\n\n[predictors.append(x) for x in predictors_]\n\n\npredictors.append('season')\npredictors.append('Win_x')\n\n\n\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint('Length of training and test data: ',len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier(n_estimators = 200, min_samples_split =4, random_state = 1)\nprint('The predictors ', predictors[0:-2])\npredictors=predictors[0:-1]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\npred_train = rf.predict(train[predictors])\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the training data\".\\\nformat(accuracy_score(train['Win_x'], pred_train),precision_score(train['Win_x'], pred_train) ) )\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) ) )\n\n\ncombined = pd.DataFrame(dict(actual = test['Win_x'], prediction = pred ))\ncrosstab=pd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\ncrosstab\n# crosstab=np.array(crosstab)\n\n# # sum(crosstab.diagonal())/\n# crosstab,np.sum(crosstab),np.sum(crosstab, axis=1)\n# # crosstab\n\n\n# df.groupby(columns=['season','round',])\n\ndfnew=df.copy()\n\ndfnew = dfnew.loc[df[\"season\"] > 2020,:]\ndef team_combo_unq(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    return stra \ndef team_combo2(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    if np.array_equal(a,a2):\n        return  'te'\n    else:\n        return  'op'\n\nteam_combo_unq(2,3)\n\ndfnew['team_unq']=dfnew.apply(lambda x: team_combo_unq(x['team_x'],x['opponent_x']), axis=1)\ndfnew['team_opp']=dfnew.apply(lambda x: team_combo2(x['team_x'],x['opponent_x']), axis=1)\n\npred__=rf.predict_proba(dfnew[predictors])\npred__2=rf.predict(dfnew[predictors])\ndfnew['pred']= pred__[:,1]\ndfnew['predAct']= pred__2\n\n\ndfnew.loc[dfnew.team_opp=='op','pred']=1-dfnew.loc[dfnew.team_opp=='op','pred']\ndfnew.loc[dfnew.team_opp=='op','predAct']=1-dfnew.loc[dfnew.team_opp=='op','predAct']\n\ndfnew.loc[dfnew.team_opp=='op','Win_x']=1-dfnew.loc[dfnew.team_opp=='op','Win_x']\n# a=np.array([1 ,3])\n# a\n\n\nA=dfnew['Win_x']\nB=dfnew[['predAct']]\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\n\n\npred_df=dfnew.loc[:,['Win_x','team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct']].groupby(by=['season','round','team_unq']).mean()\n\ndef bina(numa):\n    if numa<0.5:\n        return 0\n    else:\n        return 1\n\npred_df['pred_bin']=pred_df['pred'].apply(bina)\npred_df['predAct']=pred_df['predAct'].apply(bina)\n\nA=np.array(pred_df['Win_x'])\nB=pred_df['pred_bin']\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\nA=pred_df['Win_x']\nB=np.array(pred_df[['predAct']])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\npred_df\n\n\n# dfnew[['Win_x','team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct']]\naccuracy_score(np.array(dfnew[['predAct']]), dfnew[['Win_x']] ) \n\n\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndf_=df_.iloc[10:,:]\nprint(len(df_.loc[df_.Win_x=='W']),len(df_.loc[df_.Win_x=='L']) )\n\ndf_[['team_x','team_y','round','Win_x']].iloc[0:11]\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(rf, train[predictors])\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n#collapse-output\npredictors2=predictors.copy()\npredictors2.append('season')\npredictors2.append('Win_x')\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\ndfAll=dfAll.loc[10:,predictors2]\ndfAll\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf['Win']=df['Win'].apply(dowin)\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef do_RF(xs,y,valid_xs):\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n#     ppred_valid=clf.predict_proba(valid_xs)\n#     ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,clf#,ppred,ppred_valid\n\n   \npred,pred_val,clf=do_RF(xs,y,valid_xs)\n\n\n# new_preds,new_y=get_reg_scores(valid_y,pred_val,.5)\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the train data\".format(\\\n  accuracy_score(y, pred),precision_score(y, pred) ) )\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".format(\\\n  accuracy_score(valid_y, pred_val),precision_score(valid_y, pred_val) ) )\n\n\ncombined = pd.DataFrame(dict(actual = valid_y, prediction = pred_val ))\ncrosstab=pd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\ncrosstab\n# crosstab=np.array(crosstab)\n\n# sum(crosstab.diagonal())/sum(sum(crosstab))\n# # crosstab\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#overview",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2022 and 2021 seasons. I will predict whether a result is a win, loss or draw.\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not to use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below.)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who - details of match, limited to those that could be predicted beforehand - referee - captain - formation - attendance\nSome details on the machine learning:\n\nA Random Forest Classifier was used for analysis.\nData is trained on the first 28 game weeks- the other 10 are used for validation\n\n23% validation / 77% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 51.5% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe stats from the last 5 games are the best parameters in predicting results\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nI would say the model probably needs more data to compete and outperform both of the controls consistently.\n\n\nCode- Prepare the data\nData is prepared in a separate page- Predicting Premier League Matches- Prepare the data"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#load-data-and-libraries",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv',\n 'epl2017-2021_wivnetscore_both-HA.csv']\n\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndfAll=dfAll.iloc[20:,:]\ndfAll\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      20\n      20\n      2\n      21\n      2.000000\n      2.000000\n      0.000000\n      Everton\n      1.000000\n      14.000000\n      4.000000\n      ...\n      16.000000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      101.000000\n      25.000000\n      26.000000\n      49.000000\n      Everton\n    \n    \n      21\n      21\n      2\n      19\n      4.000000\n      4.000000\n      0.000000\n      Swansea City\n      4.000000\n      20.000000\n      5.000000\n      ...\n      14.000000\n      5.000000\n      0.000000\n      0.000000\n      0.000000\n      55.000000\n      20.000000\n      24.000000\n      45.500000\n      Swansea City\n    \n    \n      22\n      22\n      2\n      20\n      2.000000\n      2.000000\n      0.000000\n      Chelsea\n      2.000000\n      18.000000\n      6.000000\n      ...\n      9.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      92.000000\n      21.000000\n      31.000000\n      40.400000\n      Chelsea\n    \n    \n      23\n      23\n      2\n      19\n      0.000000\n      3.000000\n      3.000000\n      Crystal Palace\n      3.000000\n      13.000000\n      4.000000\n      ...\n      21.000000\n      13.000000\n      0.000000\n      0.000000\n      1.000000\n      100.000000\n      19.000000\n      19.000000\n      50.000000\n      Crystal Palace\n    \n    \n      24\n      24\n      2\n      20\n      -1.000000\n      2.000000\n      3.000000\n      Tottenham Hotspur\n      2.000000\n      19.000000\n      6.000000\n      ...\n      17.000000\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      75.000000\n      21.000000\n      19.000000\n      52.500000\n      Tottenham Hotspur\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      3795\n      38\n      22\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n    \n    \n      3796\n      3796\n      38\n      22\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n    \n    \n      3797\n      3797\n      38\n      22\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      3798\n      3798\n      38\n      22\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n    \n    \n      3799\n      3799\n      38\n      22\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n3780 rows × 345 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      sot%_x\n      g/sh_x\n      g/sot_x\n      dist_x\n      fk_shooting_x\n      pk_x\n      pkatt_shooting_x\n      xg_x\n      npxg_x\n      npxg/sh_x\n      g-xg_x\n      np:g-xg_x\n      sota_x\n      saves_x\n      save%_x\n      cs_x\n      psxg_x\n      psxg+/-_x\n      pkatt_keeper_x\n      pka_x\n      pksv_x\n      pkm_x\n      cmp_keeper_x\n      att_keeper_x\n      cmp%_keeper_x\n      att_keeper.1_x\n      thr_x\n      launch%_x\n      avglen_x\n      att_keeper.2_x\n      launch%.1_x\n      avglen.1_x\n      opp_x\n      stp_x\n      stp%_x\n      #opa_x\n      avgdist_x\n      cmp_passing_x\n      att_passing_x\n      cmp%_passing_x\n      totdist_passing_x\n      prgdist_passing_x\n      cmp_passing.1_x\n      att_passing.1_x\n      cmp%_passing.1_x\n      cmp_passing.2_x\n      att_passing.2_x\n      cmp%_passing.2_x\n      cmp_passing.3_x\n      att_passing.3_x\n      cmp%_passing.3_x\n      ast_x\n      xa_x\n      kp_x\n      1/3_passing_x\n      ppa_x\n      crspa_x\n      prog_passing_x\n      att_passing_types_x\n      live_passing_types_x\n      dead_x\n      fk_passing_types_x\n      tb_x\n      press_passing_types_x\n      sw_x\n      crs_passing_types_x\n      ck_x\n      in_x\n      out_x\n      str_x\n      ground_x\n      low_x\n      high_x\n      left_x\n      right_x\n      head_x\n      ti_x\n      other_x\n      cmp_passing_types_x\n      off_passing_types_x\n      out.1_x\n      int_passing_types_x\n      blocks_passing_types_x\n      sca_x\n      passlive_x\n      passdead_x\n      drib_x\n      sh_gca_x\n      fld_gca_x\n      def_x\n      gca_x\n      passlive.1_x\n      passdead.1_x\n      drib.1_x\n      sh_gca.1_x\n      fld_gca.1_x\n      def.1_x\n      tkl_x\n      tklw_defense_x\n      def 3rd_defense_x\n      mid 3rd_defense_x\n      att 3rd_defense_x\n      tkl.1_x\n      att_defense_x\n      tkl%_x\n      past_x\n      press_defense_x\n      succ_defense_x\n      %_x\n      def 3rd_defense.1_x\n      mid 3rd_defense.1_x\n      att 3rd_defense.1_x\n      blocks_defense_x\n      sh_defense_x\n      shsv_x\n      pass_x\n      int_defense_x\n      clr_x\n      err_x\n      poss_x\n      touches_x\n      def pen_x\n      def 3rd_possession_x\n      mid 3rd_possession_x\n      att 3rd_possession_x\n      att pen_x\n      live_possession_x\n      succ_possession_x\n      att_possession_x\n      succ%_x\n      #pl_x\n      megs_x\n      carries_x\n      totdist_possession_x\n      prgdist_possession_x\n      prog_possession_x\n      1/3_possession_x\n      cpa_x\n      mis_x\n      dis_x\n      targ_x\n      rec_x\n      rec%_x\n      prog_possession.1_x\n      crdy_x\n      crdr_x\n      2crdy_x\n      fls_x\n      fld_misc_x\n      off_misc_x\n      crs_misc_x\n      int_misc_x\n      tklw_misc_x\n      pkwon_x\n      pkcon_x\n      og_x\n      recov_x\n      won_x\n      lost_x\n      won%_x\n      team_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      NetScore_x\n      result_y\n      gf_y\n      ga_y\n      opponent_y\n      gls_y\n      sh_shooting_y\n      sot_y\n      sot%_y\n      g/sh_y\n      g/sot_y\n      dist_y\n      fk_shooting_y\n      pk_y\n      pkatt_shooting_y\n      xg_y\n      npxg_y\n      npxg/sh_y\n      g-xg_y\n      np:g-xg_y\n      sota_y\n      saves_y\n      save%_y\n      cs_y\n      psxg_y\n      psxg+/-_y\n      pkatt_keeper_y\n      pka_y\n      pksv_y\n      pkm_y\n      cmp_keeper_y\n      att_keeper_y\n      cmp%_keeper_y\n      att_keeper.1_y\n      thr_y\n      launch%_y\n      avglen_y\n      att_keeper.2_y\n      launch%.1_y\n      avglen.1_y\n      opp_y\n      stp_y\n      stp%_y\n      #opa_y\n      avgdist_y\n      cmp_passing_y\n      att_passing_y\n      cmp%_passing_y\n      totdist_passing_y\n      prgdist_passing_y\n      cmp_passing.1_y\n      att_passing.1_y\n      cmp%_passing.1_y\n      cmp_passing.2_y\n      att_passing.2_y\n      cmp%_passing.2_y\n      cmp_passing.3_y\n      att_passing.3_y\n      cmp%_passing.3_y\n      ast_y\n      xa_y\n      kp_y\n      1/3_passing_y\n      ppa_y\n      crspa_y\n      prog_passing_y\n      att_passing_types_y\n      live_passing_types_y\n      dead_y\n      fk_passing_types_y\n      tb_y\n      press_passing_types_y\n      sw_y\n      crs_passing_types_y\n      ck_y\n      in_y\n      out_y\n      str_y\n      ground_y\n      low_y\n      high_y\n      left_y\n      right_y\n      head_y\n      ti_y\n      other_y\n      cmp_passing_types_y\n      off_passing_types_y\n      out.1_y\n      int_passing_types_y\n      blocks_passing_types_y\n      sca_y\n      passlive_y\n      passdead_y\n      drib_y\n      sh_gca_y\n      fld_gca_y\n      def_y\n      gca_y\n      passlive.1_y\n      passdead.1_y\n      drib.1_y\n      sh_gca.1_y\n      fld_gca.1_y\n      def.1_y\n      tkl_y\n      tklw_defense_y\n      def 3rd_defense_y\n      mid 3rd_defense_y\n      att 3rd_defense_y\n      tkl.1_y\n      att_defense_y\n      tkl%_y\n      past_y\n      press_defense_y\n      succ_defense_y\n      %_y\n      def 3rd_defense.1_y\n      mid 3rd_defense.1_y\n      att 3rd_defense.1_y\n      blocks_defense_y\n      sh_defense_y\n      shsv_y\n      pass_y\n      int_defense_y\n      clr_y\n      err_y\n      poss_y\n      touches_y\n      def pen_y\n      def 3rd_possession_y\n      mid 3rd_possession_y\n      att 3rd_possession_y\n      att pen_y\n      live_possession_y\n      succ_possession_y\n      att_possession_y\n      succ%_y\n      #pl_y\n      megs_y\n      carries_y\n      totdist_possession_y\n      prgdist_possession_y\n      prog_possession_y\n      1/3_possession_y\n      cpa_y\n      mis_y\n      dis_y\n      targ_y\n      rec_y\n      rec%_y\n      prog_possession.1_y\n      crdy_y\n      crdr_y\n      2crdy_y\n      fls_y\n      fld_misc_y\n      off_misc_y\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      team_y\n    \n  \n  \n    \n      count\n      3780.000000\n      3780.000000\n      3780.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n      3780.000000\n      3780.000000\n      3780.000000\n      3780.000000\n      3780\n      3780.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3771.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3772.000000\n      3780\n    \n    \n      unique\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n    \n    \n      top\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Crystal Palace\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Crystal Palace\n      NaN\n      NaN\n      NaN\n      NaN\n      L\n      NaN\n      NaN\n      NaN\n      NaN\n      Crystal Palace\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Crystal Palace\n    \n    \n      freq\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n      NaN\n      NaN\n      NaN\n      NaN\n      1459\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      189\n    \n    \n      mean\n      1909.500000\n      19.597884\n      15.918519\n      0.000221\n      1.371377\n      1.371156\n      NaN\n      1.327324\n      12.328694\n      4.086736\n      33.681354\n      0.103442\n      0.295899\n      17.038874\n      0.457317\n      0.103659\n      0.131053\n      1.321112\n      1.221841\n      0.101015\n      0.006212\n      0.001825\n      4.081919\n      2.814290\n      68.923159\n      0.286983\n      1.331880\n      0.004953\n      0.133572\n      0.104145\n      0.021916\n      0.007511\n      6.711647\n      17.384367\n      41.403566\n      24.145988\n      4.083598\n      51.041048\n      42.498842\n      7.464077\n      66.955015\n      52.474775\n      8.757246\n      0.662734\n      7.554092\n      0.650009\n      14.422137\n      391.102421\n      494.825513\n      77.249540\n      7678.838547\n      2568.776820\n      159.738644\n      182.065527\n      86.667511\n      165.802625\n      193.222782\n      83.943880\n      58.435313\n      100.837177\n      57.020710\n      0.946978\n      0.898657\n      8.934915\n      29.419450\n      8.262416\n      1.991119\n      32.412602\n      494.825513\n      447.033183\n      47.792329\n      11.663264\n      0.930055\n      74.225654\n      14.500707\n      12.001414\n      5.182308\n      2.178994\n      1.756760\n      0.398595\n      323.428994\n      67.895458\n      103.501060\n      136.682441\n      296.281151\n      20.487761\n      21.091905\n      6.511665\n      391.102421\n      1.656327\n      8.910127\n      11.740191\n      12.047367\n      19.239440\n      13.883218\n      1.690571\n      1.184562\n      0.993593\n      1.057662\n      0.429834\n      2.155046\n      1.474063\n      0.142895\n      0.147269\n      0.181469\n      0.159818\n      0.049532\n      17.768072\n      10.747040\n      8.927006\n      6.670732\n      2.170334\n      5.989086\n      16.447066\n      36.544989\n      10.457980\n      150.759323\n      43.803199\n      29.564413\n      52.393558\n      65.194945\n      33.170820\n      15.854763\n      3.809650\n      0.081168\n      12.045113\n      12.302536\n      25.147623\n      0.273286\n      50.025539\n      615.507335\n      65.741428\n      199.614307\n      290.554613\n      162.431866\n      23.944901\n      568.799311\n      9.627519\n      16.480161\n      58.261519\n      10.456212\n      0.715094\n      383.732900\n      1960.921085\n      1055.256363\n      42.916313\n      12.918036\n      4.202103\n      12.217701\n      11.783006\n      465.939113\n      391.102421\n      82.517652\n      34.585543\n      1.633793\n      0.058899\n      0.024081\n      12.383484\n      11.974505\n      1.869477\n      12.001414\n      12.302536\n      10.747040\n      0.109668\n      0.128005\n      0.044495\n      90.101582\n      19.226273\n      19.220617\n      50.000057\n      NaN\n      2019.010582\n      6.777249\n      2019.515344\n      4.365608\n      NaN\n      0.000000\n      0.000221\n      1.371377\n      1.371156\n      NaN\n      1.327324\n      12.328694\n      4.086736\n      33.681354\n      0.103442\n      0.295899\n      17.038874\n      0.457317\n      0.103659\n      0.131053\n      1.321112\n      1.221841\n      0.101015\n      0.006212\n      0.001825\n      4.081919\n      2.814290\n      68.923159\n      0.286983\n      1.331880\n      0.004953\n      0.133572\n      0.104145\n      0.021916\n      0.007511\n      6.711647\n      17.384367\n      41.403566\n      24.145988\n      4.083598\n      51.041048\n      42.498842\n      7.464077\n      66.955015\n      52.474775\n      8.757246\n      0.662734\n      7.554092\n      0.650009\n      14.422137\n      391.102421\n      494.825513\n      77.249540\n      7678.838547\n      2568.776820\n      159.738644\n      182.065527\n      86.667511\n      165.802625\n      193.222782\n      83.943880\n      58.435313\n      100.837177\n      57.020710\n      0.946978\n      0.898657\n      8.934915\n      29.419450\n      8.262416\n      1.991119\n      32.412602\n      494.825513\n      447.033183\n      47.792329\n      11.663264\n      0.930055\n      74.225654\n      14.500707\n      12.001414\n      5.182308\n      2.178994\n      1.756760\n      0.398595\n      323.428994\n      67.895458\n      103.501060\n      136.682441\n      296.281151\n      20.487761\n      21.091905\n      6.511665\n      391.102421\n      1.656327\n      8.910127\n      11.740191\n      12.047367\n      19.239440\n      13.883218\n      1.690571\n      1.184562\n      0.993593\n      1.057662\n      0.429834\n      2.155046\n      1.474063\n      0.142895\n      0.147269\n      0.181469\n      0.159818\n      0.049532\n      17.768072\n      10.747040\n      8.927006\n      6.670732\n      2.170334\n      5.989086\n      16.447066\n      36.544989\n      10.457980\n      150.759323\n      43.803199\n      29.564413\n      52.393558\n      65.194945\n      33.170820\n      15.854763\n      3.809650\n      0.081168\n      12.045113\n      12.302536\n      25.147623\n      0.273286\n      50.025539\n      615.507335\n      65.741428\n      199.614307\n      290.554613\n      162.431866\n      23.944901\n      568.799311\n      9.627519\n      16.480161\n      58.261519\n      10.456212\n      0.715094\n      383.732900\n      1960.921085\n      1055.256363\n      42.916313\n      12.918036\n      4.202103\n      12.217701\n      11.783006\n      465.939113\n      391.102421\n      82.517652\n      34.585543\n      1.633793\n      0.058899\n      0.024081\n      12.383484\n      11.974505\n      1.869477\n      12.001414\n      12.302536\n      10.747040\n      0.109668\n      0.128005\n      0.044495\n      90.101582\n      19.226273\n      19.220617\n      50.000057\n      NaN\n    \n    \n      std\n      1091.336337\n      10.913172\n      9.051306\n      1.267149\n      0.814710\n      0.779479\n      NaN\n      0.801358\n      3.621576\n      1.613890\n      9.672940\n      0.064026\n      0.161877\n      1.889526\n      0.404593\n      0.189731\n      0.213943\n      0.541559\n      0.501267\n      0.028322\n      0.554154\n      0.551213\n      1.542838\n      1.196087\n      17.338263\n      0.273559\n      0.623814\n      0.429410\n      0.218415\n      0.189406\n      0.089143\n      0.051805\n      2.682255\n      6.846205\n      11.794523\n      5.579152\n      1.678371\n      20.058375\n      9.617763\n      2.153293\n      24.722086\n      13.897199\n      2.805977\n      0.532600\n      6.404008\n      0.569639\n      3.158617\n      119.795017\n      116.504310\n      6.147428\n      2169.950196\n      445.059788\n      51.228787\n      52.435581\n      3.656848\n      59.205916\n      59.432201\n      5.374873\n      14.543057\n      13.485654\n      8.958675\n      0.668489\n      0.402482\n      2.904157\n      10.343238\n      3.441974\n      0.990676\n      10.330583\n      116.504310\n      117.353062\n      5.156562\n      2.405973\n      0.828669\n      18.995091\n      4.473470\n      3.451168\n      1.850036\n      1.250564\n      1.240981\n      0.559510\n      118.128920\n      14.587994\n      17.753818\n      50.311388\n      89.532113\n      5.067518\n      3.851733\n      1.986154\n      119.795017\n      0.905545\n      2.225536\n      4.828711\n      2.639124\n      6.200819\n      5.098831\n      0.849591\n      0.769741\n      0.699258\n      0.602324\n      0.408099\n      1.396673\n      1.129872\n      0.217520\n      0.251369\n      0.256781\n      0.239248\n      0.134061\n      3.491470\n      2.302299\n      2.590827\n      1.875103\n      1.021698\n      1.915844\n      3.961702\n      8.547288\n      2.923483\n      27.892752\n      8.250700\n      3.962793\n      15.083441\n      13.571567\n      8.719067\n      3.439718\n      1.683631\n      0.174849\n      2.680905\n      4.898996\n      7.824680\n      0.332131\n      9.619667\n      112.673828\n      11.594328\n      29.446189\n      74.522116\n      47.917507\n      8.147638\n      113.434679\n      2.919538\n      4.126423\n      8.948358\n      3.062536\n      0.567075\n      109.297402\n      561.618942\n      347.751186\n      17.326925\n      4.955229\n      2.119579\n      2.446371\n      2.736179\n      119.338777\n      119.795017\n      5.166767\n      10.869089\n      0.749157\n      0.142842\n      0.090678\n      2.536570\n      2.601125\n      0.963851\n      3.451168\n      4.898996\n      2.302299\n      0.195579\n      0.211175\n      0.120651\n      11.283443\n      5.659011\n      5.808954\n      6.289977\n      NaN\n      1.410614\n      3.950422\n      1.527044\n      1.793577\n      NaN\n      1.945813\n      1.267149\n      0.814710\n      0.779479\n      NaN\n      0.801358\n      3.621576\n      1.613890\n      9.672940\n      0.064026\n      0.161877\n      1.889526\n      0.404593\n      0.189731\n      0.213943\n      0.541559\n      0.501267\n      0.028322\n      0.554154\n      0.551213\n      1.542838\n      1.196087\n      17.338263\n      0.273559\n      0.623814\n      0.429410\n      0.218415\n      0.189406\n      0.089143\n      0.051805\n      2.682255\n      6.846205\n      11.794523\n      5.579152\n      1.678371\n      20.058375\n      9.617763\n      2.153293\n      24.722086\n      13.897199\n      2.805977\n      0.532600\n      6.404008\n      0.569639\n      3.158617\n      119.795017\n      116.504310\n      6.147428\n      2169.950196\n      445.059788\n      51.228787\n      52.435581\n      3.656848\n      59.205916\n      59.432201\n      5.374873\n      14.543057\n      13.485654\n      8.958675\n      0.668489\n      0.402482\n      2.904157\n      10.343238\n      3.441974\n      0.990676\n      10.330583\n      116.504310\n      117.353062\n      5.156562\n      2.405973\n      0.828669\n      18.995091\n      4.473470\n      3.451168\n      1.850036\n      1.250564\n      1.240981\n      0.559510\n      118.128920\n      14.587994\n      17.753818\n      50.311388\n      89.532113\n      5.067518\n      3.851733\n      1.986154\n      119.795017\n      0.905545\n      2.225536\n      4.828711\n      2.639124\n      6.200819\n      5.098831\n      0.849591\n      0.769741\n      0.699258\n      0.602324\n      0.408099\n      1.396673\n      1.129872\n      0.217520\n      0.251369\n      0.256781\n      0.239248\n      0.134061\n      3.491470\n      2.302299\n      2.590827\n      1.875103\n      1.021698\n      1.915844\n      3.961702\n      8.547288\n      2.923483\n      27.892752\n      8.250700\n      3.962793\n      15.083441\n      13.571567\n      8.719067\n      3.439718\n      1.683631\n      0.174849\n      2.680905\n      4.898996\n      7.824680\n      0.332131\n      9.619667\n      112.673828\n      11.594328\n      29.446189\n      74.522116\n      47.917507\n      8.147638\n      113.434679\n      2.919538\n      4.126423\n      8.948358\n      3.062536\n      0.567075\n      109.297402\n      561.618942\n      347.751186\n      17.326925\n      4.955229\n      2.119579\n      2.446371\n      2.736179\n      119.338777\n      119.795017\n      5.166767\n      10.869089\n      0.749157\n      0.142842\n      0.090678\n      2.536570\n      2.601125\n      0.963851\n      3.451168\n      4.898996\n      2.302299\n      0.195579\n      0.211175\n      0.120651\n      11.283443\n      5.659011\n      5.808954\n      6.289977\n      NaN\n    \n    \n      min\n      20.000000\n      1.000000\n      1.000000\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.030000\n      -2.100000\n      -2.100000\n      0.000000\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      137.000000\n      235.000000\n      58.200000\n      3027.000000\n      1359.000000\n      53.000000\n      68.000000\n      68.133333\n      51.000000\n      72.000000\n      63.566667\n      26.333333\n      65.666667\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      9.000000\n      0.000000\n      0.000000\n      6.000000\n      235.000000\n      190.000000\n      29.666667\n      3.000000\n      0.000000\n      32.000000\n      4.333333\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      88.000000\n      27.666667\n      54.333333\n      37.000000\n      112.000000\n      7.000000\n      7.000000\n      0.666667\n      137.000000\n      0.000000\n      2.666667\n      1.333333\n      4.333333\n      4.666667\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      4.000000\n      1.666667\n      1.000000\n      0.000000\n      1.000000\n      6.000000\n      9.166667\n      2.000000\n      66.000000\n      17.333333\n      13.700000\n      12.000000\n      30.666667\n      9.500000\n      6.000000\n      0.000000\n      0.000000\n      4.666667\n      1.333333\n      6.333333\n      0.000000\n      23.000000\n      346.000000\n      25.000000\n      112.000000\n      124.000000\n      54.666667\n      5.666667\n      303.000000\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      142.000000\n      778.000000\n      348.666667\n      9.000000\n      1.000000\n      0.000000\n      5.000000\n      3.666667\n      203.000000\n      137.000000\n      61.866667\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      -9.000000\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      10.300000\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.030000\n      -2.100000\n      -2.100000\n      0.000000\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      137.000000\n      235.000000\n      58.200000\n      3027.000000\n      1359.000000\n      53.000000\n      68.000000\n      68.133333\n      51.000000\n      72.000000\n      63.566667\n      26.333333\n      65.666667\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      9.000000\n      0.000000\n      0.000000\n      6.000000\n      235.000000\n      190.000000\n      29.666667\n      3.000000\n      0.000000\n      32.000000\n      4.333333\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      88.000000\n      27.666667\n      54.333333\n      37.000000\n      112.000000\n      7.000000\n      7.000000\n      0.666667\n      137.000000\n      0.000000\n      2.666667\n      1.333333\n      4.333333\n      4.666667\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      4.000000\n      1.666667\n      1.000000\n      0.000000\n      1.000000\n      6.000000\n      9.166667\n      2.000000\n      66.000000\n      17.333333\n      13.700000\n      12.000000\n      30.666667\n      9.500000\n      6.000000\n      0.000000\n      0.000000\n      4.666667\n      1.333333\n      6.333333\n      0.000000\n      23.000000\n      346.000000\n      25.000000\n      112.000000\n      124.000000\n      54.666667\n      5.666667\n      303.000000\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      142.000000\n      778.000000\n      348.666667\n      9.000000\n      1.000000\n      0.000000\n      5.000000\n      3.666667\n      203.000000\n      137.000000\n      61.866667\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n    \n    \n      25%\n      964.750000\n      10.000000\n      8.000000\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.233333\n      0.060000\n      0.176667\n      15.766667\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.225000\n      20.333333\n      3.000000\n      34.566667\n      34.658333\n      6.000000\n      48.100000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      408.666667\n      73.000000\n      6061.833333\n      2253.000000\n      122.250000\n      144.333333\n      84.366667\n      120.666667\n      148.333333\n      80.466667\n      47.666667\n      91.333333\n      50.333333\n      0.333333\n      0.600000\n      6.916667\n      22.000000\n      6.000000\n      1.333333\n      25.000000\n      408.666667\n      360.000000\n      44.333333\n      10.000000\n      0.333333\n      61.000000\n      11.333333\n      9.666667\n      4.000000\n      1.333333\n      1.000000\n      0.000000\n      233.333333\n      57.333333\n      90.666667\n      104.000000\n      229.000000\n      17.000000\n      18.666667\n      5.000000\n      302.000000\n      1.000000\n      7.333333\n      8.000000\n      10.333333\n      14.666667\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.333333\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.600000\n      8.333333\n      130.666667\n      38.000000\n      26.900000\n      41.666667\n      55.666667\n      27.000000\n      13.333333\n      2.666667\n      0.000000\n      10.000000\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      57.666667\n      178.333333\n      236.333333\n      129.333333\n      18.000000\n      486.000000\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      790.916667\n      30.333333\n      9.333333\n      2.666667\n      10.666667\n      10.000000\n      377.333333\n      302.000000\n      79.133333\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.333333\n      15.000000\n      45.933333\n      NaN\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      -1.000000\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.233333\n      0.060000\n      0.176667\n      15.766667\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.225000\n      20.333333\n      3.000000\n      34.566667\n      34.658333\n      6.000000\n      48.100000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      408.666667\n      73.000000\n      6061.833333\n      2253.000000\n      122.250000\n      144.333333\n      84.366667\n      120.666667\n      148.333333\n      80.466667\n      47.666667\n      91.333333\n      50.333333\n      0.333333\n      0.600000\n      6.916667\n      22.000000\n      6.000000\n      1.333333\n      25.000000\n      408.666667\n      360.000000\n      44.333333\n      10.000000\n      0.333333\n      61.000000\n      11.333333\n      9.666667\n      4.000000\n      1.333333\n      1.000000\n      0.000000\n      233.333333\n      57.333333\n      90.666667\n      104.000000\n      229.000000\n      17.000000\n      18.666667\n      5.000000\n      302.000000\n      1.000000\n      7.333333\n      8.000000\n      10.333333\n      14.666667\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      9.333333\n      7.000000\n      5.333333\n      1.333333\n      4.666667\n      13.666667\n      30.600000\n      8.333333\n      130.666667\n      38.000000\n      26.900000\n      41.666667\n      55.666667\n      27.000000\n      13.333333\n      2.666667\n      0.000000\n      10.000000\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      57.666667\n      178.333333\n      236.333333\n      129.333333\n      18.000000\n      486.000000\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      790.916667\n      30.333333\n      9.333333\n      2.666667\n      10.666667\n      10.000000\n      377.333333\n      302.000000\n      79.133333\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.333333\n      15.000000\n      45.933333\n      NaN\n    \n    \n      50%\n      1909.500000\n      20.000000\n      16.000000\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.300000\n      0.096667\n      0.276667\n      16.966667\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.333333\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      71.000000\n      53.933333\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.833333\n      475.666667\n      77.533333\n      7296.500000\n      2514.500000\n      151.000000\n      173.500000\n      87.033333\n      155.333333\n      183.000000\n      84.733333\n      56.500000\n      100.000000\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      27.000000\n      7.666667\n      2.000000\n      30.666667\n      475.666667\n      427.000000\n      47.666667\n      11.666667\n      0.666667\n      71.666667\n      14.000000\n      11.666667\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      303.000000\n      66.666667\n      102.333333\n      126.666667\n      283.000000\n      20.000000\n      21.000000\n      6.333333\n      369.833333\n      1.666667\n      8.666667\n      11.333333\n      12.000000\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      8.666667\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.333333\n      10.333333\n      148.666667\n      43.333333\n      29.500000\n      51.333333\n      64.000000\n      32.333333\n      16.000000\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.666667\n      0.333333\n      49.333333\n      598.333333\n      65.000000\n      197.333333\n      279.000000\n      153.000000\n      22.666667\n      550.000000\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      1007.000000\n      39.333333\n      12.000000\n      4.000000\n      12.000000\n      11.666667\n      447.000000\n      369.833333\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.900000\n      NaN\n      2019.000000\n      7.000000\n      2019.000000\n      5.000000\n      NaN\n      0.000000\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.300000\n      0.096667\n      0.276667\n      16.966667\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.333333\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      71.000000\n      53.933333\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.833333\n      475.666667\n      77.533333\n      7296.500000\n      2514.500000\n      151.000000\n      173.500000\n      87.033333\n      155.333333\n      183.000000\n      84.733333\n      56.500000\n      100.000000\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      27.000000\n      7.666667\n      2.000000\n      30.666667\n      475.666667\n      427.000000\n      47.666667\n      11.666667\n      0.666667\n      71.666667\n      14.000000\n      11.666667\n      5.000000\n      2.000000\n      1.666667\n      0.333333\n      303.000000\n      66.666667\n      102.333333\n      126.666667\n      283.000000\n      20.000000\n      21.000000\n      6.333333\n      369.833333\n      1.666667\n      8.666667\n      11.333333\n      12.000000\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      10.666667\n      8.666667\n      6.666667\n      2.000000\n      6.000000\n      16.000000\n      36.333333\n      10.333333\n      148.666667\n      43.333333\n      29.500000\n      51.333333\n      64.000000\n      32.333333\n      16.000000\n      3.666667\n      0.000000\n      12.000000\n      12.333333\n      24.666667\n      0.333333\n      49.333333\n      598.333333\n      65.000000\n      197.333333\n      279.000000\n      153.000000\n      22.666667\n      550.000000\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      1007.000000\n      39.333333\n      12.000000\n      4.000000\n      12.000000\n      11.666667\n      447.000000\n      369.833333\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.900000\n      NaN\n    \n    \n      75%\n      2854.250000\n      29.000000\n      23.000000\n      0.666667\n      2.000000\n      2.000000\n      NaN\n      1.666667\n      14.666667\n      5.000000\n      39.841667\n      0.140000\n      0.400000\n      18.200000\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.883333\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.866667\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      566.333333\n      81.900000\n      8987.750000\n      2830.833333\n      188.000000\n      211.666667\n      89.308333\n      203.083333\n      230.333333\n      88.033333\n      67.416667\n      109.333333\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      34.000000\n      10.000000\n      2.666667\n      37.750000\n      566.333333\n      519.000000\n      51.333333\n      13.333333\n      1.333333\n      85.000000\n      17.333333\n      14.000000\n      6.333333\n      3.000000\n      2.333333\n      0.666667\n      397.000000\n      77.000000\n      115.666667\n      155.750000\n      352.083333\n      23.666667\n      23.666667\n      7.666667\n      463.000000\n      2.333333\n      10.333333\n      15.000000\n      13.666667\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      8.000000\n      2.666667\n      7.333333\n      18.666667\n      42.133333\n      12.333333\n      168.000000\n      49.000000\n      32.200000\n      61.333333\n      73.666667\n      38.666667\n      18.000000\n      5.000000\n      0.000000\n      14.000000\n      15.666667\n      30.000000\n      0.333333\n      56.666667\n      685.000000\n      73.000000\n      218.666667\n      331.666667\n      184.666667\n      28.333333\n      638.333333\n      11.333333\n      19.000000\n      64.266667\n      12.333333\n      1.000000\n      450.666667\n      2323.083333\n      1273.750000\n      52.333333\n      15.333333\n      5.333333\n      13.666667\n      13.666667\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      1.000000\n      0.666667\n      2.000000\n      2.000000\n      NaN\n      1.666667\n      14.666667\n      5.000000\n      39.841667\n      0.140000\n      0.400000\n      18.200000\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.883333\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.866667\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      566.333333\n      81.900000\n      8987.750000\n      2830.833333\n      188.000000\n      211.666667\n      89.308333\n      203.083333\n      230.333333\n      88.033333\n      67.416667\n      109.333333\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      34.000000\n      10.000000\n      2.666667\n      37.750000\n      566.333333\n      519.000000\n      51.333333\n      13.333333\n      1.333333\n      85.000000\n      17.333333\n      14.000000\n      6.333333\n      3.000000\n      2.333333\n      0.666667\n      397.000000\n      77.000000\n      115.666667\n      155.750000\n      352.083333\n      23.666667\n      23.666667\n      7.666667\n      463.000000\n      2.333333\n      10.333333\n      15.000000\n      13.666667\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      12.333333\n      10.666667\n      8.000000\n      2.666667\n      7.333333\n      18.666667\n      42.133333\n      12.333333\n      168.000000\n      49.000000\n      32.200000\n      61.333333\n      73.666667\n      38.666667\n      18.000000\n      5.000000\n      0.000000\n      14.000000\n      15.666667\n      30.000000\n      0.333333\n      56.666667\n      685.000000\n      73.000000\n      218.666667\n      331.666667\n      184.666667\n      28.333333\n      638.333333\n      11.333333\n      19.000000\n      64.266667\n      12.333333\n      1.000000\n      450.666667\n      2323.083333\n      1273.750000\n      52.333333\n      15.333333\n      5.333333\n      13.666667\n      13.666667\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n    \n    \n      max\n      3799.000000\n      38.000000\n      31.000000\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      28.000000\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      25.600000\n      3.000000\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      22.000000\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      930.666667\n      91.066667\n      15066.666667\n      4280.333333\n      406.333333\n      429.333333\n      95.100000\n      366.666667\n      397.000000\n      94.633333\n      117.666667\n      164.000000\n      83.633333\n      5.000000\n      2.833333\n      25.000000\n      79.333333\n      25.333333\n      8.000000\n      76.666667\n      930.666667\n      890.666667\n      67.000000\n      20.500000\n      5.333333\n      171.333333\n      35.000000\n      26.666667\n      14.000000\n      8.000000\n      9.333333\n      5.000000\n      786.000000\n      141.333333\n      169.000000\n      400.333333\n      620.000000\n      42.333333\n      36.333333\n      14.666667\n      846.333333\n      7.000000\n      16.666667\n      32.666667\n      22.333333\n      50.000000\n      39.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      2.000000\n      1.666667\n      1.000000\n      32.000000\n      19.666667\n      21.000000\n      16.000000\n      6.666667\n      17.666667\n      39.000000\n      71.400000\n      27.000000\n      268.333333\n      83.000000\n      45.566667\n      125.000000\n      123.666667\n      76.666667\n      30.666667\n      14.666667\n      1.333333\n      22.666667\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      141.000000\n      363.000000\n      651.666667\n      382.333333\n      67.000000\n      984.666667\n      26.000000\n      39.000000\n      90.000000\n      27.000000\n      4.666667\n      746.333333\n      4209.000000\n      2418.333333\n      116.000000\n      37.000000\n      14.666667\n      23.000000\n      25.333333\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      2.000000\n      1.000000\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      9.000000\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      28.000000\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      25.600000\n      3.000000\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      22.000000\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      930.666667\n      91.066667\n      15066.666667\n      4280.333333\n      406.333333\n      429.333333\n      95.100000\n      366.666667\n      397.000000\n      94.633333\n      117.666667\n      164.000000\n      83.633333\n      5.000000\n      2.833333\n      25.000000\n      79.333333\n      25.333333\n      8.000000\n      76.666667\n      930.666667\n      890.666667\n      67.000000\n      20.500000\n      5.333333\n      171.333333\n      35.000000\n      26.666667\n      14.000000\n      8.000000\n      9.333333\n      5.000000\n      786.000000\n      141.333333\n      169.000000\n      400.333333\n      620.000000\n      42.333333\n      36.333333\n      14.666667\n      846.333333\n      7.000000\n      16.666667\n      32.666667\n      22.333333\n      50.000000\n      39.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      2.000000\n      1.666667\n      1.000000\n      32.000000\n      19.666667\n      21.000000\n      16.000000\n      6.666667\n      17.666667\n      39.000000\n      71.400000\n      27.000000\n      268.333333\n      83.000000\n      45.566667\n      125.000000\n      123.666667\n      76.666667\n      30.666667\n      14.666667\n      1.333333\n      22.666667\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      141.000000\n      363.000000\n      651.666667\n      382.333333\n      67.000000\n      984.666667\n      26.000000\n      39.000000\n      90.000000\n      27.000000\n      4.666667\n      746.333333\n      4209.000000\n      2418.333333\n      116.000000\n      37.000000\n      14.666667\n      23.000000\n      25.333333\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      2.000000\n      1.000000\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN\n    \n  \n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom dtreeviz.trees import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\n\nfrom sklearn.experimental import enable_halving_search_cv  # noqa\nfrom sklearn.model_selection import HalvingRandomSearchCV\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\n\nimport copy\n\n\nTrain / Valid split\nIn this case valid is actually test as train will be split by fits into train and valid\n\nimport copy\ndf=copy.copy(dfAll)\n\n## if want to do randomly\n# sza=np.shape(df)[0]\n# randAr=np.random.randint(0,100, size=sza)\n# cond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\n\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/len(df)\n\n0.20105820105820105\n\n\n\ndf=df.drop(columns=['Unnamed: 0','NetScore_x','opponent_y','team_y'])\n\n\nwant_binary=0\nif want_binary==1:\n    df.loc[df['Win_x']=='D','Win_x']='L'\n\n\n\nCreate tabular pandas & x and y values\n\ndep_var='Win_x'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\ncat\n\n['opponent_x', 'team_x']\n\n\n\n# procs = [Categorify, FillMissing]\n# to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\n# xs,y = to.train.xs,to.train.y\n# valid_xs,valid_y = to.valid.xs,to.valid.y\ndf=df.dropna()\ndf[\"opponent_x\"] = df[\"opponent_x\"].astype(\"category\").cat.codes\ndf[\"team_x\"] = df[\"team_x\"].astype(\"category\").cat.codes\n\ntrain=df.loc[cond].copy()\nvalid=df.loc[~cond].copy()\n\nlen(valid)/len(df),(len(train)+len(valid))/len(df)\n\ntarget = 'Win_x'\npredictors = [x for x in train.columns if x != 'Win_x']\n\n\nxs = train[predictors]\nvalid_xs = valid[predictors]\n\ny = train[target]\nvalid_y = valid[target]"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#fit-the-data",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#fit-the-data",
    "title": "ThomasHSimm",
    "section": "Fit the data",
    "text": "Fit the data\n\nclf=RandomForestClassifier(random_state=42)\nclf.fit(xs,y)\n\nRandomForestClassifier(random_state=42)\n\n\n\nclf.score(xs,y),clf.score(valid_xs,valid_y)\n\n(1.0, 0.4894459102902375)\n\n\n\npred=clf.predict(valid_xs)\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      2\n      83\n      91\n    \n    \n      L\n      4\n      191\n      96\n    \n    \n      W\n      7\n      106\n      178\n    \n  \n\n\n\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n\n\n\nlen(fi[fi['imp']>0.0043])\n\n31\n\n\n\ncol_use = fi[fi['imp']>0.004].cols.values\n\n\n# xs,y = to.train.xs,to.train.y\n# valid_xs,valid_y = to.valid.xs,to.valid.y\n\ndef do_fit_red_col(xs,valid_xs,y,valid_y,col_use,class_weight=None):\n    xs_imp= xs[col_use]\n    valid_xs_imp =valid_xs[col_use]\n    clf_imp=RandomForestClassifier(random_state=42,class_weight=class_weight)\n    clf_imp.fit(xs_imp,y)\n\n    print('Accuracy scores of train {:.3f} and validation {:.3f} sets'.format(\\\n    clf_imp.score(xs_imp,y),clf_imp.score(valid_xs_imp,valid_y)))\n    \n    return clf_imp\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use)\npred=clf.predict(valid_xs[col_use])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\nAccuracy scores of train 1.000 and validation 0.480 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      5\n      86\n      85\n    \n    \n      L\n      14\n      186\n      91\n    \n    \n      W\n      15\n      103\n      173\n    \n  \n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 0.994 and validation 0.484 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      31\n      73\n      72\n    \n    \n      L\n      42\n      171\n      78\n    \n    \n      W\n      40\n      86\n      165\n    \n  \n\n\n\n\nChnage amount of draws weight\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,'balanced')\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 0.994 and validation 0.479 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      31\n      71\n      74\n    \n    \n      L\n      44\n      165\n      82\n    \n    \n      W\n      41\n      83\n      167\n    \n  \n\n\n\n\n\ncol_use = fi[fi['imp']>0.004].cols.values\nXX=[1, 10, 100, 1e3, 1e6, 1e9,1e30]\nfor Draw_weght in XX:\n    print(Draw_weght)\n    clf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use,{'D':Draw_weght,'L':1,'W':1})\n    pred=clf.predict(valid_xs[col_use])\n    crosstab=pd.crosstab(index = valid_y, columns = pred)\n    ratio_draw_good=100*crosstab.iloc[0,0]/sum(crosstab.iloc[0,:])\n    print('weight draw = {}, how many draws predicted {:.1f}%'.format(Draw_weght,ratio_draw_good))\n    \n\n\n1\nAccuracy scores of train 1.000 and validation 0.480 sets\nweight draw = 1, how many draws predicted 2.8%\n10\nAccuracy scores of train 1.000 and validation 0.496 sets\nweight draw = 10, how many draws predicted 6.2%\n100\nAccuracy scores of train 1.000 and validation 0.482 sets\nweight draw = 100, how many draws predicted 4.0%\n1000.0\nAccuracy scores of train 1.000 and validation 0.474 sets\nweight draw = 1000.0, how many draws predicted 5.7%\n1000000.0\nAccuracy scores of train 1.000 and validation 0.479 sets\nweight draw = 1000000.0, how many draws predicted 4.5%\n1000000000.0\nAccuracy scores of train 1.000 and validation 0.503 sets\nweight draw = 1000000000.0, how many draws predicted 6.2%\n1e+30\nAccuracy scores of train 0.227 and validation 0.232 sets\nweight draw = 1e+30, how many draws predicted 100.0%"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#try-with-a-binary-question-does-the-team-win",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#try-with-a-binary-question-does-the-team-win",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one\n\ny2=y.copy()\nvalid_y2=valid_y.copy()\n\nwant_binary=1\nif want_binary==1:\n    y2[y=='D']='L'\n    valid_y2[valid_y=='D']='L'\n    \n\ny2\n\n20      L\n22      L\n23      W\n24      W\n25      L\n       ..\n3035    L\n3036    L\n3037    L\n3038    L\n3039    W\nName: Win_x, Length: 3002, dtype: object\n\n\n\ncol_use = xs.columns\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, col_use)\npred=clf.predict(valid_xs[col_use])\nprint('Length of predictors is: ',len(col_use))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.669 sets\nLength of predictors is:  340\n\n\n\n\n\n\n  \n    \n      col_0\n      L\n      W\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      D\n      143\n      33\n    \n    \n      L\n      257\n      34\n    \n    \n      W\n      184\n      107\n    \n  \n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y2, columns = pred)\nprint('Length of predictors is: ',len(predictors_))\ncrosstab\n\nAccuracy scores of train 0.995 and validation 0.656 sets\nLength of predictors is:  4\n\n\n\n\n\n\n  \n    \n      col_0\n      L\n      W\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      L\n      358\n      109\n    \n    \n      W\n      152\n      139\n    \n  \n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, xs.columns)\nfi = rf_feat_importance(clf, xs)\ncol_use = fi[fi['imp']>0.004].cols.values\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, col_use)\npred=clf.predict(valid_xs[col_use])\nprint('Length of predictors is: ',len(col_use))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.669 sets\nAccuracy scores of train 1.000 and validation 0.657 sets\nLength of predictors is:  59\n\n\n\n\n\n\n  \n    \n      col_0\n      L\n      W\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      L\n      395\n      72\n    \n    \n      W\n      188\n      103\n    \n  \n\n\n\n\n\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_,'balanced')\npred=clf.predict(valid_xs[predictors_])\n# print(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\n# format(accuracy_score(valid_y2, pred),precision_score(valid_y2, pred) ) )\nprint('Length of predictors is: ',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.658 sets\nLength of predictors is:  63\n\n\n\n\n\n\n  \n    \n      col_0\n      L\n      W\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      L\n      415\n      52\n    \n    \n      W\n      207\n      84\n    \n  \n\n\n\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\n\n\n\n  \n    \n      \n      category\n      NetScore_x\n    \n  \n  \n    \n      0\n      NetScore_y\n      -1.000000\n    \n    \n      1\n      ground_y\n      -0.264919\n    \n    \n      2\n      cmp_passing.2_y\n      -0.264773\n    \n    \n      3\n      cmp_passing_y\n      -0.263268\n    \n    \n      4\n      rec_y\n      -0.263268\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336\n      att_passing_x\n      0.307719\n    \n    \n      337\n      carries_x\n      0.307754\n    \n    \n      338\n      live_passing_types_x\n      0.307866\n    \n    \n      339\n      mid 3rd_possession_x\n      0.309859\n    \n    \n      340\n      NetScore_x\n      1.000000\n    \n  \n\n341 rows × 2 columns\n\n\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.26) )]]\n# Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.24) )]]\n\n# Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\n\nXuse=list(Xuse[-20:-1].category.values)\nXuse\n\n\n['att_passing.1_x',\n '1/3_passing_x',\n 'prgdist_possession_x',\n 'ground_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'totdist_passing_x',\n 'touches_x',\n 'cmp_passing_types_x',\n 'cmp_passing_x',\n 'rec_x',\n 'targ_x',\n 'live_possession_x',\n 'prog_possession_x',\n 'att_passing_types_x',\n 'att_passing_x',\n 'carries_x',\n 'live_passing_types_x',\n 'mid 3rd_possession_x']\n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, Xuse)\npred=clf.predict(valid_xs[Xuse])\n\n# print(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\n# format(accuracy_score(valid_y2, pred),precision_score(valid_y2, pred) ) )\n\nprint('Length of predictors is: ',len(Xuse))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.632 sets\nLength of predictors is:  19\n\n\n\n\n\n\n  \n    \n      col_0\n      L\n      W\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      L\n      405\n      62\n    \n    \n      W\n      217\n      74\n    \n  \n\n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[predictors_.append(x) for x in Xuse]\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)\npred=clf.predict(valid_xs[predictors_])\n\n# print(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\n# format(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\nprint('number of predictors =',len(predictors_))\n\ncrosstab=pd.crosstab(index = valid_y2, columns = pred)\ncrosstab\n\nAccuracy scores of train 1.000 and validation 0.656 sets\nnumber of predictors = 23\n\n\n\n\n\n\n  \n    \n      col_0\n      L\n      W\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      L\n      410\n      57\n    \n    \n      W\n      204\n      87\n    \n  \n\n\n\n\n\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)\npred=clf.predict(valid_xs[predictors_])\n\n# print(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\n# format(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\n\nprint('number of predictors =',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred)\ncrosstab\n\nclf.score(valid_xs[predictors_],valid_y2)\n\nAccuracy scores of train 1.000 and validation 0.653 sets\nnumber of predictors = 82\n\n\n0.6530343007915568"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#combine-the-same-results",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#combine-the-same-results",
    "title": "ThomasHSimm",
    "section": "Combine the same results",
    "text": "Combine the same results\n\ndf_comb=valid_xs.copy()\n\ndf_comb['pred']=clf.predict(valid_xs[predictors_])\ndf_comb['predProb']=clf.predict_proba(valid_xs[predictors_])[:,1]\ndf_comb['Win']=valid_y2\ndf_comb['y1']=valid_y\n\n\ndef team_combo_unq(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    return stra \ndef team_combo2(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    if np.array_equal(a,a2):\n        return  'te'\n    else:\n        return  'op'\ndef winbinary(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\n    \ndf_comb['team_unq']=df_comb.apply(lambda x: team_combo_unq(x['team_x'],x['opponent_x']), axis=1)\ndf_comb['team_opp']=df_comb.apply(lambda x: team_combo2(x['team_x'],x['opponent_x']), axis=1)\ndf_comb['WinBinary']=df_comb['Win'].apply(winbinary)\n\ndf_comb['pred']=df_comb['pred'].apply(winbinary)\n\ndf_comb.iloc[:10,:]\n\ndf_comb.loc[df_comb['team_opp']=='te','WinBinary']=1-df_comb.loc[df_comb['team_opp']=='te','WinBinary']\ndf_comb.loc[df_comb['team_opp']=='te','predProb']=1-df_comb.loc[df_comb['team_opp']=='te','predProb']\ndf_comb.loc[df_comb['team_opp']=='te','pred']=1-df_comb.loc[df_comb['team_opp']=='te','pred']\n\n\nbb=df_comb.groupby(by=['round','team_unq']).mean()\n\nbb\n\n\n\n\n\n  \n    \n      \n      \n      day\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      sot%_x\n      g/sh_x\n      ...\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n      pred\n      predProb\n      WinBinary\n    \n    \n      round\n      team_unq\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      1 24\n      14.0\n      -1.000000\n      1.500000\n      2.500000\n      12.5\n      1.333333\n      13.000000\n      3.166667\n      22.583333\n      0.081667\n      ...\n      0.333333\n      0.333333\n      0.000000\n      81.500000\n      20.333333\n      20.833333\n      50.450000\n      0.5\n      0.465\n      1.0\n    \n    \n      12 16\n      14.0\n      1.333333\n      2.166667\n      0.833333\n      14.0\n      2.166667\n      12.333333\n      5.166667\n      39.416667\n      0.156667\n      ...\n      0.166667\n      0.000000\n      0.000000\n      79.333333\n      14.666667\n      14.166667\n      51.850000\n      0.5\n      0.595\n      1.0\n    \n    \n      13 27\n      14.0\n      -1.000000\n      1.000000\n      2.000000\n      20.0\n      1.000000\n      10.833333\n      3.166667\n      32.100000\n      0.063333\n      ...\n      0.333333\n      0.333333\n      0.166667\n      74.666667\n      12.166667\n      16.000000\n      44.300000\n      0.5\n      0.605\n      0.0\n    \n    \n      14 18\n      14.0\n      -0.333333\n      1.166667\n      1.500000\n      16.0\n      1.166667\n      13.000000\n      3.333333\n      29.616667\n      0.056667\n      ...\n      0.000000\n      0.000000\n      0.166667\n      80.333333\n      15.666667\n      16.500000\n      48.533333\n      0.0\n      0.225\n      0.0\n    \n    \n      15 23\n      15.0\n      1.333333\n      3.000000\n      1.666667\n      19.0\n      2.833333\n      14.833333\n      6.666667\n      44.100000\n      0.201667\n      ...\n      0.000000\n      0.833333\n      0.166667\n      75.000000\n      11.666667\n      13.000000\n      47.033333\n      0.0\n      0.270\n      1.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      38\n      3 12\n      22.0\n      -0.666667\n      1.333333\n      2.000000\n      7.5\n      1.166667\n      12.833333\n      3.666667\n      32.750000\n      0.110000\n      ...\n      0.000000\n      0.333333\n      0.000000\n      80.166667\n      13.666667\n      16.000000\n      45.633333\n      0.5\n      0.450\n      1.0\n    \n    \n      4 26\n      22.0\n      1.666667\n      2.500000\n      0.833333\n      15.0\n      2.500000\n      12.166667\n      4.666667\n      37.800000\n      0.191667\n      ...\n      0.166667\n      0.166667\n      0.166667\n      78.000000\n      14.500000\n      14.166667\n      50.183333\n      0.5\n      0.550\n      0.0\n    \n    \n      5 17\n      22.0\n      -1.000000\n      0.833333\n      1.833333\n      11.0\n      0.666667\n      11.000000\n      3.666667\n      34.766667\n      0.041667\n      ...\n      0.000000\n      0.166667\n      0.166667\n      78.666667\n      22.333333\n      24.000000\n      47.533333\n      0.0\n      0.355\n      1.0\n    \n    \n      7 24\n      22.0\n      -1.166667\n      0.833333\n      2.000000\n      15.5\n      0.666667\n      14.833333\n      4.000000\n      27.300000\n      0.030000\n      ...\n      0.166667\n      0.166667\n      0.000000\n      83.333333\n      19.666667\n      18.500000\n      52.133333\n      0.0\n      0.220\n      0.0\n    \n    \n      8 16\n      22.0\n      0.166667\n      1.333333\n      1.166667\n      12.0\n      1.333333\n      12.166667\n      4.500000\n      39.483333\n      0.103333\n      ...\n      0.166667\n      0.000000\n      0.000000\n      80.166667\n      20.000000\n      17.666667\n      54.716667\n      0.5\n      0.575\n      0.0\n    \n  \n\n379 rows × 342 columns\n\n\n\n\ndef roundaa(num):\n    if num>.5:\n        return 1\n    else:\n        return 0\n    \nbb.loc[bb.WinBinary==0.5,'WinBinary']=0\nbb['WinBinary']=bb['WinBinary'].astype('int')\n\nbb.loc[bb.pred==0.5,'pred']=0\nbb['pred']=bb['pred'].astype('int')\n\nbb['predProb']=bb['predProb'].apply(roundaa)\naccuracy_score(bb['predProb'].values,bb['WinBinary'].values)\n# bb['WinBinary'].values\n\n0.6121372031662269\n\n\n\nbb['pred'].unique()\naccuracy_score(bb['pred'].values,bb['WinBinary'].values)\n# bb['WinBinary'].values\n\n0.6675461741424802\n\n\n\n# df.groupby(columns=['season','round',])\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndfnew=df_.copy()\nrf=copy.copy(clf)\npredictors=copy.copy(predictors_)\ndfnew[\"opponent_x\"] = dfnew[\"opponent_x\"].astype(\"category\").cat.codes\ndfnew[\"team_x\"] = dfnew[\"team_x\"].astype(\"category\").cat.codes\n\n# dfnew = dfnew.loc[dfnew[\"season\"] > 2020,:]\ndfnew=dfnew.dropna()\ndef team_combo_unq(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    return stra \ndef team_combo2(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    if np.array_equal(a,a2):\n        return  'te'\n    else:\n        return  'op'\n\n# team_combo_unq(2,3)\n\ndfnew['WinLoss']=dfnew[target]\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndfnew.loc[dfnew.WinLoss!='D','WinLoss']=dfnew.loc[dfnew.WinLoss!='D','WinLoss'].apply(dowin)\n\ndfnew['team_unq']=dfnew.apply(lambda x: team_combo_unq(x['team_x'],x['opponent_x']), axis=1)\ndfnew['team_opp']=dfnew.apply(lambda x: team_combo2(x['team_x'],x['opponent_x']), axis=1)\n\npred__=rf.predict_proba(dfnew[predictors])\npred__2=rf.predict(dfnew[predictors])\n\n\ndfnew['pred']= pred__[:,1]\ndfnew['predAct']= pred__2\n\ndfnew['predAct']=dfnew['predAct'].apply(dowin)\n\n# reverse Win/Loss labels for the different order of games - i.e. team vs opponent VS opponent vs team\ndfnew.loc[dfnew.team_opp=='op','pred']=1-dfnew.loc[dfnew.team_opp=='op','pred']\ndfnew.loc[dfnew.team_opp=='op','predAct']=1-dfnew.loc[dfnew.team_opp=='op','predAct']\n\ndfnew.loc[( (dfnew.WinLoss!='D') & (dfnew.team_opp=='op') ),'WinLoss']=1-dfnew.loc[( (dfnew.WinLoss!='D') & (dfnew.team_opp=='op') ),'WinLoss']\n\ndfnew.loc[dfnew.Win_x=='D','WinLoss']=0\n\ndfnew[['round','Win_x','WinLoss','team_unq','predAct']].iloc[0:20].sort_values(by='team_unq')\n\n\n\n\n\n\n  \n    \n      \n      round\n      Win_x\n      WinLoss\n      team_unq\n      predAct\n    \n  \n  \n    \n      43\n      3\n      W\n      0\n      0 14\n      0\n    \n    \n      25\n      2\n      L\n      0\n      0 21\n      0\n    \n    \n      38\n      2\n      W\n      0\n      0 21\n      0\n    \n    \n      29\n      2\n      L\n      1\n      11 17\n      1\n    \n    \n      35\n      2\n      W\n      1\n      11 17\n      1\n    \n    \n      41\n      3\n      W\n      0\n      13 16\n      0\n    \n    \n      40\n      3\n      W\n      0\n      2 15\n      0\n    \n    \n      31\n      2\n      L\n      0\n      2 24\n      0\n    \n    \n      33\n      2\n      W\n      0\n      2 24\n      0\n    \n    \n      28\n      2\n      W\n      0\n      4 13\n      0\n    \n    \n      34\n      2\n      L\n      0\n      4 13\n      0\n    \n    \n      42\n      3\n      D\n      0\n      5 23\n      1\n    \n    \n      26\n      2\n      L\n      0\n      5 25\n      0\n    \n    \n      39\n      2\n      W\n      0\n      5 25\n      0\n    \n    \n      22\n      2\n      L\n      1\n      7 23\n      1\n    \n    \n      24\n      2\n      W\n      1\n      7 23\n      1\n    \n    \n      30\n      2\n      L\n      0\n      8 14\n      0\n    \n    \n      23\n      2\n      W\n      0\n      8 14\n      0\n    \n    \n      27\n      2\n      D\n      0\n      9 15\n      0\n    \n    \n      20\n      2\n      D\n      0\n      9 15\n      1\n    \n  \n\n\n\n\n\nclf.score(valid_xs[predictors_],valid_y2)\n\n\n0.658311345646438\n\n\n\ndfnew['WinLoss'] = dfnew['WinLoss'].astype('int')\n\nA=np.array(dfnew.loc[~cond,'WinLoss'])\nB=np.array(dfnew.loc[~cond,'predAct'])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),1 ) )\n\n\nThe accuracy 0.587 and precision 1.000 of the test data\n\n\n\n\npred_df=dfnew.loc[~cond,['team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct','WinLoss']].groupby(by=['season','round','team_unq','WinLoss'],observed=True).mean()\npred_df=pred_df.reset_index()\ndef bina(numa):\n    if numa<0.5:\n        return 0\n    else:\n        return 1\n\npred_df['pred_bin']=pred_df['pred'].apply(bina)\npred_df['predAct']=pred_df['predAct'].apply(bina)\n\nA=np.array(pred_df['WinLoss'])\nB=np.array(pred_df['pred_bin'])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\nA=pred_df['WinLoss']\nB=np.array(pred_df[['predAct']])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\n# A,B\n\n# pred_df.iloc[0:20]\n\nThe accuracy 0.628 and precision 0.529 of the test data\nThe accuracy 0.536 and precision 0.458 of the test data\n\n\n\npred_df\n\n\n\n\n\n  \n    \n      \n      season\n      round\n      team_unq\n      WinLoss\n      team_x\n      opponent_x\n      pred\n      predAct\n      pred_bin\n    \n  \n  \n    \n      0\n      2021\n      1\n      1 24\n      0\n      12.5\n      12.5\n      0.535\n      1\n      1\n    \n    \n      1\n      2021\n      1\n      12 16\n      0\n      14.0\n      14.0\n      0.405\n      1\n      0\n    \n    \n      2\n      2021\n      1\n      13 27\n      1\n      20.0\n      20.0\n      0.395\n      1\n      0\n    \n    \n      3\n      2021\n      1\n      14 18\n      1\n      16.0\n      16.0\n      0.775\n      1\n      1\n    \n    \n      4\n      2021\n      1\n      15 23\n      0\n      19.0\n      19.0\n      0.730\n      1\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      374\n      2021\n      38\n      3 12\n      0\n      7.5\n      7.5\n      0.550\n      1\n      1\n    \n    \n      375\n      2021\n      38\n      4 26\n      1\n      15.0\n      15.0\n      0.450\n      1\n      0\n    \n    \n      376\n      2021\n      38\n      5 17\n      0\n      11.0\n      11.0\n      0.645\n      1\n      1\n    \n    \n      377\n      2021\n      38\n      7 24\n      1\n      15.5\n      15.5\n      0.780\n      1\n      1\n    \n    \n      378\n      2021\n      38\n      8 16\n      1\n      12.0\n      12.0\n      0.425\n      1\n      0\n    \n  \n\n379 rows × 9 columns\n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors)\npred=clf.predict(valid_xs[predictors])\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y, pred),precision_score(valid_y, pred) ) )\n\nprint('number of predictors =',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs[predictors])\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\nclf.score(valid_xs[predictors_],valid_y)\n\n0.46701846965699206\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[Xuse.append(x) for x in predictors_]\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, Xuse)\npred=clf.predict(valid_xs)\n\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#look-at-the-predictions",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#look-at-the-predictions",
    "title": "ThomasHSimm",
    "section": "Look at the predictions",
    "text": "Look at the predictions\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#try-with-a-binary-question-does-the-team-win-1",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#try-with-a-binary-question-does-the-team-win-1",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import Ridge\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\ncolsextraX=[x for x in df.columns if  x[-2:]!='_y']\ncolsextraY=[x for x in df.columns if  x[-2:]!='_x']\n\n#collapse-hide\n\nimport copy\ndf=copy.copy(dfAll)\n\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\n\ndf=df.rename(columns={'Win_x':'Win'})\ndf=df.loc[( ((df['round']>1) & (df['season']==2017)) | (df['season']>2017)  ) ]\n\n#     df=df.loc[:,colsextra]\n\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n#############\nwant_binary=1\nif want_binary==1:\n    df.loc[df['Win']=='D','Win']='L'\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\ndef do_RF():\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n    ppred_valid=clf.predict_proba(valid_xs)\n    ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,ppred,ppred_valid\n\ndef do_XGB(n_estimators=1000, learning_rate=0.0001, n_jobs=100):\n    # !pip install xgboost\n    \n\n    # Define the model\n    my_model_2 = XGBClassifier(n_estimators=1000, learning_rate=0.01) # Your code here\n\n    # Fit the model\n    my_model_2.fit(xs, y) \n\n    # Get predictions\n    ppred = my_model_2.predict_proba(xs)\n    ppred_valid = my_model_2.predict_proba(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n\n    return pred,pred_valid,ppred,ppred_valid \n\ndef do_ridge():\n    my_model_2 = Ridge(alpha=21)\n    my_model_2.fit(xs, y)\n    \n    # Get predictions\n    ppred = my_model_2.predict(xs)\n    ppred_valid = my_model_2.predict(valid_xs)\n    \n    pred = my_model_2.predict(xs)\n    pred_valid = my_model_2.predict(valid_xs)\n    \n    pred[pred>0.5]=1\n    pred[pred<=0.5]=0\n    \n    pred_valid[pred_valid>0.5]=1\n    pred_valid[pred_valid<=0.5]=0\n\n    return pred,pred_valid , ppred,ppred_valid\n    \n    \n\n\npred_RF,pred_valid_RF, ppred_RF,ppred_valid_RF  = do_RF()\npred_XGB,pred_valid_XGB,ppred_XGB,ppred_valid_XGB = do_XGB()\npred_rdg,pred_valid_rdg,ppred_rdg,ppred_valid_rdg = do_ridge()\n\n\npred_combo=(ppred_valid_RF[:,1]+ppred_valid_XGB[:,1])\npred_combo[pred_combo>=1]=1\npred_combo[pred_combo<1] =0\n\n\ndef get_scores(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.2f} and precision = {:.2f}\".format(nom,acc,prec))\n\nget_scores('RF train',pred_RF, y)\nget_scores('RF valid',pred_valid_RF, valid_y)\nprint('-----')\nget_scores('XGB train',pred_XGB, y)\nget_scores('XGB valid',pred_valid_XGB, valid_y)\nprint('-----')\nget_scores('Ridge train',pred_rdg, y)\nget_scores('Ridge valid',pred_valid_rdg, valid_y)\nprint('-----')\nget_scores('Combined valid',pred_combo, valid_y)"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#try-reducing-the-predictors",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-Copy4.html#try-reducing-the-predictors",
    "title": "ThomasHSimm",
    "section": "Try reducing the predictors",
    "text": "Try reducing the predictors\nThere is a lot of variance, do we need all the columns and what accuracy do we get with just a few basic ones?\n\n##hide\ndf_=pd.read_csv(folda+'epl2017-2021.csv')\ndf_=df_.iloc[10:,:]\n\npredictors=['day','opponent_x','team_x','weekday']\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\n\npredictors.append('Win_x')\npredictors.append('season')\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint('Length of training and test data: ',len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier()#n_estimators = 40, min_samples_split =10, random_state = 1)\nprint('The predictors ', predictors[0:-2])\npredictors=predictors[0:-2]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\npred_train = rf.predict(train[predictors])\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the training data\".format(accuracy_score(train['Win_x'], pred_train),precision_score(train['Win_x'], pred_train) ) )\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".format(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) ) )\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.26) )]]\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.24) )]]\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\n\nXuse=list(Xuse[-20:-1].category.values)\nXuse\n\n\n##hide\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndf_=df_.iloc[10:,:]\n\npredictors_=['round','opponent_x','team_x','weekday']\n\ndf_[\"opponent_x\"] = df_[\"opponent_x\"].astype(\"category\").cat.codes\ndf_[\"team_x\"] = df_[\"team_x\"].astype(\"category\").cat.codes\n\n\ndf_=df_[df_['Win_x']!='D']\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf_['Win_x']=df_['Win_x'].apply(dowin)\n\npredictors=Xuse.copy()\n\n[predictors.append(x) for x in predictors_]\n\n\npredictors.append('season')\npredictors.append('Win_x')\n\n\n\n\ndf=df_.copy()\ndf=df.loc[:,predictors]\ndf=df.dropna()\n\ntrain = df.loc[df[\"season\"] <= 2020,:]\ntest = df.loc[df[\"season\"] > 2020,:]\n\nprint('Length of training and test data: ',len(train) , len(test))\n# RandomForestClassifie\nrf = RandomForestClassifier(n_estimators = 200, min_samples_split =4, random_state = 1)\nprint('The predictors ', predictors[0:-2])\npredictors=predictors[0:-1]\nrf.fit(train[predictors], train['Win_x'])\npred = rf.predict(test[predictors])\npred_train = rf.predict(train[predictors])\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the training data\".\\\nformat(accuracy_score(train['Win_x'], pred_train),precision_score(train['Win_x'], pred_train) ) )\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(test['Win_x'], pred),precision_score(test['Win_x'], pred) ) )\n\n\ncombined = pd.DataFrame(dict(actual = test['Win_x'], prediction = pred ))\ncrosstab=pd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\ncrosstab\n# crosstab=np.array(crosstab)\n\n# # sum(crosstab.diagonal())/\n# crosstab,np.sum(crosstab),np.sum(crosstab, axis=1)\n# # crosstab\n\n\n# df.groupby(columns=['season','round',])\n\ndfnew=df.copy()\n\ndfnew = dfnew.loc[df[\"season\"] > 2020,:]\ndef team_combo_unq(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    return stra \ndef team_combo2(inta1,inta2):\n    a2=np.array([inta1,inta2])\n    a=np.sort(a2)\n    stra = str(int(a[0]))+' '+ str(int(a[1]))\n    if np.array_equal(a,a2):\n        return  'te'\n    else:\n        return  'op'\n\nteam_combo_unq(2,3)\n\ndfnew['team_unq']=dfnew.apply(lambda x: team_combo_unq(x['team_x'],x['opponent_x']), axis=1)\ndfnew['team_opp']=dfnew.apply(lambda x: team_combo2(x['team_x'],x['opponent_x']), axis=1)\n\npred__=rf.predict_proba(dfnew[predictors])\npred__2=rf.predict(dfnew[predictors])\ndfnew['pred']= pred__[:,1]\ndfnew['predAct']= pred__2\n\n\ndfnew.loc[dfnew.team_opp=='op','pred']=1-dfnew.loc[dfnew.team_opp=='op','pred']\ndfnew.loc[dfnew.team_opp=='op','predAct']=1-dfnew.loc[dfnew.team_opp=='op','predAct']\n\ndfnew.loc[dfnew.team_opp=='op','Win_x']=1-dfnew.loc[dfnew.team_opp=='op','Win_x']\n# a=np.array([1 ,3])\n# a\n\n\nA=dfnew['Win_x']\nB=dfnew[['predAct']]\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\n\n\npred_df=dfnew.loc[:,['Win_x','team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct']].groupby(by=['season','round','team_unq']).mean()\n\ndef bina(numa):\n    if numa<0.5:\n        return 0\n    else:\n        return 1\n\npred_df['pred_bin']=pred_df['pred'].apply(bina)\npred_df['predAct']=pred_df['predAct'].apply(bina)\n\nA=np.array(pred_df['Win_x'])\nB=pred_df['pred_bin']\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\nA=pred_df['Win_x']\nB=np.array(pred_df[['predAct']])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".\\\nformat(accuracy_score(A, B),precision_score(A, B) ) )\n\npred_df\n\n\n# dfnew[['Win_x','team_x','season','opponent_x','round','team_unq','pred','team_opp','predAct']]\naccuracy_score(np.array(dfnew[['predAct']]), dfnew[['Win_x']] ) \n\n\ndf_=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndf_=df_.iloc[10:,:]\nprint(len(df_.loc[df_.Win_x=='W']),len(df_.loc[df_.Win_x=='L']) )\n\ndf_[['team_x','team_y','round','Win_x']].iloc[0:11]\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(rf, train[predictors])\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n#collapse-output\npredictors2=predictors.copy()\npredictors2.append('season')\npredictors2.append('Win_x')\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\ndfAll=dfAll.loc[10:,predictors2]\ndfAll\n\n\ndf=copy.copy(dfAll)\ntry:\n    df=df.drop(columns=['Unnamed: 0'])\nexcept:\n    pass\ndf=df.rename(columns={'Win_x':'Win'})\n\ndef dowin(string):\n    if string=='W':\n        return 1\n    else:\n        return 0\ndf['Win']=df['Win'].apply(dowin)\nsza=np.shape(df)[0]\n\nrandAr=np.random.randint(0,100, size=sza)\ncond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\nsplits = (list(train_idx),list(valid_idx))\n\n\n##############\n\ndep_var='Win'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n\n###############\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef do_RF(xs,y,valid_xs):\n##############\n    clf=RandomForestClassifier(random_state=42)\n    clf.fit(xs,y)\n\n    # clf.score(xs,y),clf.score(valid_xs,valid_y)\n    pred_valid=clf.predict(valid_xs)\n    pred=clf.predict(xs)\n    \n#     ppred_valid=clf.predict_proba(valid_xs)\n#     ppred=clf.predict_proba(xs)\n    \n    return pred,pred_valid,clf#,ppred,ppred_valid\n\n   \npred,pred_val,clf=do_RF(xs,y,valid_xs)\n\n\n# new_preds,new_y=get_reg_scores(valid_y,pred_val,.5)\n\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the train data\".format(\\\n  accuracy_score(y, pred),precision_score(y, pred) ) )\nprint(\"The accuracy {:.3f} and precision {:.3f} of the test data\".format(\\\n  accuracy_score(valid_y, pred_val),precision_score(valid_y, pred_val) ) )\n\n\ncombined = pd.DataFrame(dict(actual = valid_y, prediction = pred_val ))\ncrosstab=pd.crosstab(index = combined[\"actual\"], columns = combined['prediction'])\ncrosstab\n# crosstab=np.array(crosstab)\n\n# sum(crosstab.diagonal())/sum(sum(crosstab))\n# # crosstab\n\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-PrepareTheData.html#introduction",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-PrepareTheData.html#introduction",
    "title": "ThomasHSimm",
    "section": "Introduction",
    "text": "Introduction\nThe aim of this page is to prepare data for modelling to predict the results.\n\nSource of the data\nThe data was downloaded with this code which uses the wesbite FBREF.\nThe data from the following seasons were used (season = year competition started), as earlier years had a different format: - 2017 - 2018 - 2019 - 2020 - 2021\nFurther down the data in each column downloaded is shown.\n\n\nMethodology\nThe data gives details of a given match along with the result. Details such as shots on goal, possession etc. But I don’t want to predict the results of a match given the data of that match. Instead I want to predict the result based on data from previous matches.\n\nSo the data for a match needs to come from data from previous matches, with preferance to matches that are near\n\nThe second important step with this data is to combine results of the home and away team to allow predictions for one match.\n#collapse-hide"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-PrepareTheData.html#the-data",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-PrepareTheData.html#the-data",
    "title": "ThomasHSimm",
    "section": "The data",
    "text": "The data\n\nOverall match details\n\nDate – Date listed is local to the match\nTime – Time listed is local to the match venue\n\nTime is written in the 24-hour notation -Your local time is in (·)\n\nComp – Competition\nNumber next to competition states which level in the country’s league pyramid this league occupies.\nRound – Round or Phase of Competition\nDay – Day of week\nGF – Goals For\nGA – Goals Against\nopponent\n\n\n\nScores & Fixtures\n\nDay – Day of week\nxG – Expected Goals\n\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nxGA – Expected Goals Allowed\n\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nPoss – Possession\n\nCalculated as the percentage of passes attempted\n\nFormation – Number of players in each row from defenders to forwards, not including the goalkeeper.\n\nFormations provided by Data Sports Group and StatsBomb.\n\n\n\n\nShooting\n\nStandard\n\nGls – Goals scored or allowed\nSh – Shots Total -Does not include penalty kicks\nSoT – Shots on target -Note: Shots on target do not include penalty kicks\nSoT% – Percentage of shots that are on target\n\nMinimum .395 shots per squad game to qualify as a leader -Note: Shots on target do not include penalty kicks\n\nG/Sh – Goals per shot\n\nMinimum .395 shots per squad game to qualify as a leader\n\nG/SoT – Goals per shot on target\n\nMinimum .111 shots on target per squad game to qualify as a leader\nNote: Shots on target do not include penalty kicks\n\nDist – Average distance, in yards, from goal of all shots taken\n\nMinimum .395 shots per squad game to qualify as a leader\nDoes not include penalty kicks\n\nFK – Shots from free kicks\nPK – Penalty Kicks Made\nPKatt – Penalty Kicks Attempted #### Expected\nxG – Expected Goals\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nnpxG – Non-Penalty Expected Goals\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nnpxG/Sh – Non-Penalty Expected Goals per shot\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\nMinimum .395 shots per squad game to qualify as a leader\n\nG-xG – Goals minus Expected Goals\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\n\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nnp:G-xG – Non-Penalty Goals minus Non-Penalty Expected Goals\n\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\n\n\n\n\nGoalkeeping\n\nPerformance\n\nSoTA – Shots on Target Against\nGA – Goals Against\nSave% – Save Percentage\n\n(Shots on Target Against - Goals Against)/Shots on Target Against\nNote that not all shots on target are stopped by the keeper, many will be stopped by defenders\nDoes not include penalty kicks\n\nCS – Clean Sheets\n\nFull matches by goalkeeper where no goals are allowed.\n\nPSxG – Post-Shot Expected Goals\n\nPSxG is expected goals based on how likely the goalkeeper is to save the shot\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nPSxG+/- – Post-Shot Expected Goals minus Goals Allowed\n\nPositive numbers suggest better luck or an above average ability to stop shots\nPSxG is expected goals based on how likely the goalkeeper is to save the shot\nNote: Does not include own goals\nxG totals include penalty kicks, but do not include penalty shootouts (unless otherwise noted).\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available. #### Penalty Kicks\n\nPKatt – Penalty Kicks Attempted\nPKA– Penalty Kicks Allowed\nPKsv – Penalty Kicks Saved\nPKm– Penalty Kicks Missed #### Launched\nCmp – Passes Completed\n\nPasses` longer than 40 yards\n\nAtt – Passes Attempted\n\nPasses longer than 40 yards\n\nCmp% – Pass Completion Percentage\n\nPasses longer than 40 yards #### Passes\n\nAtt – Passes Attempted\n\nNot including goal kicks\n\nThr – Throws Attempted\nLaunch% – Percentage of Passes that were Launched\n\nNot including goal kicks\nPasses longer than 40 yards\n\nAvgLen – Average length of passes, in yards\n\nNot including goal kicks #### Goal Kicks\n\nAtt – Goal Kicks Attempted\nLaunch% – Percentage of Goal Kicks that were Launched\n\nPasses longer than 40 yards\n\nAvgLen – Average length of goal kicks, in yards #### Crosses\nOpp – Opponent’s attempted crosses into penalty area\nStp – Number of crosses into penalty area which were successfully stopped by the goalkeeper\nStp% – Percentage of crosses into penalty area which were successfully stopped by the goalkeeper #### Sweeper\n#OPA – # of defensive actions outside of penalty area\nAvgDist – Average distance from goal (in yards) of all defensive actions\n\n\n\n\nPassing\n\nTotal\n\nCmp – Passes Completed\nAtt – Passes Attempted\nCmp% – Pass Completion Percentage\n\nMinimum 30 minutes played per squad game to qualify as a leader\n\nTotDist – Total distance, in yards, that completed passes have traveled in any direction\nPrgDist – Progressive Distance\n\nTotal distance, in yards, that completed passes have traveled towards the opponent’s goal. Note: Passes away from opponent’s goal are counted as zero progressive yards. #### Short\n\nCmp – Passes Completed\n\nPasses between 5 and 15 yards\n\nAtt – Passes Attempted\n\nPasses between 5 and 15 yards\n\nCmp% – Pass Completion Percentage\n\nPasses between 5 and 15 yards\nMinimum 30 minutes played per squad game to qualify as a leader #### Medium\n\nCmp – Passes Completed\n\nPasses between 15 and 30 yards\n\nAtt – Passes Attempted\n\nPasses between 15 and 30 yards\n\nCmp% – Pass Completion Percentage\n\nPasses between 15 and 30 yards\nMinimum 30 minutes played per squad game to qualify as a leader #### Long\n\nCmp – Passes Completed\n\nPasses longer than 30 yards\n\nAtt – Passes Attempted\n\nPasses longer than 30 yards\n\nCmp% – Pass Completion Percentage\n\nPasses longer than 30 yards\nMinimum 30 minutes played per squad game to qualify as a leader #### Others\n\nAst – Assists\nxA – xG Assisted\n\nxG which follows a pass that assists a shot\nProvided by StatsBomb.\nAn underline indicates there is a match that is missing data, but will be updated when available.\n\nKP – Passes that directly lead to a shot (assisted shots)\n1/3 – Completed passes that enter the 1/3 of the pitch closest to the goal\n\nNot including set pieces\n\nPPA – Completed passes into the 18-yard box\n\nNot including set pieces\n\nCrsPA – Completed crosses into the 18-yard box\n\nNot including set pieces\n\nProg – Progressive Passes\n\nCompleted passes that move the ball towards the opponent’s goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area. Excludes passes from the defending 40% of the pitch\n\n\n\n\n\nPass Types\n\nTotal\n\nAtt – Passes Attempted #### Pass Types\nLive – Live-ball passes\nDead – Dead-ball passes\n\nIncludes free kicks, corner kicks, kick offs, throw-ins and goal kicks\n\nFK – Passes attempted from free kicks\nTB – Completed pass sent between back defenders into open space\nPress – Passes made while under pressure from opponent\nSw – Passes that travel more than 40 yards of the width of the pitch\nCrs – Crosses\nCK – Corner Kicks\n\n\n\nCorner Kicks\n\nIn – Inswinging Corner Kicks\nOut – Outswinging Corner Kicks\nStr – Straight Corner Kicks #### Height\nGround – Ground passes\nLow – Passes that leave the ground, but stay below shoulder-level\nHigh – Passes that are above shoulder-level at the peak height #### Body Parts\nLeft – Passes attempted using left foot\nRight – Passes attempted using right foot\nHead – Passes attempted using head\nTI – Throw-Ins taken\nOther – Passes attempted using body parts other than the player’s head or feet #### Outcomes\nCmp – Passes Completed\nOff – Offsides\nOut – Out of bounds\nInt – Intercepted\nBlocks – Blocked by the opponent who was standing it the path\n\n\n\n\nGoal and Shot Creation\n\nSCA Types\n\nSCA – Shot-Creating Actions\n\nThe two offensive actions directly leading to a shot, such as passes, dribbles and drawing fouls. Note: A single player can receive credit for multiple actions and the shot-taker can also receive credit.\n\nPassLive – Completed live-ball passes that lead to a shot attempt\nPassDead – Completed dead-ball passes that lead to a shot attempt.\n\nIncludes free kicks, corner kicks, kick offs, throw-ins and goal kicks\n\nDrib – Successful dribbles that lead to a shot attempt\nSh – Shots that lead to another shot attempt\nFld – Fouls drawn that lead to a shot attempt\nDef – Defensive actions that lead to a shot attempt #### GCA Types\nGCA – Goal-Creating Actions\n\nThe two offensive actions directly leading to a goal, such as passes, dribbles and drawing fouls. Note: A single player can receive credit for multiple actions and the shot-taker can also receive credit.\n\nPassLive – Completed live-ball passes that lead to a goal\nPassDead – Completed dead-ball passes that lead to a goal. Includes free kicks, corner kicks, kick offs, throw-ins and goal kicks\nDrib – Successful dribbles that lead to a goal\nSh – Shots that lead to another goal-scoring shot\nFld – Fouls drawn that lead to a goal\nDef – Defensive actions that lead to a goal\n\n\n\n\nDefensive Actions\n\n\nTackles\n\nTkl – Number of players tackled\nTklW – Tackles in which the tackler’s team won possession of the ball\nDef 3rd – Tackles in defensive 1/3\nMid 3rd – Tackles in middle 1/3\nAtt 3rd – Tackles in attacking 1/3\n\n\nVs Dribbles\n\nTkl – Number of dribblers tackled\nAtt – Number of times dribbled past plus number of tackles\nTkl% – Percentage of dribblers tackled\n\nDribblers tackled divided by dribblers tackled plus times dribbled past\nMinimum .625 dribblers contested per squad game to qualify as a leader\n\nPast – Number of times dribbled past by an opposing player\n\n\n\nPressures\n\nPress – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball\nSucc – Number of times the squad gained possession withing five seconds of applying pressure\n% – Successful Pressure Percentage\n\nPercentage of time the squad gained possession withing five seconds of applying pressure\nMinimum 6.44 pressures per squad game to qualify as a leader\n\nDef 3rd – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the defensive 1/3\nMid 3rd – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the middle 1/3\nAtt 3rd – Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the attacking 1/3\n\n\n\nBlocks\n\nBlocks – Number of times blocking the ball by standing in its path\nSh – Number of times blocking a shot by standing in its path\nShSv – Number of times blocking a shot that was on target, by standing in its path\nPass – Number of times blocking a pass by standing in its path\nInt – Interceptions\nTkl+Int – Number of players tackled plus number of interceptions\nClr – Clearances\nErr – Mistakes leading to an opponent’s shot\n\n\n\n\nPossession\n\nPoss – Possession\n\nCalculated as the percentage of passes attempted #### Touches\n\nTouches – Number of times a player touched the ball. Note: Receiving a pass, then dribbling, then sending a pass counts as one touch\nDef Pen – Touches in defensive penalty area\nDef 3rd – Touches in defensive 1/3\nMid 3rd – Touches in middle 1/3\nAtt 3rd – Touches in attacking 1/3\nAtt Pen – Touches in attacking penalty area\nLive – Live-ball touches. Does not include corner kicks, free kicks, throw-ins, kick-offs, goal kicks or penalty kicks #### Dribbles\nSucc – Dribbles Completed Successfully\nAtt – Dribbles Attempted\nSucc% – Percentage of Dribbles Completed Successfully\n\nMinimum .5 dribbles per squad game to qualify as a leader\n\n#Pl – Number of Players Dribbled Past\nMegs – Number of times a player dribbled the ball through an opposing player’s legs\n\n\nCarries\n\nCarries – Number of times the player controlled the ball with their feet\nTotDist – Total distance, in yards, a player moved the ball while controlling - it with their feet, in any direction\nPrgDist – Progressive Distance\n\nTotal distance, in yards, a player moved the ball while controlling it with - their feet towards the opponent’s goal\n\nProg – Carries that move the ball towards the opponent’s goal at least 5 - yards, or any carry into the penalty area. Excludes carries from the defending 40% of the pitch\n1/3 – Carries that enter the 1/3 of the pitch closest to the goal\nCPA – Carries into the 18-yard box\nMis – Number of times a player failed when attempting to gain control of a ball\nDis – Number of times a player loses control of the ball after being tackled - by an opposing player. Does not include attempted dribbles\n\n\n\nReceiving\n\nTarg – Number of times a player was the target of an attempted pass\nRec – Number of times a player successfully received a pass\nRec% – Passes Received Percentage\n\nPercentage of time a player successfully received a pass\nMinimum 30 minutes played per squad game to qualify as a leader\n\nProg – Progressive Passes Received\n\nCompleted passes that move the ball towards the opponent’s goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area. Excludes passes from the defending 40% of the pitch\n\n\n\n\n\nMiscellaneous Stats\n\nPerformance\n\nCrdY– Yellow Cards\nCrdR– Red Cards\n2CrdY – Second Yellow Card\nFls- Fouls Committed\nFld – Fouls Drawn\nOff – Offsides\nCrs – Crosses\nInt – Interceptions\nTklW– Tackles in which the tackler’s team won possession of the ball\nPKwon – Penalty Kicks Won\nPKcon – Penalty Kicks Conceded\nOG -- Own Goals\nRecov – Number of loose balls recovered #### Aerial Duels\nWon – Aerials won\nLost – Aerials lost\nWon% – Percentage of aerials won Minimum .97 aerial duels per squad game to qualify as a leader"
  },
  {
    "objectID": "posts/2022-08-11-PredictingPremierLeagueMatches-PrepareTheData.html#prepare-the-data",
    "href": "posts/2022-08-11-PredictingPremierLeagueMatches-PrepareTheData.html#prepare-the-data",
    "title": "ThomasHSimm",
    "section": "Prepare the data",
    "text": "Prepare the data\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',\n 'epl2017-2021_wivnetscore_both-HA.csv',\n 'epl_beforeAVG_HA.csv']\n\n\nLoad the data and combine in one big DataFrame\n\n#collapse-output\ni=0\nfor d in dira:\n    if d[0]=='d':\n        df = pd.read_csv(folda+d,index_col=0)\n        df['Season']=int(d.split('.')[0].split('_')[-1]) \n        if i==0:\n            dfAll=df\n            i=i+1\n        else:\n            dfAll=pd.concat([dfAll,df])\n        \nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll)\n\n\n\n\n\n  \n    \n      \n      Date\n      Time\n      Comp\n      Round\n      Day\n      Venue\n      Result\n      GF\n      GA\n      Opponent\n      Gls\n      Sh_shooting\n      SoT\n      SoT%\n      G/Sh\n      G/SoT\n      Dist\n      FK_shooting\n      PK\n      PKatt_shooting\n      xG\n      npxG\n      npxG/Sh\n      G-xG\n      np:G-xG\n      Match Report\n      SoTA\n      Saves\n      Save%\n      CS\n      PSxG\n      PSxG+/-\n      PKatt_keeper\n      PKA\n      PKsv\n      PKm\n      Cmp_keeper\n      Att_keeper\n      Cmp%_keeper\n      Att_keeper.1\n      Thr\n      Launch%\n      AvgLen\n      Att_keeper.2\n      Launch%.1\n      AvgLen.1\n      Opp\n      Stp\n      Stp%\n      #OPA\n      AvgDist\n      Cmp_passing\n      Att_passing\n      Cmp%_passing\n      TotDist_passing\n      PrgDist_passing\n      Cmp_passing.1\n      Att_passing.1\n      Cmp%_passing.1\n      Cmp_passing.2\n      Att_passing.2\n      Cmp%_passing.2\n      Cmp_passing.3\n      Att_passing.3\n      Cmp%_passing.3\n      Ast\n      xA\n      KP\n      1/3_passing\n      PPA\n      CrsPA\n      Prog_passing\n      Att_passing_types\n      Live_passing_types\n      Dead\n      FK_passing_types\n      TB\n      Press_passing_types\n      Sw\n      Crs_passing_types\n      CK\n      In\n      Out\n      Str\n      Ground\n      Low\n      High\n      Left\n      Right\n      Head\n      TI\n      Other\n      Cmp_passing_types\n      Off_passing_types\n      Out.1\n      Int_passing_types\n      Blocks_passing_types\n      SCA\n      PassLive\n      PassDead\n      Drib\n      Sh_gca\n      Fld_gca\n      Def\n      GCA\n      PassLive.1\n      PassDead.1\n      Drib.1\n      Sh_gca.1\n      Fld_gca.1\n      Def.1\n      Tkl\n      TklW_defense\n      Def 3rd_defense\n      Mid 3rd_defense\n      Att 3rd_defense\n      Tkl.1\n      Att_defense\n      Tkl%\n      Past\n      Press_defense\n      Succ_defense\n      %\n      Def 3rd_defense.1\n      Mid 3rd_defense.1\n      Att 3rd_defense.1\n      Blocks_defense\n      Sh_defense\n      ShSv\n      Pass\n      Int_defense\n      Tkl+Int\n      Clr\n      Err\n      Poss\n      Touches\n      Def Pen\n      Def 3rd_possession\n      Mid 3rd_possession\n      Att 3rd_possession\n      Att Pen\n      Live_possession\n      Succ_possession\n      Att_possession\n      Succ%\n      #Pl\n      Megs\n      Carries\n      TotDist_possession\n      PrgDist_possession\n      Prog_possession\n      1/3_possession\n      CPA\n      Mis\n      Dis\n      Targ\n      Rec\n      Rec%\n      Prog_possession.1\n      CrdY\n      CrdR\n      2CrdY\n      Fls\n      Fld_misc\n      Off_misc\n      Crs_misc\n      Int_misc\n      TklW_misc\n      PKwon\n      PKcon\n      OG\n      Recov\n      Won\n      Lost\n      Won%\n      team\n      Season\n    \n  \n  \n    \n      0\n      2017-08-12\n      17:30\n      Premier League\n      Matchweek 1\n      Sat\n      Away\n      W\n      2\n      0\n      Brighton\n      1.0\n      14.0\n      4.0\n      28.6\n      0.07\n      0.25\n      19.4\n      2.0\n      0.0\n      0.0\n      1.8\n      1.8\n      0.14\n      -0.8\n      -0.8\n      Match Report\n      2.0\n      2.0\n      100.0\n      1.0\n      0.4\n      0.4\n      0.0\n      0.0\n      0.0\n      0.0\n      2.0\n      5.0\n      40.0\n      20.0\n      7.0\n      10.0\n      22.5\n      4.0\n      75.0\n      56.8\n      3.0\n      0.0\n      0.0\n      1.0\n      24.2\n      712.0\n      808.0\n      88.1\n      13422.0\n      3465.0\n      297.0\n      320.0\n      92.8\n      315.0\n      346.0\n      91.0\n      89.0\n      117.0\n      76.1\n      1.0\n      1.1\n      9.0\n      69.0\n      15.0\n      1.0\n      60.0\n      808.0\n      766.0\n      42.0\n      10.0\n      2.0\n      63.0\n      28.0\n      16.0\n      10.0\n      1.0\n      5.0\n      0.0\n      612.0\n      105.0\n      91.0\n      182.0\n      570.0\n      20.0\n      17.0\n      10.0\n      712.0\n      1.0\n      8.0\n      19.0\n      17.0\n      22.0\n      17.0\n      1.0\n      0.0\n      1.0\n      2.0\n      1.0\n      2.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      4.0\n      5.0\n      6.0\n      0.0\n      4.0\n      14.0\n      28.6\n      10.0\n      104.0\n      28.0\n      26.9\n      25.0\n      42.0\n      37.0\n      7.0\n      2.0\n      0.0\n      5.0\n      13.0\n      NaN\n      15.0\n      0.0\n      77.0\n      902.0\n      30.0\n      146.0\n      484.0\n      329.0\n      31.0\n      858.0\n      8.0\n      15.0\n      53.3\n      9.0\n      1.0\n      646.0\n      3346.0\n      1924.0\n      91.0\n      27.0\n      3.0\n      15.0\n      4.0\n      794.0\n      712.0\n      89.7\n      60.0\n      2.0\n      0.0\n      0.0\n      9.0\n      8.0\n      1.0\n      16.0\n      13.0\n      4.0\n      0.0\n      0.0\n      0.0\n      85.0\n      19.0\n      17.0\n      52.8\n      ManchesterCity\n      2017\n    \n    \n      1\n      2017-08-21\n      20:00\n      Premier League\n      Matchweek 2\n      Mon\n      Home\n      D\n      1\n      1\n      Everton\n      1.0\n      20.0\n      6.0\n      30.0\n      0.05\n      0.17\n      18.9\n      1.0\n      0.0\n      0.0\n      1.2\n      1.2\n      0.06\n      -0.2\n      -0.2\n      Match Report\n      2.0\n      1.0\n      50.0\n      0.0\n      0.8\n      -0.2\n      0.0\n      0.0\n      0.0\n      0.0\n      7.0\n      10.0\n      70.0\n      27.0\n      5.0\n      25.9\n      33.5\n      6.0\n      50.0\n      46.0\n      3.0\n      2.0\n      66.7\n      1.0\n      16.0\n      497.0\n      611.0\n      81.3\n      9615.0\n      3476.0\n      199.0\n      228.0\n      87.3\n      217.0\n      254.0\n      85.4\n      72.0\n      110.0\n      65.5\n      0.0\n      1.0\n      16.0\n      39.0\n      16.0\n      0.0\n      67.0\n      611.0\n      556.0\n      55.0\n      11.0\n      2.0\n      135.0\n      24.0\n      14.0\n      7.0\n      0.0\n      6.0\n      0.0\n      389.0\n      113.0\n      109.0\n      158.0\n      370.0\n      22.0\n      29.0\n      10.0\n      497.0\n      0.0\n      13.0\n      10.0\n      14.0\n      33.0\n      27.0\n      3.0\n      0.0\n      1.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      15.0\n      10.0\n      9.0\n      5.0\n      1.0\n      7.0\n      14.0\n      50.0\n      7.0\n      127.0\n      42.0\n      33.1\n      42.0\n      51.0\n      34.0\n      13.0\n      0.0\n      0.0\n      13.0\n      13.0\n      NaN\n      18.0\n      0.0\n      63.0\n      732.0\n      47.0\n      190.0\n      374.0\n      227.0\n      42.0\n      678.0\n      6.0\n      15.0\n      40.0\n      7.0\n      0.0\n      447.0\n      2863.0\n      1715.0\n      77.0\n      25.0\n      9.0\n      12.0\n      16.0\n      580.0\n      497.0\n      85.7\n      67.0\n      2.0\n      1.0\n      1.0\n      8.0\n      13.0\n      0.0\n      14.0\n      13.0\n      10.0\n      0.0\n      0.0\n      0.0\n      108.0\n      28.0\n      14.0\n      66.7\n      ManchesterCity\n      2017\n    \n    \n      2\n      2017-08-26\n      12:30\n      Premier League\n      Matchweek 3\n      Sat\n      Away\n      W\n      2\n      1\n      Bournemouth\n      2.0\n      18.0\n      8.0\n      44.4\n      0.11\n      0.25\n      16.4\n      1.0\n      0.0\n      0.0\n      1.6\n      1.6\n      0.09\n      0.4\n      0.4\n      Match Report\n      3.0\n      2.0\n      66.7\n      0.0\n      1.1\n      0.1\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      3.0\n      33.3\n      17.0\n      6.0\n      11.8\n      26.9\n      1.0\n      100.0\n      98.0\n      7.0\n      1.0\n      14.3\n      0.0\n      18.6\n      568.0\n      676.0\n      84.0\n      10625.0\n      3119.0\n      243.0\n      268.0\n      90.7\n      240.0\n      280.0\n      85.7\n      78.0\n      107.0\n      72.9\n      2.0\n      1.3\n      12.0\n      47.0\n      14.0\n      2.0\n      48.0\n      676.0\n      621.0\n      55.0\n      12.0\n      1.0\n      96.0\n      16.0\n      17.0\n      5.0\n      2.0\n      2.0\n      0.0\n      445.0\n      126.0\n      105.0\n      201.0\n      377.0\n      30.0\n      35.0\n      7.0\n      568.0\n      3.0\n      7.0\n      7.0\n      22.0\n      26.0\n      18.0\n      3.0\n      1.0\n      2.0\n      2.0\n      0.0\n      4.0\n      3.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      8.0\n      6.0\n      5.0\n      1.0\n      2.0\n      1.0\n      11.0\n      9.1\n      10.0\n      91.0\n      29.0\n      31.9\n      15.0\n      38.0\n      38.0\n      13.0\n      4.0\n      0.0\n      9.0\n      8.0\n      NaN\n      23.0\n      0.0\n      71.0\n      802.0\n      54.0\n      191.0\n      403.0\n      268.0\n      41.0\n      748.0\n      11.0\n      17.0\n      64.7\n      13.0\n      0.0\n      566.0\n      2875.0\n      1691.0\n      77.0\n      25.0\n      5.0\n      25.0\n      15.0\n      653.0\n      568.0\n      87.0\n      56.0\n      5.0\n      1.0\n      1.0\n      14.0\n      16.0\n      3.0\n      17.0\n      8.0\n      6.0\n      0.0\n      0.0\n      0.0\n      119.0\n      30.0\n      11.0\n      73.2\n      ManchesterCity\n      2017\n    \n    \n      3\n      2017-09-09\n      12:30\n      Premier League\n      Matchweek 4\n      Sat\n      Home\n      W\n      5\n      0\n      Liverpool\n      5.0\n      13.0\n      10.0\n      76.9\n      0.38\n      0.50\n      14.2\n      0.0\n      0.0\n      0.0\n      2.7\n      2.7\n      0.21\n      2.3\n      2.3\n      Match Report\n      3.0\n      3.0\n      100.0\n      2.0\n      0.5\n      0.5\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      8.0\n      62.5\n      30.0\n      5.0\n      23.3\n      33.6\n      3.0\n      33.3\n      50.3\n      0.0\n      0.0\n      NaN\n      1.0\n      16.0\n      694.0\n      773.0\n      89.8\n      13656.0\n      3583.0\n      254.0\n      268.0\n      94.8\n      338.0\n      365.0\n      92.6\n      94.0\n      122.0\n      77.0\n      5.0\n      2.6\n      11.0\n      32.0\n      8.0\n      5.0\n      44.0\n      773.0\n      729.0\n      44.0\n      11.0\n      2.0\n      111.0\n      22.0\n      20.0\n      8.0\n      0.0\n      3.0\n      0.0\n      631.0\n      73.0\n      69.0\n      241.0\n      475.0\n      20.0\n      21.0\n      6.0\n      694.0\n      5.0\n      6.0\n      18.0\n      11.0\n      23.0\n      17.0\n      3.0\n      1.0\n      0.0\n      1.0\n      1.0\n      10.0\n      9.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      20.0\n      14.0\n      9.0\n      7.0\n      4.0\n      7.0\n      21.0\n      33.3\n      14.0\n      135.0\n      43.0\n      31.9\n      33.0\n      62.0\n      40.0\n      10.0\n      2.0\n      0.0\n      8.0\n      16.0\n      NaN\n      18.0\n      0.0\n      65.0\n      878.0\n      51.0\n      182.0\n      588.0\n      152.0\n      26.0\n      835.0\n      3.0\n      12.0\n      25.0\n      5.0\n      2.0\n      678.0\n      2392.0\n      1341.0\n      54.0\n      17.0\n      7.0\n      10.0\n      9.0\n      754.0\n      694.0\n      92.0\n      44.0\n      2.0\n      0.0\n      0.0\n      12.0\n      11.0\n      5.0\n      20.0\n      16.0\n      14.0\n      0.0\n      0.0\n      0.0\n      62.0\n      12.0\n      8.0\n      60.0\n      ManchesterCity\n      2017\n    \n    \n      4\n      2017-09-13\n      20:45\n      Champions Lg\n      Group stage\n      Wed\n      Away\n      W\n      4\n      0\n      nl Feyenoord\n      4.0\n      11.0\n      8.0\n      72.7\n      0.36\n      0.50\n      NaN\n      NaN\n      0.0\n      0.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Match Report\n      1.0\n      1.0\n      100.0\n      1.0\n      NaN\n      NaN\n      0.0\n      0.0\n      0.0\n      0.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      3.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      22.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      6.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      9.0\n      NaN\n      NaN\n      NaN\n      72.0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      0.0\n      0.0\n      10.0\n      12.0\n      6.0\n      22.0\n      9.0\n      6.0\n      0.0\n      0.0\n      0.0\n      NaN\n      NaN\n      NaN\n      NaN\n      ManchesterCity\n      2017\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      39\n      2022-05-08\n      14:00\n      Premier League\n      Matchweek 36\n      Sun\n      Home\n      L\n      0\n      4\n      West Ham\n      0.0\n      8.0\n      2.0\n      25.0\n      0.00\n      0.00\n      21.5\n      1.0\n      0.0\n      0.0\n      0.7\n      0.7\n      0.08\n      -0.7\n      -0.7\n      Match Report\n      4.0\n      1.0\n      25.0\n      0.0\n      2.3\n      -1.7\n      1.0\n      1.0\n      0.0\n      0.0\n      4.0\n      10.0\n      40.0\n      25.0\n      4.0\n      28.0\n      31.3\n      5.0\n      60.0\n      52.0\n      10.0\n      0.0\n      0.0\n      0.0\n      11.3\n      335.0\n      412.0\n      81.3\n      6189.0\n      2105.0\n      140.0\n      158.0\n      88.6\n      146.0\n      162.0\n      90.1\n      42.0\n      72.0\n      58.3\n      0.0\n      0.5\n      5.0\n      19.0\n      6.0\n      1.0\n      25.0\n      412.0\n      375.0\n      37.0\n      10.0\n      4.0\n      36.0\n      11.0\n      12.0\n      9.0\n      7.0\n      0.0\n      0.0\n      306.0\n      37.0\n      69.0\n      102.0\n      275.0\n      12.0\n      8.0\n      8.0\n      335.0\n      3.0\n      4.0\n      11.0\n      14.0\n      12.0\n      8.0\n      0.0\n      1.0\n      0.0\n      2.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      6.0\n      3.0\n      5.0\n      3.0\n      3.0\n      14.0\n      21.4\n      11.0\n      161.0\n      32.0\n      19.9\n      64.0\n      65.0\n      32.0\n      16.0\n      6.0\n      0.0\n      10.0\n      12.0\n      NaN\n      21.0\n      1.0\n      37.0\n      499.0\n      66.0\n      188.0\n      215.0\n      132.0\n      19.0\n      462.0\n      7.0\n      8.0\n      87.5\n      7.0\n      1.0\n      310.0\n      1933.0\n      1122.0\n      55.0\n      19.0\n      4.0\n      8.0\n      7.0\n      374.0\n      335.0\n      89.6\n      25.0\n      1.0\n      0.0\n      0.0\n      15.0\n      12.0\n      2.0\n      12.0\n      12.0\n      6.0\n      0.0\n      1.0\n      0.0\n      57.0\n      12.0\n      13.0\n      48.0\n      NorwichCity\n      2021\n    \n    \n      40\n      2022-05-11\n      19:45\n      Premier League\n      Matchweek 21\n      Wed\n      Away\n      L\n      0\n      3\n      Leicester City\n      0.0\n      9.0\n      5.0\n      55.6\n      0.00\n      0.00\n      16.2\n      0.0\n      0.0\n      0.0\n      1.2\n      1.2\n      0.15\n      -1.2\n      -1.2\n      Match Report\n      8.0\n      5.0\n      62.5\n      0.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      3.0\n      20.0\n      15.0\n      26.0\n      3.0\n      50.0\n      38.9\n      9.0\n      77.8\n      57.4\n      10.0\n      1.0\n      10.0\n      0.0\n      8.0\n      295.0\n      367.0\n      80.4\n      5864.0\n      2054.0\n      132.0\n      148.0\n      89.2\n      119.0\n      133.0\n      89.5\n      41.0\n      74.0\n      55.4\n      0.0\n      0.8\n      5.0\n      16.0\n      7.0\n      1.0\n      22.0\n      367.0\n      323.0\n      44.0\n      11.0\n      0.0\n      58.0\n      18.0\n      7.0\n      2.0\n      2.0\n      0.0\n      0.0\n      250.0\n      46.0\n      71.0\n      90.0\n      238.0\n      11.0\n      18.0\n      4.0\n      295.0\n      0.0\n      6.0\n      9.0\n      11.0\n      12.0\n      8.0\n      1.0\n      1.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      20.0\n      9.0\n      9.0\n      9.0\n      2.0\n      7.0\n      16.0\n      43.8\n      9.0\n      264.0\n      56.0\n      21.2\n      102.0\n      124.0\n      38.0\n      19.0\n      8.0\n      0.0\n      11.0\n      16.0\n      NaN\n      26.0\n      0.0\n      36.0\n      511.0\n      95.0\n      242.0\n      194.0\n      99.0\n      19.0\n      468.0\n      6.0\n      15.0\n      40.0\n      7.0\n      0.0\n      310.0\n      1330.0\n      723.0\n      26.0\n      9.0\n      1.0\n      13.0\n      17.0\n      307.0\n      295.0\n      96.1\n      22.0\n      0.0\n      0.0\n      0.0\n      10.0\n      12.0\n      0.0\n      7.0\n      16.0\n      9.0\n      0.0\n      0.0\n      0.0\n      71.0\n      8.0\n      14.0\n      36.4\n      NorwichCity\n      2021\n    \n    \n      41\n      2022-05-15\n      14:00\n      Premier League\n      Matchweek 37\n      Sun\n      Away\n      D\n      1\n      1\n      Wolves\n      1.0\n      11.0\n      2.0\n      18.2\n      0.09\n      0.50\n      13.4\n      0.0\n      0.0\n      0.0\n      1.3\n      1.3\n      0.12\n      -0.3\n      -0.3\n      Match Report\n      4.0\n      3.0\n      75.0\n      0.0\n      1.1\n      0.1\n      0.0\n      0.0\n      0.0\n      0.0\n      10.0\n      22.0\n      45.5\n      25.0\n      4.0\n      60.0\n      40.9\n      14.0\n      50.0\n      40.6\n      15.0\n      0.0\n      0.0\n      1.0\n      14.0\n      275.0\n      363.0\n      75.8\n      4915.0\n      1856.0\n      125.0\n      143.0\n      87.4\n      112.0\n      131.0\n      85.5\n      31.0\n      73.0\n      42.5\n      1.0\n      1.2\n      9.0\n      12.0\n      2.0\n      0.0\n      14.0\n      363.0\n      320.0\n      43.0\n      5.0\n      2.0\n      40.0\n      6.0\n      4.0\n      3.0\n      3.0\n      0.0\n      0.0\n      243.0\n      47.0\n      73.0\n      120.0\n      199.0\n      13.0\n      19.0\n      7.0\n      275.0\n      0.0\n      10.0\n      15.0\n      6.0\n      19.0\n      8.0\n      4.0\n      3.0\n      0.0\n      1.0\n      3.0\n      2.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      24.0\n      15.0\n      16.0\n      6.0\n      2.0\n      8.0\n      22.0\n      36.4\n      14.0\n      180.0\n      41.0\n      22.8\n      99.0\n      58.0\n      23.0\n      10.0\n      5.0\n      0.0\n      5.0\n      22.0\n      NaN\n      23.0\n      0.0\n      37.0\n      465.0\n      96.0\n      250.0\n      173.0\n      72.0\n      14.0\n      423.0\n      12.0\n      16.0\n      75.0\n      13.0\n      2.0\n      275.0\n      1615.0\n      844.0\n      29.0\n      6.0\n      5.0\n      4.0\n      5.0\n      340.0\n      275.0\n      80.9\n      14.0\n      3.0\n      0.0\n      0.0\n      11.0\n      6.0\n      0.0\n      4.0\n      22.0\n      15.0\n      0.0\n      0.0\n      0.0\n      53.0\n      11.0\n      16.0\n      40.7\n      NorwichCity\n      2021\n    \n    \n      42\n      2022-05-22\n      16:00\n      Premier League\n      Matchweek 38\n      Sun\n      Home\n      L\n      0\n      5\n      Tottenham\n      0.0\n      9.0\n      0.0\n      0.0\n      0.00\n      NaN\n      17.1\n      0.0\n      0.0\n      0.0\n      0.3\n      0.3\n      0.04\n      -0.3\n      -0.3\n      Match Report\n      12.0\n      7.0\n      58.3\n      0.0\n      4.6\n      -0.4\n      0.0\n      0.0\n      0.0\n      0.0\n      4.0\n      14.0\n      28.6\n      28.0\n      7.0\n      39.3\n      39.1\n      4.0\n      75.0\n      59.3\n      5.0\n      0.0\n      0.0\n      0.0\n      11.0\n      335.0\n      422.0\n      79.4\n      7435.0\n      1726.0\n      99.0\n      114.0\n      86.8\n      163.0\n      184.0\n      88.6\n      71.0\n      116.0\n      61.2\n      0.0\n      0.2\n      5.0\n      18.0\n      4.0\n      1.0\n      21.0\n      422.0\n      383.0\n      39.0\n      9.0\n      0.0\n      57.0\n      24.0\n      12.0\n      3.0\n      2.0\n      1.0\n      0.0\n      299.0\n      42.0\n      81.0\n      136.0\n      244.0\n      12.0\n      17.0\n      8.0\n      335.0\n      0.0\n      9.0\n      16.0\n      8.0\n      12.0\n      6.0\n      2.0\n      1.0\n      1.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      11.0\n      5.0\n      9.0\n      2.0\n      0.0\n      3.0\n      16.0\n      18.8\n      13.0\n      117.0\n      32.0\n      27.4\n      44.0\n      40.0\n      33.0\n      8.0\n      4.0\n      1.0\n      4.0\n      16.0\n      NaN\n      7.0\n      1.0\n      40.0\n      505.0\n      61.0\n      206.0\n      222.0\n      101.0\n      17.0\n      466.0\n      6.0\n      13.0\n      46.2\n      8.0\n      2.0\n      344.0\n      1648.0\n      875.0\n      42.0\n      9.0\n      4.0\n      11.0\n      4.0\n      417.0\n      335.0\n      80.3\n      21.0\n      3.0\n      0.0\n      0.0\n      17.0\n      8.0\n      0.0\n      12.0\n      16.0\n      5.0\n      0.0\n      0.0\n      0.0\n      58.0\n      9.0\n      13.0\n      40.9\n      NorwichCity\n      2021\n    \n    \n      43\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      8-7-28\n      32\n      89\n      NaN\n      30.0\n      426.0\n      131.0\n      30.8\n      0.06\n      0.21\n      18.1\n      18.0\n      3.0\n      4.0\n      33.3\n      31.0\n      0.09\n      -3.3\n      -4.0\n      NaN\n      224.0\n      142.0\n      64.3\n      9.0\n      78.7\n      -3.3\n      13.0\n      9.0\n      2.0\n      2.0\n      250.0\n      649.0\n      38.5\n      1046.0\n      194.0\n      46.6\n      39.6\n      309.0\n      52.4\n      44.1\n      350.0\n      17.0\n      4.9\n      17.0\n      12.9\n      11974.0\n      15658.0\n      76.5\n      242050.0\n      81553.0\n      4705.0\n      5440.0\n      86.5\n      5095.0\n      6038.0\n      84.4\n      1985.0\n      3585.0\n      55.4\n      24.0\n      22.7\n      254.0\n      705.0\n      230.0\n      47.0\n      922.0\n      15658.0\n      13820.0\n      1838.0\n      475.0\n      27.0\n      2280.0\n      518.0\n      411.0\n      164.0\n      87.0\n      61.0\n      4.0\n      10004.0\n      2064.0\n      3590.0\n      4770.0\n      8734.0\n      721.0\n      767.0\n      253.0\n      11974.0\n      48.0\n      315.0\n      518.0\n      399.0\n      546.0\n      368.0\n      59.0\n      30.0\n      29.0\n      40.0\n      20.0\n      32.0\n      25.0\n      2.0\n      1.0\n      0.0\n      2.0\n      2.0\n      678.0\n      429.0\n      358.0\n      256.0\n      64.0\n      256.0\n      643.0\n      39.8\n      387.0\n      6146.0\n      1570.0\n      25.5\n      2410.0\n      2488.0\n      1248.0\n      639.0\n      207.0\n      5.0\n      432.0\n      673.0\n      NaN\n      840.0\n      9.0\n      42.7\n      20165.0\n      3068.0\n      8529.0\n      8372.0\n      4463.0\n      692.0\n      18371.0\n      289.0\n      576.0\n      50.2\n      317.0\n      35.0\n      11712.0\n      62580.0\n      33620.0\n      1194.0\n      384.0\n      115.0\n      415.0\n      388.0\n      14702.0\n      11974.0\n      81.4\n      922.0\n      72.0\n      1.0\n      1.0\n      524.0\n      548.0\n      71.0\n      411.0\n      673.0\n      429.0\n      2.0\n      12.0\n      2.0\n      2883.0\n      585.0\n      669.0\n      46.7\n      NorwichCity\n      2021\n    \n  \n\n4884 rows × 177 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      Date\n      Time\n      Comp\n      Round\n      Day\n      Venue\n      Result\n      GF\n      GA\n      Opponent\n      Gls\n      Sh_shooting\n      SoT\n      SoT%\n      G/Sh\n      G/SoT\n      Dist\n      FK_shooting\n      PK\n      PKatt_shooting\n      xG\n      npxG\n      npxG/Sh\n      G-xG\n      np:G-xG\n      Match Report\n      SoTA\n      Saves\n      Save%\n      CS\n      PSxG\n      PSxG+/-\n      PKatt_keeper\n      PKA\n      PKsv\n      PKm\n      Cmp_keeper\n      Att_keeper\n      Cmp%_keeper\n      Att_keeper.1\n      Thr\n      Launch%\n      AvgLen\n      Att_keeper.2\n      Launch%.1\n      AvgLen.1\n      Opp\n      Stp\n      Stp%\n      #OPA\n      AvgDist\n      Cmp_passing\n      Att_passing\n      Cmp%_passing\n      TotDist_passing\n      PrgDist_passing\n      Cmp_passing.1\n      Att_passing.1\n      Cmp%_passing.1\n      Cmp_passing.2\n      Att_passing.2\n      Cmp%_passing.2\n      Cmp_passing.3\n      Att_passing.3\n      Cmp%_passing.3\n      Ast\n      xA\n      KP\n      1/3_passing\n      PPA\n      CrsPA\n      Prog_passing\n      Att_passing_types\n      Live_passing_types\n      Dead\n      FK_passing_types\n      TB\n      Press_passing_types\n      Sw\n      Crs_passing_types\n      CK\n      In\n      Out\n      Str\n      Ground\n      Low\n      High\n      Left\n      Right\n      Head\n      TI\n      Other\n      Cmp_passing_types\n      Off_passing_types\n      Out.1\n      Int_passing_types\n      Blocks_passing_types\n      SCA\n      PassLive\n      PassDead\n      Drib\n      Sh_gca\n      Fld_gca\n      Def\n      GCA\n      PassLive.1\n      PassDead.1\n      Drib.1\n      Sh_gca.1\n      Fld_gca.1\n      Def.1\n      Tkl\n      TklW_defense\n      Def 3rd_defense\n      Mid 3rd_defense\n      Att 3rd_defense\n      Tkl.1\n      Att_defense\n      Tkl%\n      Past\n      Press_defense\n      Succ_defense\n      %\n      Def 3rd_defense.1\n      Mid 3rd_defense.1\n      Att 3rd_defense.1\n      Blocks_defense\n      Sh_defense\n      ShSv\n      Pass\n      Int_defense\n      Tkl+Int\n      Clr\n      Err\n      Poss\n      Touches\n      Def Pen\n      Def 3rd_possession\n      Mid 3rd_possession\n      Att 3rd_possession\n      Att Pen\n      Live_possession\n      Succ_possession\n      Att_possession\n      Succ%\n      #Pl\n      Megs\n      Carries\n      TotDist_possession\n      PrgDist_possession\n      Prog_possession\n      1/3_possession\n      CPA\n      Mis\n      Dis\n      Targ\n      Rec\n      Rec%\n      Prog_possession.1\n      CrdY\n      CrdR\n      2CrdY\n      Fls\n      Fld_misc\n      Off_misc\n      Crs_misc\n      Int_misc\n      TklW_misc\n      PKwon\n      PKcon\n      OG\n      Recov\n      Won\n      Lost\n      Won%\n      team\n      Season\n    \n  \n  \n    \n      count\n      4784\n      4784\n      4784\n      4784\n      4784\n      4784\n      4884\n      4884\n      4884\n      4784\n      4882.000000\n      4855.000000\n      4855.000000\n      4852.000000\n      4852.000000\n      4702.000000\n      4183.000000\n      4186.000000\n      4882.000000\n      4882.000000\n      4186.000000\n      4186.000000\n      4183.000000\n      4186.000000\n      4186.000000\n      4784\n      4855.000000\n      4855.000000\n      4665.000000\n      4872.000000\n      4186.000000\n      4186.000000\n      4882.000000\n      4882.000000\n      4882.000000\n      4882.000000\n      4186.000000\n      4186.000000\n      4180.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4174.000000\n      4174.000000\n      4186.000000\n      4186.000000\n      4167.000000\n      4186.000000\n      4152.00000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.00000\n      4186.000000\n      4880.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4855.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4855.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4855.000000\n      0.0\n      4186.000000\n      4186.000000\n      4853.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4185.000000\n      4185.000000\n      4185.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4882.000000\n      4882.000000\n      4882.000000\n      4855.000000\n      4855.000000\n      4851.000000\n      4855.000000\n      4855.000000\n      4855.000000\n      4429.000000\n      4429.000000\n      4882.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4186.000000\n      4884\n      4884.000000\n    \n    \n      unique\n      932\n      55\n      8\n      57\n      7\n      3\n      102\n      100\n      79\n      196\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n    \n    \n      top\n      2020-07-26\n      15:00\n      Premier League\n      Group stage\n      Sat\n      Away\n      W\n      1\n      1\n      Chelsea\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Match Report\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Chelsea\n      NaN\n    \n    \n      freq\n      20\n      1304\n      3800\n      204\n      1955\n      2379\n      2024\n      1458\n      1530\n      223\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4784\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      302\n      NaN\n    \n    \n      mean\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2.807046\n      25.024099\n      8.454377\n      34.208780\n      0.107178\n      0.302303\n      17.016161\n      0.916866\n      0.212618\n      0.265465\n      2.650358\n      2.447611\n      0.102305\n      0.325991\n      0.297731\n      NaN\n      7.774253\n      5.405973\n      69.542851\n      0.599343\n      2.554754\n      0.007215\n      0.244982\n      0.191315\n      0.038918\n      0.014748\n      12.899188\n      33.093168\n      41.963493\n      47.056856\n      7.976589\n      49.877926\n      41.947181\n      14.445294\n      65.545208\n      51.673766\n      16.774009\n      1.260870\n      7.495824\n      1.270425\n      14.44039\n      778.702819\n      979.663641\n      77.703321\n      15260.310081\n      5068.769231\n      318.322026\n      361.893454\n      86.891519\n      330.830387\n      384.102246\n      84.293048\n      115.584329\n      197.11419\n      57.708624\n      2.017623\n      1.808576\n      17.715719\n      58.741042\n      16.486861\n      3.909221\n      64.507883\n      979.663641\n      886.577162\n      93.086479\n      22.768275\n      1.907788\n      146.339226\n      28.565217\n      25.307930\n      10.187769\n      4.153846\n      3.428571\n      0.769231\n      646.799331\n      132.541806\n      200.322504\n      271.279025\n      588.523650\n      39.738175\n      41.058290\n      12.734353\n      778.702819\n      3.241280\n      17.334448\n      22.790731\n      23.553751\n      38.194458\n      27.595318\n      3.312470\n      2.381749\n      1.967511\n      2.090301\n      0.847109\n      4.365504\n      2.998567\n      0.281892\n      0.305781\n      0.356904\n      0.320115\n      0.102246\n      34.440038\n      20.515345\n      17.107023\n      13.040134\n      4.292881\n      11.609651\n      31.862398\n      36.524319\n      20.252747\n      294.902054\n      85.661252\n      29.545485\n      100.644052\n      128.161968\n      66.096034\n      30.767320\n      7.319637\n      0.153846\n      23.447683\n      23.006797\n      NaN\n      47.913521\n      0.542284\n      51.159242\n      1213.857143\n      127.489250\n      388.689441\n      576.553273\n      322.073101\n      47.647396\n      1122.888677\n      19.130435\n      32.597707\n      58.473340\n      20.764931\n      1.397516\n      763.685141\n      3891.837076\n      2095.075490\n      85.597611\n      25.697013\n      8.394265\n      23.881032\n      23.030100\n      923.780698\n      778.700430\n      82.872934\n      68.917821\n      3.081934\n      0.107743\n      0.046293\n      23.768486\n      22.819773\n      3.692022\n      25.307930\n      23.006797\n      20.515345\n      0.222624\n      0.245202\n      0.081934\n      175.380315\n      36.778309\n      36.482083\n      50.300263\n      NaN\n      2018.999795\n    \n    \n      std\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      10.633434\n      88.799785\n      30.533485\n      15.894195\n      0.106387\n      0.260790\n      2.956683\n      3.218861\n      0.931731\n      1.123947\n      8.894023\n      8.208661\n      0.045897\n      3.151378\n      3.001137\n      NaN\n      26.650273\n      18.596239\n      27.910813\n      2.295011\n      8.196880\n      1.103346\n      0.979508\n      0.793245\n      0.237192\n      0.134986\n      41.759788\n      107.882512\n      17.911863\n      150.427337\n      26.089799\n      23.767444\n      11.250174\n      45.771924\n      31.433860\n      17.035460\n      53.173125\n      4.175571\n      10.930395\n      4.553672\n      4.93127\n      2605.489763\n      3208.035980\n      7.414447\n      50630.636493\n      16299.172616\n      1068.855698\n      1202.422025\n      4.805741\n      1123.135331\n      1282.943241\n      6.690822\n      377.078549\n      624.91629\n      11.307517\n      7.763338\n      6.131791\n      58.080111\n      197.829053\n      55.986741\n      12.654073\n      214.622704\n      3208.035980\n      2925.037009\n      292.535663\n      72.090205\n      7.136800\n      470.335604\n      93.135721\n      88.390685\n      33.119199\n      13.731657\n      12.164358\n      2.915172\n      2207.910917\n      423.589872\n      630.932794\n      917.313240\n      1963.754151\n      125.726147\n      129.347165\n      40.881764\n      2605.489763\n      10.552076\n      54.773459\n      75.022925\n      74.970220\n      125.518394\n      91.755801\n      10.691361\n      8.137498\n      6.618276\n      6.873735\n      2.885309\n      15.374347\n      10.847460\n      1.038030\n      1.256439\n      1.326036\n      1.209979\n      0.497602\n      108.322327\n      70.287520\n      54.061008\n      41.315181\n      13.986381\n      36.726989\n      100.519999\n      14.096407\n      64.120993\n      927.776033\n      270.289930\n      6.137151\n      318.495026\n      404.369150\n      212.614304\n      96.855501\n      23.584690\n      0.649772\n      73.919927\n      80.317731\n      NaN\n      152.214124\n      1.913732\n      12.765971\n      3922.818669\n      401.789918\n      1232.300695\n      1895.667845\n      1063.463054\n      158.530092\n      3643.085181\n      62.084728\n      104.776235\n      14.357941\n      67.270208\n      4.731968\n      2539.014612\n      12895.247448\n      7030.655371\n      293.742138\n      86.595433\n      29.033431\n      75.264289\n      73.034432\n      3043.493873\n      2605.477967\n      6.643909\n      228.821950\n      10.680582\n      0.491127\n      0.269891\n      81.167475\n      78.675002\n      13.030748\n      88.390685\n      80.317731\n      70.287520\n      0.936620\n      0.944928\n      0.389166\n      552.150279\n      116.590220\n      116.000905\n      10.049628\n      NaN\n      1.414431\n    \n    \n      min\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.020000\n      -10.300000\n      -9.700000\n      NaN\n      0.000000\n      0.000000\n      -100.000000\n      0.000000\n      0.000000\n      -11.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      5.000000\n      0.000000\n      0.000000\n      15.800000\n      0.000000\n      0.000000\n      6.700000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      2.00000\n      97.000000\n      179.000000\n      49.100000\n      2201.000000\n      931.000000\n      34.000000\n      54.000000\n      60.700000\n      22.000000\n      41.000000\n      53.700000\n      11.000000\n      46.00000\n      20.400000\n      0.000000\n      0.000000\n      0.000000\n      3.000000\n      0.000000\n      0.000000\n      2.000000\n      179.000000\n      130.000000\n      21.000000\n      0.000000\n      0.000000\n      5.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      56.000000\n      12.000000\n      41.000000\n      26.000000\n      92.000000\n      2.000000\n      3.000000\n      0.000000\n      97.000000\n      0.000000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      3.000000\n      0.000000\n      0.000000\n      39.000000\n      10.000000\n      11.500000\n      4.000000\n      11.000000\n      3.000000\n      2.000000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      NaN\n      1.000000\n      0.000000\n      17.000000\n      299.000000\n      16.000000\n      56.000000\n      91.000000\n      25.000000\n      0.000000\n      261.000000\n      0.000000\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      105.000000\n      446.000000\n      188.000000\n      3.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      150.000000\n      97.000000\n      55.000000\n      2.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      37.000000\n      1.000000\n      1.000000\n      10.000000\n      NaN\n      2017.000000\n    \n    \n      25%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      0.000000\n      9.000000\n      2.000000\n      23.800000\n      0.000000\n      0.000000\n      15.100000\n      0.000000\n      0.000000\n      0.000000\n      0.800000\n      0.700000\n      0.070000\n      -0.600000\n      -0.600000\n      NaN\n      2.000000\n      1.000000\n      50.000000\n      0.000000\n      0.600000\n      -0.400000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      10.000000\n      30.000000\n      19.000000\n      2.000000\n      30.800000\n      33.000000\n      5.000000\n      42.900000\n      38.600000\n      5.000000\n      0.000000\n      0.000000\n      0.000000\n      11.30000\n      289.250000\n      395.000000\n      73.000000\n      5805.250000\n      2197.000000\n      117.000000\n      139.000000\n      84.100000\n      114.000000\n      141.000000\n      80.625000\n      45.000000\n      88.00000\n      49.600000\n      0.000000\n      0.500000\n      6.000000\n      20.000000\n      5.000000\n      1.000000\n      23.000000\n      395.000000\n      346.250000\n      42.000000\n      9.000000\n      0.000000\n      54.000000\n      10.000000\n      8.000000\n      3.000000\n      1.000000\n      0.000000\n      0.000000\n      224.000000\n      53.000000\n      86.000000\n      99.000000\n      220.000000\n      15.000000\n      17.000000\n      4.000000\n      289.250000\n      1.000000\n      7.000000\n      7.000000\n      9.000000\n      13.000000\n      9.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      14.000000\n      8.000000\n      6.000000\n      5.000000\n      1.000000\n      4.000000\n      12.000000\n      27.300000\n      7.000000\n      122.000000\n      35.000000\n      25.400000\n      36.000000\n      51.000000\n      25.000000\n      12.000000\n      2.000000\n      0.000000\n      9.000000\n      7.000000\n      NaN\n      16.000000\n      0.000000\n      42.000000\n      521.000000\n      53.000000\n      171.000000\n      227.000000\n      120.000000\n      16.000000\n      473.000000\n      7.000000\n      12.000000\n      50.000000\n      7.000000\n      0.000000\n      289.000000\n      1457.500000\n      743.000000\n      27.000000\n      8.000000\n      2.000000\n      9.000000\n      9.000000\n      365.000000\n      289.250000\n      78.700000\n      25.000000\n      1.000000\n      0.000000\n      0.000000\n      9.000000\n      9.000000\n      1.000000\n      8.000000\n      7.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      78.000000\n      13.000000\n      13.000000\n      44.000000\n      NaN\n      2018.000000\n    \n    \n      50%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.000000\n      12.000000\n      4.000000\n      33.300000\n      0.090000\n      0.290000\n      16.900000\n      0.000000\n      0.000000\n      0.000000\n      1.300000\n      1.100000\n      0.090000\n      -0.100000\n      -0.100000\n      NaN\n      4.000000\n      3.000000\n      71.400000\n      0.000000\n      1.200000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.000000\n      17.000000\n      40.000000\n      23.000000\n      4.000000\n      50.000000\n      40.900000\n      7.000000\n      71.400000\n      54.300000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      14.00000\n      384.000000\n      491.000000\n      78.600000\n      7600.500000\n      2575.000000\n      155.500000\n      178.000000\n      87.700000\n      162.000000\n      189.000000\n      85.600000\n      58.000000\n      100.00000\n      57.800000\n      1.000000\n      0.800000\n      9.000000\n      28.000000\n      8.000000\n      2.000000\n      32.000000\n      491.000000\n      441.000000\n      48.000000\n      12.000000\n      1.000000\n      72.000000\n      14.000000\n      12.000000\n      5.000000\n      2.000000\n      1.000000\n      0.000000\n      315.000000\n      66.000000\n      102.000000\n      129.000000\n      290.000000\n      20.000000\n      21.000000\n      6.000000\n      384.000000\n      1.000000\n      9.000000\n      11.000000\n      12.000000\n      19.000000\n      13.000000\n      2.000000\n      1.000000\n      1.000000\n      1.000000\n      0.000000\n      2.000000\n      1.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.000000\n      10.000000\n      8.000000\n      6.000000\n      2.000000\n      6.000000\n      16.000000\n      36.250000\n      10.000000\n      148.000000\n      43.000000\n      29.300000\n      49.000000\n      64.000000\n      33.000000\n      15.000000\n      3.000000\n      0.000000\n      12.000000\n      11.000000\n      NaN\n      23.000000\n      0.000000\n      51.000000\n      611.000000\n      64.000000\n      198.000000\n      288.000000\n      155.000000\n      23.000000\n      564.000000\n      9.000000\n      16.000000\n      58.800000\n      10.000000\n      0.000000\n      379.000000\n      1935.500000\n      1024.500000\n      40.000000\n      12.000000\n      4.000000\n      12.000000\n      12.000000\n      460.500000\n      384.000000\n      83.800000\n      34.000000\n      1.000000\n      0.000000\n      0.000000\n      12.000000\n      12.000000\n      2.000000\n      12.000000\n      11.000000\n      10.000000\n      0.000000\n      0.000000\n      0.000000\n      89.000000\n      18.000000\n      18.000000\n      50.000000\n      NaN\n      2019.000000\n    \n    \n      75%\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2.000000\n      16.000000\n      6.000000\n      43.800000\n      0.170000\n      0.500000\n      18.700000\n      1.000000\n      0.000000\n      0.000000\n      1.900000\n      1.700000\n      0.120000\n      0.600000\n      0.600000\n      NaN\n      6.000000\n      4.000000\n      100.000000\n      1.000000\n      1.900000\n      0.400000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      9.000000\n      24.000000\n      50.000000\n      29.000000\n      6.000000\n      68.400000\n      50.400000\n      10.000000\n      100.000000\n      66.000000\n      11.000000\n      1.000000\n      12.500000\n      1.000000\n      16.90000\n      502.000000\n      605.000000\n      83.300000\n      9785.250000\n      3022.750000\n      203.000000\n      228.000000\n      90.300000\n      223.000000\n      252.000000\n      89.400000\n      73.000000\n      114.00000\n      66.100000\n      2.000000\n      1.300000\n      12.000000\n      39.000000\n      11.000000\n      3.000000\n      43.000000\n      605.000000\n      557.000000\n      53.750000\n      14.000000\n      2.000000\n      93.000000\n      19.000000\n      17.000000\n      7.000000\n      3.000000\n      3.000000\n      1.000000\n      433.000000\n      82.000000\n      119.000000\n      169.000000\n      379.000000\n      25.000000\n      25.000000\n      9.000000\n      502.000000\n      3.000000\n      11.000000\n      16.000000\n      15.000000\n      26.000000\n      19.000000\n      3.000000\n      2.000000\n      2.000000\n      2.000000\n      1.000000\n      4.000000\n      2.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      21.000000\n      13.000000\n      11.000000\n      9.000000\n      3.000000\n      8.000000\n      20.000000\n      45.500000\n      13.000000\n      179.000000\n      53.000000\n      33.500000\n      65.000000\n      80.000000\n      43.000000\n      20.000000\n      5.000000\n      0.000000\n      15.000000\n      16.000000\n      NaN\n      32.000000\n      0.000000\n      61.000000\n      723.000000\n      77.000000\n      226.000000\n      358.000000\n      206.000000\n      32.000000\n      676.000000\n      13.000000\n      21.000000\n      68.150000\n      14.000000\n      1.000000\n      491.000000\n      2538.000000\n      1391.750000\n      58.000000\n      17.000000\n      6.000000\n      15.000000\n      15.000000\n      578.000000\n      502.000000\n      87.800000\n      45.000000\n      2.000000\n      0.000000\n      0.000000\n      15.000000\n      14.000000\n      3.000000\n      17.000000\n      16.000000\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      102.000000\n      24.000000\n      24.000000\n      56.700000\n      NaN\n      2020.000000\n    \n    \n      max\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      162.000000\n      1140.000000\n      418.000000\n      100.000000\n      1.000000\n      1.000000\n      34.900000\n      50.000000\n      18.000000\n      22.000000\n      115.600000\n      107.600000\n      0.370000\n      59.200000\n      57.500000\n      NaN\n      246.000000\n      184.000000\n      100.000000\n      33.000000\n      78.700000\n      11.900000\n      13.000000\n      13.000000\n      3.000000\n      3.000000\n      435.000000\n      1122.000000\n      100.000000\n      1702.000000\n      290.000000\n      100.000000\n      78.000000\n      417.000000\n      100.000000\n      106.000000\n      464.000000\n      53.000000\n      100.000000\n      80.000000\n      85.00000\n      32015.000000\n      37015.000000\n      93.000000\n      597272.000000\n      176070.000000\n      14699.000000\n      16107.000000\n      97.700000\n      14051.000000\n      15205.000000\n      96.400000\n      4291.000000\n      6303.00000\n      89.000000\n      127.000000\n      82.600000\n      676.000000\n      2552.000000\n      734.000000\n      135.000000\n      2578.000000\n      37015.000000\n      34410.000000\n      2728.000000\n      751.000000\n      136.000000\n      5062.000000\n      1145.000000\n      1035.000000\n      398.000000\n      170.000000\n      267.000000\n      51.000000\n      28713.000000\n      4655.000000\n      5891.000000\n      14393.000000\n      27064.000000\n      1190.000000\n      1223.000000\n      419.000000\n      32015.000000\n      110.000000\n      509.000000\n      962.000000\n      744.000000\n      1471.000000\n      1128.000000\n      130.000000\n      119.000000\n      97.000000\n      81.000000\n      39.000000\n      216.000000\n      164.000000\n      14.000000\n      19.000000\n      22.000000\n      17.000000\n      10.000000\n      901.000000\n      670.000000\n      476.000000\n      377.000000\n      168.000000\n      373.000000\n      916.000000\n      100.000000\n      585.000000\n      8089.000000\n      2429.000000\n      53.800000\n      2948.000000\n      3705.000000\n      2388.000000\n      867.000000\n      251.000000\n      9.000000\n      688.000000\n      846.000000\n      NaN\n      1486.000000\n      29.000000\n      85.000000\n      43032.000000\n      3617.000000\n      12063.000000\n      22515.000000\n      13154.000000\n      2090.000000\n      40508.000000\n      695.000000\n      1086.000000\n      100.000000\n      743.000000\n      70.000000\n      31423.000000\n      154478.000000\n      89994.000000\n      4119.000000\n      1150.000000\n      463.000000\n      697.000000\n      735.000000\n      35814.000000\n      32015.000000\n      99.600000\n      2725.000000\n      110.000000\n      7.000000\n      4.000000\n      836.000000\n      889.000000\n      170.000000\n      1035.000000\n      846.000000\n      670.000000\n      16.000000\n      12.000000\n      5.000000\n      5087.000000\n      1155.000000\n      1193.000000\n      90.900000\n      NaN\n      2021.000000\n    \n  \n\n\n\n\n\n#collapse-output\n[ (x,dfAll[x].dtype) for x in dfAll]\n\n[('Date', dtype('O')),\n ('Time', dtype('O')),\n ('Comp', dtype('O')),\n ('Round', dtype('O')),\n ('Day', dtype('O')),\n ('Venue', dtype('O')),\n ('Result', dtype('O')),\n ('GF', dtype('O')),\n ('GA', dtype('O')),\n ('Opponent', dtype('O')),\n ('Gls', dtype('float64')),\n ('Sh_shooting', dtype('float64')),\n ('SoT', dtype('float64')),\n ('SoT%', dtype('float64')),\n ('G/Sh', dtype('float64')),\n ('G/SoT', dtype('float64')),\n ('Dist', dtype('float64')),\n ('FK_shooting', dtype('float64')),\n ('PK', dtype('float64')),\n ('PKatt_shooting', dtype('float64')),\n ('xG', dtype('float64')),\n ('npxG', dtype('float64')),\n ('npxG/Sh', dtype('float64')),\n ('G-xG', dtype('float64')),\n ('np:G-xG', dtype('float64')),\n ('Match Report', dtype('O')),\n ('SoTA', dtype('float64')),\n ('Saves', dtype('float64')),\n ('Save%', dtype('float64')),\n ('CS', dtype('float64')),\n ('PSxG', dtype('float64')),\n ('PSxG+/-', dtype('float64')),\n ('PKatt_keeper', dtype('float64')),\n ('PKA', dtype('float64')),\n ('PKsv', dtype('float64')),\n ('PKm', dtype('float64')),\n ('Cmp_keeper', dtype('float64')),\n ('Att_keeper', dtype('float64')),\n ('Cmp%_keeper', dtype('float64')),\n ('Att_keeper.1', dtype('float64')),\n ('Thr', dtype('float64')),\n ('Launch%', dtype('float64')),\n ('AvgLen', dtype('float64')),\n ('Att_keeper.2', dtype('float64')),\n ('Launch%.1', dtype('float64')),\n ('AvgLen.1', dtype('float64')),\n ('Opp', dtype('float64')),\n ('Stp', dtype('float64')),\n ('Stp%', dtype('float64')),\n ('#OPA', dtype('float64')),\n ('AvgDist', dtype('float64')),\n ('Cmp_passing', dtype('float64')),\n ('Att_passing', dtype('float64')),\n ('Cmp%_passing', dtype('float64')),\n ('TotDist_passing', dtype('float64')),\n ('PrgDist_passing', dtype('float64')),\n ('Cmp_passing.1', dtype('float64')),\n ('Att_passing.1', dtype('float64')),\n ('Cmp%_passing.1', dtype('float64')),\n ('Cmp_passing.2', dtype('float64')),\n ('Att_passing.2', dtype('float64')),\n ('Cmp%_passing.2', dtype('float64')),\n ('Cmp_passing.3', dtype('float64')),\n ('Att_passing.3', dtype('float64')),\n ('Cmp%_passing.3', dtype('float64')),\n ('Ast', dtype('float64')),\n ('xA', dtype('float64')),\n ('KP', dtype('float64')),\n ('1/3_passing', dtype('float64')),\n ('PPA', dtype('float64')),\n ('CrsPA', dtype('float64')),\n ('Prog_passing', dtype('float64')),\n ('Att_passing_types', dtype('float64')),\n ('Live_passing_types', dtype('float64')),\n ('Dead', dtype('float64')),\n ('FK_passing_types', dtype('float64')),\n ('TB', dtype('float64')),\n ('Press_passing_types', dtype('float64')),\n ('Sw', dtype('float64')),\n ('Crs_passing_types', dtype('float64')),\n ('CK', dtype('float64')),\n ('In', dtype('float64')),\n ('Out', dtype('float64')),\n ('Str', dtype('float64')),\n ('Ground', dtype('float64')),\n ('Low', dtype('float64')),\n ('High', dtype('float64')),\n ('Left', dtype('float64')),\n ('Right', dtype('float64')),\n ('Head', dtype('float64')),\n ('TI', dtype('float64')),\n ('Other', dtype('float64')),\n ('Cmp_passing_types', dtype('float64')),\n ('Off_passing_types', dtype('float64')),\n ('Out.1', dtype('float64')),\n ('Int_passing_types', dtype('float64')),\n ('Blocks_passing_types', dtype('float64')),\n ('SCA', dtype('float64')),\n ('PassLive', dtype('float64')),\n ('PassDead', dtype('float64')),\n ('Drib', dtype('float64')),\n ('Sh_gca', dtype('float64')),\n ('Fld_gca', dtype('float64')),\n ('Def', dtype('float64')),\n ('GCA', dtype('float64')),\n ('PassLive.1', dtype('float64')),\n ('PassDead.1', dtype('float64')),\n ('Drib.1', dtype('float64')),\n ('Sh_gca.1', dtype('float64')),\n ('Fld_gca.1', dtype('float64')),\n ('Def.1', dtype('float64')),\n ('Tkl', dtype('float64')),\n ('TklW_defense', dtype('float64')),\n ('Def 3rd_defense', dtype('float64')),\n ('Mid 3rd_defense', dtype('float64')),\n ('Att 3rd_defense', dtype('float64')),\n ('Tkl.1', dtype('float64')),\n ('Att_defense', dtype('float64')),\n ('Tkl%', dtype('float64')),\n ('Past', dtype('float64')),\n ('Press_defense', dtype('float64')),\n ('Succ_defense', dtype('float64')),\n ('%', dtype('float64')),\n ('Def 3rd_defense.1', dtype('float64')),\n ('Mid 3rd_defense.1', dtype('float64')),\n ('Att 3rd_defense.1', dtype('float64')),\n ('Blocks_defense', dtype('float64')),\n ('Sh_defense', dtype('float64')),\n ('ShSv', dtype('float64')),\n ('Pass', dtype('float64')),\n ('Int_defense', dtype('float64')),\n ('Tkl+Int', dtype('float64')),\n ('Clr', dtype('float64')),\n ('Err', dtype('float64')),\n ('Poss', dtype('float64')),\n ('Touches', dtype('float64')),\n ('Def Pen', dtype('float64')),\n ('Def 3rd_possession', dtype('float64')),\n ('Mid 3rd_possession', dtype('float64')),\n ('Att 3rd_possession', dtype('float64')),\n ('Att Pen', dtype('float64')),\n ('Live_possession', dtype('float64')),\n ('Succ_possession', dtype('float64')),\n ('Att_possession', dtype('float64')),\n ('Succ%', dtype('float64')),\n ('#Pl', dtype('float64')),\n ('Megs', dtype('float64')),\n ('Carries', dtype('float64')),\n ('TotDist_possession', dtype('float64')),\n ('PrgDist_possession', dtype('float64')),\n ('Prog_possession', dtype('float64')),\n ('1/3_possession', dtype('float64')),\n ('CPA', dtype('float64')),\n ('Mis', dtype('float64')),\n ('Dis', dtype('float64')),\n ('Targ', dtype('float64')),\n ('Rec', dtype('float64')),\n ('Rec%', dtype('float64')),\n ('Prog_possession.1', dtype('float64')),\n ('CrdY', dtype('float64')),\n ('CrdR', dtype('float64')),\n ('2CrdY', dtype('float64')),\n ('Fls', dtype('float64')),\n ('Fld_misc', dtype('float64')),\n ('Off_misc', dtype('float64')),\n ('Crs_misc', dtype('float64')),\n ('Int_misc', dtype('float64')),\n ('TklW_misc', dtype('float64')),\n ('PKwon', dtype('float64')),\n ('PKcon', dtype('float64')),\n ('OG', dtype('float64')),\n ('Recov', dtype('float64')),\n ('Won', dtype('float64')),\n ('Lost', dtype('float64')),\n ('Won%', dtype('float64')),\n ('team', dtype('O')),\n ('Season', dtype('int64'))]\n\n\n\nChange some columns\n\nAdd the predictor column as Win from result\nChange time to an int of the time eg 16:30 goes to 16.5\nChange date to day, month, year and day of week weekday\nConvert result to int of 2, 1, 0 for W/D/L\nChange round to just an int of the matchweek\nConvert some columns to int\nSort the DataFrame by season and then round\nMake sure team names are consistent (sometimes name in opponent column differ from team column\ndrop columns won’t be using\nselect matches from Premier league only\ncreate a new DataFrame not lined to old one in case we want old details\n\n\nimport re\n# Some date time functions\ndef just_time(time):\n    return time.time().hour+time.time().minute/60\ndef just_datesDay(time):\n    return time.day\ndef just_datesMonth(time):\n    return time.month\ndef just_datesYear(time):\n    return time.year\ndef just_datesWeekDay(time):\n    return time.weekday()\n\n# Mods to target result\ndef Result(string):\n    if string=='W':\n        return 2\n    elif string=='D':\n        return 1\n    else:\n        return 0\n    \ndef columnMods(matches):\n    \n    cols= matches.columns\n    cols=[x.lower() for x in cols]\n    matches.columns = cols\n    \n    # Misc\n    \n    matches = matches.astype({'gf': 'int'})\n    matches = matches.astype({'ga': 'int'})\n    \n    \n    # some adjustments to time/dates\n    \n    matches=matches.astype({'date': 'datetime64[ns]'})\n    matches = matches.astype({'time': 'datetime64[ns]'})\n    \n    matches['day'] = matches['date'].apply(just_datesDay)\n    matches['month'] = matches['date'].apply(just_datesMonth)\n    matches['year'] = matches['date'].apply(just_datesYear)\n    matches['weekday'] = matches['date'].apply(just_datesWeekDay)\n\n    # target and results\n    matches['Win']=matches['result']\n    \n    matches['NetScore']=matches['gf']-matches['ga']\n    matches['GoalsFor']=matches['gf']\n    matches['GoalsAgainst']=matches['ga']\n\n    matches['result'] = matches['NetScore']#matches['result'].apply(Result)\n    \n    # Change round to an int\n    matches['round']=matches['round'].str.replace('Matchweek ','').astype('int')\n    \n    # drop some columns\n    \n    matches.drop(columns=['comp','match report','date','time','tkl+int'],inplace=True)\n    \n    try:\n        matches = matches.drop(columns='index')\n    except:\n        pass\n        \n    try:\n        matches = matches.drop(columns='unnamed: 0')\n    except:\n        pass\n    \n    \n    #order by date\n    matches=matches.sort_values(['season','round']).reset_index(drop=True)\n\n    \n    # team name changes\n    changeTeamName={'Brighton':'Brighton and Hove Albion',\n                'Manchester Utd':'Manchester United',\n                'Newcastle Utd':'Newcastle United',\n                'Sheffield Utd' : 'Sheffield United',\n                'Huddersfield' : 'Huddersfield Town',\n                'Tottenham' : 'Tottenham Hotspur',\n                'West Brom' : 'West Bromwich Albion',\n                'West Ham' : 'West Ham United',\n                'Wolves' : 'Wolverhampton Wanderers'}\n    matches['opponent']=matches['opponent'].replace(changeTeamName)\n    matches['team']=matches['team'].replace(changeTeamName)\n\n    noms=pd.concat([matches.team,matches.opponent]).sort_values().unique()\n\n    teamDict={}\n    for team in noms:\n\n        x= re.sub(r\"([a-z])([A-Z])\",r\"\\1 \\2\",team) \n        teamout =  re.sub(r\"(and)\\s\",r\" \\1 \",x).strip().replace('  ',' ')    \n        teamDict[team]=teamout\n        \n    matches['team']=matches['team'].replace(teamDict)\n    matches['opponent']=matches['opponent'].replace(teamDict)\n    \n    return matches\n\nimport copy\nmatches=copy.copy(dfAll)\nmatches=matches[matches.Comp=='Premier League']\n\nmatches = columnMods(matches)\nmatches[matches.season==2019]\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue\n      result\n      gf\n      ga\n      opponent\n      gls\n      sh_shooting\n      sot\n      ...\n      won%\n      team\n      season\n      month\n      year\n      weekday\n      Win\n      NetScore\n      GoalsFor\n      GoalsAgainst\n    \n  \n  \n    \n      1520\n      1\n      9\n      Home\n      3\n      4\n      1\n      Norwich City\n      3.0\n      15.0\n      7.0\n      ...\n      77.8\n      Liverpool\n      2019\n      8\n      2019\n      4\n      W\n      3\n      4\n      1\n    \n    \n      1521\n      1\n      10\n      Away\n      5\n      5\n      0\n      West Ham United\n      5.0\n      13.0\n      8.0\n      ...\n      50.0\n      Manchester City\n      2019\n      8\n      2019\n      5\n      W\n      5\n      5\n      0\n    \n    \n      1522\n      1\n      11\n      Home\n      4\n      4\n      0\n      Chelsea\n      4.0\n      10.0\n      4.0\n      ...\n      70.6\n      Manchester United\n      2019\n      8\n      2019\n      6\n      W\n      4\n      4\n      0\n    \n    \n      1523\n      1\n      11\n      Away\n      -4\n      0\n      4\n      Manchester United\n      0.0\n      18.0\n      7.0\n      ...\n      29.4\n      Chelsea\n      2019\n      8\n      2019\n      6\n      L\n      -4\n      0\n      4\n    \n    \n      1524\n      1\n      11\n      Home\n      0\n      0\n      0\n      Wolverhampton Wanderers\n      0.0\n      17.0\n      1.0\n      ...\n      56.8\n      Leicester City\n      2019\n      8\n      2019\n      6\n      D\n      0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2275\n      38\n      26\n      Home\n      0\n      1\n      1\n      Aston Villa\n      1.0\n      10.0\n      1.0\n      ...\n      61.0\n      West Ham United\n      2019\n      7\n      2020\n      6\n      D\n      0\n      1\n      1\n    \n    \n      2276\n      38\n      26\n      Away\n      0\n      1\n      1\n      West Ham United\n      1.0\n      13.0\n      4.0\n      ...\n      39.0\n      Aston Villa\n      2019\n      7\n      2020\n      6\n      D\n      0\n      1\n      1\n    \n    \n      2277\n      38\n      26\n      Away\n      2\n      3\n      1\n      Everton\n      3.0\n      12.0\n      6.0\n      ...\n      46.3\n      Bournemouth\n      2019\n      7\n      2020\n      6\n      W\n      2\n      3\n      1\n    \n    \n      2278\n      38\n      26\n      Away\n      -1\n      2\n      3\n      Arsenal\n      2.0\n      18.0\n      5.0\n      ...\n      56.1\n      Watford\n      2019\n      7\n      2020\n      6\n      L\n      -1\n      2\n      3\n    \n    \n      2279\n      38\n      26\n      Away\n      -5\n      0\n      5\n      Manchester City\n      0.0\n      5.0\n      4.0\n      ...\n      40.0\n      Norwich City\n      2019\n      7\n      2020\n      6\n      L\n      -5\n      0\n      5\n    \n  \n\n760 rows × 179 columns\n\n\n\n\ncluster_features_shootingAll = [\n    \"gls_x\",\"sh_shooting_x\",\n    \"sot_x\",\"sot%_x\",\"g/sh_x\",\"g/sot_x\",\n    \"dist_x\",'fk_shooting_x',\"pk_x\",\"pkatt_shooting_x\",\n    'xg_x','npxg_x','npxg/sh_x','g-xg_x','np:g-xg_x'\n]\n\ncluster_features_keeperAll=[\n    'sota_x','saves_x','save%_x','cs_x',\n 'psxg_x','psxg+/-_x','pkatt_keeper_x','pka_x',\n 'pksv_x','pkm_x','cmp_keeper_x','att_keeper_x','cmp%_keeper_x',\n'cmp%_keeper_x','att_keeper.1_x','thr_x','launch%_x','avglen_x',\n'att_keeper.2_x','launch%.1_x','avglen.1_x','opp_x','stp_x','stp%_x',\n    '#opa_x','avgdist_x'\n]\n\ncluster_features_passingAll=[\n 'cmp_passing_x', 'att_passing_x', 'cmp%_passing_x', 'totdist_passing_x', 'prgdist_passing_x', 'cmp_passing.1_x', 'att_passing.1_x', 'cmp%_passing.1_x',\n 'cmp_passing.2_x', 'att_passing.2_x', 'cmp%_passing.2_x', 'cmp_passing.3_x', 'att_passing.3_x', 'cmp%_passing.3_x', 'ast_x', 'xa_x', 'kp_x', '1/3_passing_x',\n 'ppa_x', 'crspa_x', 'prog_passing_x']\n\ncluster_features_passtypeAll=[\n 'att_passing_types_x', 'live_passing_types_x', 'dead_x', 'fk_passing_types_x', 'tb_x', 'press_passing_types_x', 'sw_x', 'crs_passing_types_x',\n 'ck_x', 'in_x', 'out_x', 'str_x', 'ground_x', 'low_x', 'high_x', 'left_x', 'right_x', 'head_x', 'ti_x', 'other_x', 'cmp_passing_types_x', 'off_passing_types_x', 'out.1_x', 'int_passing_types_x', 'blocks_passing_types_x']\n\ncluster_features_shotcreateAll=[\n 'sca_x', 'passlive_x', 'passdead_x', 'drib_x', 'sh_gca_x', 'fld_gca_x', 'def_x', 'gca_x', 'passlive.1_x', 'passdead.1_x', 'drib.1_x', 'sh_gca.1_x',\n 'fld_gca.1_x', 'def.1_x']\n\ncluster_features_tackleAll=[ 'tkl_x', 'tklw_defense_x', 'def 3rd_defense_x', 'mid 3rd_defense_x', 'att 3rd_defense_x', 'tkl.1_x', 'att_defense_x',\n 'tkl%_x', 'past_x', 'press_defense_x', 'succ_defense_x', '%_x', 'def 3rd_defense.1_x', 'mid 3rd_defense.1_x', 'att 3rd_defense.1_x', 'blocks_defense_x',\n 'sh_defense_x', 'shsv_x', 'pass_x', 'tkl+int_x','int_defense_x', 'clr_x', 'err_x']\n\ncluster_features_possessionAll=[\n 'poss_x', 'touches_x', 'def pen_x', 'def 3rd_possession_x', 'mid 3rd_possession_x', 'att 3rd_possession_x', 'att pen_x', 'live_possession_x', 'succ_possession_x', 'att_possession_x', 'succ%_x',\n '#pl_x', 'megs_x', 'carries_x', 'totdist_possession_x', 'prgdist_possession_x', 'prog_possession_x', '1/3_possession_x', 'cpa_x', 'mis_x', 'dis_x', 'targ_x', 'rec_x',\n 'rec%_x', 'prog_possession.1_x']\n\ncluster_features_miscAll=[ 'crdy_x', 'crdr_x', '2crdy_x', 'fls_x', 'fld_misc_x', 'off_misc_x', 'crs_misc_x', 'int_misc_x', 'tklw_misc_x', 'pkwon_x', 'pkcon_x', 'og_x', 'recov_x', 'won_x', 'lost_x', 'won%_x']\n\n\n# [x for x in df]\n\n\nimport re\n\ndef do_dict_col_names(dict1,string,col_names):\n    regexp=string\n    \n    for x in col_names:\n        x=re.sub('(_x$)','',x)\n        if not re.search(regexp,x):\n            x2=string+'_'+x\n#             print(x2)\n            dict1[x]=x2\n        else:\n            x2=re.sub(regexp,'',x)\n            x2=string+'_'+x2\n            x2=x2.strip('_')\n            dict1[x]=x2\n#             print(x,'---',x2)\n    return dict1\n\ndict1={}\ndict1=do_dict_col_names(dict1,r'shooting',cluster_features_shootingAll)\ndict1=do_dict_col_names(dict1,r'keeper',cluster_features_keeperAll)\ndict1=do_dict_col_names(dict1,r'passing',cluster_features_passingAll)\ndict1=do_dict_col_names(dict1,r'passing_types',cluster_features_passtypeAll)\ndict1=do_dict_col_names(dict1,r'shotcreate',cluster_features_shotcreateAll)\ndict1=do_dict_col_names(dict1,r'tackle',cluster_features_tackleAll)\ndict1=do_dict_col_names(dict1,r'possession',cluster_features_possessionAll)\ndict1=do_dict_col_names(dict1,r'misc',cluster_features_miscAll)\n\n\ndictall=dict1.copy()\n\nmatches.columns=matches.columns.str.lower()\n    \ncols=[]\nfor x in matches:\n    try:\n        cols.append(dictall[x])\n#         print('---')\n    except:\n        cols.append(x)\n        \n# for i,x in enumerate(cols):\n#     if re.search(r'^passing_types',x):\n#         x=re.sub(r'(^passing_types)','passingtypes',x)\n#         cols[i]=x\nmatches.columns=cols\nmatches.columns=matches.columns.str.replace('passing_types','passingtypes')\n\n\nnoms=pd.concat([matches.team,matches.opponent]).sort_values().unique()\nnoms\n\narray(['Arsenal', 'Aston Villa', 'Bournemouth', 'Brentford',\n       'Brighton and Hove Albion', 'Burnley', 'Cardiff City', 'Chelsea',\n       'Crystal Palace', 'Everton', 'Fulham', 'Huddersfield Town',\n       'Leeds United', 'Leicester City', 'Liverpool', 'Manchester City',\n       'Manchester United', 'Newcastle United', 'Norwich City',\n       'Sheffield United', 'Southampton', 'Stoke City', 'Swansea City',\n       'Tottenham Hotspur', 'Watford', 'West Bromwich Albion',\n       'West Ham United', 'Wolverhampton Wanderers'], dtype=object)\n\n\n\n\nI want to make some columns percentages\ni.e. number of passes in final 3rd -> pc of passes in final 3rd\n\ndef change_to_pc(col,col_tot,df_matches):\n    df_matches.loc[:,col]=df_matches.loc[:,col].div(df_matches.loc[:,col_tot])*100\n    col_new=re.sub(r'(^[a-z]*_)',r\"\\1PC_\",col)\n\n    df_matches.rename(columns={col:col_new},inplace=True)\n    return df_matches\n\n\n# drop columns 'attempts' but keep the % one after it\ncols_to_drop=[x for x in matches if re.search(r'^passing_',x) and re.search(r'att',x)]\nprint(cols_to_drop)\nmatches = matches.drop(columns=cols_to_drop)\n\n['passing_att', 'passing_att_.1', 'passing_att_.2', 'passing_att_.3']\n\n\n\ncols_to_pc=[x for x in matches if re.search(r'passing_',x) and not re.search(r'passing_ty',x) and not re.search(r'%',x)\\\nand not re.search(r'xa',x) and not re.search(r'kp',x) and not re.search(r'ast',x)\\\nand not re.search(r'dist',x) and not re.search(r'passing_cmp$',x) ]\n\nprint(cols_to_pc)\ncol_tot='passing_cmp'\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \n\n\n   \nmatches = change_to_pc('passing_prgdist','passing_cmp',matches)\nmatches = change_to_pc('passing_totdist','passing_cmp',matches)\n\n['passing_cmp_.1', 'passing_cmp_.2', 'passing_cmp_.3', 'passing_1/3', 'passing_ppa', 'passing_crspa', 'passing_prog']\n\n\n\nmatches=matches.rename(columns={'passing_cmp': 'passing_pass_complete',\n 'passing_PCcmp_.1': 'passing_pass_complete.shortPC',\n 'passing_PCcmp_.2': 'passing_pass_complete.mediumPC',\n 'passing_PCcmp_.3': 'passing_pass_complete.longPC',\n})\n\n\n\ncols_to_pc=[x for x in matches if re.search(r'passingtype',x) and not re.search(r'passingtypes_att',x)]\nprint(cols_to_pc)\ncol_tot='passingtypes_att'\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n   \nmatches=matches.drop(columns='passingtypes_att')\n\n\n['passingtypes_live', 'passingtypes_dead', 'passingtypes_fk', 'passingtypes_tb', 'passingtypes_press', 'passingtypes_sw', 'passingtypes_crs', 'passingtypes_ck', 'passingtypes_in', 'passingtypes_out', 'passingtypes_str', 'passingtypes_ground', 'passingtypes_low', 'passingtypes_high', 'passingtypes_left', 'passingtypes_right', 'passingtypes_head', 'passingtypes_ti', 'passingtypes_other', 'passingtypes_cmp', 'passingtypes_off', 'passingtypes_out.1', 'passingtypes_int', 'passingtypes_blocks']\n\n\n\n\nmatches=matches.rename(columns={'tackle_tkl.1':'tackle_tkl_dribble',\n                      'tackle_tkl%' : 'tackle_dribble%',\n                      'tackle_past' : 'tackle_dribllepast',\n                       'tackle_def 3rd_defense.1':'tackle_press_def3rd',\n                       'tackle_mid 3rd_defense.1':'tackle_press_mid3rd',    \n                       'tackle_att 3rd_defense.1':'tackle_press_att3rd',\n                     })\nmatches=matches.drop(columns='tackle_att_defense')\nmatches=matches.drop(columns='tackle_succ_defense')\n\n\n## this makes tackles as % for first 6 values\ncols_to_pc=[x for x in matches if re.search(r'tackle',x) \\\n            and not re.search(r'passingtypes_att',x)]\ncol_tot=cols_to_pc[0]\ncols_to_pc = cols_to_pc[1:6]\n\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \n\ncols_to_pc=['tackle_press_def3rd',\n'tackle_press_mid3rd',    \n'tackle_press_att3rd']\ncol_tot='tackle_press_defense'\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \ncol_tot='tackle_blocks_defense'\ncols_to_pc=['tackle_sh_defense','tackle_shsv' ,'tackle_pass']\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n\n\n## possession touches\ncols_to_pc=[x for x in matches if re.search(r'possession',x)  ]\n\n\ncol_tot=cols_to_pc[1]\ncols_to_pc=cols_to_pc[2:8]\nprint(cols_to_pc, col_tot)\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n\n['possession_def pen', 'possession_def 3rd', 'possession_mid 3rd', 'possession_att 3rd', 'possession_att pen', 'possession_live'] possession_touches\n\n\n\nmatches=matches.rename(columns={'possession_succ':'possession_dribblesucc',\n'possession_att':'possession_dribbleatt',\n'possession_succ%':'possession_dribblesucc%',\n'possession_#pl':'possession_dribblepast'})\n\n\ncol_tot='possession_totdist'\ncol='possession_prgdist'\nmatches = change_to_pc(col,col_tot,matches)\n\ncol_tot='possession_carries'\ncols_to_pc=['possession_prog','possession_1/3','possession_cpa','possession_mis','possession_dis']\nfor col in cols_to_pc:\n    matches = change_to_pc(col,col_tot,matches)\n    \n\n\n\ncol_tot='shooting_sh'\ncol='shooting_dist'\nmatches = change_to_pc(col,col_tot,matches)\n\n\nmatches.to_csv(folda+'epl_beforeAVG_HA.csv')\n\n\n\nI want to predict the results without knowing details of the game\n\nso some mods\n\nSo as a first step I will give each gameweek stats for the previous gameweek and the average of the last 5 gameweeks\nThese stats are everything EXCEPT:\n\nround\nday\nvenue\nopponent\nteam\nmonth\nyear\nweekday\nWin\n\n\n#collapse-output\nno_change=['round','day','venue','opponent','team',\\\n 'month','year','weekday','season','Win','NetScore','GoalsFor','GoalsAgainst']\ncolRepeat = [x for x in matches.columns if x not in no_change]\n[x for x in colRepeat]\n\n['result',\n 'gf',\n 'ga',\n 'shooting_gls',\n 'shooting_sh',\n 'shooting_sot',\n 'shooting_sot%',\n 'shooting_g/sh',\n 'shooting_g/sot',\n 'shooting_PC_dist',\n 'shooting_fk',\n 'shooting_pk',\n 'shooting_pkatt',\n 'shooting_xg',\n 'shooting_npxg',\n 'shooting_npxg/sh',\n 'shooting_g-xg',\n 'shooting_np:g-xg',\n 'keeper_sota',\n 'keeper_saves',\n 'keeper_save%',\n 'keeper_cs',\n 'keeper_psxg',\n 'keeper_psxg+/-',\n 'keeper_pkatt',\n 'keeper_pka',\n 'keeper_pksv',\n 'keeper_pkm',\n 'keeper_cmp',\n 'keeper_att',\n 'keeper_cmp%',\n 'keeper_att_.1',\n 'keeper_thr',\n 'keeper_launch%',\n 'keeper_avglen',\n 'keeper_att_.2',\n 'keeper_launch%.1',\n 'keeper_avglen.1',\n 'keeper_opp',\n 'keeper_stp',\n 'keeper_stp%',\n 'keeper_#opa',\n 'keeper_avgdist',\n 'passing_pass_complete',\n 'passing_cmp%',\n 'passing_PC_totdist',\n 'passing_PC_prgdist',\n 'passing_PC_cmp_.1',\n 'passing_cmp%_.1',\n 'passing_PC_cmp_.2',\n 'passing_cmp%_.2',\n 'passing_PC_cmp_.3',\n 'passing_cmp%_.3',\n 'passing_ast',\n 'passing_xa',\n 'passing_kp',\n 'passing_PC_1/3',\n 'passing_PC_ppa',\n 'passing_PC_crspa',\n 'passing_PC_prog',\n 'passingtypes_PC_live',\n 'passingtypes_PC_dead',\n 'passingtypes_PC_fk',\n 'passingtypes_PC_tb',\n 'passingtypes_PC_press',\n 'passingtypes_PC_sw',\n 'passingtypes_PC_crs',\n 'passingtypes_PC_ck',\n 'passingtypes_PC_in',\n 'passingtypes_PC_out',\n 'passingtypes_PC_str',\n 'passingtypes_PC_ground',\n 'passingtypes_PC_low',\n 'passingtypes_PC_high',\n 'passingtypes_PC_left',\n 'passingtypes_PC_right',\n 'passingtypes_PC_head',\n 'passingtypes_PC_ti',\n 'passingtypes_PC_other',\n 'passingtypes_PC_cmp',\n 'passingtypes_PC_off',\n 'passingtypes_PC_out.1',\n 'passingtypes_PC_int',\n 'passingtypes_PC_blocks',\n 'shotcreate_sca',\n 'shotcreate_passlive',\n 'shotcreate_passdead',\n 'shotcreate_drib',\n 'shotcreate_sh_gca',\n 'shotcreate_fld_gca',\n 'shotcreate_def',\n 'shotcreate_gca',\n 'shotcreate_passlive.1',\n 'shotcreate_passdead.1',\n 'shotcreate_drib.1',\n 'shotcreate_sh_gca.1',\n 'shotcreate_fld_gca.1',\n 'shotcreate_def.1',\n 'tackle_tkl',\n 'tackle_PC_tklw_defense',\n 'tackle_PC_def 3rd_defense',\n 'tackle_PC_mid 3rd_defense',\n 'tackle_PC_att 3rd_defense',\n 'tackle_PC_tkl_dribble',\n 'tackle_dribble%',\n 'tackle_dribllepast',\n 'tackle_press_defense',\n 'tackle_%',\n 'tackle_PC_press_def3rd',\n 'tackle_PC_press_mid3rd',\n 'tackle_PC_press_att3rd',\n 'tackle_blocks_defense',\n 'tackle_PC_sh_defense',\n 'tackle_PC_shsv',\n 'tackle_PC_pass',\n 'tackle_int_defense',\n 'tackle_clr',\n 'tackle_err',\n 'possession_poss',\n 'possession_touches',\n 'possession_PC_def pen',\n 'possession_PC_def 3rd',\n 'possession_PC_mid 3rd',\n 'possession_PC_att 3rd',\n 'possession_PC_att pen',\n 'possession_PC_live',\n 'possession_dribblesucc',\n 'possession_dribbleatt',\n 'possession_dribblesucc%',\n 'possession_dribblepast',\n 'possession_megs',\n 'possession_carries',\n 'possession_totdist',\n 'possession_PC_prgdist',\n 'possession_PC_prog',\n 'possession_PC_1/3',\n 'possession_PC_cpa',\n 'possession_PC_mis',\n 'possession_PC_dis',\n 'possession_targ',\n 'possession_rec',\n 'possession_rec%',\n 'possession_prog_.1',\n 'misc_crdy',\n 'misc_crdr',\n 'misc_2crdy',\n 'misc_fls',\n 'misc_fld',\n 'misc_off',\n 'misc_crs',\n 'misc_int',\n 'misc_tklw',\n 'misc_pkwon',\n 'misc_pkcon',\n 'misc_og',\n 'misc_recov',\n 'misc_won',\n 'misc_lost',\n 'misc_won%',\n 'win',\n 'netscore',\n 'goalsfor',\n 'goalsagainst']\n\n\n\n\nConverts data into rolling average of previous matches\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html\n\nwindowint, offset, or BaseIndexer subclass\n\nSize of the moving window.\nIf an integer, the fixed number of observations used for each window.\nIf an offset, the time period of each window. Each window will be a variable sized based on the observations included in the time-period. This is only valid for datetimelike indexes. To learn more about the offsets & frequency strings, please see this link.\nIf a BaseIndexer subclass, the window boundaries based on the defined get_window_bounds method. Additional rolling keyword arguments, namely min_periods, center, and closed will be passed to get_window_bounds.\n\n\n\nmin_periodsint, default None\n\nMinimum number of observations in window required to have a value; otherwise, result is np.nan.\nFor a window that is specified by an offset, min_periods will default to 1.\nFor a window that is specified by an integer, min_periods will default to the size of the window.\n\n\n\nclosed : str, default None\n\nIf ‘right’, the first point in the window is excluded from calculations.\nIf ‘left’, the last point in the window is excluded from calculations.\nIf ‘both’, the no points in the window are excluded from calculations.\nIf ‘neither’, the first and last points in the window are excluded from calculations.\nDefault None (‘right’).\n\n\n#collapse-output\nmatches_=matches.copy()\nfor x in matches_.team.unique():\n    matches_.loc[matches_.team==x,colRepeat] = matches_.loc[matches_.team==x,colRepeat].rolling(window=3,closed='left',min_periods=1).mean()\n\nmatches_.loc[matches_['round']>10].head()\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue\n      result\n      gf\n      ga\n      opponent\n      shooting_gls\n      shooting_sh\n      shooting_sot\n      ...\n      misc_won%\n      team\n      season\n      month\n      year\n      weekday\n      win\n      netscore\n      goalsfor\n      goalsagainst\n    \n  \n  \n    \n      200\n      11\n      5\n      Home\n      3.000000\n      4.333333\n      1.333333\n      Arsenal\n      4.333333\n      16.666667\n      8.666667\n      ...\n      63.633333\n      Manchester City\n      2017\n      11\n      2017\n      6\n      NaN\n      3.000000\n      4.333333\n      1.333333\n    \n    \n      201\n      11\n      5\n      Away\n      0.000000\n      0.666667\n      0.666667\n      Chelsea\n      0.666667\n      9.000000\n      2.666667\n      ...\n      54.000000\n      Manchester United\n      2017\n      11\n      2017\n      6\n      NaN\n      0.000000\n      0.666667\n      0.666667\n    \n    \n      202\n      11\n      5\n      Home\n      1.000000\n      1.666667\n      0.666667\n      Crystal Palace\n      1.666667\n      14.666667\n      5.000000\n      ...\n      51.466667\n      Tottenham Hotspur\n      2017\n      11\n      2017\n      6\n      NaN\n      1.000000\n      1.666667\n      0.666667\n    \n    \n      203\n      11\n      4\n      Away\n      0.000000\n      1.333333\n      1.333333\n      West Ham United\n      1.333333\n      16.000000\n      6.333333\n      ...\n      46.800000\n      Liverpool\n      2017\n      11\n      2017\n      5\n      NaN\n      0.000000\n      1.333333\n      1.333333\n    \n    \n      204\n      11\n      5\n      Home\n      0.666667\n      2.000000\n      1.333333\n      Manchester United\n      2.000000\n      16.000000\n      5.666667\n      ...\n      63.433333\n      Chelsea\n      2017\n      11\n      2017\n      6\n      NaN\n      0.666667\n      2.000000\n      1.333333\n    \n  \n\n5 rows × 172 columns\n\n\n\n\nmatches_.loc[(matches.team=='Arsenal'),['round',]]\n\n\n\n\n\n  \n    \n      \n      round\n    \n  \n  \n    \n      5\n      1\n    \n    \n      25\n      2\n    \n    \n      45\n      3\n    \n    \n      65\n      4\n    \n    \n      85\n      5\n    \n    \n      ...\n      ...\n    \n    \n      3704\n      34\n    \n    \n      3724\n      35\n    \n    \n      3744\n      36\n    \n    \n      3764\n      37\n    \n    \n      3784\n      38\n    \n  \n\n190 rows × 1 columns\n\n\n\n\nmatches.loc[(matches.team=='Arsenal')]\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue\n      result\n      gf\n      ga\n      opponent\n      shooting_gls\n      shooting_sh\n      shooting_sot\n      ...\n      misc_won%\n      team\n      season\n      month\n      year\n      weekday\n      win\n      netscore\n      goalsfor\n      goalsagainst\n    \n  \n  \n    \n      5\n      1\n      11\n      Home\n      1\n      4\n      3\n      Leicester City\n      4.0\n      27.0\n      10.0\n      ...\n      50.0\n      Arsenal\n      2017\n      8\n      2017\n      4\n      W\n      1\n      4\n      3\n    \n    \n      25\n      2\n      19\n      Away\n      -1\n      0\n      1\n      Stoke City\n      0.0\n      19.0\n      7.0\n      ...\n      40.0\n      Arsenal\n      2017\n      8\n      2017\n      5\n      L\n      -1\n      0\n      1\n    \n    \n      45\n      3\n      27\n      Away\n      -4\n      0\n      4\n      Liverpool\n      0.0\n      8.0\n      0.0\n      ...\n      54.5\n      Arsenal\n      2017\n      8\n      2017\n      6\n      L\n      -4\n      0\n      4\n    \n    \n      65\n      4\n      9\n      Home\n      3\n      3\n      0\n      Bournemouth\n      3.0\n      17.0\n      9.0\n      ...\n      51.1\n      Arsenal\n      2017\n      9\n      2017\n      5\n      W\n      3\n      3\n      0\n    \n    \n      85\n      5\n      17\n      Away\n      0\n      0\n      0\n      Chelsea\n      0.0\n      11.0\n      2.0\n      ...\n      48.8\n      Arsenal\n      2017\n      9\n      2017\n      6\n      D\n      0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3704\n      34\n      23\n      Home\n      2\n      3\n      1\n      Manchester United\n      3.0\n      13.0\n      6.0\n      ...\n      19.0\n      Arsenal\n      2021\n      4\n      2022\n      5\n      W\n      2\n      3\n      1\n    \n    \n      3724\n      35\n      1\n      Away\n      1\n      2\n      1\n      West Ham United\n      2.0\n      13.0\n      7.0\n      ...\n      51.5\n      Arsenal\n      2021\n      5\n      2022\n      6\n      W\n      1\n      2\n      1\n    \n    \n      3744\n      36\n      8\n      Home\n      1\n      2\n      1\n      Leeds United\n      2.0\n      19.0\n      9.0\n      ...\n      42.9\n      Arsenal\n      2021\n      5\n      2022\n      6\n      W\n      1\n      2\n      1\n    \n    \n      3764\n      37\n      16\n      Away\n      -2\n      0\n      2\n      Newcastle United\n      0.0\n      11.0\n      2.0\n      ...\n      45.0\n      Arsenal\n      2021\n      5\n      2022\n      0\n      L\n      -2\n      0\n      2\n    \n    \n      3784\n      38\n      22\n      Home\n      4\n      5\n      1\n      Everton\n      5.0\n      25.0\n      8.0\n      ...\n      48.4\n      Arsenal\n      2021\n      5\n      2022\n      6\n      W\n      4\n      5\n      1\n    \n  \n\n190 rows × 172 columns\n\n\n\n\n\n\nCombine results for both home and away teams\ni.e. combine team/opponent combos for a particular match. Will have different data for team/opponent\n\n#collapse-output\nmatchesC=matches_.copy()\n\n\nmatchesC=matches_.merge(matches_, left_on = [\"month\",'year','weekday',\"round\",\"day\",'season', \"team\"], \\\n                       right_on= [\"month\",'year','weekday',\"round\",\"day\",'season', \"opponent\"])\nmatchesC\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      ...\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n      win_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n  \n  \n    \n      0\n      1\n      12\n      Away\n      NaN\n      NaN\n      NaN\n      Brighton and Hove Albion\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Brighton and Hove Albion\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      1\n      13\n      Home\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      West Ham United\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      13\n      Away\n      NaN\n      NaN\n      NaN\n      Newcastle United\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Newcastle United\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      1\n      12\n      Away\n      NaN\n      NaN\n      NaN\n      Watford\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Watford\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      1\n      12\n      Home\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n      NaN\n      0.000000\n      1.333333\n      1.333333\n    \n    \n      3796\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n      NaN\n      0.333333\n      2.000000\n      1.666667\n    \n    \n      3797\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n      NaN\n      -1.333333\n      0.666667\n      2.000000\n    \n    \n      3798\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n      NaN\n      -0.333333\n      1.000000\n      1.333333\n    \n    \n      3799\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n      NaN\n      1.000000\n      1.666667\n      0.666667\n    \n  \n\n3800 rows × 338 columns\n\n\n\n\nSave the data\n\nwhatsave=1\n\nif whatsave==0:\n    matchesOut=matchesC.copy()\n    matchesOut=matchesOut.drop(columns=['venue_x','venue_y','win_y','netscore_y','goalsfor_x','goalsfor_y',\n                                        'goalsagainst_x','goalsagainst_y'])\n    matchesOut.to_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\nelif whatsave==1:\n    matchesOut=matchesC.copy()\n    matchesOut=matchesOut.drop(columns=['venue_y','win_y','netscore_y','goalsfor_y','goalsagainst_y'])\n    matchesOut.to_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv')\n#    \n\n# matchesC=matchesC.drop(columns=['opponent_x','opponent_y'])\n# matchesC=matchesC.loc[matchesC['venue_x']=='Home']\n\n\nmatchesC[['venue_x','venue_y','win_y','netscore_y','goalsfor_x','goalsfor_y',\n          'goalsagainst_x','goalsagainst_y']]\n\n\n\n\n\n  \n    \n      \n      venue_x\n      venue_y\n      win_y\n      netscore_y\n      goalsfor_x\n      goalsfor_y\n      goalsagainst_x\n      goalsagainst_y\n    \n  \n  \n    \n      0\n      Away\n      Home\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      Home\n      Away\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      Away\n      Home\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      Away\n      Home\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Home\n      Away\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      Away\n      Home\n      NaN\n      0.000000\n      1.666667\n      1.333333\n      1.333333\n      1.333333\n    \n    \n      3796\n      Away\n      Home\n      NaN\n      0.333333\n      0.666667\n      2.000000\n      2.333333\n      1.666667\n    \n    \n      3797\n      Home\n      Away\n      NaN\n      -1.333333\n      1.000000\n      0.666667\n      1.666667\n      2.000000\n    \n    \n      3798\n      Away\n      Home\n      NaN\n      -0.333333\n      0.666667\n      1.000000\n      2.666667\n      1.333333\n    \n    \n      3799\n      Home\n      Away\n      NaN\n      1.000000\n      0.333333\n      1.666667\n      2.333333\n      0.666667\n    \n  \n\n3800 rows × 8 columns\n\n\n\n\n## SANITY CHECKS\nteamName='Manchester United'\nyear=2017\nmc=matchesC.loc[((  (matchesC.team_x==teamName) ))][['round','team_x','team_y','result_x','season']]\n\nmraw=matches.loc[((  matches.team==teamName  ))][['round','team','opponent','result','season']]\n\n\n\nplt.subplots(figsize=(15,5))\nplt.plot( (mc['round']+(mc['season']-2017)*38)/38, mraw['result'] ,'.-')\nplt.plot( (mc['round']+(mc['season']-2017)*38)/38, mc['result_x'] ,'.-')\nplt.legend(['raw','running average']);\nplt.grid(True)\n\n\n\n\n\nmg = matchesC.groupby('team_x').mean()\nmg\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      ...\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n    \n      team_x\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Arsenal\n      19.5\n      15.210526\n      0.421517\n      1.675485\n      1.253968\n      1.633157\n      13.111111\n      4.514109\n      35.496473\n      0.126499\n      ...\n      0.112589\n      0.136525\n      0.042553\n      91.012411\n      19.406915\n      19.757979\n      49.480762\n      -0.061170\n      1.287234\n      1.348404\n    \n    \n      Aston Villa\n      19.5\n      15.903509\n      -0.181416\n      1.286136\n      1.467552\n      1.233038\n      12.609145\n      4.261062\n      33.371829\n      0.092640\n      ...\n      0.102339\n      0.122807\n      0.052632\n      89.173977\n      17.751462\n      18.026316\n      49.695760\n      0.114035\n      1.388889\n      1.274854\n    \n    \n      Bournemouth\n      19.5\n      15.868421\n      -0.500000\n      1.218289\n      1.718289\n      1.191740\n      11.336283\n      3.691740\n      32.124926\n      0.095973\n      ...\n      0.093093\n      0.123123\n      0.030030\n      93.247748\n      20.250751\n      20.214715\n      50.193544\n      0.057057\n      1.409910\n      1.352853\n    \n    \n      Brentford\n      19.5\n      15.394737\n      -0.189189\n      1.234234\n      1.423423\n      1.198198\n      11.297297\n      3.549550\n      31.855405\n      0.092117\n      ...\n      0.114035\n      0.140351\n      0.061404\n      82.771930\n      16.850877\n      16.429825\n      51.121930\n      0.052632\n      1.394737\n      1.342105\n    \n    \n      Brighton and Hove Albion\n      19.5\n      16.052632\n      -0.388007\n      0.978836\n      1.366843\n      0.936508\n      11.276014\n      3.218695\n      30.280688\n      0.080811\n      ...\n      0.095238\n      0.127866\n      0.040564\n      89.408289\n      19.255732\n      19.731041\n      49.229630\n      0.059965\n      1.424162\n      1.364198\n    \n    \n      Burnley\n      19.5\n      16.168421\n      -0.375661\n      1.016755\n      1.392416\n      0.974427\n      10.093474\n      3.194004\n      31.874427\n      0.103527\n      ...\n      0.095238\n      0.128748\n      0.038801\n      88.843034\n      18.495591\n      18.074074\n      50.651764\n      -0.073192\n      1.338624\n      1.411817\n    \n    \n      Cardiff City\n      19.5\n      15.921053\n      -1.018018\n      0.828829\n      1.846847\n      0.819820\n      10.761261\n      2.842342\n      29.641441\n      0.074865\n      ...\n      0.078947\n      0.149123\n      0.026316\n      91.561404\n      19.140351\n      18.307018\n      51.198246\n      0.026316\n      1.412281\n      1.385965\n    \n    \n      Chelsea\n      19.5\n      15.963158\n      0.668430\n      1.728395\n      1.059965\n      1.691358\n      15.545855\n      5.257496\n      34.136684\n      0.103307\n      ...\n      0.121693\n      0.126984\n      0.052028\n      91.537919\n      20.075838\n      19.852734\n      50.077778\n      -0.105820\n      1.294533\n      1.400353\n    \n    \n      Crystal Palace\n      19.5\n      16.310526\n      -0.296296\n      1.142857\n      1.439153\n      1.100529\n      10.937390\n      3.427690\n      32.483686\n      0.100838\n      ...\n      0.109929\n      0.143617\n      0.028369\n      90.376773\n      19.329787\n      19.449468\n      49.848493\n      0.152482\n      1.443262\n      1.290780\n    \n    \n      Everton\n      19.5\n      14.710526\n      -0.194885\n      1.216931\n      1.411817\n      1.174603\n      11.298060\n      3.654321\n      32.695414\n      0.100979\n      ...\n      0.093972\n      0.126773\n      0.057624\n      89.239362\n      18.835993\n      18.802305\n      49.994415\n      -0.075355\n      1.358156\n      1.433511\n    \n    \n      Fulham\n      19.5\n      15.289474\n      -0.964444\n      0.802222\n      1.766667\n      0.775556\n      11.673333\n      3.460000\n      29.526667\n      0.058756\n      ...\n      0.118421\n      0.184211\n      0.043860\n      88.429825\n      18.258772\n      18.456140\n      49.566228\n      -0.188596\n      1.381579\n      1.570175\n    \n    \n      Huddersfield Town\n      19.5\n      16.026316\n      -1.062222\n      0.680000\n      1.742222\n      0.602222\n      10.044444\n      2.935556\n      30.048889\n      0.055511\n      ...\n      0.146667\n      0.142222\n      0.044444\n      91.108889\n      21.348889\n      21.073333\n      50.432222\n      -0.233333\n      1.282222\n      1.515556\n    \n    \n      Leeds United\n      19.5\n      16.078947\n      -0.404444\n      1.388889\n      1.793333\n      1.362222\n      13.184444\n      4.442222\n      35.603778\n      0.110378\n      ...\n      0.114035\n      0.162281\n      0.048246\n      84.732456\n      18.061404\n      17.293860\n      51.365789\n      0.008772\n      1.364035\n      1.355263\n    \n    \n      Leicester City\n      19.5\n      15.889474\n      0.212522\n      1.582892\n      1.370370\n      1.519400\n      12.416226\n      4.320106\n      35.845767\n      0.121587\n      ...\n      0.121693\n      0.111111\n      0.045855\n      88.839506\n      18.775132\n      19.029101\n      49.624868\n      -0.096120\n      1.342152\n      1.438272\n    \n    \n      Liverpool\n      19.5\n      16.289474\n      1.357143\n      2.211640\n      0.854497\n      2.158730\n      16.320106\n      5.810406\n      36.395767\n      0.129691\n      ...\n      0.096257\n      0.126560\n      0.048128\n      89.806595\n      19.374332\n      19.647950\n      49.776827\n      0.067736\n      1.356506\n      1.288770\n    \n    \n      Manchester City\n      19.5\n      15.947368\n      1.804233\n      2.544092\n      0.739859\n      2.474427\n      17.603175\n      6.336861\n      36.914815\n      0.140406\n      ...\n      0.134039\n      0.121693\n      0.046737\n      91.272487\n      19.769841\n      19.767196\n      50.053086\n      0.152557\n      1.456790\n      1.304233\n    \n    \n      Manchester United\n      19.5\n      16.047368\n      0.615520\n      1.758377\n      1.142857\n      1.726631\n      13.648148\n      5.078483\n      38.115608\n      0.119489\n      ...\n      0.097002\n      0.116402\n      0.040564\n      90.966490\n      19.932981\n      19.534392\n      50.678660\n      0.007937\n      1.358907\n      1.350970\n    \n    \n      Newcastle United\n      19.5\n      16.042105\n      -0.373016\n      1.088183\n      1.461199\n      1.054674\n      11.138448\n      3.601411\n      32.866755\n      0.095344\n      ...\n      0.119929\n      0.125220\n      0.047619\n      90.180776\n      18.980600\n      19.029982\n      49.676367\n      0.069665\n      1.417989\n      1.348325\n    \n    \n      Norwich City\n      19.5\n      15.973684\n      -1.411111\n      0.662222\n      2.073333\n      0.622222\n      10.364444\n      3.097778\n      30.114889\n      0.054400\n      ...\n      0.092105\n      0.144737\n      0.043860\n      89.100877\n      18.320175\n      18.162281\n      50.484211\n      -0.127193\n      1.271930\n      1.399123\n    \n    \n      Sheffield United\n      19.5\n      15.657895\n      -0.580000\n      0.782222\n      1.362222\n      0.728889\n      8.780000\n      2.657778\n      30.685556\n      0.083556\n      ...\n      0.129386\n      0.164474\n      0.039474\n      90.660088\n      16.978070\n      17.546053\n      49.354605\n      -0.109649\n      1.361842\n      1.471491\n    \n    \n      Southampton\n      19.5\n      16.231579\n      -0.466490\n      1.173721\n      1.640212\n      1.152557\n      12.388007\n      4.113757\n      34.837654\n      0.090088\n      ...\n      0.125220\n      0.121693\n      0.045855\n      89.746914\n      19.088183\n      18.665785\n      50.723016\n      0.035273\n      1.398589\n      1.363316\n    \n    \n      Stoke City\n      19.5\n      16.394737\n      -0.918919\n      0.878378\n      1.797297\n      0.851351\n      10.432432\n      3.184685\n      33.167117\n      0.087342\n      ...\n      0.081081\n      0.072072\n      0.009009\n      94.153153\n      21.887387\n      23.333333\n      48.231532\n      0.450450\n      1.522523\n      1.072072\n    \n    \n      Swansea City\n      19.5\n      16.868421\n      -0.720721\n      0.729730\n      1.450450\n      0.702703\n      8.189189\n      2.193694\n      28.216667\n      0.092162\n      ...\n      0.099099\n      0.081081\n      0.031532\n      95.824324\n      24.725225\n      22.824324\n      52.114414\n      0.216216\n      1.459459\n      1.243243\n    \n    \n      Tottenham Hotspur\n      19.5\n      15.394737\n      0.676367\n      1.771605\n      1.095238\n      1.675485\n      13.314815\n      4.734568\n      36.830423\n      0.129233\n      ...\n      0.093972\n      0.125887\n      0.035461\n      90.899823\n      19.563830\n      19.655142\n      49.633688\n      0.017730\n      1.366135\n      1.348404\n    \n    \n      Watford\n      19.5\n      16.184211\n      -0.620309\n      1.107064\n      1.727373\n      1.073951\n      11.065121\n      3.399558\n      31.508940\n      0.089536\n      ...\n      0.099338\n      0.116998\n      0.038631\n      90.599338\n      19.486755\n      19.296909\n      50.105740\n      -0.099338\n      1.304636\n      1.403974\n    \n    \n      West Bromwich Albion\n      19.5\n      16.421053\n      -0.817778\n      0.866667\n      1.684444\n      0.840000\n      9.457778\n      2.793333\n      31.112000\n      0.083800\n      ...\n      0.111111\n      0.151111\n      0.057778\n      89.895556\n      20.335556\n      20.268889\n      50.009333\n      0.017778\n      1.380000\n      1.362222\n    \n    \n      West Ham United\n      19.5\n      16.157895\n      -0.078483\n      1.416226\n      1.494709\n      1.389771\n      11.238095\n      3.870370\n      35.340388\n      0.120414\n      ...\n      0.125220\n      0.114638\n      0.047619\n      90.360670\n      19.217813\n      19.444444\n      49.579894\n      0.006173\n      1.402116\n      1.395944\n    \n    \n      Wolverhampton Wanderers\n      19.5\n      15.559211\n      -0.048565\n      1.134658\n      1.183223\n      1.081678\n      11.768212\n      3.706402\n      31.860706\n      0.091347\n      ...\n      0.118421\n      0.120614\n      0.067982\n      89.114035\n      17.844298\n      17.971491\n      49.912939\n      -0.085526\n      1.357456\n      1.442982\n    \n  \n\n28 rows × 330 columns\n\n\n\n\nX\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      ...\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n  \n  \n    \n      round\n      1.000000\n      -0.101106\n      -0.000427\n      -0.032829\n      -0.033619\n      -0.031728\n      -0.033182\n      -0.031253\n      -0.012582\n      -0.005572\n      ...\n      -0.026473\n      -0.039209\n      -0.016878\n      0.053467\n      0.027972\n      0.028820\n      0.000147\n      -0.000427\n      -0.032829\n      -0.033619\n    \n    \n      day\n      -0.101106\n      1.000000\n      0.001526\n      0.012942\n      0.011046\n      0.017277\n      0.018508\n      0.013796\n      0.011117\n      0.013813\n      ...\n      0.017057\n      -0.014209\n      -0.019603\n      0.000052\n      0.011315\n      0.008934\n      0.007511\n      0.001526\n      0.012942\n      0.011046\n    \n    \n      result_x\n      -0.000427\n      0.001526\n      1.000000\n      0.804871\n      -0.784386\n      0.796159\n      0.489624\n      0.598669\n      0.302810\n      0.553999\n      ...\n      -0.008706\n      -0.020023\n      0.015524\n      0.000158\n      -0.003279\n      -0.004667\n      0.006454\n      0.020826\n      0.017049\n      -0.016039\n    \n    \n      gf_x\n      -0.032829\n      0.012942\n      0.804871\n      1.000000\n      -0.263228\n      0.988970\n      0.489024\n      0.682367\n      0.418380\n      0.724261\n      ...\n      0.010279\n      -0.026590\n      0.016782\n      0.015622\n      0.005549\n      0.006301\n      0.001188\n      0.017049\n      0.011392\n      -0.015809\n    \n    \n      ga_x\n      -0.033619\n      0.011046\n      -0.784386\n      -0.263228\n      1.000000\n      -0.260595\n      -0.284823\n      -0.260010\n      -0.054968\n      -0.143603\n      ...\n      0.024876\n      0.004775\n      -0.007703\n      0.016053\n      0.011122\n      0.014161\n      -0.009246\n      -0.016039\n      -0.015809\n      0.009557\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      misc_lost_y\n      0.028820\n      0.008934\n      -0.004667\n      0.006301\n      0.014161\n      0.007396\n      0.001735\n      0.012405\n      0.009634\n      0.014438\n      ...\n      -0.119425\n      -0.028281\n      0.011898\n      0.373947\n      0.694807\n      1.000000\n      -0.398785\n      -0.222763\n      -0.280020\n      0.069455\n    \n    \n      misc_won%_y\n      0.000147\n      0.007511\n      0.006454\n      0.001188\n      -0.009246\n      -0.000937\n      -0.002138\n      0.005459\n      0.010180\n      0.009635\n      ...\n      0.058702\n      -0.067979\n      -0.029776\n      0.040269\n      0.327227\n      -0.398785\n      1.000000\n      0.202235\n      0.155459\n      -0.166274\n    \n    \n      netscore_y\n      -0.000427\n      0.001526\n      0.020826\n      0.017049\n      -0.016039\n      0.018878\n      -0.000026\n      0.013563\n      0.023359\n      0.019314\n      ...\n      0.189385\n      -0.197948\n      -0.164797\n      0.084513\n      -0.111881\n      -0.222763\n      0.202235\n      1.000000\n      0.804871\n      -0.784386\n    \n    \n      goalsfor_y\n      -0.032829\n      0.012942\n      0.017049\n      0.011392\n      -0.015809\n      0.012763\n      0.007157\n      0.006324\n      0.017994\n      0.014789\n      ...\n      0.253819\n      -0.045267\n      -0.062638\n      0.016541\n      -0.197868\n      -0.280020\n      0.155459\n      0.804871\n      1.000000\n      -0.263228\n    \n    \n      goalsagainst_y\n      -0.033619\n      0.011046\n      -0.016039\n      -0.015809\n      0.009557\n      -0.017349\n      0.007515\n      -0.015435\n      -0.019168\n      -0.015943\n      ...\n      -0.042581\n      0.274478\n      0.202431\n      -0.120098\n      -0.024934\n      0.069455\n      -0.166274\n      -0.784386\n      -0.263228\n      1.000000\n    \n  \n\n330 rows × 330 columns\n\n\n\n\nplt.plot(mg.netscore_x,mg.shooting_sh_x,'ok')\n\n# plt.plot(matchesC.gf_x,matchesC.NetScore_x,'ok')\n\nX=matchesC.corr()\ncorrnetscore=X.sort_values(by=\"netscore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\n\n\n\n  \n    \n      \n      category\n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh_x\n      shooting_sot_x\n      shooting_sot%_x\n      ...\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      netscore_y\n      goalsfor_y\n      goalsagainst_y\n    \n  \n  \n    \n      0\n      ga_x\n      -0.033619\n      0.011046\n      -0.784386\n      -0.263228\n      1.000000\n      -0.260595\n      -0.284823\n      -0.260010\n      -0.054968\n      ...\n      0.024876\n      0.004775\n      -0.007703\n      0.016053\n      0.011122\n      0.014161\n      -0.009246\n      -0.016039\n      -0.015809\n      0.009557\n    \n    \n      1\n      goalsagainst_x\n      -0.033619\n      0.011046\n      -0.784386\n      -0.263228\n      1.000000\n      -0.260595\n      -0.284823\n      -0.260010\n      -0.054968\n      ...\n      0.024876\n      0.004775\n      -0.007703\n      0.016053\n      0.011122\n      0.014161\n      -0.009246\n      -0.016039\n      -0.015809\n      0.009557\n    \n    \n      2\n      keeper_psxg_x\n      -0.020151\n      0.004270\n      -0.689039\n      -0.288664\n      0.818415\n      -0.285579\n      -0.342578\n      -0.292562\n      -0.040214\n      ...\n      0.016138\n      0.005909\n      0.004696\n      0.022612\n      0.008525\n      0.021666\n      -0.019468\n      -0.026014\n      -0.025878\n      0.015252\n    \n    \n      3\n      keeper_sota_x\n      -0.027422\n      0.009134\n      -0.585212\n      -0.306845\n      0.630628\n      -0.303735\n      -0.390630\n      -0.326298\n      -0.029044\n      ...\n      -0.003544\n      0.019901\n      -0.012280\n      0.008879\n      0.015911\n      0.029753\n      -0.018988\n      -0.016977\n      -0.017976\n      0.008819\n    \n    \n      4\n      passingtypes_PC_dead_x\n      -0.020593\n      0.025862\n      -0.428442\n      -0.400000\n      0.278412\n      -0.400698\n      -0.520973\n      -0.469203\n      -0.092371\n      ...\n      -0.022421\n      0.000464\n      -0.011870\n      -0.003227\n      0.015526\n      0.010683\n      0.004033\n      -0.001923\n      -0.001384\n      0.001681\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      325\n      shooting_gls_x\n      -0.031728\n      0.017277\n      0.796159\n      0.988970\n      -0.260595\n      1.000000\n      0.489307\n      0.687750\n      0.424698\n      ...\n      0.008137\n      -0.028288\n      0.015246\n      0.016248\n      0.005333\n      0.007396\n      -0.000937\n      0.018878\n      0.012763\n      -0.017349\n    \n    \n      326\n      gf_x\n      -0.032829\n      0.012942\n      0.804871\n      1.000000\n      -0.263228\n      0.988970\n      0.489024\n      0.682367\n      0.418380\n      ...\n      0.010279\n      -0.026590\n      0.016782\n      0.015622\n      0.005549\n      0.006301\n      0.001188\n      0.017049\n      0.011392\n      -0.015809\n    \n    \n      327\n      goalsfor_x\n      -0.032829\n      0.012942\n      0.804871\n      1.000000\n      -0.263228\n      0.988970\n      0.489024\n      0.682367\n      0.418380\n      ...\n      0.010279\n      -0.026590\n      0.016782\n      0.015622\n      0.005549\n      0.006301\n      0.001188\n      0.017049\n      0.011392\n      -0.015809\n    \n    \n      328\n      result_x\n      -0.000427\n      0.001526\n      1.000000\n      0.804871\n      -0.784386\n      0.796159\n      0.489624\n      0.598669\n      0.302810\n      ...\n      -0.008706\n      -0.020023\n      0.015524\n      0.000158\n      -0.003279\n      -0.004667\n      0.006454\n      0.020826\n      0.017049\n      -0.016039\n    \n    \n      329\n      netscore_x\n      -0.000427\n      0.001526\n      1.000000\n      0.804871\n      -0.784386\n      0.796159\n      0.489624\n      0.598669\n      0.302810\n      ...\n      -0.008706\n      -0.020023\n      0.015524\n      0.000158\n      -0.003279\n      -0.004667\n      0.006454\n      0.020826\n      0.017049\n      -0.016039\n    \n  \n\n330 rows × 331 columns"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#overview",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2017 to 2021 seasons. I will predict whether a result is a win, loss or draw, and then simplify as a binary question- is it a win?\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below like who is playing who and where)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who\nSome details on the machine learning:\n\nA Random Forest Classifier was the main model used for analysis.\nData is trained on years 2017 to 2020 with season 2021 used as validation\n\n20% validation / 80% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 52% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe more data the better,\n\nbut the increase from just using a basic four parameter fit to one with 300+ columns is relatively small (a difference of ~1-2% (based on values 50-65%))\n\nBy searching for the best hyper parameters the results of a random forest (RF) model were increased from 49% accuracy to 52%\nRF, XG boost and grad boost methods all performed similar\n\nRidge model was the worst performing\nNeural networks with fastai tabular data also performed poorly. NN analysis of EPL\n\nSimilar results were obtained by using classification and regression methods\n\nRegression on the net score performed the best\nRegression methods performed worse on predicting draws though\n\nEnsembling (combining results from different methods by adding them) can increase the overall results. The accuracy would need to be comparable and the results different enough for their to be a benefit\n\nA summary of the results is shown below\n\n\n\n\n\n\n\n\n\nAccuracy W/L/D\nAccuracy Win\nClassification/Regression\nDetails\n\n\n\n\n0.489\n0.669\nClassification\nRF with all parameters\n\n\n0.479\n0.661\nClassification\nRF with 43 parameters from feature imp\n\n\n0.487\n0.666\nClassification\nRF as above with basic features\n\n\n0.484\n0.656\nClassification\nRF with 4 basic features\n\n\n0.479\n-\nClassification\nRF with 4 basic ones + balanced\n\n\n0.485\n0.656\nClassification\nRF with 23 correlation parameters plus basic\n\n\n0.451\n0.678\nRegression\nRF with all parameters on net score\n\n\n-\n0.657\nRegression\nXGB with all parameters on net score\n\n\n-\n0.639\nRegression\nRidge with all parameters on net score\n\n\n-\n0.666\nRegression\nGrad boost with all parameters on net score\n\n\n0.427\n0.670\nRegression\nRF with all parameters on GF/GA\n\n\n-\n0.670\nRegression\nXGB with all parameters on GF/GA score\n\n\n-\n0.665\nRegression\nRF+XGB+Grad boost on netscore\n\n\n-\n0.678\nRegression\nRF on netscore + RF on GF/GA\n\n\n\n\n\nCode- Prepare the data\nData is prepared in a separate page- Predicting Premier League Matches- Prepare the data"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#possession",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#possession",
    "title": "ThomasHSimm",
    "section": "Possession",
    "text": "Possession\n\npossession_poss - percentage of passes attempted\npossession_touches - Number of times a player touched the ball\npossession_def pen - Touches in defensive penalty area\npossession_def 3rd - Touches in defensive 3rd\npossession_mid 3rd - Touches in mid 3rd\npossession_att 3rd - Touches in att 3rd\npossession_att pen - Touches in att penalty area\npossession_live - live ball touches\npossession_rec% - Passes Received Percentage"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#passing-type",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#passing-type",
    "title": "ThomasHSimm",
    "section": "Passing Type",
    "text": "Passing Type\n\npassingtype_tb - Completed pass sent between back defenders into open space\npassingtype_press - Passes made while under pressure from opponent\npassingtype_sw - Passes that travel more than 40 yards of the width of the pitch\npassingtype_crs - crosses\npassingtype_ground - Ground passes\npassingtype_low - Passes that leave the ground, but stay below shoulder-level\npassingtype_high - Passes that are above shoulder-level at the peak height\npassingtype_head - Passes attempted using head\npassingtype_cmp - Passes Completed\npassingtype_blocks - Blocked by the opponent who was standing it the path"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#passing",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#passing",
    "title": "ThomasHSimm",
    "section": "Passing",
    "text": "Passing\n\npassing_pass_complete - Passes Completed\npassing_cmp% - Passes Completed %\npassing_PC_totdist - Total distance, in yards, that completed passes have traveled in any direction divided by passes completed\npassing_PC_prgdist - Total progressive distance (towards opponent goal), in yards, that completed passes have traveled in any direction divided by passes completed\npassing_PC_cmp_.1 - % Passes between 5 and 15 yards (of total completed passes)\npassing_cmp%_.1 - Pass completion % for passes between 5 and 15 yards\npassing_PC_cmp_.2 - % Passes between 15 and 30 yards (of total completed passes)\npassing_cmp%_.2 - Pass completion % for passes between 15 and 30 yards\npassing_PC_cmp_.3 - % Passes over 30 yards (of total completed passes)\npassing_cmp%_.3 - Pass completion % for passes over 30 yards\npassing_PC_1/3 - Completed passes that enter the 1/3 of the pitch closest to the goal as a % of completed passes\npassing_PC_ppa - Completed passes into the 18-yard box as a % of completed passes\npassing_PC_crspa - Completed crosses into the 18-yard box as a % of completed passes\npassing_PC_prog - Progressive Passes as a % of completed passes (Completed passes that move the ball towards the opponent’s goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area. Excludes passes from the defending 40% of the pitch)"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#load-data-and-libraries",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\ncwd=os.getcwd()\n\n\n#hide\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',\n 'epl2017-2021_wivnetscore_both-HA.csv']\n\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',index_col=0)\ndfAll=dfAll.iloc[20:,:]\ndfAll\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh__x\n      shooting_sot_x\n      ...\n      misc_int__y\n      misc_tklw__y\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n    \n  \n  \n    \n      44\n      3\n      27\n      Home\n      0.000000\n      2.000000\n      2.000000\n      Everton\n      2.000000\n      14.500000\n      4.000000\n      ...\n      13.000000\n      12.000000\n      0.000000\n      0.000000\n      0.000000\n      94.500000\n      19.500000\n      27.000000\n      41.150000\n      Everton\n    \n    \n      45\n      3\n      27\n      Away\n      0.000000\n      2.000000\n      2.000000\n      Liverpool\n      2.000000\n      23.000000\n      8.500000\n      ...\n      16.000000\n      12.000000\n      0.500000\n      0.000000\n      0.000000\n      114.000000\n      28.500000\n      20.500000\n      57.450000\n      Liverpool\n    \n    \n      46\n      3\n      27\n      Away\n      0.000000\n      1.500000\n      1.500000\n      Tottenham Hotspur\n      1.500000\n      15.000000\n      3.000000\n      ...\n      8.500000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      21.000000\n      22.500000\n      48.600000\n      Tottenham Hotspur\n    \n    \n      47\n      3\n      27\n      Away\n      0.500000\n      1.000000\n      0.500000\n      Chelsea\n      1.000000\n      8.000000\n      3.000000\n      ...\n      7.000000\n      14.000000\n      0.000000\n      0.000000\n      0.500000\n      92.000000\n      23.500000\n      26.000000\n      47.850000\n      Chelsea\n    \n    \n      48\n      3\n      26\n      Away\n      0.500000\n      2.500000\n      2.000000\n      Manchester United\n      2.500000\n      10.000000\n      3.500000\n      ...\n      16.000000\n      10.500000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      21.500000\n      19.500000\n      50.300000\n      Manchester United\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n    \n    \n      3796\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n    \n    \n      3797\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      3798\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n    \n    \n      3799\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n3740 rows × 333 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      result_x\n      gf_x\n      ga_x\n      shooting_gls_x\n      shooting_sh__x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      shooting_g/sot_x\n      shooting_PC_dist_x\n      shooting_fk__x\n      shooting_pk_x\n      shooting_pkatt__x\n      shooting_xg_x\n      shooting_npxg_x\n      shooting_npxg/sh_x\n      shooting_g-xg_x\n      shooting_np:g-xg_x\n      keeper_sota_x\n      keeper_saves_x\n      keeper_save%_x\n      keeper_cs_x\n      keeper_psxg_x\n      keeper_psxg+/-_x\n      keeper_pkatt__x\n      keeper_pka_x\n      keeper_pksv_x\n      keeper_pkm_x\n      keeper_cmp__x\n      keeper_att__x\n      keeper_cmp%__x\n      keeper_att_.1_x\n      keeper_thr_x\n      keeper_launch%_x\n      keeper_avglen_x\n      keeper_att_.2_x\n      keeper_launch%.1_x\n      keeper_avglen.1_x\n      keeper_opp_x\n      keeper_stp_x\n      keeper_stp%_x\n      keeper_#opa_x\n      keeper_avgdist_x\n      passing_pass_complete_x\n      passing_cmp%__x\n      passing_PC_totdist__x\n      passing_PC_prgdist__x\n      passing_PC_cmp_.1_x\n      passing_cmp%_.1_x\n      passing_PC_cmp_.2_x\n      passing_cmp%_.2_x\n      passing_PC_cmp_.3_x\n      passing_cmp%_.3_x\n      passing_ast_x\n      passing_xa_x\n      passing_kp_x\n      passing_PC_1/3__x\n      passing_PC_ppa_x\n      passing_PC_crspa_x\n      passing_PC_prog__x\n      passing_PC_types_live__x\n      passing_PC_types_dead_x\n      passing_PC_types_fk__x\n      passing_PC_types_tb_x\n      passing_PC_types_press__x\n      passing_PC_types_sw_x\n      passing_PC_types_crs__x\n      passing_PC_types_ck_x\n      passing_PC_types_in_x\n      passing_PC_types_out_x\n      passing_PC_types_str_x\n      passing_PC_types_ground_x\n      passing_PC_types_low_x\n      passing_PC_types_high_x\n      passing_PC_types_left_x\n      passing_PC_types_right_x\n      passing_PC_types_head_x\n      passing_PC_types_ti_x\n      passing_PC_types_other_x\n      passing_PC_types_cmp__x\n      passing_PC_types_off__x\n      passing_PC_types_out.1_x\n      passing_PC_types_int__x\n      passing_PC_types_blocks__x\n      shotcreate_sca_x\n      shotcreate_passlive_x\n      shotcreate_passdead_x\n      shotcreate_drib_x\n      shotcreate_sh_gca_x\n      shotcreate_fld_gca_x\n      shotcreate_def_x\n      shotcreate_gca_x\n      shotcreate_passlive.1_x\n      shotcreate_passdead.1_x\n      shotcreate_drib.1_x\n      shotcreate_sh_gca.1_x\n      shotcreate_fld_gca.1_x\n      shotcreate_def.1_x\n      tackle_tkl_x\n      tackle_PC_tklw_defense_x\n      tackle_PC_def 3rd_defense_x\n      tackle_PC_mid 3rd_defense_x\n      tackle_PC_att 3rd_defense_x\n      tackle_PC_tkl_dribble_x\n      tackle_dribble%_x\n      tackle_dribllepast_x\n      tackle_press_defense_x\n      tackle_%_x\n      tackle_PC_press_def3rd_x\n      tackle_PC_press_mid3rd_x\n      tackle_PC_press_att3rd_x\n      tackle_blocks_defense_x\n      tackle_PC_sh_defense_x\n      tackle_PC_shsv_x\n      tackle_PC_pass_x\n      tackle_int_defense_x\n      tackle_clr_x\n      tackle_err_x\n      possession_poss_x\n      possession_touches_x\n      possession_PC_def pen_x\n      possession_PC_def 3rd__x\n      possession_PC_mid 3rd__x\n      possession_PC_att 3rd__x\n      possession_PC_att pen_x\n      possession_PC_live__x\n      possession_dribblesucc__x\n      possession_dribbleatt__x\n      possession_dribblesucc%_x\n      possession_dribblepast_x\n      possession_megs_x\n      possession_carries_x\n      possession_totdist__x\n      possession_PC_prgdist__x\n      possession_PC_prog__x\n      possession_PC_1/3__x\n      possession_PC_cpa_x\n      possession_PC_mis_x\n      possession_PC_dis_x\n      possession_targ_x\n      possession_rec_x\n      possession_rec%_x\n      possession_prog_.1_x\n      misc_crdy_x\n      misc_crdr_x\n      misc_2crdy_x\n      misc_fls_x\n      misc_fld__x\n      misc_off__x\n      misc_crs__x\n      misc_int__x\n      misc_tklw__x\n      misc_pkwon_x\n      misc_pkcon_x\n      misc_og_x\n      misc_recov_x\n      misc_won_x\n      misc_lost_x\n      misc_won%_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      result_y\n      gf_y\n      ga_y\n      shooting_gls_y\n      shooting_sh__y\n      shooting_sot_y\n      shooting_sot%_y\n      shooting_g/sh_y\n      shooting_g/sot_y\n      shooting_PC_dist_y\n      shooting_fk__y\n      shooting_pk_y\n      shooting_pkatt__y\n      shooting_yg_y\n      shooting_npxg_y\n      shooting_npxg/sh_y\n      shooting_g-xg_y\n      shooting_np:g-xg_y\n      keeper_sota_y\n      keeper_saves_y\n      keeper_save%_y\n      keeper_cs_y\n      keeper_psxg_y\n      keeper_psxg+/-_y\n      keeper_pkatt__y\n      keeper_pka_y\n      keeper_pksv_y\n      keeper_pkm_y\n      keeper_cmp__y\n      keeper_att__y\n      keeper_cmp%__y\n      keeper_att_.1_y\n      keeper_thr_y\n      keeper_launch%_y\n      keeper_avglen_y\n      keeper_att_.2_y\n      keeper_launch%.1_y\n      keeper_avglen.1_y\n      keeper_opp_y\n      keeper_stp_y\n      keeper_stp%_y\n      keeper_#opa_y\n      keeper_avgdist_y\n      passing_pass_complete_y\n      passing_cmp%__y\n      passing_PC_totdist__y\n      passing_PC_prgdist__y\n      passing_PC_cmp_.1_y\n      passing_cmp%_.1_y\n      passing_PC_cmp_.2_y\n      passing_cmp%_.2_y\n      passing_PC_cmp_.3_y\n      passing_cmp%_.3_y\n      passing_ast_y\n      passing_ya_y\n      passing_kp_y\n      passing_PC_1/3__y\n      passing_PC_ppa_y\n      passing_PC_crspa_y\n      passing_PC_prog__y\n      passing_PC_types_live__y\n      passing_PC_types_dead_y\n      passing_PC_types_fk__y\n      passing_PC_types_tb_y\n      passing_PC_types_press__y\n      passing_PC_types_sw_y\n      passing_PC_types_crs__y\n      passing_PC_types_ck_y\n      passing_PC_types_in_y\n      passing_PC_types_out_y\n      passing_PC_types_str_y\n      passing_PC_types_ground_y\n      passing_PC_types_low_y\n      passing_PC_types_high_y\n      passing_PC_types_left_y\n      passing_PC_types_right_y\n      passing_PC_types_head_y\n      passing_PC_types_ti_y\n      passing_PC_types_other_y\n      passing_PC_types_cmp__y\n      passing_PC_types_off__y\n      passing_PC_types_out.1_y\n      passing_PC_types_int__y\n      passing_PC_types_blocks__y\n      shotcreate_sca_y\n      shotcreate_passlive_y\n      shotcreate_passdead_y\n      shotcreate_drib_y\n      shotcreate_sh_gca_y\n      shotcreate_fld_gca_y\n      shotcreate_def_y\n      shotcreate_gca_y\n      shotcreate_passlive.1_y\n      shotcreate_passdead.1_y\n      shotcreate_drib.1_y\n      shotcreate_sh_gca.1_y\n      shotcreate_fld_gca.1_y\n      shotcreate_def.1_y\n      tackle_tkl_y\n      tackle_PC_tklw_defense_y\n      tackle_PC_def 3rd_defense_y\n      tackle_PC_mid 3rd_defense_y\n      tackle_PC_att 3rd_defense_y\n      tackle_PC_tkl_dribble_y\n      tackle_dribble%_y\n      tackle_dribllepast_y\n      tackle_press_defense_y\n      tackle_%_y\n      tackle_PC_press_def3rd_y\n      tackle_PC_press_mid3rd_y\n      tackle_PC_press_att3rd_y\n      tackle_blocks_defense_y\n      tackle_PC_sh_defense_y\n      tackle_PC_shsv_y\n      tackle_PC_pass_y\n      tackle_int_defense_y\n      tackle_clr_y\n      tackle_err_y\n      possession_poss_y\n      possession_touches_y\n      possession_PC_def pen_y\n      possession_PC_def 3rd__y\n      possession_PC_mid 3rd__y\n      possession_PC_att 3rd__y\n      possession_PC_att pen_y\n      possession_PC_live__y\n      possession_dribblesucc__y\n      possession_dribbleatt__y\n      possession_dribblesucc%_y\n      possession_dribblepast_y\n      possession_megs_y\n      possession_carries_y\n      possession_totdist__y\n      possession_PC_prgdist__y\n      possession_PC_prog__y\n      possession_PC_1/3__y\n      possession_PC_cpa_y\n      possession_PC_mis_y\n      possession_PC_dis_y\n      possession_targ_y\n      possession_rec_y\n      possession_rec%_y\n      possession_prog_.1_y\n      misc_crdy_y\n      misc_crdr_y\n      misc_2crdy_y\n      misc_fls_y\n      misc_fld__y\n      misc_off__y\n      misc_crs__y\n      misc_int__y\n      misc_tklw__y\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n    \n  \n  \n    \n      count\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n    \n    \n      unique\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      top\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      L\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      freq\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1444\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      mean\n      19.789305\n      15.910160\n      -0.003342\n      1.367870\n      1.371212\n      1.324242\n      12.318806\n      4.082620\n      33.666230\n      0.103205\n      0.295620\n      151.814870\n      0.457487\n      0.104055\n      0.131684\n      1.320134\n      1.220357\n      0.100935\n      0.004109\n      -0.000169\n      4.084715\n      2.817513\n      68.905134\n      0.285829\n      1.332852\n      0.005624\n      0.134447\n      0.104768\n      0.022103\n      0.007576\n      6.711765\n      17.383601\n      41.413993\n      24.147148\n      4.075178\n      51.061034\n      42.502959\n      7.459848\n      66.906448\n      52.437215\n      8.755080\n      0.661631\n      7.543382\n      0.649643\n      14.412273\n      390.931194\n      77.247553\n      1979.363069\n      687.824335\n      40.897515\n      86.660709\n      41.792130\n      83.940147\n      15.411750\n      57.009621\n      0.942959\n      0.897821\n      8.928030\n      7.547074\n      2.120160\n      0.545131\n      8.387274\n      89.802235\n      10.197765\n      2.484955\n      0.183265\n      15.459547\n      2.967840\n      2.486263\n      1.061565\n      0.467084\n      0.350791\n      0.082297\n      63.555635\n      14.102166\n      22.342199\n      27.469285\n      59.267074\n      4.388067\n      4.484950\n      1.347329\n      77.794521\n      0.354085\n      1.919054\n      2.424604\n      2.519446\n      19.230080\n      13.878342\n      1.687032\n      1.185428\n      0.992647\n      1.057353\n      0.429278\n      2.148217\n      1.469563\n      0.141355\n      0.147816\n      0.180793\n      0.159358\n      0.049332\n      17.782130\n      60.717652\n      50.005406\n      37.636636\n      12.357958\n      33.790802\n      36.547767\n      10.469430\n      150.873797\n      29.555771\n      34.517406\n      43.220499\n      22.262095\n      15.869519\n      23.681976\n      0.506995\n      76.318024\n      12.285829\n      25.121970\n      0.274911\n      49.998217\n      615.295811\n      11.131009\n      33.164347\n      46.679487\n      26.100825\n      3.856162\n      92.155582\n      9.629144\n      16.482531\n      58.265330\n      10.457442\n      0.714572\n      383.570811\n      1960.431774\n      53.252857\n      10.944362\n      3.339541\n      1.091207\n      3.437701\n      3.274796\n      465.705749\n      390.931194\n      82.527647\n      34.576738\n      1.634715\n      0.058289\n      0.023886\n      12.389394\n      11.971569\n      1.868182\n      12.004590\n      12.285829\n      10.759091\n      0.110116\n      0.128832\n      0.044251\n      90.116667\n      19.210250\n      19.209581\n      49.993079\n      2019.023529\n      6.763636\n      2019.533690\n      4.360963\n      NaN\n      -0.001471\n      1.368672\n      1.370143\n      1.324777\n      12.322950\n      4.084759\n      33.665749\n      0.103174\n      0.295648\n      151.783431\n      0.457888\n      0.104189\n      0.131818\n      1.320963\n      1.221092\n      0.100949\n      0.003815\n      -0.000504\n      4.081640\n      2.815374\n      68.919652\n      0.286364\n      1.331836\n      0.005677\n      0.134447\n      0.104768\n      0.022103\n      0.007576\n      6.709358\n      17.376381\n      41.415183\n      24.147549\n      4.076114\n      51.039416\n      42.493012\n      7.457843\n      66.902732\n      52.430985\n      8.752540\n      0.662701\n      7.562781\n      0.649777\n      14.412968\n      391.065285\n      77.252794\n      1979.240478\n      687.729735\n      40.898842\n      86.663770\n      41.792418\n      83.941805\n      15.409745\n      57.018378\n      0.943093\n      0.898075\n      8.930303\n      7.547489\n      2.119949\n      0.544611\n      8.387497\n      89.804963\n      10.195037\n      2.483827\n      0.183429\n      15.457410\n      2.966877\n      2.485392\n      1.061554\n      0.466670\n      0.351048\n      0.082452\n      63.562637\n      14.102245\n      22.335118\n      27.463310\n      59.275168\n      4.386860\n      4.484425\n      1.347030\n      77.799389\n      0.353852\n      1.918207\n      2.423601\n      2.519481\n      19.238102\n      13.884492\n      1.687299\n      1.185963\n      0.993182\n      1.058021\n      0.429144\n      2.149020\n      1.470766\n      0.141087\n      0.147683\n      0.180526\n      0.159759\n      0.049198\n      17.784135\n      60.719894\n      50.000323\n      37.647136\n      12.352541\n      33.783894\n      36.543182\n      10.470232\n      150.897059\n      29.560998\n      34.512083\n      43.224267\n      22.263651\n      15.867112\n      23.665236\n      0.506995\n      76.334764\n      12.288636\n      25.107932\n      0.274777\n      50.007442\n      615.434180\n      11.127372\n      33.157686\n      46.683163\n      26.103830\n      3.856597\n      92.157298\n      9.633021\n      16.488681\n      58.268097\n      10.461988\n      0.714840\n      383.703164\n      1960.965196\n      53.255401\n      10.945468\n      3.339802\n      1.091572\n      3.436512\n      3.274502\n      465.841176\n      391.065285\n      82.532513\n      34.589305\n      1.635918\n      0.058422\n      0.024020\n      12.391800\n      11.971836\n      1.866979\n      12.004055\n      12.288636\n      10.760561\n      0.110250\n      0.128832\n      0.044251\n      90.128164\n      19.211854\n      19.208779\n      49.995499\n    \n    \n      std\n      10.812190\n      9.082985\n      1.260926\n      0.808001\n      0.774004\n      0.794644\n      3.597818\n      1.608375\n      9.614793\n      0.063311\n      0.160978\n      54.846307\n      0.401409\n      0.189608\n      0.213964\n      0.539431\n      0.499269\n      0.028063\n      0.548592\n      0.545514\n      1.536609\n      1.192484\n      17.268237\n      0.271639\n      0.620853\n      0.426968\n      0.218550\n      0.189411\n      0.089500\n      0.052022\n      2.673514\n      6.831725\n      11.779479\n      5.578168\n      1.668569\n      20.032654\n      9.608195\n      2.134183\n      24.745854\n      13.899819\n      2.799294\n      0.530528\n      6.377266\n      0.567336\n      3.132228\n      119.477131\n      6.127586\n      108.661242\n      122.423021\n      3.621674\n      3.653049\n      3.620413\n      5.360235\n      2.776097\n      8.948543\n      0.660216\n      0.400746\n      2.878542\n      1.266651\n      0.599713\n      0.297163\n      1.457260\n      2.574413\n      2.574413\n      0.758481\n      0.151459\n      3.983513\n      0.780574\n      0.691667\n      0.342776\n      0.294596\n      0.231719\n      0.116260\n      9.270781\n      2.990125\n      7.202335\n      6.437151\n      7.071222\n      1.538933\n      1.257358\n      0.410721\n      6.000126\n      0.218160\n      0.703913\n      0.971685\n      0.625166\n      6.158332\n      5.057429\n      0.842449\n      0.768469\n      0.696029\n      0.600697\n      0.406695\n      1.383549\n      1.122031\n      0.214337\n      0.251428\n      0.253063\n      0.238379\n      0.133121\n      3.479814\n      7.282239\n      9.782546\n      7.986327\n      5.688972\n      8.586122\n      8.484729\n      2.904268\n      27.877080\n      3.933526\n      6.492833\n      3.781661\n      5.400574\n      3.425881\n      8.158337\n      1.101893\n      8.158337\n      4.887549\n      7.802474\n      0.332278\n      9.573898\n      112.341294\n      3.073200\n      5.869180\n      4.246802\n      4.196696\n      0.939337\n      1.639189\n      2.899335\n      4.097558\n      8.885281\n      3.039749\n      0.565743\n      109.013451\n      560.207630\n      3.728944\n      1.931172\n      0.714923\n      0.444086\n      1.165160\n      1.051011\n      119.023950\n      119.477131\n      5.138379\n      10.830988\n      0.746549\n      0.138407\n      0.089291\n      2.524250\n      2.591855\n      0.956812\n      3.444791\n      4.887549\n      2.295753\n      0.195497\n      0.211274\n      0.118976\n      11.267654\n      5.659847\n      5.813950\n      6.294121\n      1.407382\n      3.969227\n      1.520015\n      1.798241\n      NaN\n      1.262519\n      0.808628\n      0.774343\n      0.795351\n      3.597067\n      1.608762\n      9.614106\n      0.063220\n      0.160880\n      54.850292\n      0.401701\n      0.189711\n      0.214038\n      0.540175\n      0.499985\n      0.028062\n      0.548811\n      0.545793\n      1.537276\n      1.192771\n      17.264720\n      0.271814\n      0.621129\n      0.426749\n      0.218550\n      0.189411\n      0.089500\n      0.052022\n      2.672028\n      6.828191\n      11.780052\n      5.577480\n      1.669308\n      20.034401\n      9.606079\n      2.134818\n      24.737701\n      13.894690\n      2.800754\n      0.530705\n      6.392757\n      0.567242\n      3.129257\n      119.515735\n      6.128051\n      108.609872\n      122.401336\n      3.621302\n      3.653428\n      3.620178\n      5.359233\n      2.775348\n      8.950187\n      0.660886\n      0.400693\n      2.874659\n      1.266934\n      0.599507\n      0.297272\n      1.457096\n      2.574378\n      2.574378\n      0.758191\n      0.151427\n      3.984765\n      0.780327\n      0.691138\n      0.342928\n      0.294658\n      0.231838\n      0.116712\n      9.267060\n      2.989201\n      7.200972\n      6.427083\n      7.065863\n      1.538999\n      1.256937\n      0.410498\n      6.000922\n      0.218247\n      0.704214\n      0.971906\n      0.625276\n      6.153878\n      5.053910\n      0.842469\n      0.768861\n      0.697474\n      0.601022\n      0.406260\n      1.385009\n      1.123701\n      0.213889\n      0.251374\n      0.252460\n      0.238531\n      0.132919\n      3.477123\n      7.276880\n      9.780540\n      7.986417\n      5.689568\n      8.581289\n      8.469441\n      2.904276\n      27.861281\n      3.935946\n      6.495629\n      3.784094\n      5.401501\n      3.426921\n      8.160210\n      1.101893\n      8.160210\n      4.886419\n      7.791726\n      0.332288\n      9.576615\n      112.388551\n      3.076070\n      5.875037\n      4.250795\n      4.198132\n      0.939326\n      1.639047\n      2.902260\n      4.103303\n      8.886728\n      3.042843\n      0.565759\n      109.038437\n      560.266760\n      3.730208\n      1.932012\n      0.714515\n      0.443880\n      1.164719\n      1.050918\n      119.069075\n      119.515735\n      5.138246\n      10.836724\n      0.746286\n      0.138592\n      0.089629\n      2.523003\n      2.591213\n      0.956610\n      3.445064\n      4.886419\n      2.293386\n      0.195592\n      0.211274\n      0.118976\n      11.274286\n      5.658357\n      5.813577\n      6.295669\n    \n    \n      min\n      1.000000\n      1.000000\n      -5.333333\n      0.000000\n      0.000000\n      0.000000\n      3.333333\n      0.333333\n      2.766667\n      0.000000\n      0.000000\n      55.061728\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.966667\n      -1.700000\n      0.333333\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      157.000000\n      58.200000\n      1690.290290\n      421.044850\n      28.197674\n      68.133333\n      31.100478\n      63.566667\n      8.301527\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      3.724138\n      0.126263\n      0.000000\n      3.750000\n      78.957169\n      3.957997\n      0.732601\n      0.000000\n      5.770965\n      1.133948\n      0.632911\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      32.774674\n      6.373355\n      6.699548\n      12.052117\n      37.898687\n      1.231423\n      1.332795\n      0.264901\n      58.153846\n      0.000000\n      0.455581\n      0.293255\n      0.691017\n      4.666667\n      2.500000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      36.170213\n      11.627907\n      12.500000\n      0.000000\n      8.333333\n      9.166667\n      2.000000\n      66.000000\n      13.700000\n      13.606911\n      29.111842\n      8.041237\n      6.000000\n      0.000000\n      0.000000\n      45.161290\n      1.333333\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      3.639121\n      14.908854\n      33.405172\n      10.754098\n      1.246334\n      85.822785\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      41.276202\n      5.420561\n      1.097695\n      0.000000\n      0.894188\n      0.889193\n      219.333333\n      157.000000\n      61.866667\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      -5.333333\n      0.000000\n      0.000000\n      0.000000\n      3.333333\n      0.333333\n      2.766667\n      0.000000\n      0.000000\n      55.061728\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.966667\n      -1.700000\n      0.333333\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      157.000000\n      58.200000\n      1690.290290\n      421.044850\n      28.197674\n      68.133333\n      31.100478\n      63.566667\n      8.301527\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      3.724138\n      0.126263\n      0.000000\n      3.750000\n      78.957169\n      3.957997\n      0.732601\n      0.000000\n      5.770965\n      1.133948\n      0.632911\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      32.774674\n      6.373355\n      6.699548\n      12.052117\n      37.898687\n      1.231423\n      1.332795\n      0.264901\n      58.153846\n      0.000000\n      0.455581\n      0.293255\n      0.691017\n      4.666667\n      2.500000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      36.170213\n      11.627907\n      12.500000\n      0.000000\n      8.333333\n      9.166667\n      2.000000\n      66.000000\n      13.700000\n      13.606911\n      29.111842\n      8.041237\n      6.000000\n      0.000000\n      0.000000\n      45.161290\n      1.333333\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      3.639121\n      14.908854\n      33.405172\n      10.754098\n      1.246334\n      85.822785\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      41.276202\n      5.420561\n      1.097695\n      0.000000\n      0.894188\n      0.889193\n      219.333333\n      157.000000\n      61.866667\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n    \n    \n      25%\n      10.000000\n      8.000000\n      -1.000000\n      0.666667\n      0.666667\n      0.666667\n      9.666667\n      3.000000\n      27.200000\n      0.060000\n      0.176667\n      114.758929\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.258333\n      20.333333\n      3.000000\n      34.625000\n      34.666667\n      6.000000\n      48.000000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      73.000000\n      1904.671024\n      597.184442\n      38.330073\n      84.366667\n      39.180032\n      80.466667\n      13.442505\n      50.300000\n      0.333333\n      0.600000\n      7.000000\n      6.676949\n      1.706103\n      0.329083\n      7.358874\n      88.052077\n      8.321893\n      1.936060\n      0.073233\n      12.539702\n      2.435745\n      1.990478\n      0.825466\n      0.251375\n      0.176815\n      0.000000\n      57.131288\n      12.020757\n      16.761444\n      22.619711\n      54.337558\n      3.223610\n      3.572207\n      1.058524\n      73.703910\n      0.198840\n      1.395349\n      1.681482\n      2.083333\n      15.000000\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      55.769231\n      43.181818\n      32.142857\n      8.333333\n      27.906977\n      30.633333\n      8.333333\n      131.000000\n      26.925000\n      30.194872\n      40.625000\n      18.408045\n      13.333333\n      17.987179\n      0.000000\n      70.833333\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      8.961050\n      29.345463\n      43.868450\n      23.254724\n      3.223858\n      91.025962\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      50.769548\n      9.595724\n      2.845528\n      0.782841\n      2.597991\n      2.543108\n      377.333333\n      302.000000\n      79.166667\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.250000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.933333\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      -1.000000\n      0.666667\n      0.666667\n      0.666667\n      9.666667\n      3.000000\n      27.200000\n      0.060000\n      0.176667\n      114.708333\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.233333\n      20.333333\n      3.000000\n      34.625000\n      34.666667\n      6.000000\n      48.000000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      73.000000\n      1904.671024\n      597.103658\n      38.327718\n      84.366667\n      39.180032\n      80.466667\n      13.441365\n      50.325000\n      0.333333\n      0.600000\n      7.000000\n      6.676949\n      1.706103\n      0.328192\n      7.358874\n      88.054636\n      8.307964\n      1.935807\n      0.073300\n      12.535171\n      2.435630\n      1.990167\n      0.824997\n      0.250117\n      0.176815\n      0.000000\n      57.140011\n      12.020757\n      16.756203\n      22.619711\n      54.346396\n      3.221214\n      3.573929\n      1.058127\n      73.710308\n      0.198282\n      1.394568\n      1.681230\n      2.083333\n      15.000000\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      55.769231\n      43.181818\n      32.142857\n      8.333333\n      27.906977\n      30.633333\n      8.333333\n      131.000000\n      26.933333\n      30.183981\n      40.625000\n      18.408045\n      13.333333\n      17.948718\n      0.000000\n      70.909091\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.916667\n      8.957279\n      29.333138\n      43.868450\n      23.260019\n      3.225334\n      91.027006\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.583333\n      50.772488\n      9.595724\n      2.845528\n      0.783429\n      2.597186\n      2.543108\n      377.333333\n      302.000000\n      79.166667\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.933333\n    \n    \n      50%\n      20.000000\n      16.000000\n      0.000000\n      1.333333\n      1.333333\n      1.333333\n      12.000000\n      4.000000\n      33.266667\n      0.096667\n      0.276667\n      141.126984\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.666667\n      40.133333\n      23.666667\n      4.000000\n      51.233333\n      41.983333\n      7.333333\n      70.883333\n      53.866667\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.666667\n      77.533333\n      1973.385792\n      674.276172\n      40.893394\n      87.033333\n      41.918119\n      84.733333\n      15.218688\n      56.616667\n      1.000000\n      0.833333\n      8.666667\n      7.505258\n      2.080172\n      0.499085\n      8.344460\n      89.793788\n      10.206212\n      2.440634\n      0.155159\n      15.109299\n      2.891967\n      2.444716\n      1.030131\n      0.415153\n      0.326624\n      0.052673\n      64.038769\n      13.965784\n      21.682644\n      27.017143\n      59.389146\n      4.180029\n      4.393993\n      1.312780\n      78.137796\n      0.312337\n      1.835510\n      2.419147\n      2.476006\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      60.606061\n      50.000000\n      37.500000\n      11.764706\n      33.333333\n      36.333333\n      10.333333\n      148.666667\n      29.500000\n      34.422759\n      43.166562\n      21.661238\n      16.000000\n      23.076923\n      0.000000\n      76.923077\n      12.333333\n      24.333333\n      0.333333\n      49.333333\n      598.000000\n      10.956981\n      33.231956\n      46.543912\n      25.917296\n      3.799952\n      92.101589\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1888.333333\n      53.271144\n      10.804122\n      3.312019\n      1.046910\n      3.311880\n      3.151388\n      447.000000\n      369.666667\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.866667\n      2019.000000\n      7.000000\n      2020.000000\n      5.000000\n      NaN\n      0.000000\n      1.333333\n      1.333333\n      1.333333\n      12.000000\n      4.000000\n      33.266667\n      0.096667\n      0.276667\n      141.096096\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.500000\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      70.833333\n      53.866667\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.666667\n      77.533333\n      1973.299213\n      674.203472\n      40.902674\n      87.033333\n      41.918119\n      84.733333\n      15.216435\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      7.505258\n      2.080172\n      0.499002\n      8.344641\n      89.807127\n      10.192873\n      2.438150\n      0.155280\n      15.107914\n      2.891076\n      2.442379\n      1.030131\n      0.414938\n      0.326731\n      0.052673\n      64.054440\n      13.965784\n      21.676691\n      27.017143\n      59.397669\n      4.179519\n      4.393352\n      1.312062\n      78.145767\n      0.312215\n      1.833579\n      2.418674\n      2.476006\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      60.606061\n      50.000000\n      37.500000\n      11.764706\n      33.333333\n      36.333333\n      10.333333\n      148.666667\n      29.500000\n      34.416938\n      43.190925\n      21.661853\n      16.000000\n      23.076923\n      0.000000\n      76.923077\n      12.333333\n      24.333333\n      0.333333\n      49.333333\n      598.166667\n      10.955386\n      33.229361\n      46.543912\n      25.917765\n      3.800716\n      92.104505\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      53.272788\n      10.807099\n      3.312348\n      1.047120\n      3.311526\n      3.150893\n      447.000000\n      369.666667\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.866667\n    \n    \n      75%\n      29.000000\n      23.000000\n      0.666667\n      1.666667\n      2.000000\n      1.666667\n      14.333333\n      5.000000\n      39.833333\n      0.136667\n      0.400000\n      174.814815\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.600000\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.800000\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      462.666667\n      81.866667\n      2046.497928\n      761.944411\n      43.321740\n      89.300000\n      44.501404\n      88.008333\n      17.192269\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      8.377245\n      2.488849\n      0.704380\n      9.353610\n      91.678107\n      11.947923\n      2.967121\n      0.259875\n      18.066159\n      3.434564\n      2.904000\n      1.275412\n      0.628931\n      0.495488\n      0.121175\n      70.360031\n      16.085472\n      27.074844\n      31.353094\n      64.326950\n      5.348022\n      5.296737\n      1.594533\n      82.279813\n      0.464769\n      2.369317\n      3.088833\n      2.916504\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      65.724070\n      56.818182\n      43.083554\n      15.733083\n      39.404609\n      42.108333\n      12.333333\n      168.083333\n      32.166667\n      38.637570\n      45.792658\n      25.485027\n      18.000000\n      29.166667\n      0.000000\n      82.012821\n      15.666667\n      29.666667\n      0.333333\n      56.666667\n      684.416667\n      13.116066\n      37.014643\n      49.525891\n      28.669936\n      4.423012\n      93.340426\n      11.333333\n      19.000000\n      64.233333\n      12.333333\n      1.000000\n      450.541667\n      2321.083333\n      55.817291\n      12.157871\n      3.783117\n      1.351732\n      4.127864\n      3.906409\n      537.666667\n      462.666667\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      0.666667\n      1.666667\n      2.000000\n      1.666667\n      14.333333\n      5.000000\n      39.833333\n      0.136667\n      0.400000\n      174.685847\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.600000\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.600000\n      49.866667\n      9.000000\n      88.900000\n      63.800000\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      81.875000\n      2046.262466\n      761.837938\n      43.322443\n      89.300000\n      44.500754\n      88.008333\n      17.189260\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      8.378284\n      2.488688\n      0.704225\n      9.352675\n      91.692036\n      11.945364\n      2.965807\n      0.259898\n      18.066159\n      3.433541\n      2.902260\n      1.275691\n      0.628931\n      0.496003\n      0.121230\n      70.360031\n      16.080614\n      27.056263\n      31.353094\n      64.338108\n      5.347347\n      5.295715\n      1.594285\n      82.292768\n      0.464563\n      2.369200\n      3.087634\n      2.916504\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      65.714286\n      56.756757\n      43.103448\n      15.733083\n      39.393939\n      42.100000\n      12.333333\n      168.083333\n      32.166667\n      38.637570\n      45.795794\n      25.485027\n      18.000000\n      29.090909\n      0.000000\n      82.051282\n      15.666667\n      29.666667\n      0.333333\n      56.666667\n      684.750000\n      13.116066\n      37.014643\n      49.526726\n      28.669936\n      4.423812\n      93.342347\n      11.333333\n      19.000000\n      64.233333\n      12.333333\n      1.000000\n      450.666667\n      2322.416667\n      55.825288\n      12.158055\n      3.783784\n      1.351732\n      4.125392\n      3.905096\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n    \n    \n      max\n      38.000000\n      31.000000\n      5.333333\n      5.666667\n      5.666667\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      708.000000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      18.666667\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      91.066667\n      2398.063380\n      1296.830986\n      54.207263\n      95.100000\n      52.490660\n      94.633333\n      25.879917\n      83.633333\n      5.000000\n      2.833333\n      21.666667\n      13.935970\n      4.793757\n      2.348066\n      14.285714\n      96.042003\n      21.042831\n      5.673759\n      1.083032\n      30.942092\n      6.671900\n      5.632716\n      2.524698\n      2.195390\n      1.541002\n      0.920680\n      84.874640\n      26.916376\n      47.310513\n      49.404117\n      78.316327\n      11.080836\n      10.986965\n      3.247863\n      91.125642\n      2.006689\n      5.189189\n      6.269113\n      4.973822\n      46.333333\n      38.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      91.666667\n      79.487179\n      62.790698\n      42.857143\n      71.428571\n      66.266667\n      25.333333\n      268.333333\n      45.566667\n      58.685446\n      56.675063\n      48.812095\n      30.666667\n      54.838710\n      7.894737\n      100.000000\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      25.899281\n      55.932203\n      63.639323\n      44.711111\n      8.444444\n      96.594982\n      24.333333\n      36.333333\n      87.166667\n      25.666667\n      4.666667\n      746.333333\n      4209.000000\n      64.982456\n      18.909306\n      6.168549\n      3.206651\n      9.473684\n      9.362280\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      1.000000\n      0.666667\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      5.333333\n      5.666667\n      5.666667\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      708.000000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      18.666667\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      91.066667\n      2398.063380\n      1296.830986\n      54.207263\n      95.100000\n      52.490660\n      94.633333\n      25.879917\n      83.633333\n      5.000000\n      2.833333\n      21.666667\n      13.935970\n      4.793757\n      2.348066\n      14.285714\n      96.042003\n      21.042831\n      5.673759\n      1.083032\n      30.942092\n      6.671900\n      5.632716\n      2.524698\n      2.195390\n      1.541002\n      0.920680\n      84.874640\n      26.916376\n      47.310513\n      49.404117\n      78.316327\n      11.080836\n      10.986965\n      3.247863\n      91.125642\n      2.006689\n      5.189189\n      6.269113\n      4.973822\n      46.333333\n      38.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      91.666667\n      79.487179\n      62.790698\n      42.857143\n      71.428571\n      66.266667\n      25.333333\n      268.333333\n      45.566667\n      58.685446\n      56.675063\n      48.812095\n      30.666667\n      54.838710\n      7.894737\n      100.000000\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      25.899281\n      55.932203\n      63.639323\n      44.711111\n      8.444444\n      96.594982\n      24.333333\n      36.333333\n      87.166667\n      25.666667\n      4.666667\n      746.333333\n      4209.000000\n      64.982456\n      18.909306\n      6.168549\n      3.206651\n      9.473684\n      9.362280\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      1.000000\n      0.666667\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n    \n  \n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom dtreeviz.trees import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\n\nfrom sklearn.experimental import enable_halving_search_cv  # noqa\nfrom sklearn.model_selection import HalvingRandomSearchCV\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\n\nimport copy\n\nfrom xgboost import XGBClassifier\n\n\nTrain / Valid split\nIn this case valid is actually test as train will be split by fits into train and valid\n\nimport copy\ndf=copy.copy(dfAll)\n\n## if want to do randomly\n# sza=np.shape(df)[0]\n# randAr=np.random.randint(0,100, size=sza)\n# cond = randAr>=15\n\ncond = df.season<2021\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\n\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/len(df)\n\n0.20267379679144384\n\n\n\n\ndf=df.drop(columns=['NetScore_x','venue_x','opponent_y','team_y','GoalsAgainst_x','GoalsFor_x'])\n\n\nwant_binary=0\nif want_binary==1:\n    df.loc[df['Win_x']=='D','Win_x']='L'\n\n\n\nCreate tabular pandas & x and y values\n\ndep_var='Win_x'\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\ncat\n\n['opponent_x', 'team_x']\n\n\n\n\ndf=df.dropna()\ndf[\"opponent_x\"] = df[\"opponent_x\"].astype(\"category\").cat.codes\ndf[\"team_x\"] = df[\"team_x\"].astype(\"category\").cat.codes\n\ntrain=df.loc[cond].copy()\nvalid=df.loc[~cond].copy()\n\nlen(valid)/len(df),(len(train)+len(valid))/len(df)\n\ntarget = 'Win_x'\npredictors = [x for x in train.columns if x != 'Win_x']\n\n\nxs = train[predictors]\nvalid_xs = valid[predictors]\n\ny = train[target]\nvalid_y = valid[target]"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#fit-the-data",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#fit-the-data",
    "title": "ThomasHSimm",
    "section": "Fit the data",
    "text": "Fit the data\n\nclf=RandomForestClassifier(random_state=42)\nclf.fit(xs,y)\n\nRandomForestClassifier(random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(random_state=42)\n\n\n\nclf.score(xs,y),clf.score(valid_xs,valid_y)\n\n(1.0, 0.521108179419525)\n\n\n\npred=clf.predict(valid_xs)\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      3\n      92\n      81\n    \n    \n      L\n      5\n      199\n      87\n    \n    \n      W\n      4\n      94\n      193\n    \n  \n\n\n\n\n\n#collapse-output\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n# pred=rf.predict(train)\n# pred_valid=best_random.predict(valid_xs)\nfi = rf_feat_importance(clf, xs)\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,25), legend=False,fontsize=12)\n\nplot_fi(fi[:50]);\n\n\n\n\n\nlen(fi[fi['imp']>0.0042])\n\n37\n\n\n\ncol_use = fi[fi['imp']>0.0042].cols.values\n\n\n# xs,y = to.train.xs,to.train.y\n# valid_xs,valid_y = to.valid.xs,to.valid.y\n\ndef do_fit_red_col(xs,valid_xs,y,valid_y,col_use,class_weight=None):\n    xs_imp= xs[col_use]\n    valid_xs_imp =valid_xs[col_use]\n    clf_imp=RandomForestClassifier(random_state=42,class_weight=class_weight)\n    clf_imp.fit(xs_imp,y)\n    \n    print('Number of parameters = ',len(col_use))\n    print('Accuracy scores of train {:.3f} and validation {:.3f} sets'.format(\\\n    clf_imp.score(xs_imp,y),clf_imp.score(valid_xs_imp,valid_y)))\n    \n    return clf_imp\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use)\npred=clf.predict(valid_xs[col_use])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\n\nNumber of parameters =  37\nAccuracy scores of train 1.000 and validation 0.479 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      11\n      91\n      74\n    \n    \n      L\n      15\n      183\n      93\n    \n    \n      W\n      16\n      106\n      169\n    \n  \n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nNumber of parameters =  4\nAccuracy scores of train 0.994 and validation 0.484 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      31\n      73\n      72\n    \n    \n      L\n      42\n      171\n      78\n    \n    \n      W\n      40\n      86\n      165\n    \n  \n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,'balanced')\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nNumber of parameters =  4\nAccuracy scores of train 0.994 and validation 0.479 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      31\n      71\n      74\n    \n    \n      L\n      44\n      165\n      82\n    \n    \n      W\n      41\n      83\n      167\n    \n  \n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nNumber of parameters =  41\nAccuracy scores of train 1.000 and validation 0.468 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      7\n      88\n      81\n    \n    \n      L\n      18\n      177\n      96\n    \n    \n      W\n      8\n      112\n      171\n    \n  \n\n\n\n\n\nmatchesC=pd.read_csv(folda+'epl2017-2021_wivnetscore.csv')\n\nX=matchesC.corr()\nval =[ i for i,x in enumerate(X.columns) if x=='NetScore_x'][0]\n\ncorrnetscore=X.iloc[:,val:val+1].sort_values(by=\"NetScore_x\").reset_index()\ncorrnetscore=corrnetscore.rename(columns={'index':'category'})\ncorrnetscore\n\n\n\n\n\n  \n    \n      \n      category\n      NetScore_x\n    \n  \n  \n    \n      0\n      NetScore_y\n      -1.000000\n    \n    \n      1\n      ground_y\n      -0.264919\n    \n    \n      2\n      cmp_passing.2_y\n      -0.264773\n    \n    \n      3\n      cmp_passing_y\n      -0.263268\n    \n    \n      4\n      rec_y\n      -0.263268\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      336\n      att_passing_x\n      0.307719\n    \n    \n      337\n      carries_x\n      0.307754\n    \n    \n      338\n      live_passing_types_x\n      0.307866\n    \n    \n      339\n      mid 3rd_possession_x\n      0.309859\n    \n    \n      340\n      NetScore_x\n      1.000000\n    \n  \n\n341 rows × 2 columns\n\n\n\n\nXuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='x') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.26) )]]\n# Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') & ( abs(corrnetscore.loc[x,'NetScore_x'])>0.24) )]]\n\n# Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])>0.27) )]]\n\nXuse=list(Xuse[-20:-1].category.values)\nXuse\n\n\n['att_passing.1_x',\n '1/3_passing_x',\n 'prgdist_possession_x',\n 'ground_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'totdist_passing_x',\n 'touches_x',\n 'cmp_passing_types_x',\n 'cmp_passing_x',\n 'rec_x',\n 'targ_x',\n 'live_possession_x',\n 'prog_possession_x',\n 'att_passing_types_x',\n 'att_passing_x',\n 'carries_x',\n 'live_passing_types_x',\n 'mid 3rd_possession_x']\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[predictors_.append(x) for x in Xuse]\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,'balanced')\n\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nNumber of parameters =  23\nAccuracy scores of train 1.000 and validation 0.485 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      18\n      101\n      57\n    \n    \n      L\n      12\n      203\n      76\n    \n    \n      W\n      13\n      131\n      147\n    \n  \n\n\n\n\n\nxAll=pd.concat([valid_xs[predictors_]])\npred=clf.predict(xAll)\n\npc_draw = 100*len(pred[pred=='D'])/len(pred)\n\npc_win = 100*len(pred[pred=='W'])/len(pred)\n\npc_loss = 100*len(pred[pred=='L'])/len(pred)\n\n\nprint(\"Percentage draw {:.1f}%, win {:.1f}% and loss {:.1f}%\".format( pc_draw,pc_win,pc_loss) )\n\n\n\nPercentage draw 5.7%, win 36.9% and loss 57.4%\n\n\n\npc_draw = 100*len(df[df['Win_x']=='D'])/len(df)\n\npc_win = 100*len(df[df['Win_x']=='W'])/len(df)\n\npc_loss = 100*len(df[df['Win_x']=='L'])/len(df)\n\n\nprint(\"Percentage draw {:.1f}%, win {:.1f}% and loss {:.1f}%\".format( pc_draw,pc_win,pc_loss) )\n\n\n\nPercentage draw 22.8%, win 38.6% and loss 38.6%\n\n\n\ncol_use = fi[fi['imp']>0.004].cols.values\nXX=[1, 10, 100, 1e3, 1e6, 1e9,1e30]\nfor Draw_weght in XX:\n    print(Draw_weght)\n    clf=do_fit_red_col(xs,valid_xs,y,valid_y, col_use,{'D':Draw_weght,'L':1,'W':1})\n    pred=clf.predict(valid_xs[col_use])\n    crosstab=pd.crosstab(index = valid_y, columns = pred)\n    ratio_draw_good=100*crosstab.iloc[0,0]/sum(crosstab.iloc[0,:])\n    print('weight draw = {}, how many draws predicted {:.1f}%'.format(Draw_weght,ratio_draw_good))\n    \n\n\n1\nNumber of parameters =  54\nAccuracy scores of train 1.000 and validation 0.480 sets\nweight draw = 1, how many draws predicted 2.8%\n10\nNumber of parameters =  54\nAccuracy scores of train 1.000 and validation 0.496 sets\nweight draw = 10, how many draws predicted 6.2%\n100\nNumber of parameters =  54\nAccuracy scores of train 1.000 and validation 0.482 sets\nweight draw = 100, how many draws predicted 4.0%\n1000.0\nNumber of parameters =  54\nAccuracy scores of train 1.000 and validation 0.474 sets\nweight draw = 1000.0, how many draws predicted 5.7%\n1000000.0\nNumber of parameters =  54\nAccuracy scores of train 1.000 and validation 0.479 sets\nweight draw = 1000000.0, how many draws predicted 4.5%\n1000000000.0\nNumber of parameters =  54\nAccuracy scores of train 1.000 and validation 0.503 sets\nweight draw = 1000000000.0, how many draws predicted 6.2%\n1e+30\nNumber of parameters =  54\nAccuracy scores of train 0.227 and validation 0.232 sets\nweight draw = 1e+30, how many draws predicted 100.0%\n\n\n\nImprove the results from hyper-parameters\nHalvingRandomSearchCV, RandomizedSearchCV and GridSearchCV can be used to search for the best hyperparameters.\nThe random ones don’t go through all the options, but pick combinations randomly. So they will be quicker but may not get the best result. You may want to do the random ones to get a rough idea of parameters followed by grid search on a reduced range.\nThe most important arguments are\n\ncv which is the number of folds to use for cross validation (we use the default values for cv of 5).\nfactor the halving parameter (2 is used)\n(or n_iter for RandomizedSearchCV, which controls the number of different combinations to try)\n\nMore iterations or lower factor will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time.\n\nn_estimators=[20,50,150,400,700]\n\n# Number of features to consider at every split\nmax_features = ['log2','sqrt',None]\n\n# Maximum number of levels in tree\nmax_depth=[10,  30,  70,  200, None]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [1.,2, 10,50]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,10]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Weights associated with classes \nclass_weight=[\"balanced\", \"balanced_subsample\",None]\n\n#Complexity parameter used for Minimal Cost-Complexity Pruning.\nccp_alpha=[0., 0.1, 0.5]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap,\n               'class_weight':class_weight,\n               'ccp_alpha' : ccp_alpha\n\n              }\n\nclf = RandomForestClassifier()\n\nrsh = HalvingRandomSearchCV(estimator = clf, param_distributions = random_grid, \\\n                              random_state=42, factor = 2)# Fit the random search model\nrsh.fit(xs, y)\n\nHalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=2,\n                      param_distributions={'bootstrap': [True, False],\n                                           'ccp_alpha': [0.0, 0.1, 0.5],\n                                           'class_weight': ['balanced',\n                                                            'balanced_subsample',\n                                                            None],\n                                           'max_depth': [10, 30, 70, 200, None],\n                                           'max_features': ['log2', 'sqrt',\n                                                            None],\n                                           'min_samples_leaf': [1, 2, 4, 10],\n                                           'min_samples_split': [1.0, 2, 10,\n                                                                 50],\n                                           'n_estimators': [20, 50, 150, 400,\n                                                            700]},\n                      random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.HalvingRandomSearchCVHalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=2,\n                      param_distributions={'bootstrap': [True, False],\n                                           'ccp_alpha': [0.0, 0.1, 0.5],\n                                           'class_weight': ['balanced',\n                                                            'balanced_subsample',\n                                                            None],\n                                           'max_depth': [10, 30, 70, 200, None],\n                                           'max_features': ['log2', 'sqrt',\n                                                            None],\n                                           'min_samples_leaf': [1, 2, 4, 10],\n                                           'min_samples_split': [1.0, 2, 10,\n                                                                 50],\n                                           'n_estimators': [20, 50, 150, 400,\n                                                            700]},\n                      random_state=42)estimator: RandomForestClassifierRandomForestClassifier()RandomForestClassifierRandomForestClassifier()\n\n\n\nrsh_best = rsh.best_estimator_\nprint(rsh_best)\n\nprint('Accuracy scores of train {:.3f} and validation {:.3f} sets'.format(\\\nrsh_best.score(xs,y),rsh_best.score(valid_xs,valid_y)))\n\npred=rsh_best.predict(valid_xs)\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\n\n\n    \ncrosstab\n\nRandomForestClassifier(class_weight='balanced', max_depth=200,\n                       max_features='log2', min_samples_leaf=4,\n                       n_estimators=700)\nAccuracy scores of train 0.981 and validation 0.522 sets\n\n\n\n\n\n\n  \n    \n      col_0\n      D\n      L\n      W\n    \n    \n      Win_x\n      \n      \n      \n    \n  \n  \n    \n      D\n      7\n      85\n      84\n    \n    \n      L\n      7\n      196\n      88\n    \n    \n      W\n      7\n      91\n      193\n    \n  \n\n\n\n\n\n(85+7 +196+7 +193)/len(valid_xs)\n\n0.6437994722955145\n\n\n\nresults = pd.DataFrame(rsh.cv_results_)\nresults[\"params_str\"] = results.params.apply(str)\nresults.drop_duplicates(subset=(\"params_str\", \"iter\"), inplace=True)\nmean_scores = results.pivot(\n    index=\"iter\", columns=\"params_str\", values=\"mean_test_score\"\n)\nax = mean_scores.plot(legend=False, alpha=0.6)\n\nlabels = [\n    f\"iter={i}\\nn_samples={rsh.n_resources_[i]}\\nn_candidates={rsh.n_candidates_[i]}\"\n    for i in range(rsh.n_iterations_)\n]\n\nax.set_xticks(range(rsh.n_iterations_))\nax.set_xticklabels(labels, rotation=45, multialignment=\"left\")\nax.set_title(\"Scores of candidates over iterations\")\nax.set_ylabel(\"mean test score\", fontsize=15)\nax.set_xlabel(\"iterations\", fontsize=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# xs = train[predictors]\n# valid_xs = valid[predictors]\n\n# y = train[target]\n# valid_y = valid[target]\n\n20      D\n22      L\n23      W\n24      W\n25      L\n       ..\n3035    L\n3036    L\n3037    L\n3038    L\n3039    W\nName: Win_x, Length: 3002, dtype: object\n\n\n\n\ndef doLWD(yy):\n    if yy=='W':\n        return 2\n    elif yy=='D':\n        return 1\n    elif yy=='L':\n        return 0\ny=y2.copy()\nvalid_y=valid_y2.copy()\n\ny= y2.apply(doLWD)\nvalid_y= valid_y2.apply(doLWD)\n\n\nrandom_grid = {'n_estimators': [50,100, 500, 1_000],\n               'max_depth': [2, 4, 6, 8]\n              }\n\n\npredictors_=[]\n[predictors_.append(x) for x in xs]\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)\n\npred=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab\n\nfrom sklearn.metrics import f1_score\n\nclf = XGBClassifier(n_estimators=500,max_depth=8,learning_rate=0.01)\nclf.fit(xs, y,sample_weight=classes_weights)\n# pred=clf.predict(valid_xs)\n# prec=precision_score(valid_y,pred,average='binary')\n\n# f1=f1_score(valid_y,pred)\n\nprint(clf.score(xs,y), clf.score(valid_xs,valid_y))#,f1)\n\n\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\ncrosstab.columns.names=['predict']\ncrosstab.index.names=['actual']\ncrosstab\n# \n\nNumber of parameters =  326\nAccuracy scores of train 1.000 and validation 0.521 sets\n\n\nNameError: name 'classes_weights' is not defined\n\n\n\nprecision_score(valid_y,clf.predict(valid_xs),pos_label=1,average='binary')\n\n# crosstab.iloc[1,1]/(crosstab.iloc[1,1]+crosstab.iloc[0,1])\n\n0.375\n\n\n\ny2\n\n20      1\n22      0\n23      0\n24      0\n25      0\n       ..\n3035    0\n3036    0\n3037    0\n3038    0\n3039    0\nName: Win_x, Length: 3002, dtype: int64\n\n\n\n# https://datascience.stackexchange.com/questions/16342/unbalanced-multiclass-data-with-xgboost\nfrom sklearn.utils import class_weight\nclasses_weights = class_weight.compute_sample_weight(\n    class_weight='balanced',\n    y=y\n)\n\n\ndef f1_eval(y_pred, dtrain):\n    y_true = dtrain.get_label()\n    err = 1-f1_score(y_true, np.round(y_pred))\n    return 'f1_err', err\n\ndef doXGB(n,md):\n    clf = XGBClassifier(n_estimators=n, max_depth=md,learning_rate=0.01,eval_metric=f1_eval)\n    clf.fit(xs, y,sample_weight=classes_weights)\n    score_train = clf.score(xs,y)\n    score_valid = clf.score(valid_xs,valid_y)\n#     pred=clf.predict(valid_xs)\n    prec=precision_score(valid_y,clf.predict(valid_xs),pos_label=1,average='binary')\n    f1=f1_score(valid_y,clf.predict(valid_xs))\n    \n    return [score_train, score_valid,prec,f1]\n\nres_xgb = np.zeros([len(random_grid['n_estimators'])*len(random_grid['max_depth']),6])\ni=0\nfor md_vals in random_grid['max_depth']:\n    for n_vals in random_grid['n_estimators']:\n        res_xgb[i,0]=n_vals\n        res_xgb[i,1]=md_vals\n        print('---')\n        print(n_vals,md_vals)\n        res_xgb[i,2:]=doXGB(n_vals,md_vals)\n        print(res_xgb[i,2:])\n        i=i+1\n\n---\n50 2\n[0.42638241 0.39313984 0.23992674 0.36288089]\n---\n100 2\n[0.5176549  0.46306069 0.23076923 0.32727273]\n---\n500 2\n[0.6479014  0.62269129 0.28174603 0.3317757 ]\n---\n1000 2\n[0.72251832 0.63588391 0.2706422  0.29949239]\n---\n50 4\n[0.57594937 0.47757256 0.24418605 0.34653465]\n---\n100 4\n[0.63291139 0.57124011 0.27076923 0.35129741]\n---\n500 4\n[0.87308461 0.676781   0.2745098  0.25531915]\n---\n1000 4\n[0.94703531 0.68997361 0.25619835 0.20875421]\n---\n50 6\n[0.71652232 0.54485488 0.26462396 0.35514019]\n---\n100 6\n[0.77948035 0.56332454 0.26586103 0.34714004]\n---\n500 6\n[0.97401732 0.69656992 0.26315789 0.20689655]\n---\n1000 6\n[0.99766822 0.72823219 0.29166667 0.16935484]\n---\n50 8\n[0.84943371 0.5883905  0.24814815 0.30044843]\n---\n100 8\n[0.88041306 0.64116095 0.28378378 0.31658291]\n---\n500 8\n[0.99766822 0.72955145 0.22641509 0.10480349]\n---\n1000 8\n[1.         0.76253298 0.375      0.0625    ]\n\n\n\nplt.plot(res_xgb[:,0],res_xgb[:,-1],'o')\n\n\n\n\n\nclf = XGBClassifier(n_estimators=500, max_depth=4,num_class=2,eval_metric ='logloss',\n                    learning_rate=0.01,objective='binary:logisticrob')\n\nfrom sklearn.utils import class_weight\nclasses_weights = class_weight.compute_sample_weight(\n    class_weight='balanced',\n    y=y\n)\n\nclf.fit(xs, y,sample_weight=classes_weights)\n    \npred=clf.predict(valid_xs)\ncrosstab=pd.crosstab(index = valid_y, columns = pred)\n    \ncrosstab\n# from sklearn.metrics import balanced_accuracy_score\n# balanced_accuracy_score(valid_y,pred)\n\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['D' 'L' 'W']\n\n\n\nclf.score(valid_xs, valid_y),(crosstab.iloc[0,0]+crosstab.iloc[1,1]+crosstab.iloc[2,2])/len(valid_y)\n# [x==max(x) for x in clf.predict_proba(valid_xs)]\n\n(0.4630606860158311, 0.4630606860158311)"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#try-with-a-binary-question-does-the-team-win",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#try-with-a-binary-question-does-the-team-win",
    "title": "ThomasHSimm",
    "section": "Try with a binary question: Does the team win?",
    "text": "Try with a binary question: Does the team win?\nModel seems poor at predicting draws- none are predicted\nAnd poor at losses- 50:50 on those\nBecause of this lets change the question to a binary one\n\ny2=y.copy()\nvalid_y2=valid_y.copy()\n\nwant_binary=1\nif want_binary==1:\n    y2[y=='D']='L'\n    valid_y2[valid_y=='D']='L'\n    \n\ny2[y2=='L']=0\ny2[y2=='W']=1\n\ny2=y2.astype('int')\n\nvalid_y2[valid_y2=='L']=0\nvalid_y2[valid_y2=='W']=1\n\nvalid_y2=valid_y2.astype('int')\n\n\ncol_use = xs.columns\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, col_use)\npred_class_RF=clf.predict(valid_xs[col_use])\nprint('Length of predictors is: ',len(col_use))\n\n\ncrosstab=pd.crosstab(index = valid_y, columns = pred_class_RF)\ncrosstab\n\nNumber of parameters =  340\nAccuracy scores of train 1.000 and validation 0.669 sets\nLength of predictors is:  340\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      D\n      143\n      33\n    \n    \n      L\n      257\n      34\n    \n    \n      W\n      184\n      107\n    \n  \n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)\npred_class_RF_basic4=clf.predict(valid_xs[predictors_])\ncrosstab=pd.crosstab(index = valid_y2, columns = pred_class_RF_basic4)\nprint('Length of predictors is: ',len(predictors_))\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y2, pred_class_RF_basic4),precision_score(valid_y2, pred_class_RF_basic4) ) )\n\ncrosstab\n\nNumber of parameters =  4\nAccuracy scores of train 0.995 and validation 0.656 sets\nLength of predictors is:  4\nThe accuracy 0.656 and precision 0.560 of the validation data\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      358\n      109\n    \n    \n      1\n      152\n      139\n    \n  \n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, xs.columns)\nfi = rf_feat_importance(clf, xs)\ncol_use = fi[fi['imp']>0.0042].cols.values\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, col_use)\npred_class_RF_imp=clf.predict(valid_xs[col_use])\nprint('Length of predictors is: ',len(col_use))\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y2, pred_class_RF_imp),precision_score(valid_y2, pred_class_RF_imp) ) )\n\ncrosstab=pd.crosstab(index = valid_y2, columns = pred_class_RF_imp)\ncrosstab\n\nNumber of parameters =  340\nAccuracy scores of train 1.000 and validation 0.669 sets\nNumber of parameters =  49\nAccuracy scores of train 1.000 and validation 0.661 sets\nLength of predictors is:  49\nThe accuracy 0.661 and precision 0.593 of the validation data\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      393\n      74\n    \n    \n      1\n      183\n      108\n    \n  \n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_,'balanced')\npred_class_RF_impBasic=clf.predict(valid_xs[predictors_])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y2, pred_class_RF_impBasic),precision_score(valid_y2, pred_class_RF_impBasic) ) )\nprint('Length of predictors is: ',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred_class_RF_impBasic)\ncrosstab\n\nNumber of parameters =  53\nAccuracy scores of train 1.000 and validation 0.666 sets\nThe accuracy 0.666 and precision 0.628 of the validation data\nLength of predictors is:  53\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      412\n      55\n    \n    \n      1\n      198\n      93\n    \n  \n\n\n\n\n\n\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, Xuse)\npred_class_RF_corr=clf.predict(valid_xs[Xuse])\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y2, pred_class_RF_corr),precision_score(valid_y2, pred_class_RF_corr) ) )\n\nprint('Length of predictors is: ',len(Xuse))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred_class_RF_corr)\ncrosstab\n\nNumber of parameters =  19\nAccuracy scores of train 1.000 and validation 0.632 sets\nThe accuracy 0.632 and precision 0.544 of the validation data\nLength of predictors is:  19\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      405\n      62\n    \n    \n      1\n      217\n      74\n    \n  \n\n\n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[predictors_.append(x) for x in Xuse]\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)\npred_class_RF_corrBasic=clf.predict(valid_xs[predictors_])\n\nprint('number of predictors =',len(predictors_))\n\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y2, pred_class_RF_corrBasic),precision_score(valid_y2, pred_class_RF_corrBasic) ) )\n\n\ncrosstab=pd.crosstab(index = valid_y2, columns = pred_class_RF_corrBasic)\ncrosstab\n\nNumber of parameters =  23\nAccuracy scores of train 1.000 and validation 0.656 sets\nnumber of predictors = 23\nThe accuracy 0.656 and precision 0.604 of the validation data\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      410\n      57\n    \n    \n      1\n      204\n      87\n    \n  \n\n\n\n\n\npredictors_=['round','opponent_x','team_x','weekday']\n[predictors_.append(x) for x in col_use]\n\nclf=do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_,'balanced')\npred_class_RF_balanced=clf.predict(valid_xs[predictors_])\nprint(\"The accuracy {:.3f} and precision {:.3f} of the validation data\".\\\nformat(accuracy_score(valid_y2, pred_class_RF_balanced),precision_score(valid_y2, pred_class_RF_balanced) ) )\nprint('Length of predictors is: ',len(predictors_))\ncrosstab=pd.crosstab(index = valid_y2, columns = pred_class_RF_balanced)\ncrosstab\n\nNumber of parameters =  53\nAccuracy scores of train 1.000 and validation 0.666 sets\nThe accuracy 0.666 and precision 0.628 of the validation data\nLength of predictors is:  53\n\n\n\n\n\n\n  \n    \n      col_0\n      0\n      1\n    \n    \n      Win_x\n      \n      \n    \n  \n  \n    \n      0\n      412\n      55\n    \n    \n      1\n      198\n      93"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#try-as-a-regression-problem",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#try-as-a-regression-problem",
    "title": "ThomasHSimm",
    "section": "Try as a regression problem",
    "text": "Try as a regression problem\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscore_both-HA.csv')\ndfAll=dfAll.iloc[20:,:]\ndf=copy.copy(dfAll)\ndf=df.drop(columns=['Unnamed: 0','opponent_y','team_y'])\n\n\ndf=df.dropna()\ndf[\"opponent_x\"] = df[\"opponent_x\"].astype(\"category\").cat.codes\ndf[\"team_x\"] = df[\"team_x\"].astype(\"category\").cat.codes\n\ntrain=df.loc[cond].copy()\nvalid=df.loc[~cond].copy()\n\ntarget = 'NetScore_x'\npredictors = [x for x in train.columns if ((x != 'Win_x') & (x != 'NetScore_x') )]\n\nxs = train[predictors]\nvalid_xs = valid[predictors]\n\ny = train[target]\nvalid_y = valid[target]\n\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel_RF=RandomForestRegressor(random_state=42)\nmodel_RF.fit(xs,y)\n\n\ndef get_scores2(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.3f} and precision = {:.3f}\".format(nom,acc,prec))\n    \ndef get_reg_scores(yy,preds,XX,binary=True):\n    yy=copy.copy(yy)\n    preds=copy.copy(preds)\n    \n    if binary:\n        yy[yy>0],yy[yy<=0] = 1, 0\n        preds[preds>=XX], preds[preds<XX]=1, 0\n        \n        get_scores2(str(model_RF.base_estimator),preds, yy)\n    else:\n        yy[yy>0]=1\n        yy[yy==0]=0\n        yy[yy<0]=-1\n        \n        preds[preds>=XX]=1\n        preds[preds<-XX]=-1\n        preds[( (preds>=-XX) & (preds<XX) )]=0\n    \n        preds_yy=np.array(preds-yy)\n        preds_yy=preds-yy\n        print( len(preds_yy[preds_yy==0])/len(yy) )\n\n    \n\n\n    return preds,yy\n\n\npred_reg_RF=model_RF.predict(valid_xs)\n\nnew_preds,new_y=get_reg_scores(valid_y,pred_reg_RF,.5)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds)\ncrosstab\n\n\nnew_preds,new_y=get_reg_scores(valid_y,pred_reg_RF,.25,False)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds)\ncrosstab.columns.name='Predicted'\ncrosstab.index.name='Actual'\ncrosstab\n\n\nnp.sum(np.diag(np.array(crosstab))  )/np.sum(np.sum(crosstab))\n\n\nfrom xgboost import XGBRegressor\nmodel_XGB = XGBRegressor(n_estimators=1000, learning_rate=0.01) # Your code here\n# Fit the model\nmodel_XGB.fit(xs, y) \npred_reg_XGB = model_XGB.predict(valid_xs)\nnew_preds,new_y=get_reg_scores(valid_y,pred_reg_XGB,.5)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds)\ncrosstab.columns.name='Predicted'\ncrosstab.index.name='Actual'\ncrosstab\n\n\nfrom sklearn.linear_model import Ridge\nmodel_ridge = Ridge(alpha=21) # Your code here\n# Fit the model\nmodel_ridge.fit(xs, y) \npred_reg_ridge = model_ridge.predict(valid_xs)\nnew_preds,new_y=get_reg_scores(valid_y,pred_reg_ridge,.5)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds)\ncrosstab.columns.name='Predicted'\ncrosstab.index.name='Actual'\ncrosstab\n\n\nGradient Boosting Regressor\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv')\ndfAll=dfAll.iloc[20:,:]\ndf=copy.copy(dfAll)\ndf=df.drop(columns=['Unnamed: 0','opponent_y','team_y','GoalsAgainst_x','GoalsFor_x'])\n\n\ndf=df.dropna()\ndf[\"opponent_x\"] = df[\"opponent_x\"].astype(\"category\").cat.codes\ndf[\"team_x\"] = df[\"team_x\"].astype(\"category\").cat.codes\ndf[\"venue_x\"] = df[\"venue_x\"].astype(\"category\").cat.codes\n\ntrain=df.loc[cond].copy()\nvalid=df.loc[~cond].copy()\n\ntarget='NetScore_x'\n\npredictors = [x for x in train.columns if ((x != 'Win_x') & (x != 'NetScore_x')  )]\n\nxs = train[predictors]\nvalid_xs = valid[predictors]\n\ny = train[target]\nvalid_y = valid[target]\n\n\nfrom sklearn import datasets, ensemble\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\n\nparams = {\n    \"n_estimators\": 500,\n    \"max_depth\": 4,\n    \"min_samples_split\": 5,\n    \"learning_rate\": 0.01,\n    \"loss\": \"squared_error\",\n}\n\nreg = ensemble.GradientBoostingRegressor(**params)\nreg.fit(xs, y)\n\nmse = mean_squared_error(valid_y, reg.predict(valid_xs))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n\n\ntest_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\nfor i, y_pred in enumerate(reg.staged_predict(valid_xs)):\n    test_score[i] = reg.loss_(valid_y, y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title(\"Deviance\")\nplt.plot(\n    np.arange(params[\"n_estimators\"]) + 1,\n    reg.train_score_,\n    \"b-\",\n    label=\"Training Set Deviance\",\n)\nplt.plot(\n    np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n)\nplt.legend(loc=\"upper right\")\nplt.xlabel(\"Boosting Iterations\")\nplt.ylabel(\"Deviance\")\nfig.tight_layout()\nplt.show()\n\n\npred_reg_gradboost = reg.predict(valid_xs)\nnew_preds_comb,new_y=get_reg_scores(valid_y, pred_reg_gradboost,.5)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds_comb)\ncrosstab"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#regression-of-goals-for-and-goals-against",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#regression-of-goals-for-and-goals-against",
    "title": "ThomasHSimm",
    "section": "Regression of Goals For and Goals Against",
    "text": "Regression of Goals For and Goals Against\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv')\ndfAll=dfAll.iloc[20:,:]\ndf=copy.copy(dfAll)\ndf=df.drop(columns=['Unnamed: 0','opponent_y','team_y','NetScore_x'])\n\n\ndf=df.dropna()\ndf[\"opponent_x\"] = df[\"opponent_x\"].astype(\"category\").cat.codes\ndf[\"team_x\"] = df[\"team_x\"].astype(\"category\").cat.codes\ndf[\"venue_x\"] = df[\"venue_x\"].astype(\"category\").cat.codes\n\ntrain=df.loc[cond].copy()\nvalid=df.loc[~cond].copy()\n\n\n\n\npredictors\n\n\ndef get_scores2(nom,predd, yy):\n\n    prec=precision_score(predd, np.array(yy)) \n    acc=accuracy_score(predd, np.array(yy))\n\n    print(\"{}: accuracy = {:.3f} and precision = {:.3f}\".format(nom,acc,prec))\n    \ndef get_reg_scores_Goals(yy,preds,XX,binary=True):\n    yy=copy.copy(yy)\n    preds=copy.copy(preds)\n    \n    \n    yy[yy>0],yy[yy<=0] = 1, 0\n    preds[preds>=XX], preds[preds<XX]=1, 0\n\n    get_scores2('Regression RF',preds, yy)\n\n\n\ndef doGFGA(target,train,valid,model='RF'):\n    \n    predictors = [x for x in train.columns if ((x != 'Win_x') & (x != 'GoalsFor_x') & (x != 'GoalsAgainst_x') )]\n\n    xs = train[predictors]\n    valid_xs = valid[predictors]\n\n    y = train[target]\n    valid_y = valid[target]\n    \n    if model!='RF':\n        print('XGB')\n        model_RF = XGBRegressor(n_estimators=1000, learning_rate=0.01)\n    else:\n        model_RF=RandomForestRegressor(random_state=42)\n        print('RF')\n    \n    model_RF.fit(xs,y)\n    pred_RF=model_RF.predict(valid_xs)\n    \n    return pred_RF\n    \ndef doGFGA_outer(model='RF'):\n    target = 'GoalsFor_x'\n    pred_GF=doGFGA(target,train,valid,model)\n    \n    target = 'GoalsAgainst_x'\n    pred_GA=doGFGA(target,train,valid,model)\n    \n    \n    \n    return pred_GF, pred_GA\n\n\npred_GF, pred_GA = doGFGA_outer()\n\npred_reg_GFGA_RF=pred_GF-pred_GA\n\n\nnew_preds_comb,new_y=get_reg_scores(valid['GoalsFor_x']-valid['GoalsAgainst_x'],pred_reg_GFGA_RF,.5)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds_comb)\ncrosstab\n\n\nnew_preds_comb,new_y=get_reg_scores(valid['GoalsFor_x']-valid['GoalsAgainst_x'],pred_reg_GFGA_RF,.5,False)\n\ncrosstab=pd.crosstab(index = new_y, columns = new_preds_comb)\ncrosstab\n\n\n# from xgboost import XGBRegressor\npred_GF_, pred_GA_ = doGFGA_outer('XGB')\npred_reg_GFGA_XGB=pred_GF-pred_GA\n\n\nnew_preds_comb_,new_y=get_reg_scores(valid['GoalsFor_x']-valid['GoalsAgainst_x'],\\\n                                     pred_reg_GFGA_XGB,.5)\ncrosstab=pd.crosstab(index = new_y, columns = new_preds_comb_)\ncrosstab\n\n\n# # pred_RF\n\n# new_preds_comb_,new_y=get_reg_scores(valid['GoalsFor_x']-valid['GoalsAgainst_x'],0.5*(pred_GF-pred_GA+pred_RF),.5)\n# valid_y\n# crosstab=pd.crosstab(index = new_y, columns = new_preds_comb_)\n# crosstab\n\npred_reg_GFGA_XGB[0:10],pred_reg_GFGA_RF[0:10]\n\n\n\nEnsembling\nThink back to the original reasoning behind why random forests work so well: each tree has errors, but those errors are not correlated with each other, so the average of those errors should tend towards zero once there are enough trees. Similar reasoning could be used to consider averaging the predictions of models trained using different algorithms.\n\nIn our case, we have two very different models.. It would be reasonable to expect that the kinds of errors that each one makes would be quite different. Therefore, we might expect that the average of their predictions would be better than either one's individual predictions.\n\nfrom fastai\n\nnew_preds,new_y=get_reg_scores(valid_y,\n   (pred_reg_RF+pred_reg_XGB+pred_reg_gradboost)/3,.5);\ncrosstab=pd.crosstab(index = new_y, columns = new_preds)\ncrosstab.columns.name='Predicted'\ncrosstab.index.name='Actual'\ncrosstab\n\n\npred_BIG=(1/2)*( pred_reg_GFGA_RF + pred_reg_RF )\n\nnew_preds_comb,new_y=get_reg_scores(valid_y, pred_BIG,.5)\ncrosstab=pd.crosstab(index = new_y, columns = new_preds_comb)\ncrosstab"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#summary",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches-Copy1.html#summary",
    "title": "ThomasHSimm",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nAccuracy W/L/D\nAccuracy Win\nClassification/Regression\nDetails\n\n\n\n\n0.489\n0.669\nClassification\nRF with all parameters\n\n\n0.479\n0.661\nClassification\nRF with 43 parameters from feature imp\n\n\n0.487\n0.666\nClassification\nRF as above with basic features\n\n\n0.484\n0.656\nClassification\nRF with 4 basic features\n\n\n0.479\n-\nClassification\nRF with 4 basic ones + balanced\n\n\n0.485\n0.656\nClassification\nRF with 23 correlation parameters plus basic\n\n\n0.451\n0.678\nRegression\nRF with all parameters on net score\n\n\n-\n0.657\nRegression\nXGB with all parameters on net score\n\n\n-\n0.639\nRegression\nRidge with all parameters on net score\n\n\n-\n0.666\nRegression\nGrad boost with all parameters on net score\n\n\n0.427\n0.670\nRegression\nRF with all parameters on GF/GA\n\n\n-\n0.670\nRegression\nXGB with all parameters on GF/GA score\n\n\n-\n0.665\nRegression\nRF+XGB+Grad boost on netscore\n\n\n-\n0.678\nRegression\nRF on netscore + RF on GF/GA"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches.html#overview",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches.html#overview",
    "title": "ThomasHSimm",
    "section": "Overview",
    "text": "Overview\n\nIntroduction\nPredicting results of English Premier League using random forests for the 2017 to 2021 seasons. I will predict whether a result is a win, loss or draw, and then simplify as a binary question- is it a win?\nFrom an article about pundit versus gambling company Pinnacle vs. Mark Lawrenson we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy\n\n\nMethod\nIn this data there are various parameters that can be used. The most important step is to not use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below like who is playing who and where)\nThe predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who\nSome details on the machine learning:\n\nNotebook on kaggle is here\nSeveral models were used:\n\nA Random Forest model\nGradient boosting models XGBoost\nRidge model\nNeural networks\n\nRegression and classification models were used\nData is trained on years 2017 to 2020 with season 2021 used as validation\n\n20% validation / 80% training\n\nSome data cleaning methods were performed and shown in the code\n\n\n\nResults\n\nModel accuracy = 52% (+-1%)\n\nSo the model is comparable with the results of Mark Lawrenson\n\nThe model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.\nDraws are under-represented by the model\n\ndraws predicted was increased by adjusting the input parameter class_weight but the issue was only reduced\n\nChanging input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy\nThe more parameters the better,\n\nbut the increase from just using a basic four parameter fit to one with 300+ columns is relatively small (a difference of ~1-2% (based on values 50-65%))\n\nBy searching for the best hyper parameters the results of a random forest (RF) model were increased from 49% accuracy to 52%\nRF, XG boost and grad boost methods all performed similar\n\nRidge model was the worst performing\nNeural networks with fastai tabular data also performed poorly. NN analysis of EPL\n\nSimilar results were obtained by using classification and regression methods\n\nRegression on the net score performed the best\nRegression methods performed worse on predicting draws though\n\nEnsembling (combining results from different methods by adding them) can increase the overall results. The accuracy would need to be comparable and the results different enough for their to be a benefit\n\nA summary of the results is shown below\n\n\n\n\n\n\n\n\n\nAccuracy W/L/D\nAccuracy Win\nClassification/Regression\nDetails\n\n\n\n\n0.489\n0.669\nClassification\nRF with all parameters\n\n\n0.479\n0.661\nClassification\nRF with 43 parameters from feature imp\n\n\n0.487\n0.666\nClassification\nRF as above with basic features\n\n\n0.484\n0.656\nClassification\nRF with 4 basic features\n\n\n0.479\n-\nClassification\nRF with 4 basic ones + balanced\n\n\n0.485\n0.656\nClassification\nRF with 23 correlation parameters plus basic\n\n\n0.451\n0.678\nRegression\nRF with all parameters on net score\n\n\n-\n0.657\nRegression\nXGB with all parameters on net score\n\n\n-\n0.639\nRegression\nRidge with all parameters on net score\n\n\n-\n0.666\nRegression\nGrad boost with all parameters on net score\n\n\n0.427\n0.670\nRegression\nRF with all parameters on GF/GA\n\n\n-\n0.670\nRegression\nXGB with all parameters on GF/GA score\n\n\n-\n0.665\nRegression\nRF+XGB+Grad boost on netscore\n\n\n-\n0.678\nRegression\nRF on netscore + RF on GF/GA"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches.html#load-data-and-libraries",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches.html#load-data-and-libraries",
    "title": "ThomasHSimm",
    "section": "Load data and libraries",
    "text": "Load data and libraries\n\n#collapse-hide\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\n\n# from sklearn.tree import DecisionTreeClassifier\n# from dtreeviz.trees import *\n# from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n# from fastai.tabular.all import *\n\n# from sklearn.experimental import enable_halving_search_cv  # noqa\n# from sklearn.model_selection import HalvingRandomSearchCV\n\n\n# from sklearn.metrics import precision_score\nfrom xgboost import XGBClassifier\n\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',index_col=0)\ndfAll=dfAll.iloc[20:,:]\ndfAll\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh__x\n      shooting_sot_x\n      ...\n      misc_int__y\n      misc_tklw__y\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n    \n  \n  \n    \n      44\n      3\n      27\n      Home\n      0.000000\n      2.000000\n      2.000000\n      Everton\n      2.000000\n      14.500000\n      4.000000\n      ...\n      13.000000\n      12.000000\n      0.000000\n      0.000000\n      0.000000\n      94.500000\n      19.500000\n      27.000000\n      41.150000\n      Everton\n    \n    \n      45\n      3\n      27\n      Away\n      0.000000\n      2.000000\n      2.000000\n      Liverpool\n      2.000000\n      23.000000\n      8.500000\n      ...\n      16.000000\n      12.000000\n      0.500000\n      0.000000\n      0.000000\n      114.000000\n      28.500000\n      20.500000\n      57.450000\n      Liverpool\n    \n    \n      46\n      3\n      27\n      Away\n      0.000000\n      1.500000\n      1.500000\n      Tottenham Hotspur\n      1.500000\n      15.000000\n      3.000000\n      ...\n      8.500000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      21.000000\n      22.500000\n      48.600000\n      Tottenham Hotspur\n    \n    \n      47\n      3\n      27\n      Away\n      0.500000\n      1.000000\n      0.500000\n      Chelsea\n      1.000000\n      8.000000\n      3.000000\n      ...\n      7.000000\n      14.000000\n      0.000000\n      0.000000\n      0.500000\n      92.000000\n      23.500000\n      26.000000\n      47.850000\n      Chelsea\n    \n    \n      48\n      3\n      26\n      Away\n      0.500000\n      2.500000\n      2.000000\n      Manchester United\n      2.500000\n      10.000000\n      3.500000\n      ...\n      16.000000\n      10.500000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      21.500000\n      19.500000\n      50.300000\n      Manchester United\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3795\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n      Arsenal\n    \n    \n      3796\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n      Brentford\n    \n    \n      3797\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n      Newcastle United\n    \n    \n      3798\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n      Chelsea\n    \n    \n      3799\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n      Tottenham Hotspur\n    \n  \n\n3740 rows × 333 columns\n\n\n\n\n#collapse-output\nwith pd.option_context(\"display.max_columns\", None):\n    display(dfAll.describe(include='all'))\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      shooting_gls_x\n      shooting_sh__x\n      shooting_sot_x\n      shooting_sot%_x\n      shooting_g/sh_x\n      shooting_g/sot_x\n      shooting_PC_dist_x\n      shooting_fk__x\n      shooting_pk_x\n      shooting_pkatt__x\n      shooting_xg_x\n      shooting_npxg_x\n      shooting_npxg/sh_x\n      shooting_g-xg_x\n      shooting_np:g-xg_x\n      keeper_sota_x\n      keeper_saves_x\n      keeper_save%_x\n      keeper_cs_x\n      keeper_psxg_x\n      keeper_psxg+/-_x\n      keeper_pkatt__x\n      keeper_pka_x\n      keeper_pksv_x\n      keeper_pkm_x\n      keeper_cmp__x\n      keeper_att__x\n      keeper_cmp%__x\n      keeper_att_.1_x\n      keeper_thr_x\n      keeper_launch%_x\n      keeper_avglen_x\n      keeper_att_.2_x\n      keeper_launch%.1_x\n      keeper_avglen.1_x\n      keeper_opp_x\n      keeper_stp_x\n      keeper_stp%_x\n      keeper_#opa_x\n      keeper_avgdist_x\n      passing_pass_complete_x\n      passing_cmp%__x\n      passing_PC_totdist__x\n      passing_PC_prgdist__x\n      passing_PC_cmp_.1_x\n      passing_cmp%_.1_x\n      passing_PC_cmp_.2_x\n      passing_cmp%_.2_x\n      passing_PC_cmp_.3_x\n      passing_cmp%_.3_x\n      passing_ast_x\n      passing_xa_x\n      passing_kp_x\n      passing_PC_1/3__x\n      passing_PC_ppa_x\n      passing_PC_crspa_x\n      passing_PC_prog__x\n      passing_PC_types_live__x\n      passing_PC_types_dead_x\n      passing_PC_types_fk__x\n      passing_PC_types_tb_x\n      passing_PC_types_press__x\n      passing_PC_types_sw_x\n      passing_PC_types_crs__x\n      passing_PC_types_ck_x\n      passing_PC_types_in_x\n      passing_PC_types_out_x\n      passing_PC_types_str_x\n      passing_PC_types_ground_x\n      passing_PC_types_low_x\n      passing_PC_types_high_x\n      passing_PC_types_left_x\n      passing_PC_types_right_x\n      passing_PC_types_head_x\n      passing_PC_types_ti_x\n      passing_PC_types_other_x\n      passing_PC_types_cmp__x\n      passing_PC_types_off__x\n      passing_PC_types_out.1_x\n      passing_PC_types_int__x\n      passing_PC_types_blocks__x\n      shotcreate_sca_x\n      shotcreate_passlive_x\n      shotcreate_passdead_x\n      shotcreate_drib_x\n      shotcreate_sh_gca_x\n      shotcreate_fld_gca_x\n      shotcreate_def_x\n      shotcreate_gca_x\n      shotcreate_passlive.1_x\n      shotcreate_passdead.1_x\n      shotcreate_drib.1_x\n      shotcreate_sh_gca.1_x\n      shotcreate_fld_gca.1_x\n      shotcreate_def.1_x\n      tackle_tkl_x\n      tackle_PC_tklw_defense_x\n      tackle_PC_def 3rd_defense_x\n      tackle_PC_mid 3rd_defense_x\n      tackle_PC_att 3rd_defense_x\n      tackle_PC_tkl_dribble_x\n      tackle_dribble%_x\n      tackle_dribllepast_x\n      tackle_press_defense_x\n      tackle_%_x\n      tackle_PC_press_def3rd_x\n      tackle_PC_press_mid3rd_x\n      tackle_PC_press_att3rd_x\n      tackle_blocks_defense_x\n      tackle_PC_sh_defense_x\n      tackle_PC_shsv_x\n      tackle_PC_pass_x\n      tackle_int_defense_x\n      tackle_clr_x\n      tackle_err_x\n      possession_poss_x\n      possession_touches_x\n      possession_PC_def pen_x\n      possession_PC_def 3rd__x\n      possession_PC_mid 3rd__x\n      possession_PC_att 3rd__x\n      possession_PC_att pen_x\n      possession_PC_live__x\n      possession_dribblesucc__x\n      possession_dribbleatt__x\n      possession_dribblesucc%_x\n      possession_dribblepast_x\n      possession_megs_x\n      possession_carries_x\n      possession_totdist__x\n      possession_PC_prgdist__x\n      possession_PC_prog__x\n      possession_PC_1/3__x\n      possession_PC_cpa_x\n      possession_PC_mis_x\n      possession_PC_dis_x\n      possession_targ_x\n      possession_rec_x\n      possession_rec%_x\n      possession_prog_.1_x\n      misc_crdy_x\n      misc_crdr_x\n      misc_2crdy_x\n      misc_fls_x\n      misc_fld__x\n      misc_off__x\n      misc_crs__x\n      misc_int__x\n      misc_tklw__x\n      misc_pkwon_x\n      misc_pkcon_x\n      misc_og_x\n      misc_recov_x\n      misc_won_x\n      misc_lost_x\n      misc_won%_x\n      team_x\n      season\n      month\n      year\n      weekday\n      Win_x\n      NetScore_x\n      GoalsFor_x\n      GoalsAgainst_x\n      result_y\n      gf_y\n      ga_y\n      opponent_y\n      shooting_gls_y\n      shooting_sh__y\n      shooting_sot_y\n      shooting_sot%_y\n      shooting_g/sh_y\n      shooting_g/sot_y\n      shooting_PC_dist_y\n      shooting_fk__y\n      shooting_pk_y\n      shooting_pkatt__y\n      shooting_yg_y\n      shooting_npxg_y\n      shooting_npxg/sh_y\n      shooting_g-xg_y\n      shooting_np:g-xg_y\n      keeper_sota_y\n      keeper_saves_y\n      keeper_save%_y\n      keeper_cs_y\n      keeper_psxg_y\n      keeper_psxg+/-_y\n      keeper_pkatt__y\n      keeper_pka_y\n      keeper_pksv_y\n      keeper_pkm_y\n      keeper_cmp__y\n      keeper_att__y\n      keeper_cmp%__y\n      keeper_att_.1_y\n      keeper_thr_y\n      keeper_launch%_y\n      keeper_avglen_y\n      keeper_att_.2_y\n      keeper_launch%.1_y\n      keeper_avglen.1_y\n      keeper_opp_y\n      keeper_stp_y\n      keeper_stp%_y\n      keeper_#opa_y\n      keeper_avgdist_y\n      passing_pass_complete_y\n      passing_cmp%__y\n      passing_PC_totdist__y\n      passing_PC_prgdist__y\n      passing_PC_cmp_.1_y\n      passing_cmp%_.1_y\n      passing_PC_cmp_.2_y\n      passing_cmp%_.2_y\n      passing_PC_cmp_.3_y\n      passing_cmp%_.3_y\n      passing_ast_y\n      passing_ya_y\n      passing_kp_y\n      passing_PC_1/3__y\n      passing_PC_ppa_y\n      passing_PC_crspa_y\n      passing_PC_prog__y\n      passing_PC_types_live__y\n      passing_PC_types_dead_y\n      passing_PC_types_fk__y\n      passing_PC_types_tb_y\n      passing_PC_types_press__y\n      passing_PC_types_sw_y\n      passing_PC_types_crs__y\n      passing_PC_types_ck_y\n      passing_PC_types_in_y\n      passing_PC_types_out_y\n      passing_PC_types_str_y\n      passing_PC_types_ground_y\n      passing_PC_types_low_y\n      passing_PC_types_high_y\n      passing_PC_types_left_y\n      passing_PC_types_right_y\n      passing_PC_types_head_y\n      passing_PC_types_ti_y\n      passing_PC_types_other_y\n      passing_PC_types_cmp__y\n      passing_PC_types_off__y\n      passing_PC_types_out.1_y\n      passing_PC_types_int__y\n      passing_PC_types_blocks__y\n      shotcreate_sca_y\n      shotcreate_passlive_y\n      shotcreate_passdead_y\n      shotcreate_drib_y\n      shotcreate_sh_gca_y\n      shotcreate_fld_gca_y\n      shotcreate_def_y\n      shotcreate_gca_y\n      shotcreate_passlive.1_y\n      shotcreate_passdead.1_y\n      shotcreate_drib.1_y\n      shotcreate_sh_gca.1_y\n      shotcreate_fld_gca.1_y\n      shotcreate_def.1_y\n      tackle_tkl_y\n      tackle_PC_tklw_defense_y\n      tackle_PC_def 3rd_defense_y\n      tackle_PC_mid 3rd_defense_y\n      tackle_PC_att 3rd_defense_y\n      tackle_PC_tkl_dribble_y\n      tackle_dribble%_y\n      tackle_dribllepast_y\n      tackle_press_defense_y\n      tackle_%_y\n      tackle_PC_press_def3rd_y\n      tackle_PC_press_mid3rd_y\n      tackle_PC_press_att3rd_y\n      tackle_blocks_defense_y\n      tackle_PC_sh_defense_y\n      tackle_PC_shsv_y\n      tackle_PC_pass_y\n      tackle_int_defense_y\n      tackle_clr_y\n      tackle_err_y\n      possession_poss_y\n      possession_touches_y\n      possession_PC_def pen_y\n      possession_PC_def 3rd__y\n      possession_PC_mid 3rd__y\n      possession_PC_att 3rd__y\n      possession_PC_att pen_y\n      possession_PC_live__y\n      possession_dribblesucc__y\n      possession_dribbleatt__y\n      possession_dribblesucc%_y\n      possession_dribblepast_y\n      possession_megs_y\n      possession_carries_y\n      possession_totdist__y\n      possession_PC_prgdist__y\n      possession_PC_prog__y\n      possession_PC_1/3__y\n      possession_PC_cpa_y\n      possession_PC_mis_y\n      possession_PC_dis_y\n      possession_targ_y\n      possession_rec_y\n      possession_rec%_y\n      possession_prog_.1_y\n      misc_crdy_y\n      misc_crdr_y\n      misc_2crdy_y\n      misc_fls_y\n      misc_fld__y\n      misc_off__y\n      misc_crs__y\n      misc_int__y\n      misc_tklw__y\n      misc_pkwon_y\n      misc_pkcon_y\n      misc_og_y\n      misc_recov_y\n      misc_won_y\n      misc_lost_y\n      misc_won%_y\n      team_y\n    \n  \n  \n    \n      count\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740.000000\n      3740\n    \n    \n      unique\n      NaN\n      NaN\n      2\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      28\n    \n    \n      top\n      NaN\n      NaN\n      Away\n      NaN\n      NaN\n      NaN\n      Newcastle United\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      NaN\n      L\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Burnley\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Newcastle United\n    \n    \n      freq\n      NaN\n      NaN\n      1871\n      NaN\n      NaN\n      NaN\n      188\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      188\n      NaN\n      NaN\n      NaN\n      NaN\n      1444\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      188\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      188\n    \n    \n      mean\n      19.789305\n      15.910160\n      NaN\n      -0.003342\n      1.367870\n      1.371212\n      NaN\n      1.324242\n      12.318806\n      4.082620\n      33.666230\n      0.103205\n      0.295620\n      151.814870\n      0.457487\n      0.104055\n      0.131684\n      1.320134\n      1.220357\n      0.100935\n      0.004109\n      -0.000169\n      4.084715\n      2.817513\n      68.905134\n      0.285829\n      1.332852\n      0.005624\n      0.134447\n      0.104768\n      0.022103\n      0.007576\n      6.711765\n      17.383601\n      41.413993\n      24.147148\n      4.075178\n      51.061034\n      42.502959\n      7.459848\n      66.906448\n      52.437215\n      8.755080\n      0.661631\n      7.543382\n      0.649643\n      14.412273\n      390.931194\n      77.247553\n      1979.363069\n      687.824335\n      40.897515\n      86.660709\n      41.792130\n      83.940147\n      15.411750\n      57.009621\n      0.942959\n      0.897821\n      8.928030\n      7.547074\n      2.120160\n      0.545131\n      8.387274\n      89.802235\n      10.197765\n      2.484955\n      0.183265\n      15.459547\n      2.967840\n      2.486263\n      1.061565\n      0.467084\n      0.350791\n      0.082297\n      63.555635\n      14.102166\n      22.342199\n      27.469285\n      59.267074\n      4.388067\n      4.484950\n      1.347329\n      77.794521\n      0.354085\n      1.919054\n      2.424604\n      2.519446\n      19.230080\n      13.878342\n      1.687032\n      1.185428\n      0.992647\n      1.057353\n      0.429278\n      2.148217\n      1.469563\n      0.141355\n      0.147816\n      0.180793\n      0.159358\n      0.049332\n      17.782130\n      60.717652\n      50.005406\n      37.636636\n      12.357958\n      33.790802\n      36.547767\n      10.469430\n      150.873797\n      29.555771\n      34.517406\n      43.220499\n      22.262095\n      15.869519\n      23.681976\n      0.506995\n      76.318024\n      12.285829\n      25.121970\n      0.274911\n      49.998217\n      615.295811\n      11.131009\n      33.164347\n      46.679487\n      26.100825\n      3.856162\n      92.155582\n      9.629144\n      16.482531\n      58.265330\n      10.457442\n      0.714572\n      383.570811\n      1960.431774\n      53.252857\n      10.944362\n      3.339541\n      1.091207\n      3.437701\n      3.274796\n      465.705749\n      390.931194\n      82.527647\n      34.576738\n      1.634715\n      0.058289\n      0.023886\n      12.389394\n      11.971569\n      1.868182\n      12.004590\n      12.285829\n      10.759091\n      0.110116\n      0.128832\n      0.044251\n      90.116667\n      19.210250\n      19.209581\n      49.993079\n      NaN\n      2019.023529\n      6.763636\n      2019.533690\n      4.360963\n      NaN\n      -0.001872\n      1.371390\n      1.373262\n      -0.001471\n      1.368672\n      1.370143\n      NaN\n      1.324777\n      12.322950\n      4.084759\n      33.665749\n      0.103174\n      0.295648\n      151.783431\n      0.457888\n      0.104189\n      0.131818\n      1.320963\n      1.221092\n      0.100949\n      0.003815\n      -0.000504\n      4.081640\n      2.815374\n      68.919652\n      0.286364\n      1.331836\n      0.005677\n      0.134447\n      0.104768\n      0.022103\n      0.007576\n      6.709358\n      17.376381\n      41.415183\n      24.147549\n      4.076114\n      51.039416\n      42.493012\n      7.457843\n      66.902732\n      52.430985\n      8.752540\n      0.662701\n      7.562781\n      0.649777\n      14.412968\n      391.065285\n      77.252794\n      1979.240478\n      687.729735\n      40.898842\n      86.663770\n      41.792418\n      83.941805\n      15.409745\n      57.018378\n      0.943093\n      0.898075\n      8.930303\n      7.547489\n      2.119949\n      0.544611\n      8.387497\n      89.804963\n      10.195037\n      2.483827\n      0.183429\n      15.457410\n      2.966877\n      2.485392\n      1.061554\n      0.466670\n      0.351048\n      0.082452\n      63.562637\n      14.102245\n      22.335118\n      27.463310\n      59.275168\n      4.386860\n      4.484425\n      1.347030\n      77.799389\n      0.353852\n      1.918207\n      2.423601\n      2.519481\n      19.238102\n      13.884492\n      1.687299\n      1.185963\n      0.993182\n      1.058021\n      0.429144\n      2.149020\n      1.470766\n      0.141087\n      0.147683\n      0.180526\n      0.159759\n      0.049198\n      17.784135\n      60.719894\n      50.000323\n      37.647136\n      12.352541\n      33.783894\n      36.543182\n      10.470232\n      150.897059\n      29.560998\n      34.512083\n      43.224267\n      22.263651\n      15.867112\n      23.665236\n      0.506995\n      76.334764\n      12.288636\n      25.107932\n      0.274777\n      50.007442\n      615.434180\n      11.127372\n      33.157686\n      46.683163\n      26.103830\n      3.856597\n      92.157298\n      9.633021\n      16.488681\n      58.268097\n      10.461988\n      0.714840\n      383.703164\n      1960.965196\n      53.255401\n      10.945468\n      3.339802\n      1.091572\n      3.436512\n      3.274502\n      465.841176\n      391.065285\n      82.532513\n      34.589305\n      1.635918\n      0.058422\n      0.024020\n      12.391800\n      11.971836\n      1.866979\n      12.004055\n      12.288636\n      10.760561\n      0.110250\n      0.128832\n      0.044251\n      90.128164\n      19.211854\n      19.208779\n      49.995499\n      NaN\n    \n    \n      std\n      10.812190\n      9.082985\n      NaN\n      1.260926\n      0.808001\n      0.774004\n      NaN\n      0.794644\n      3.597818\n      1.608375\n      9.614793\n      0.063311\n      0.160978\n      54.846307\n      0.401409\n      0.189608\n      0.213964\n      0.539431\n      0.499269\n      0.028063\n      0.548592\n      0.545514\n      1.536609\n      1.192484\n      17.268237\n      0.271639\n      0.620853\n      0.426968\n      0.218550\n      0.189411\n      0.089500\n      0.052022\n      2.673514\n      6.831725\n      11.779479\n      5.578168\n      1.668569\n      20.032654\n      9.608195\n      2.134183\n      24.745854\n      13.899819\n      2.799294\n      0.530528\n      6.377266\n      0.567336\n      3.132228\n      119.477131\n      6.127586\n      108.661242\n      122.423021\n      3.621674\n      3.653049\n      3.620413\n      5.360235\n      2.776097\n      8.948543\n      0.660216\n      0.400746\n      2.878542\n      1.266651\n      0.599713\n      0.297163\n      1.457260\n      2.574413\n      2.574413\n      0.758481\n      0.151459\n      3.983513\n      0.780574\n      0.691667\n      0.342776\n      0.294596\n      0.231719\n      0.116260\n      9.270781\n      2.990125\n      7.202335\n      6.437151\n      7.071222\n      1.538933\n      1.257358\n      0.410721\n      6.000126\n      0.218160\n      0.703913\n      0.971685\n      0.625166\n      6.158332\n      5.057429\n      0.842449\n      0.768469\n      0.696029\n      0.600697\n      0.406695\n      1.383549\n      1.122031\n      0.214337\n      0.251428\n      0.253063\n      0.238379\n      0.133121\n      3.479814\n      7.282239\n      9.782546\n      7.986327\n      5.688972\n      8.586122\n      8.484729\n      2.904268\n      27.877080\n      3.933526\n      6.492833\n      3.781661\n      5.400574\n      3.425881\n      8.158337\n      1.101893\n      8.158337\n      4.887549\n      7.802474\n      0.332278\n      9.573898\n      112.341294\n      3.073200\n      5.869180\n      4.246802\n      4.196696\n      0.939337\n      1.639189\n      2.899335\n      4.097558\n      8.885281\n      3.039749\n      0.565743\n      109.013451\n      560.207630\n      3.728944\n      1.931172\n      0.714923\n      0.444086\n      1.165160\n      1.051011\n      119.023950\n      119.477131\n      5.138379\n      10.830988\n      0.746549\n      0.138407\n      0.089291\n      2.524250\n      2.591855\n      0.956812\n      3.444791\n      4.887549\n      2.295753\n      0.195497\n      0.211274\n      0.118976\n      11.267654\n      5.659847\n      5.813950\n      6.294121\n      NaN\n      1.407382\n      3.969227\n      1.520015\n      1.798241\n      NaN\n      1.947079\n      1.269421\n      1.269820\n      1.262519\n      0.808628\n      0.774343\n      NaN\n      0.795351\n      3.597067\n      1.608762\n      9.614106\n      0.063220\n      0.160880\n      54.850292\n      0.401701\n      0.189711\n      0.214038\n      0.540175\n      0.499985\n      0.028062\n      0.548811\n      0.545793\n      1.537276\n      1.192771\n      17.264720\n      0.271814\n      0.621129\n      0.426749\n      0.218550\n      0.189411\n      0.089500\n      0.052022\n      2.672028\n      6.828191\n      11.780052\n      5.577480\n      1.669308\n      20.034401\n      9.606079\n      2.134818\n      24.737701\n      13.894690\n      2.800754\n      0.530705\n      6.392757\n      0.567242\n      3.129257\n      119.515735\n      6.128051\n      108.609872\n      122.401336\n      3.621302\n      3.653428\n      3.620178\n      5.359233\n      2.775348\n      8.950187\n      0.660886\n      0.400693\n      2.874659\n      1.266934\n      0.599507\n      0.297272\n      1.457096\n      2.574378\n      2.574378\n      0.758191\n      0.151427\n      3.984765\n      0.780327\n      0.691138\n      0.342928\n      0.294658\n      0.231838\n      0.116712\n      9.267060\n      2.989201\n      7.200972\n      6.427083\n      7.065863\n      1.538999\n      1.256937\n      0.410498\n      6.000922\n      0.218247\n      0.704214\n      0.971906\n      0.625276\n      6.153878\n      5.053910\n      0.842469\n      0.768861\n      0.697474\n      0.601022\n      0.406260\n      1.385009\n      1.123701\n      0.213889\n      0.251374\n      0.252460\n      0.238531\n      0.132919\n      3.477123\n      7.276880\n      9.780540\n      7.986417\n      5.689568\n      8.581289\n      8.469441\n      2.904276\n      27.861281\n      3.935946\n      6.495629\n      3.784094\n      5.401501\n      3.426921\n      8.160210\n      1.101893\n      8.160210\n      4.886419\n      7.791726\n      0.332288\n      9.576615\n      112.388551\n      3.076070\n      5.875037\n      4.250795\n      4.198132\n      0.939326\n      1.639047\n      2.902260\n      4.103303\n      8.886728\n      3.042843\n      0.565759\n      109.038437\n      560.266760\n      3.730208\n      1.932012\n      0.714515\n      0.443880\n      1.164719\n      1.050918\n      119.069075\n      119.515735\n      5.138246\n      10.836724\n      0.746286\n      0.138592\n      0.089629\n      2.523003\n      2.591213\n      0.956610\n      3.445064\n      4.886419\n      2.293386\n      0.195592\n      0.211274\n      0.118976\n      11.274286\n      5.658357\n      5.813577\n      6.295669\n      NaN\n    \n    \n      min\n      1.000000\n      1.000000\n      NaN\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.333333\n      2.766667\n      0.000000\n      0.000000\n      55.061728\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.966667\n      -1.700000\n      0.333333\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      157.000000\n      58.200000\n      1690.290290\n      421.044850\n      28.197674\n      68.133333\n      31.100478\n      63.566667\n      8.301527\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      3.724138\n      0.126263\n      0.000000\n      3.750000\n      78.957169\n      3.957997\n      0.732601\n      0.000000\n      5.770965\n      1.133948\n      0.632911\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      32.774674\n      6.373355\n      6.699548\n      12.052117\n      37.898687\n      1.231423\n      1.332795\n      0.264901\n      58.153846\n      0.000000\n      0.455581\n      0.293255\n      0.691017\n      4.666667\n      2.500000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      36.170213\n      11.627907\n      12.500000\n      0.000000\n      8.333333\n      9.166667\n      2.000000\n      66.000000\n      13.700000\n      13.606911\n      29.111842\n      8.041237\n      6.000000\n      0.000000\n      0.000000\n      45.161290\n      1.333333\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      3.639121\n      14.908854\n      33.405172\n      10.754098\n      1.246334\n      85.822785\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      41.276202\n      5.420561\n      1.097695\n      0.000000\n      0.894188\n      0.889193\n      219.333333\n      157.000000\n      61.866667\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n      2017.000000\n      1.000000\n      2017.000000\n      0.000000\n      NaN\n      -9.000000\n      0.000000\n      0.000000\n      -5.333333\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      3.333333\n      0.333333\n      2.766667\n      0.000000\n      0.000000\n      55.061728\n      0.000000\n      0.000000\n      0.000000\n      0.200000\n      0.166667\n      0.033333\n      -1.966667\n      -1.700000\n      0.333333\n      0.000000\n      -25.000000\n      0.000000\n      0.000000\n      -1.833333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.666667\n      2.333333\n      9.333333\n      10.000000\n      0.000000\n      7.933333\n      22.033333\n      1.000000\n      0.000000\n      10.733333\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      4.000000\n      157.000000\n      58.200000\n      1690.290290\n      421.044850\n      28.197674\n      68.133333\n      31.100478\n      63.566667\n      8.301527\n      32.133333\n      0.000000\n      0.100000\n      1.666667\n      3.724138\n      0.126263\n      0.000000\n      3.750000\n      78.957169\n      3.957997\n      0.732601\n      0.000000\n      5.770965\n      1.133948\n      0.632911\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      32.774674\n      6.373355\n      6.699548\n      12.052117\n      37.898687\n      1.231423\n      1.332795\n      0.264901\n      58.153846\n      0.000000\n      0.455581\n      0.293255\n      0.691017\n      4.666667\n      2.500000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      7.333333\n      36.170213\n      11.627907\n      12.500000\n      0.000000\n      8.333333\n      9.166667\n      2.000000\n      66.000000\n      13.700000\n      13.606911\n      29.111842\n      8.041237\n      6.000000\n      0.000000\n      0.000000\n      45.161290\n      1.333333\n      6.333333\n      0.000000\n      24.666667\n      361.666667\n      3.639121\n      14.908854\n      33.405172\n      10.754098\n      1.246334\n      85.822785\n      2.000000\n      5.000000\n      22.333333\n      3.000000\n      0.000000\n      157.000000\n      778.000000\n      41.276202\n      5.420561\n      1.097695\n      0.000000\n      0.894188\n      0.889193\n      219.333333\n      157.000000\n      61.866667\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      4.333333\n      3.666667\n      0.000000\n      3.000000\n      1.333333\n      4.333333\n      0.000000\n      0.000000\n      0.000000\n      50.333333\n      4.000000\n      5.666667\n      22.200000\n      NaN\n    \n    \n      25%\n      10.000000\n      8.000000\n      NaN\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.200000\n      0.060000\n      0.176667\n      114.758929\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.258333\n      20.333333\n      3.000000\n      34.625000\n      34.666667\n      6.000000\n      48.000000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      73.000000\n      1904.671024\n      597.184442\n      38.330073\n      84.366667\n      39.180032\n      80.466667\n      13.442505\n      50.300000\n      0.333333\n      0.600000\n      7.000000\n      6.676949\n      1.706103\n      0.329083\n      7.358874\n      88.052077\n      8.321893\n      1.936060\n      0.073233\n      12.539702\n      2.435745\n      1.990478\n      0.825466\n      0.251375\n      0.176815\n      0.000000\n      57.131288\n      12.020757\n      16.761444\n      22.619711\n      54.337558\n      3.223610\n      3.572207\n      1.058524\n      73.703910\n      0.198840\n      1.395349\n      1.681482\n      2.083333\n      15.000000\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      55.769231\n      43.181818\n      32.142857\n      8.333333\n      27.906977\n      30.633333\n      8.333333\n      131.000000\n      26.925000\n      30.194872\n      40.625000\n      18.408045\n      13.333333\n      17.987179\n      0.000000\n      70.833333\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.666667\n      8.961050\n      29.345463\n      43.868450\n      23.254724\n      3.223858\n      91.025962\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.333333\n      50.769548\n      9.595724\n      2.845528\n      0.782841\n      2.597991\n      2.543108\n      377.333333\n      302.000000\n      79.166667\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.250000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.933333\n      NaN\n      2018.000000\n      3.000000\n      2018.000000\n      4.000000\n      NaN\n      -1.000000\n      0.000000\n      0.000000\n      -1.000000\n      0.666667\n      0.666667\n      NaN\n      0.666667\n      9.666667\n      3.000000\n      27.200000\n      0.060000\n      0.176667\n      114.708333\n      0.000000\n      0.000000\n      0.000000\n      0.933333\n      0.866667\n      0.080000\n      -0.366667\n      -0.366667\n      3.000000\n      2.000000\n      58.333333\n      0.000000\n      0.866667\n      -0.266667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      4.666667\n      12.000000\n      33.233333\n      20.333333\n      3.000000\n      34.625000\n      34.666667\n      6.000000\n      48.000000\n      41.300000\n      6.666667\n      0.333333\n      3.033333\n      0.333333\n      12.233333\n      302.000000\n      73.000000\n      1904.671024\n      597.103658\n      38.327718\n      84.366667\n      39.180032\n      80.466667\n      13.441365\n      50.325000\n      0.333333\n      0.600000\n      7.000000\n      6.676949\n      1.706103\n      0.328192\n      7.358874\n      88.054636\n      8.307964\n      1.935807\n      0.073300\n      12.535171\n      2.435630\n      1.990167\n      0.824997\n      0.250117\n      0.176815\n      0.000000\n      57.140011\n      12.020757\n      16.756203\n      22.619711\n      54.346396\n      3.221214\n      3.573929\n      1.058127\n      73.710308\n      0.198282\n      1.394568\n      1.681230\n      2.083333\n      15.000000\n      10.333333\n      1.000000\n      0.666667\n      0.333333\n      0.666667\n      0.000000\n      1.333333\n      0.666667\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      15.333333\n      55.769231\n      43.181818\n      32.142857\n      8.333333\n      27.906977\n      30.633333\n      8.333333\n      131.000000\n      26.933333\n      30.183981\n      40.625000\n      18.408045\n      13.333333\n      17.948718\n      0.000000\n      70.909091\n      8.333333\n      19.666667\n      0.000000\n      43.000000\n      532.916667\n      8.957279\n      29.333138\n      43.868450\n      23.260019\n      3.225334\n      91.027006\n      7.333333\n      13.666667\n      52.566667\n      8.333333\n      0.333333\n      302.333333\n      1531.583333\n      50.772488\n      9.595724\n      2.845528\n      0.783429\n      2.597186\n      2.543108\n      377.333333\n      302.000000\n      79.166667\n      26.666667\n      1.000000\n      0.000000\n      0.000000\n      10.666667\n      10.333333\n      1.000000\n      9.666667\n      8.333333\n      9.333333\n      0.000000\n      0.000000\n      0.000000\n      82.333333\n      15.000000\n      15.000000\n      45.933333\n      NaN\n    \n    \n      50%\n      20.000000\n      16.000000\n      NaN\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.266667\n      0.096667\n      0.276667\n      141.126984\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.666667\n      40.133333\n      23.666667\n      4.000000\n      51.233333\n      41.983333\n      7.333333\n      70.883333\n      53.866667\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.666667\n      77.533333\n      1973.385792\n      674.276172\n      40.893394\n      87.033333\n      41.918119\n      84.733333\n      15.218688\n      56.616667\n      1.000000\n      0.833333\n      8.666667\n      7.505258\n      2.080172\n      0.499085\n      8.344460\n      89.793788\n      10.206212\n      2.440634\n      0.155159\n      15.109299\n      2.891967\n      2.444716\n      1.030131\n      0.415153\n      0.326624\n      0.052673\n      64.038769\n      13.965784\n      21.682644\n      27.017143\n      59.389146\n      4.180029\n      4.393993\n      1.312780\n      78.137796\n      0.312337\n      1.835510\n      2.419147\n      2.476006\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      60.606061\n      50.000000\n      37.500000\n      11.764706\n      33.333333\n      36.333333\n      10.333333\n      148.666667\n      29.500000\n      34.422759\n      43.166562\n      21.661238\n      16.000000\n      23.076923\n      0.000000\n      76.923077\n      12.333333\n      24.333333\n      0.333333\n      49.333333\n      598.000000\n      10.956981\n      33.231956\n      46.543912\n      25.917296\n      3.799952\n      92.101589\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1888.333333\n      53.271144\n      10.804122\n      3.312019\n      1.046910\n      3.311880\n      3.151388\n      447.000000\n      369.666667\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.866667\n      NaN\n      2019.000000\n      7.000000\n      2020.000000\n      5.000000\n      NaN\n      0.000000\n      1.000000\n      1.000000\n      0.000000\n      1.333333\n      1.333333\n      NaN\n      1.333333\n      12.000000\n      4.000000\n      33.266667\n      0.096667\n      0.276667\n      141.096096\n      0.333333\n      0.000000\n      0.000000\n      1.233333\n      1.133333\n      0.096667\n      -0.033333\n      -0.033333\n      4.000000\n      2.666667\n      70.000000\n      0.333333\n      1.266667\n      0.033333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      6.333333\n      17.500000\n      40.133333\n      23.666667\n      4.000000\n      51.216667\n      41.966667\n      7.333333\n      70.833333\n      53.866667\n      8.666667\n      0.666667\n      6.533333\n      0.666667\n      14.200000\n      369.666667\n      77.533333\n      1973.299213\n      674.203472\n      40.902674\n      87.033333\n      41.918119\n      84.733333\n      15.216435\n      56.633333\n      1.000000\n      0.833333\n      8.666667\n      7.505258\n      2.080172\n      0.499002\n      8.344641\n      89.807127\n      10.192873\n      2.438150\n      0.155280\n      15.107914\n      2.891076\n      2.442379\n      1.030131\n      0.414938\n      0.326731\n      0.052673\n      64.054440\n      13.965784\n      21.676691\n      27.017143\n      59.397669\n      4.179519\n      4.393352\n      1.312062\n      78.145767\n      0.312215\n      1.833579\n      2.418674\n      2.476006\n      18.666667\n      13.000000\n      1.666667\n      1.000000\n      1.000000\n      1.000000\n      0.333333\n      2.000000\n      1.333333\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      17.666667\n      60.606061\n      50.000000\n      37.500000\n      11.764706\n      33.333333\n      36.333333\n      10.333333\n      148.666667\n      29.500000\n      34.416938\n      43.190925\n      21.661853\n      16.000000\n      23.076923\n      0.000000\n      76.923077\n      12.333333\n      24.333333\n      0.333333\n      49.333333\n      598.166667\n      10.955386\n      33.229361\n      46.543912\n      25.917765\n      3.800716\n      92.104505\n      9.333333\n      16.333333\n      58.266667\n      10.333333\n      0.666667\n      365.000000\n      1889.166667\n      53.272788\n      10.807099\n      3.312348\n      1.047120\n      3.311526\n      3.150893\n      447.000000\n      369.666667\n      82.966667\n      33.000000\n      1.666667\n      0.000000\n      0.000000\n      12.333333\n      12.000000\n      1.666667\n      11.666667\n      12.333333\n      10.666667\n      0.000000\n      0.000000\n      0.000000\n      89.666667\n      18.666667\n      18.666667\n      49.866667\n      NaN\n    \n    \n      75%\n      29.000000\n      23.000000\n      NaN\n      0.666667\n      1.666667\n      2.000000\n      NaN\n      1.666667\n      14.333333\n      5.000000\n      39.833333\n      0.136667\n      0.400000\n      174.814815\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.600000\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.608333\n      49.875000\n      9.000000\n      88.900000\n      63.800000\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      462.666667\n      81.866667\n      2046.497928\n      761.944411\n      43.321740\n      89.300000\n      44.501404\n      88.008333\n      17.192269\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      8.377245\n      2.488849\n      0.704380\n      9.353610\n      91.678107\n      11.947923\n      2.967121\n      0.259875\n      18.066159\n      3.434564\n      2.904000\n      1.275412\n      0.628931\n      0.495488\n      0.121175\n      70.360031\n      16.085472\n      27.074844\n      31.353094\n      64.326950\n      5.348022\n      5.296737\n      1.594533\n      82.279813\n      0.464769\n      2.369317\n      3.088833\n      2.916504\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      65.724070\n      56.818182\n      43.083554\n      15.733083\n      39.404609\n      42.108333\n      12.333333\n      168.083333\n      32.166667\n      38.637570\n      45.792658\n      25.485027\n      18.000000\n      29.166667\n      0.000000\n      82.012821\n      15.666667\n      29.666667\n      0.333333\n      56.666667\n      684.416667\n      13.116066\n      37.014643\n      49.525891\n      28.669936\n      4.423012\n      93.340426\n      11.333333\n      19.000000\n      64.233333\n      12.333333\n      1.000000\n      450.541667\n      2321.083333\n      55.817291\n      12.157871\n      3.783117\n      1.351732\n      4.127864\n      3.906409\n      537.666667\n      462.666667\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n      2020.000000\n      11.000000\n      2021.000000\n      6.000000\n      NaN\n      1.000000\n      2.000000\n      2.000000\n      0.666667\n      1.666667\n      2.000000\n      NaN\n      1.666667\n      14.333333\n      5.000000\n      39.833333\n      0.136667\n      0.400000\n      174.685847\n      0.666667\n      0.333333\n      0.333333\n      1.633333\n      1.500000\n      0.116667\n      0.333333\n      0.333333\n      5.000000\n      3.666667\n      80.600000\n      0.333333\n      1.733333\n      0.300000\n      0.333333\n      0.333333\n      0.000000\n      0.000000\n      8.666667\n      22.333333\n      48.008333\n      27.333333\n      5.000000\n      66.600000\n      49.866667\n      9.000000\n      88.900000\n      63.800000\n      10.666667\n      1.000000\n      11.100000\n      1.000000\n      16.233333\n      463.000000\n      81.875000\n      2046.262466\n      761.837938\n      43.322443\n      89.300000\n      44.500754\n      88.008333\n      17.189260\n      63.400000\n      1.333333\n      1.133333\n      10.666667\n      8.378284\n      2.488688\n      0.704225\n      9.352675\n      91.692036\n      11.945364\n      2.965807\n      0.259898\n      18.066159\n      3.433541\n      2.902260\n      1.275691\n      0.628931\n      0.496003\n      0.121230\n      70.360031\n      16.080614\n      27.056263\n      31.353094\n      64.338108\n      5.347347\n      5.295715\n      1.594285\n      82.292768\n      0.464563\n      2.369200\n      3.087634\n      2.916504\n      23.000000\n      17.000000\n      2.333333\n      1.666667\n      1.333333\n      1.333333\n      0.666667\n      3.000000\n      2.000000\n      0.333333\n      0.333333\n      0.333333\n      0.333333\n      0.000000\n      20.000000\n      65.714286\n      56.756757\n      43.103448\n      15.733083\n      39.393939\n      42.100000\n      12.333333\n      168.083333\n      32.166667\n      38.637570\n      45.795794\n      25.485027\n      18.000000\n      29.090909\n      0.000000\n      82.051282\n      15.666667\n      29.666667\n      0.333333\n      56.666667\n      684.750000\n      13.116066\n      37.014643\n      49.526726\n      28.669936\n      4.423812\n      93.342347\n      11.333333\n      19.000000\n      64.233333\n      12.333333\n      1.000000\n      450.666667\n      2322.416667\n      55.825288\n      12.158055\n      3.783784\n      1.351732\n      4.125392\n      3.905096\n      538.000000\n      463.000000\n      86.300000\n      40.666667\n      2.000000\n      0.000000\n      0.000000\n      14.000000\n      13.666667\n      2.333333\n      14.000000\n      15.666667\n      12.333333\n      0.333333\n      0.333333\n      0.000000\n      97.666667\n      22.666667\n      23.000000\n      54.000000\n      NaN\n    \n    \n      max\n      38.000000\n      31.000000\n      NaN\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      708.000000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      18.666667\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      91.066667\n      2398.063380\n      1296.830986\n      54.207263\n      95.100000\n      52.490660\n      94.633333\n      25.879917\n      83.633333\n      5.000000\n      2.833333\n      21.666667\n      13.935970\n      4.793757\n      2.348066\n      14.285714\n      96.042003\n      21.042831\n      5.673759\n      1.083032\n      30.942092\n      6.671900\n      5.632716\n      2.524698\n      2.195390\n      1.541002\n      0.920680\n      84.874640\n      26.916376\n      47.310513\n      49.404117\n      78.316327\n      11.080836\n      10.986965\n      3.247863\n      91.125642\n      2.006689\n      5.189189\n      6.269113\n      4.973822\n      46.333333\n      38.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      91.666667\n      79.487179\n      62.790698\n      42.857143\n      71.428571\n      66.266667\n      25.333333\n      268.333333\n      45.566667\n      58.685446\n      56.675063\n      48.812095\n      30.666667\n      54.838710\n      7.894737\n      100.000000\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      25.899281\n      55.932203\n      63.639323\n      44.711111\n      8.444444\n      96.594982\n      24.333333\n      36.333333\n      87.166667\n      25.666667\n      4.666667\n      746.333333\n      4209.000000\n      64.982456\n      18.909306\n      6.168549\n      3.206651\n      9.473684\n      9.362280\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      1.000000\n      0.666667\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN\n      2021.000000\n      12.000000\n      2022.000000\n      6.000000\n      NaN\n      9.000000\n      9.000000\n      9.000000\n      5.333333\n      5.666667\n      5.666667\n      NaN\n      5.666667\n      27.666667\n      11.666667\n      75.000000\n      0.500000\n      1.000000\n      708.000000\n      2.333333\n      1.666667\n      1.666667\n      3.833333\n      3.733333\n      0.240000\n      2.400000\n      2.400000\n      13.000000\n      8.000000\n      100.000000\n      1.333333\n      3.933333\n      1.600000\n      2.000000\n      2.000000\n      1.000000\n      0.666667\n      17.666667\n      42.000000\n      95.233333\n      50.333333\n      10.666667\n      100.000000\n      71.666667\n      18.666667\n      100.000000\n      85.850000\n      21.333333\n      3.666667\n      44.766667\n      3.666667\n      40.666667\n      846.333333\n      91.066667\n      2398.063380\n      1296.830986\n      54.207263\n      95.100000\n      52.490660\n      94.633333\n      25.879917\n      83.633333\n      5.000000\n      2.833333\n      21.666667\n      13.935970\n      4.793757\n      2.348066\n      14.285714\n      96.042003\n      21.042831\n      5.673759\n      1.083032\n      30.942092\n      6.671900\n      5.632716\n      2.524698\n      2.195390\n      1.541002\n      0.920680\n      84.874640\n      26.916376\n      47.310513\n      49.404117\n      78.316327\n      11.080836\n      10.986965\n      3.247863\n      91.125642\n      2.006689\n      5.189189\n      6.269113\n      4.973822\n      46.333333\n      38.000000\n      5.333333\n      5.666667\n      5.666667\n      3.666667\n      2.333333\n      10.666667\n      8.666667\n      1.333333\n      2.000000\n      1.333333\n      1.666667\n      1.000000\n      32.000000\n      91.666667\n      79.487179\n      62.790698\n      42.857143\n      71.428571\n      66.266667\n      25.333333\n      268.333333\n      45.566667\n      58.685446\n      56.675063\n      48.812095\n      30.666667\n      54.838710\n      7.894737\n      100.000000\n      31.666667\n      62.666667\n      2.666667\n      78.333333\n      1024.000000\n      25.899281\n      55.932203\n      63.639323\n      44.711111\n      8.444444\n      96.594982\n      24.333333\n      36.333333\n      87.166667\n      25.666667\n      4.666667\n      746.333333\n      4209.000000\n      64.982456\n      18.909306\n      6.168549\n      3.206651\n      9.473684\n      9.362280\n      914.666667\n      846.333333\n      94.300000\n      78.333333\n      5.000000\n      1.000000\n      0.666667\n      22.333333\n      22.000000\n      7.000000\n      26.666667\n      31.666667\n      19.666667\n      1.666667\n      2.000000\n      1.000000\n      126.666667\n      50.333333\n      45.333333\n      75.766667\n      NaN"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches.html#prepare-the-data",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches.html#prepare-the-data",
    "title": "ThomasHSimm",
    "section": "Prepare the data",
    "text": "Prepare the data\nBasically just make numerical data normalised, categorical data encoded and split into train and validation sets\n\n#toggle-hide\ndef do_pre_proc(dfAll,target = 'NetScore_x'):\n    \n    dfAll=dfAll.iloc[20:,:]\n\n    if target == 'NetScore_x':\n        dfAll=dfAll.drop(columns=['Win_x','opponent_y','team_y','GoalsAgainst_x','GoalsFor_x'])\n    elif target=='Win_x':\n        dfAll=dfAll.drop(columns=['NetScore_x','opponent_y','team_y','GoalsAgainst_x','GoalsFor_x'])\n        dfAll[target]=dfAll[target].map({'W':2,'D':1,'L':0})\n    else:\n        return 'error'\n    \n    \n    dfAll=dfAll[[c for c in dfAll if c!=target]+[target]]\n    \n    features_cat=[x for x in dfAll if dfAll[x].dtype=='O']\n    features_num = [x for x in dfAll.columns if x != target and dfAll[x].dtype!='O' ]\n    \n    preprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n    (OneHotEncoder(), features_cat),\n    )\n      \n    dfAll=dfAll.fillna(0)\n    cond = dfAll.season<2021\n    \n    predictors = [x for x in dfAll.columns if x != target ]\n    X=dfAll.copy()\n    \n    y=X.pop(target)\n    X = preprocessor.fit_transform(X)\n    \n    \n    X_train=X[cond]\n    X_valid=X[~cond]\n    y_train = y[cond]\n    y_valid = y[~cond]\n\n    return X_train, X_valid, y_train, y_valid\n\n\nX_train, X_valid, y_train, y_valid = do_pre_proc(dfAll,'Win_x')"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches.html#xgboost",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches.html#xgboost",
    "title": "ThomasHSimm",
    "section": "XGBoost",
    "text": "XGBoost\nGradient Boosting\nGradient boosting is a method that goes through cycles to iteratively add models into an ensemble.\nIt begins by initializing the ensemble with a single model, whose predictions can be pretty naive. (Even if its predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.)\nThen, we start the cycle:\n\nFirst, we use the current ensemble to generate predictions for each observation in the dataset. To make a prediction, we add the predictions from all models in the ensemble.\nThese predictions are used to calculate a loss function (like mean squared error, for instance).\nThen, we use the loss function to fit a new model that will be added to the ensemble. Specifically, we determine model parameters so that adding this new model to the ensemble will reduce the loss. (Side note: The “gradient” in “gradient boosting” refers to the fact that we’ll use gradient descent on the loss function to determine the parameters in this new model.)\nFinally, we add the new model to ensemble, and …\n… repeat!\n\nGBoost stands for extreme gradient boosting, which is an implementation of gradient boosting with several additional features focused on performance and speed\n\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X_train,y_train)\n\naccuracy_score(y_train,model_rf.predict(X_train)),accuracy_score(y_valid,model_rf.predict(X_valid))\n\n(1.0, 0.49868073878627966)\n\n\n\nmodel_XGB = XGBClassifier()\nmodel_XGB.fit(X_train,y_train)\n\naccuracy_score(y_train,model_XGB.predict(X_train)),accuracy_score(y_valid,model_XGB.predict(X_valid))\n\n(1.0, 0.5092348284960422)\n\n\n\nParameter tuning\nn_estimators specifies how many times to go through the modeling cycle described above. It is equal to the number of models that we include in the ensemble.\n\nToo low a value causes underfitting, which leads to inaccurate predictions on both training data and test data.\nToo high a value causes overfitting, which causes accurate predictions on training data, but inaccurate predictions on test data (which is what we care about).\n\nTypical values range from 100-1000\nearly_stopping_rounds offers a way to automatically find the ideal value for n_estimators. Early stopping causes the model to stop iterating when the validation score stops improving, even if we aren’t at the hard stop for n_estimators. Setting early_stopping_rounds=5 is a reasonable choice. In this case, we stop after 5 straight rounds of deteriorating validation scores.\nlearning_rate\nInstead of getting predictions by simply adding up the predictions from each component model, we can multiply the predictions from each model by a small number (known as the learning rate) before adding them in.\nThis means each tree we add to the ensemble helps us less. So, we can set a higher value for n_estimators without overfitting. If we use early stopping, the appropriate number of trees will be determined automatically.\nIn general, a small learning rate and large number of estimators will yield more accurate XGBoost models, though it will also take the model longer to train since it does more iterations through the cycle. As default, XGBoost sets learning_rate=0.1\n\ndef do_model(n_estimators,learning_rate):\n    model_XGB = XGBClassifier(n_estimators=n_estimators,\n             learning_rate=learning_rate,\n             early_stopping_rounds=10,\n             )\n    \n    model_XGB.fit(X_train,y_train,\n             eval_set=[(X_valid, y_valid)],\n             verbose=False)\n\n    acc_train=accuracy_score(y_train,model_XGB.predict(X_train))\n    acc_valid=accuracy_score(y_valid,model_XGB.predict(X_valid))\n    \n    return acc_train, acc_valid\n\nlearning_rate=1e-4\nn_estimators=[100,250,500,1_000,1500,2_500,5_000,10_000]\n\nscore=[]\nfor n in n_estimators:\n    score.append( do_model(n,learning_rate) )\n\n\nscore=np.array(score)\nplt.plot(n_estimators,score,'o-')\nplt.legend(['train','validation'])\nnp.max(score[:,1])\n\n0.5290237467018469\n\n\n\n\n\n\nn_estimator=n_estimators[np.argmax(score[:,1])]\nmodel_XGB = XGBClassifier(n_estimators=n_estimator,\n             learning_rate=learning_rate,\n             early_stopping_rounds=10,\n             )\n    \nmodel_XGB.fit(X_train,y_train,\n         eval_set=[(X_valid, y_valid)],\n         verbose=False)\n\npred_XGB=model_XGB.predict(X_valid)\npred_XGB=[np.argmax(x) for x in pred_XGB ]"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches.html#deep-learning",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches.html#deep-learning",
    "title": "ThomasHSimm",
    "section": "Deep Learning",
    "text": "Deep Learning\nThis dataset is prone to lots of overfitting (bias) and also has a high ratio of numberof parameters to number of data points.\nTo get around the 2 issues: - model has a high dropout rate - a relatively high number of units (i.e. a wide neural network)\nFor more information see the kaggle notebook of keras binary EPL which goes over this in more detail for the binary issue.\n\ny_valid=pd.get_dummies(y_valid)\ny_train=pd.get_dummies(y_train)\n\ndrop_pc=0.8\nunits=512*2\nmodel=keras.Sequential([\n        layers.Dense(units,activation='relu',input_shape=[np.shape(X_train)[1]]),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(3,activation='softmax')\n        ])\n\nopt = keras.optimizers.Adam(learning_rate=0.0005)\nmodel.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    #loss='binary_crossentropy',#for binary classification 0-1\n    metrics=['accuracy'],\n)\n\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=40, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_accuracy',\n)\n\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=len(X_valid),\n    epochs=700,\n    callbacks=[early_stopping],\n    verbose=0, # hide the output because we have so many epochs\n)\n\n\nhistory_df = pd.DataFrame(history.history)\n\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_accuracy'].max()))\n\nBest Validation Loss: 1.0254\nBest Validation Accuracy: 0.5369\n\n\n\n\n\n\n\n\n\nepochs=history_df['val_accuracy'].argmax()\nmodel=keras.Sequential([\n        layers.Dense(units,activation='relu',input_shape=[np.shape(X_train)[1]]),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(units,activation='relu'),\n        layers.Dropout(drop_pc),\n        layers.Dense(3,activation='softmax')\n        ])\n\nopt = keras.optimizers.Adam(learning_rate=0.0005)\nmodel.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    #loss='binary_crossentropy',#for binary classification 0-1\n    metrics=['accuracy'],\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=len(X_valid),\n    epochs=epochs,\n    verbose=0, # hide the output because we have so many epochs\n)\n\n\npreds=model.predict(X_valid).argmax(axis=1)\ny_valid_=[np.argmax(y_valid.iloc[i,:]) for i in range(len(y_valid))]\nacc_nn=accuracy_score(y_valid_,preds)\n\nprint(f\"accuracy of nn model = {acc_nn:.3f}\")\n\naccuracy of nn model = 0.516"
  },
  {
    "objectID": "posts/2022-08-22-PredictingPremierLeagueMatches.html#ensembling",
    "href": "posts/2022-08-22-PredictingPremierLeagueMatches.html#ensembling",
    "title": "ThomasHSimm",
    "section": "Ensembling",
    "text": "Ensembling\nCombine the results of the two models\n\npreds_combo=(model.predict(X_valid)+ model_XGB.predict_proba(X_valid)).argmax(axis=1)\n\nacc_combo=accuracy_score(y_valid_,preds_combo)\n\nprint(f\"accuracy of combined model = {acc_combo:.3f}\")\n\naccuracy of combined model = 0.534"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#general",
    "href": "posts/2022-09-28-Tensorflow.html#general",
    "title": "ThomasHSimm",
    "section": "General",
    "text": "General\nLibrary websites:\nhttps://keras.io/\nhttps://www.tensorflow.org/"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#courses",
    "href": "posts/2022-09-28-Tensorflow.html#courses",
    "title": "ThomasHSimm",
    "section": "Courses",
    "text": "Courses\nI have tried both of the following courses: DeepLearning.AI TensorFlow Developer Professional Certificate and TensorFlow 2 for Deep Learning Specialization.\n\nDeepLearning.AI TensorFlow Developer Professional Certificate\nTensorFlow 2 for Deep Learning Specialization\n\nThe Tensorflow2 course is a bit longer and goes into more depth, although there are additional extended courses for the deeplearning one. The deeplearning one can be done within the current 7 days trail period of coursera. The Tensorflow2 course is tricky to do in this timeframe. This is due to more material, the harder coursework, and waiting for capstone projects to be marked.\nIn the end I only did the first course of Tensorflow2 as I found the tests had material that wasn’t explained within the course and I found the lectures lacking in detail and the instructors became increasingly boring. I gave up after getting to the capstone in course 2 (of 3) when they asked a question about an NLP network that was never explained anywhere. However, the coursework is a good challenge, so it may be worth doing the course for this alone and learning from other sources in addition to this one.\nI prefered the DeepLearning courses as they were more in depth and didn’t assume as much prior knowledge, and the presentation was better. I am currently working through the follow-up course TensorFlow: Advanced Techniques Specialization and given time will do the NLP and MLOps courses.\nSome Others:\nOne by Udacity Intro to TensorFlow for Deep Learning is being offered for free and looks okay too.\nTensorFlow example tutorials written as Jupyter notebooks and run directly in Google Colab—a hosted notebook environment that requires no setup. Click the Run in Google Colab button. Part of the TensorFlow resources."
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#resources",
    "href": "posts/2022-09-28-Tensorflow.html#resources",
    "title": "ThomasHSimm",
    "section": "Resources",
    "text": "Resources\n\nTensorFlow’s website recommendations\nFrançois Chollet\n\nHis book Deep Learning with Python, Second Edition can be read online.\n\nDeep learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville\n\navailable free online\n\nProbabilistic Programming & Bayesian Methods for Hackers\n\navailable online"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#model-creations",
    "href": "posts/2022-09-28-Tensorflow.html#model-creations",
    "title": "ThomasHSimm",
    "section": "Model creations",
    "text": "Model creations\nThe easiest way to create a model in Keras is through keras.Sequential, which creates a neural network as a stack of layers.\nSo in the examplel below - the 1st layer has units = 4 and input_shape=2 with a relu activation function - the 2nd layer has units = 3 with a relu activation function - the 3rd layer has units = 1\nThe 3rd layer is the output layer. Since there is no activation function this would be a regression problem to predict one value.\n\nFor non sequential models or with multiple inputs/outputs see functional API\n\nTabular Data\nhttps://www.kaggle.com/code/thomassimm/premier-league-predictions-using-tensorflow\n\nmodel = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(512//8,activation='relu'),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\n\n\nImage Data\n\nmodel = tf.keras.models.Sequential([ \n          tf.keras.layers.Convolution2D( 64,(3,3),activation='relu',input_shape=(28,28,1) ),\n          tf.keras.layers.MaxPool2D(2,2),\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(256//2,activation='relu'),\n          tf.keras.layers.Dense(1,activation='sigmoid') ])\n\n\n\nLanguage Data\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\n    model = tf.keras.Sequential([ \n        tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n        tf.keras.layers.GlobalAveragePooling1D(),\n        tf.keras.layers.Dense(24,activation='relu'),\n        tf.keras.layers.Dense(5,'softmax')\n    ])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#compile-the-model",
    "href": "posts/2022-09-28-Tensorflow.html#compile-the-model",
    "title": "ThomasHSimm",
    "section": "Compile the model",
    "text": "Compile the model\nTo compile the model, need to define the following:\n\nthe optimizer to use, i.e. how to update the parameters to improve model during fitting\nthe loss, i.e. what defines the goodness of the fit\nany metrics to record\n\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#evaluate-predict-the-model",
    "href": "posts/2022-09-28-Tensorflow.html#evaluate-predict-the-model",
    "title": "ThomasHSimm",
    "section": "Evaluate / Predict the model",
    "text": "Evaluate / Predict the model\ntest_loss, test_accuracy = model.evaluate(scaled_test_images,\ntf.keras.utils.to_categorical(test_labels),\nverbose=0)\nand more or less outputs depending on metrics used\npred = model.predict(X_sample)"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#saving-and-loading",
    "href": "posts/2022-09-28-Tensorflow.html#saving-and-loading",
    "title": "ThomasHSimm",
    "section": "Saving and Loading",
    "text": "Saving and Loading\n\nSaving / Loading weights\n\nmodel_weights_file='my_file'\n\nmodel.save_weights(model_weights_file)\n\nmodel.load_weights(model_weights_file)\n\n\n# All the model\n\nmodel.save('saved_model/my_model')\n\nnew_model = tf.keras.models.load_model('saved_model/my_model')"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#callbacks",
    "href": "posts/2022-09-28-Tensorflow.html#callbacks",
    "title": "ThomasHSimm",
    "section": "Callbacks",
    "text": "Callbacks\nwithin model.fit(....)\ncallbacks=[callback_function]\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n\nEarlyStopping\n\nto stop the model early if some conditions are met\n\nModelCheckpoint\n\nsave the model/model weights (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\nmain data stored similar to ‘.data-00000-of-00001’\nhttps://www.tensorflow.org/tutorials/keras/save_and_load#what_are_these_files\nCan give file names with variables using {}\n\nval_loss\nval_accuracy\nbatch\nepoch\n\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_binary_accuracy',\n)\n\nfilepath = os.path.join(cwd,'checkpoints_every_epoch/checkpoint.{epoch}.{batch}')\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n        save_weights_only=True,\n        save_best_only=True,\n        filepath=filepath,\n    )"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#overfitting-strategies",
    "href": "posts/2022-09-28-Tensorflow.html#overfitting-strategies",
    "title": "ThomasHSimm",
    "section": "Overfitting strategies",
    "text": "Overfitting strategies\n\nDropout\nThe idea behind dropout is to randomly drop out some fraction of a layer’s input units every step of training, making it much harder for the network to learn those spurious patterns in the training data that leads to overfitting.\nInstead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\nYou could also think about dropout as creating a kind of ensemble of networks like with RandomForests.\nExample useage, apply 30% dropout to the next layer\nlayers.Dropout(rate=0.3),\nlayers.Dense(16)\nExample taken from kaggle https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization\n\n\n\nBatch Normalization\nNormalization is important in neural networks, it can really significantly improve the results of the values of the input and output are between 0 and 1.\nIn contrast, it is not important in other models such as random forests. Hence, the input data is often normalised such as train_datagen = ImageDataGenerator(rescale=1./255.) in image models.\nSo if it is good to normalize the input data it can also be good to normalize the layers of the network. This can be done with a BatchNormalization layer.A batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.\nAs stated in https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization batchnorm: - batchnorm is most often added as an aid to the optimization process - but it can sometimes also help prediction performance - Models with batchnorm tend to need fewer epochs to complete training. - And can fix various problems that can cause the training to get “stuck”. - it can be used at almost any point in a network.\nlayers.Dense(16, activation='relu'),\nlayers.BatchNormalization(),\n… or between a layer and its activation function:\nlayers.Dense(16),\nlayers.BatchNormalization(),\nlayers.Activation('relu'),\n… Or if you add it as the first layer of your network it can act as a kind of adaptive preprocessor like Sci-Kit Learn’s StandardScaler."
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#multiple-inputs-and-outputs",
    "href": "posts/2022-09-28-Tensorflow.html#multiple-inputs-and-outputs",
    "title": "ThomasHSimm",
    "section": "Multiple inputs and outputs",
    "text": "Multiple inputs and outputs\n3 inputs and 2 outputs. Simple model\nInputs: - temp_train - nocc_train - lumbp_train\nOutputs: - out1_train - out2_train\nThings to note: - inputs in the model is a list of the Input() parts - concatentate is used with the input list to provide input to the next layers of the model - outputs in the model is a list of the output layers - When compiling use dictionary to set loss and metrics to each output - or lists ['binary_crossentropy','binary_crossentropy'] - When fitting, for the inputs/outputs either: - provide a list of the inputs [temp_train,nocc_train, lumbp_train] - give as a dict {'layer_name':variable_name}\n\n## Functional: multiple inputs\n# N.B. lowercase 'c' concatenate\nimport tensorflow as tf \nfrom tensorflow.keras.layers import Input, Dense, concatenate\ninput_shape=(1,)\n\n# get individual inputs\ninputs_temp = Input(shape=input_shape,name='temp')\ninputs_nocc = Input(shape=input_shape,name='nocc')\ninputs_lumbp = Input(shape=input_shape,name='lumbp')\n\n# combine them\ninput_list = [inputs_temp,inputs_nocc,inputs_lumbp]\ninput_layer =concatenate(input_list)\n\n# add inputs to the model for two outputs\noutput_pred1  = Dense(2,activation='sigmoid',name='out_1')(input_layer)\noutput_pred2 = Dense(2,activation='sigmoid',name='out_2')(input_layer)\n\n# output layer\noutput_list = [output_pred1, output_pred2]\n\n# create the model object\nmodel = tf.keras.Model(inputs=input_list, outputs=output_list )\n\n# show the model\nmodel.summary()\n\n# Compile\nmodel.compile(\n        optimizer='SGD',\n        loss={'out_1':'binary_crossentropy',\n              'out_2':'binary_crossentropy'},\n        metrics={'out_1':['accuracy'],\n                 'out_2':['accuracy']},\n        loss_weights=[1,0.2]\n        )\n\ntf.keras.utils.plot_model(model)\n\n\n# Define training inputs and outputs\ninputs_train = {'temp': temp_train, 'nocc': nocc_train, 'lumbp': lumbp_train}\noutputs_train = {'out_1': out1_train, 'out_2': out2_train}\n\n# fit the model\nmodel.fit(inputs_train,outputs_train)"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#inception-images",
    "href": "posts/2022-09-28-Tensorflow.html#inception-images",
    "title": "ThomasHSimm",
    "section": "Inception (images)",
    "text": "Inception (images)\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#summary-info-of-model",
    "href": "posts/2022-09-28-Tensorflow.html#summary-info-of-model",
    "title": "ThomasHSimm",
    "section": "Summary / info of model",
    "text": "Summary / info of model\nmodel.summary()\nGet summary of the model"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#class-or-function---metrics-and-losses",
    "href": "posts/2022-09-28-Tensorflow.html#class-or-function---metrics-and-losses",
    "title": "ThomasHSimm",
    "section": "Class or Function - Metrics and Losses",
    "text": "Class or Function - Metrics and Losses\nIn general, classes use camel formatting CategoricalAccuracy whereas function use underscores and lower case categorical_accuracy and sometimes initials MAE\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#low-level-handling-of-metrics",
    "href": "posts/2022-09-28-Tensorflow.html#low-level-handling-of-metrics",
    "title": "ThomasHSimm",
    "section": "Low level handling of metrics",
    "text": "Low level handling of metrics\n\nmetric.update_state() to accumulate metric stats after each batch\nmetric.result get current value of metric to display\nmetric.reset_state() to reset metric value typically at the end of epoch"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#categorical-binary-versus-multiple",
    "href": "posts/2022-09-28-Tensorflow.html#categorical-binary-versus-multiple",
    "title": "ThomasHSimm",
    "section": "Categorical: Binary versus Multiple",
    "text": "Categorical: Binary versus Multiple\nFor categorical data there is a slight difference between if there are only 2 categories or more.\nGoing from binary to multiple: - We need to change activation in model from sigmoid to softmax in final Dense layer - Change loss function from binary_crossentropy to categorical_crossentropy in compile - Making data one-hot encoded, i.e. columns for each outcome - Or use SparseCategoricalCrossentropy\n\nmodel_binary = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\nmodel_multi = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(4,activation='softmax')        \n    ])\n\n\nmodel_binary.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\nmodel_multi.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\n\n# One-hot encoding method\n\ny_binary =[1,0,0,0,0,0,1,1,1,1,0,1,0,1]\n\ny_multi=[1,2,4,6,1,3,4,2,4,2,5,2,1,4,2,1]\ny_multi=tf.keras.utils.to_categorical(y_multi)\ny_multi\n\narray([[0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)\n\n\nAlternatively, with output data like [0, 1, 4, 0, 2, 3, 3, 0, …]\nuse: - SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(\n                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer='adam',\n                 metrics=['accuracy'])"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#learning-rate",
    "href": "posts/2022-09-28-Tensorflow.html#learning-rate",
    "title": "ThomasHSimm",
    "section": "Learning rate",
    "text": "Learning rate\nFind the best learning rate by using callbacks\nThe learning rate to use on the data below would be where the loss is low (y-axis) but not too close to where it increases or is unstable.\nSo for this on the downward part of the curve between 10E-6 and 10E-5\n\n# Set the learning rate scheduler\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 20) )\n    \n# Set the training parameters\nmodel_tune.compile(loss=\"mse\", optimizer=optimizer)\n    \n# train the model\nhistory = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])\n\n# plot the results\n# Define the learning rate array\nlrs = 1e-8 * (10 ** (np.arange(100) / 20))\n\n# Plot the loss in log scale\nplt.semilogx(lrs, history.history[\"loss\"])"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#lambda-functions",
    "href": "posts/2022-09-28-Tensorflow.html#lambda-functions",
    "title": "ThomasHSimm",
    "section": "lambda functions",
    "text": "lambda functions\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda\ntf.keras.layers.Lambda(     function, output_shape=None, mask=None, arguments=None, **kwargs )\nAdd a function that works on the data within the model\n\n# expand the dimensions\ntf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n                      input_shape=[window_size])\n\n# make the output larger (can be useful if predicting to large values, but previous layer have activation function so values are close to 1)\ntf.keras.layers.Lambda(lambda x: x * 100.0)"
  },
  {
    "objectID": "posts/2022-09-28-Tensorflow.html#force-cpugpu",
    "href": "posts/2022-09-28-Tensorflow.html#force-cpugpu",
    "title": "ThomasHSimm",
    "section": "Force CPU/GPU",
    "text": "Force CPU/GPU\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\n\n# Check available CPU/GPU devices\n\nprint(tf.config.list_physical_devices('CPU'))\n\nprint(tf.config.list_physical_devices('GPU'))\n\nwith tf.device(\"CPU:0\"):\n    model.fit(....)\n    \nwith tf.device(\"GPU:0\"):\n    model.fit(....)"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2-Copy1.html#modifications",
    "href": "posts/2022-10-07-Tensorflow-2-Copy1.html#modifications",
    "title": "ThomasHSimm",
    "section": "Modifications",
    "text": "Modifications\nSay we want to run differently on training and predicting by adding a dropout layer in init then call it if Training = True\ndef call(self,inputs,training=True):\n,    x = self.Dense_1(inputs)\n,    if training:\n,         x = self.Dropout_1(x)\n,    return self.Dense_2(x)\nhttps://www.tensorflow.org/guide/keras/custom_layers_and_models#best_practice_deferring_weight_creation_until_the_shape_of_the_inputs_is_known"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2-Copy1.html#create-the-custom-model",
    "href": "posts/2022-10-07-Tensorflow-2-Copy1.html#create-the-custom-model",
    "title": "ThomasHSimm",
    "section": "Create the custom model",
    "text": "Create the custom model\nSame as above but using the custom layers instead\n\n# Build the model using custom layers with the model subclassing API\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Layer, Softmax\n\nclass MyModel(Model):\n\n    def __init__(self, units_1, input_dim_1, units_2, units_3):\n        super(MyModel, self).__init__()\n        # Define layers\n        self.layer_1 = MyLayer(units_1, input_dim_1)  \n        self.dropout_1 = MyDropout(0.5)\n        self.layer_2 = MyLayer(units_2, units_1)\n        self.dropout_2 = MyDropout(0.5)\n        self.layer_3 = MyLayer(units_3, units_2)\n        self.softmax = Softmax()\n        \n    def call(self, inputs):\n        # Define forward pass\n        x = self.layer_1(inputs)\n        x = tf.nn.relu(x)\n        x = self.dropout_1(x)\n        x = self.layer_2(x)\n        x = tf.nn.relu(x)\n        x = self.dropout_2(x)\n        x = self.layer_3(x)\n        \n        return self.softmax(x)\n\n\n# Instantiate a model object\n\nmodel = MyModel(64,10000,64,46)\nprint(model(tf.ones((1, 10000))))\nprint()\nmodel.summary()\n\ntf.Tensor(\n[[0.00593624 0.00634939 0.05267304 0.00782295 0.01955794 0.0013299\n  0.00763652 0.22506231 0.04023628 0.00110034 0.02134436 0.01490009\n  0.00174251 0.01910679 0.05380287 0.00071206 0.0641818  0.00902538\n  0.00163135 0.00276065 0.00214337 0.00366833 0.11546794 0.00362498\n  0.03105447 0.00112369 0.0003199  0.02285093 0.00455131 0.00351223\n  0.01460814 0.03380786 0.01641758 0.05988773 0.05288981 0.00567744\n  0.01013041 0.02062218 0.01893481 0.00864016 0.00199537 0.00243362\n  0.00046626 0.00392747 0.00084952 0.00348179]], shape=(1, 46), dtype=float32)\n\nModel: \"my_model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmy_layer_28 (MyLayer)        multiple                  640064    \n_________________________________________________________________\nmy_dropout_6 (MyDropout)     multiple                  0         \n_________________________________________________________________\nmy_layer_29 (MyLayer)        multiple                  4160      \n_________________________________________________________________\nmy_dropout_7 (MyDropout)     multiple                  0         \n_________________________________________________________________\nmy_layer_30 (MyLayer)        multiple                  2990      \n_________________________________________________________________\nsoftmax_3 (Softmax)          multiple                  0         \n=================================================================\nTotal params: 647,214\nTrainable params: 647,214\nNon-trainable params: 0\n_________________________________________________________________"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2.html#dataset-generators",
    "href": "posts/2022-10-07-Tensorflow-2.html#dataset-generators",
    "title": "ThomasHSimm",
    "section": "Dataset generators",
    "text": "Dataset generators\nHave you ever had to work with a dataset so large that it overwhelmed your machine’s memory? Or maybe you have a complex function that needs to maintain an internal state every time it’s called, but the function is too small to justify creating its own class. In these cases and more, generators and the Python yield statement are here to help\nhttps://realpython.com/introduction-to-python-generators/\nHow yield works:\n\ndef do_yield():\n    for i in range(20):\n        yield i\n        \ngot_yield =  do_yield()\n\nprint(got_yield)\nprint(next(got_yield))\nprint(next(got_yield))\n\nnext(got_yield)\n\nprint(next(got_yield))\ngot_yield\nprint(next(got_yield))\n\nWhen datasets are large and won’t fit into memory, a way to handle this is to use detaset generators. Where data is fed into the model without loading it into memory at once.Each time we iterate the generator, it yields the next value in the series.\nAn example is below. The function takes a path to a file but returns a yield statement, or a data generator, and not a line of the data.\nAs above x,y = next(text_datagen) gets the next line of the text.\nThis can be used when fitting to the model using model.fit_generator(text_datagen)\nSee also load images.\n\ndef get_data(filepath):\n    with open(filepath,'r') as f:\n        for row in f:\n            x=row[0]\n            y=row[1]\n            yield (x,y)\n            \ntext_datagen = get_data('file.txt')\n\nmodel.fit_generator(text_datagen, steps_per_epoch=1000, epochs=5)\n\n\n# or something more practical:\ndef get_generator(features, labels, batch_size=1):\n    for n in range(int(len(features)/batch_size)):\n        x = features[n*batch_size: (n+1)*batch_size]\n        y = labels[n*batch_size: (n+1)*batch_size]\n        yield (x,y)"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2.html#the-dataset-class",
    "href": "posts/2022-10-07-Tensorflow-2.html#the-dataset-class",
    "title": "ThomasHSimm",
    "section": "The dataset Class",
    "text": "The dataset Class\n\nx=np.random.randint(0,255,(100,20,2,2))\ny=np.random.randint(0,4,size=(100,1))\n\ndataset_1 = tf.data.Dataset.from_tensor_slices(x)\n\nprint(\">>\",dataset_1.element_spec)\nprint('>> N.B. first dimension inetrpreted as batch size')\n\ndataset_2 = tf.data.Dataset.from_tensor_slices(y)\nprint(\">>\",dataset_2.element_spec)\n\ndataset_zipped = tf.data.Dataset.zip((dataset_1,dataset_2))\nprint(\">>\",dataset_zipped.element_spec)\n\ndataset_comb = tf.data.Dataset.from_tensor_slices((x,y))\nprint(\">>\",dataset_comb.element_spec)\n\n>> TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None)\n>> N.B. first dimension inetrpreted as batch size\n>> TensorSpec(shape=(1,), dtype=tf.int32, name=None)\n>> (TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))\n>> (TensorSpec(shape=(20, 2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))\n\n\nCan access the values by iterating\n\ndef check3s(dataset_comb):\n    dataset_iter = iter(dataset_comb)\n    for i,x in enumerate(dataset_iter):\n        if tf.squeeze(x[1])==3:\n            print('Has 3s')\n            return\n    return 'no 3s'\ncheck3s(dataset_comb)\n\nHas 3s\n\n\n\nFilter\nFilter certain values\n\ndef label_func(image,label):\n    return tf.squeeze(label) != 3\n\ndataset_comb = dataset_comb.filter(label_func)\n\ncheck3s(dataset_comb)\n\n'no 3s'\n\n\n\n\nMap\nModify values. Below creates one-hot encoding\n\ndef map_func(image, x):\n    return (image,tf.one_hot(x,depth=3) )\ndataset_comb_2=dataset_comb.map(map_func)\n\nfor i,x in enumerate(dataset_comb):\n    if i<5:\n        print(i,x[1].numpy())    \n    else:\n        break\n        \nfor i,x in enumerate(dataset_comb_2):\n    if i<5:\n        print(i,x[1].numpy())    \n    else:\n        break\n\n0 [0]\n1 [1]\n2 [2]\n3 [2]\n4 [2]\n0 [[1. 0. 0.]]\n1 [[0. 1. 0.]]\n2 [[0. 0. 1.]]\n3 [[0. 0. 1.]]\n4 [[0. 0. 1.]]\n\n\n\ndataset.batch(20), drop_remainder=True set batch size to 16 and remove any remaining samples if not divisible\ndataset.repeat(10) set the number of epochs. No value inside is indefinitely\ndataset.shuffle(100) shuffle the data, no of sample in the buffer\ndataset.filter(function_name) filter the values use lambda or a function that returns a boolean\ndataset.map(func_name) transform the values\n\ne.g. dataset.map(lambda x:x*2) doubles all values\n\ndataset.take(1) take a value from the dataset"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2.html#tensor-math",
    "href": "posts/2022-10-07-Tensorflow-2.html#tensor-math",
    "title": "ThomasHSimm",
    "section": "Tensor Math",
    "text": "Tensor Math\n\nimport tensorflow.keras.backend as K\n\nx = K.arange(0,10)\ny = K.square(x)\ny_mean = K.mean(y)\n\nprint(f\"x = {x},\\ny = {y},\\ny_mean = {y_mean}\")\n\nx = [0 1 2 3 4 5 6 7 8 9],\ny = [ 0  1  4  9 16 25 36 49 64 81],\ny_mean = 28\n\n\n\n#hide-input\nprint(f\"tf.add([1,2],[3,4]) = {tf.add([1,2],[3,4])}\\n\")\nprint(\"Or with operator overloading\")\nprint(f\"tf.Variable([1,2])+tf.Variable([3,4]) = {tf.Variable([1,2])+tf.Variable([3,4])}\\n\")\nprint(f\"x = tf.Variable([[1,2],[3,4]])\\n\")\nx=tf.Variable([[1,2],[3,4]])\nprint(f\"tf.square(x) = {tf.square(x)}\\n\")\nprint(\"Reduces dimension by adding up components\")\nprint(f\"tf.reduce_sum(x) = {tf.reduce_sum(x)}\\n\")\n      \n\ntf.add([1,2],[3,4]) = [4 6]\n\nOr with operator overloading\ntf.Variable([1,2])+tf.Variable([3,4]) = [4 6]\n\nx = tf.Variable([[1,2],[3,4]])\n\ntf.square(x) = [[ 1  4]\n [ 9 16]]\n\nReduces dimension by adding up components\ntf.reduce_sum(x) = 10"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2.html#tensor-operations",
    "href": "posts/2022-10-07-Tensorflow-2.html#tensor-operations",
    "title": "ThomasHSimm",
    "section": "Tensor Operations",
    "text": "Tensor Operations\n\nEvaluated immediately\nTensorFlow supports two types of code execution, graph-based where all of the data and ops are loaded into a graph before evaluating them within a session, or eager based where all of the code is executed line by line.\nIf eager mode was off, tensor would not be evaluated so\nx_sq = tf.square(2)\nprint(x_sq)\nthe print statement would just show details of the tensor object, such as its name, shape, data type and all that but it would not yet store the number 4 as a value.\nOtherwise values are evaluated immediately in custom eager mode = On\n\n\nBroadcasting\nBroadcasting is where adding or subtracting two tensors of different dimensions is handled in a way where the tensor with fewer dimensions is replicated to match the dimensions of the tensor with more dimensions.\na = tf.constant([[1,2],[3,4]])\n>>tf.add(a,1)\n=tf.Tensor([[2,3],[4,5]])\nOr overloading can utilise Python syntax such as\n>>a ** 2\n=tf.Tensor([[1,4],[9,16]])\nOr using numpy math operations. TensorFlow will convert the tensor objects a and b into ndarrays, and then pass those ndarrays to the np.cos function.\n>>np.cos(a)\n=array([[ 0.54030231, -0.41614684],        [-0.9899925 , -0.65364362]])\nDon’t need to preconvert from the ndarray data type into a tensor data type. TensorFlow handles this automatically.\nndarray = np.ones([3,3])\n=[[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]]\ntf.multiply(ndarray,3)\n=tf.Tensor( [[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]], shape=(3,3), dtype=float64)\nTensors can be easily converted back to numpy arrays using tensor.numpy()"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2.html#simple-example-of-using-gradient-tape-to-calculate-gradient-of-a-function",
    "href": "posts/2022-10-07-Tensorflow-2.html#simple-example-of-using-gradient-tape-to-calculate-gradient-of-a-function",
    "title": "ThomasHSimm",
    "section": "Simple example of using gradient tape to calculate gradient of a function",
    "text": "Simple example of using gradient tape to calculate gradient of a function\n\ndef myfunc(x):\n    return tf.math.sin(x) + tf.math.exp(x/3)\n\nw = tf.Variable(np.arange(0, np.pi*2,.2))\nwith tf.GradientTape() as tape:\n    loss = myfunc(w)\ngradient = tape.gradient(loss, w).numpy()\n\nplt.plot(w.numpy(), loss,'.-')\nplt.grid(True)\nplt.plot(w.numpy(), gradient,'x--');\nplt.legend(['Loss','Gradient of Loss']);"
  },
  {
    "objectID": "posts/2022-10-07-Tensorflow-2.html#using-watch",
    "href": "posts/2022-10-07-Tensorflow-2.html#using-watch",
    "title": "ThomasHSimm",
    "section": "Using watch",
    "text": "Using watch\nIf use watch on a variable the following variables referencing that variable are also watched\nBut the calls to new functions need to be within the with statement, but the gradient getting doesn’t\n\nx = tf.Variable(np.arange(0, np.pi*2,.2))\n\nwith tf.GradientTape() as t:\n    t.watch(x)\n    \n    y = tf.sin(x)\n    z = tf.exp(y)\ndz_dx = t.gradient(z,x)\n\nplt.plot(x.numpy(),z.numpy())\nplt.plot(x.numpy(),dz_dx.numpy(),'--')\nplt.legend(['z','dz/dx'])\nplt.grid(True)"
  },
  {
    "objectID": "posts/2022-10-10-NeuralNetworksMaths.html#gradient-descent",
    "href": "posts/2022-10-10-NeuralNetworksMaths.html#gradient-descent",
    "title": "ThomasHSimm",
    "section": "Gradient Descent",
    "text": "Gradient Descent\nGradient descent is an algroithm used to determine the value of parameters that are used to map input variables to target variables. The steps are: - Determine a loss function that relates predictions and actual values, i.e. a function that determines how good the predictions are - N.B. the function needs to be of a form to encourage gradient descent - Find the gradient of the loss function with respect to the parameters - Update the weights based on this gradient\nFor example, in the figure below - if the weight W=0 then the Loss is 1 and the gradient is -1.0. In this case we’d want to increase the value of the weight W towards it’s minimum 0.5 - if the weight W=1 then the Loss is also 1 but the gradient is +1.0. In this case we’d want to reduce the value of the weight W towards it’s minimum 0.5 - if the weight W=0.5 then the loss is close 0 and so is the garient, in this case we wouldn’t want to change the weights by much\ni.e. the weights can be updated by a formula of the form below to get the best fit:\n\\[W_{i+1} = W_i - const . \\frac{dJ}{dW}\\]\n\nGradient descent is not the only optimisation method to determine parameters but is an easy one to understand.\n\n\n\n\n\n\nSome definitions.\n\nX are the input variables\nY the target variables\n\\(\\hat{y}\\) is the prediction\nThe loss function J is what we are trying to minimise and is the sum of \\({Y-\\hat{y}^2}\\). For simplicity we’ll remove the summation below.\nm and b are the parameters we are looking to obtain\n\n\\(\\hat{Y}= mX +b\\)\n\\(Error = \\hat{Y} - Y\\)\n\\(J(m,b) = Error^2\\)\n\\(Error = mX + b - Y\\)\nWhat we want to do is update m and b so that J is reduced and the predictions is better. That is for m we obtain a new value (1) from the previous one (0) as follows:\n\\(m_1 = m_0 - \\frac{dJ}{dm} . \\alpha\\)\nWhere we have also included a learning rate (\\(\\alpha\\)<1) to make the changes smoother.\nSo to improve the predictions of the model we need to find and . Which involves a bit of differentiation and rearanging as follows.\nChain rule for differentiation to find db and dm\n\\(\\frac{dJ}{dm}\\ = \\frac{dJ}{dError}\\ \\frac{dError}{dm}\\)\n\\(\\frac{dJ}{db}\\ = \\frac{dJ}{dError}\\ \\frac{dError}{db}\\)\nfrom definition of J\n\\(\\frac{dJ}{dError}\\ = 2 . Error\\)\nfrom definition of Error\n\\(\\frac{dError}{dm} = X\\)\n\\(\\frac{dError}{db} = 1\\)\nSo\n\\(\\frac{dJ}{dm} = 2 . Error . X\\)\n\\(\\frac{dJ}{db} = 2 . Error . 1\\)\nAnd to account for the summation we divide by the length of the array.\nTo allow for matrix multiplication we create X as a matrix of two vectors one with just ones and the 2nd part the original X. This then allows us to have one variable for the weights m and b that we are fitting to.\nSo for each iteration (K) the weights W (j are the different parts to the weights e.g. b and m) are updated. Noting that there are N observations (length of y is N) we get:\n\\(W_j^{K+1} = W_j^{K} - [\\alpha . \\frac{1}{N}\\sum(\\hat{Y}-Y).X_j]\\)\n\ndef computeCost(X,y, theta):\n    Ypred = np.matmul(X,theta)\n    J =np.sum( (1/(2*len(y)))* (Ypred - y)**2 )\n    return J,Ypred\ndef computeGrad(X, y, theta,learningRate):\n    J,Ypred = computeCost(X,y, theta)\n    error = (Ypred - y)*learningRate/len(y)\n    return [np.sum(error),np.sum(X[:,1]*error)], J\n    \n\nCreate the variables to fit to\n\nX = np.ones((50,2))\nX[:,1]=np.arange(0,1,.02)\ntheta_act = [.5,3]\ny = np.matmul(X,theta_act)\nplt.plot(X[:,0],y,'.r')\nplt.plot(X[:,1],y,'.k')\nplt.grid(True)\nplt.title('Data')\nplt.legend(['bias b','m gradient']);\nplt.xlabel('X')\nplt.ylabel('y');\n\n\n\n\nUse the gradient descent iteration\n\ntheta_=np.array([0, 0])\nthetaALL=[]; jALL=[]\niterTot=100\nfor _ in range(iterTot):\n    thetaALL.append( theta_ )\n    (deltaTheta, J) =computeGrad(X, y, theta_,learningRate=.5)\n    theta_ = theta_ - deltaTheta\n    \n    jALL.append(J)\n\nplt.plot(range(iterTot),thetaALL,'.-')\nplt.plot(range(iterTot),np.ones((iterTot,2))*theta_act,'--',linewidth=4)\n# plt.plot(range(iterTot),jALL,':',linewidth=4)\nplt.grid(True)\nplt.legend(['b','m','actual values b','actual values m','Loss'])\nplt.xlabel('Iteration')\nplt.ylabel('Values');"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#coding-custom-layer",
    "href": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#coding-custom-layer",
    "title": "ThomasHSimm",
    "section": "Coding custom layer",
    "text": "Coding custom layer\nA layer class is inherited from Kera’s Layer class. Hence, MyLayer(Layer):\n\ndef __init__(self, units=32):\n\nInitializes the class, accepts parameters and sets up internal variables.\nsuper().__init__() returns a temporary object of the superclass (proxy object) the Layer class. This allows us to acces methods of the base class. - make sure to pass class name and self in super() - or **kwargs\nThen build and call functions can be added to create the layer and when it is called. N.B. build can often be moved to __init__.\n\ndef build(self, input_shape):\n\nruns when instance is created\ncreates state of layers (weights)\n\ndef call(self, inputs):\n\ncall does the computation\n\n\nThe values for the parameters can be explicitly set using functions like tf.random_normal_initializer() and sepcifying a shape.\nThe key to call is defining how the parts in build and __init__ are put together to create the computation of the layer.\nAlso note that in the call the format is the same as for the functional API, where the previous layer is added at the end of the next layer.\nAll the variables (weights and biases) can also be accesed with layer_class.variables.\n\n# Create a custom layer\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\nclass SimpleDense(Layer):\n    \n    def __init__(self,units=32):\n        super(SimpleDense, self).__init__()\n        self.units = units\n        \n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.w = tf.Variable(\n                initial_value=w_init(shape=(input_shape[-1], self.units), dtype='float32'),\n                trainable=True,name='kernel',\n                                )\n        b_init = tf.zeros_initializer()\n        self.b = tf.Variable(\n                initial_value=b_init(shape=(self.units), dtype='float32'),\n                trainable=True, name='bias',\n                                )\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w)+self.b\n    \ndense_layer = SimpleDense(units=32)\n\nx = tf.ones((1,1))\n\nprint(dense_layer(x) )\nprint()\nprint(f\"Weights = {dense_layer.weights[0].numpy()} \\n\\nand biases {dense_layer.weights[1].numpy()}\")\nprint()\nprint([ var.numpy() for var in dense_layer.variables])\n\ntf.Tensor(\n[[-0.07436698 -0.02011585  0.05582675  0.05404044  0.02519816  0.02855827\n   0.00046192  0.01360966  0.04663334  0.04556176  0.04592257  0.04647708\n  -0.03950281 -0.00014847 -0.03248019  0.08354251  0.07218082 -0.01156685\n   0.04577427 -0.06801199 -0.02725383 -0.02071865  0.08600459 -0.00035707\n  -0.03410981  0.00493511 -0.05133317 -0.12937713 -0.13792662 -0.01709494\n  -0.05110807 -0.01718794]], shape=(1, 32), dtype=float32)\n\nWeights = [[-0.07436698 -0.02011585  0.05582675  0.05404044  0.02519816  0.02855827\n   0.00046192  0.01360966  0.04663334  0.04556176  0.04592257  0.04647708\n  -0.03950281 -0.00014847 -0.03248019  0.08354251  0.07218082 -0.01156685\n   0.04577427 -0.06801199 -0.02725383 -0.02071865  0.08600459 -0.00035707\n  -0.03410981  0.00493511 -0.05133317 -0.12937713 -0.13792662 -0.01709494\n  -0.05110807 -0.01718794]] \n\nand biases [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0.]\n\n[array([[-0.07436698, -0.02011585,  0.05582675,  0.05404044,  0.02519816,\n         0.02855827,  0.00046192,  0.01360966,  0.04663334,  0.04556176,\n         0.04592257,  0.04647708, -0.03950281, -0.00014847, -0.03248019,\n         0.08354251,  0.07218082, -0.01156685,  0.04577427, -0.06801199,\n        -0.02725383, -0.02071865,  0.08600459, -0.00035707, -0.03410981,\n         0.00493511, -0.05133317, -0.12937713, -0.13792662, -0.01709494,\n        -0.05110807, -0.01718794]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)]\n\n\nOr equivalently…\n\n# Create a custom layer\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\n\nclass MyLayer(Layer):\n    \n    def __init__(self,units,input_dim):\n        super(MyLayer, self).__init__()\n        self.w = self.add_weight(shape=(input_dim,units),\n                                initializer='random_normal',\n                                trainable=True)\n        self.b = self.add_weight(shape=(units,),\n                                 initializer='zeros',\n                                trainable=True)\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w)+self.b\n    \ndense_layer = MyLayer(3,5)\n\nx = tf.ones((1,5))\n\nprint(dense_layer(x) )\nprint()\nprint(f\"Weights = {dense_layer.weights[0].numpy()} \\n\\nand biases {dense_layer.weights[1].numpy()}\")"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#create-a-dropout-layer-as-a-custom-layer",
    "href": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#create-a-dropout-layer-as-a-custom-layer",
    "title": "ThomasHSimm",
    "section": "Create a Dropout layer as a custom layer",
    "text": "Create a Dropout layer as a custom layer\nN.B. uses tf.nn primitive Neural Net (NN) Operations.\n\nclass MyDropout(Layer):\n\n    def __init__(self, rate):\n        super(MyDropout, self).__init__()\n        self.rate = rate\n        \n    def call(self, inputs):\n        # Define forward pass for dropout layer\n        return tf.nn.dropout(inputs, rate=self.rate)"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#add-activation-functions",
    "href": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#add-activation-functions",
    "title": "ThomasHSimm",
    "section": "Add activation functions",
    "text": "Add activation functions\nTo add activation functions in the layer\n\nadd activation=None to the __init__ inputs so it accepts an activation but defaults to None if doesn’t recieve one\nadd the activation to the self variable\n\nuse self.activation = tf.keras.activations.get(activation)\ni.e. so we can pass a string or a function\n\ncall the activation function within the call\n\ni.e. return  self.activation(tf.matmul(inputs, self.w)+self.b)"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#custom-layers-in-a-model",
    "href": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#custom-layers-in-a-model",
    "title": "ThomasHSimm",
    "section": "Custom layers in a model",
    "text": "Custom layers in a model\nCan create the model by passing the layer into keras.Sequential as a list. In the same way as done with other layer elements.\n\nxs = np.arange(-1,5,dtype=float)\nys = xs*2 -1\n\nmodel = tf.keras.Sequential([SimpleDense(units=1)])\n\nmodel.compile(optimizer='sgd',loss='mse')\nmodel.fit(xs,ys,epochs=500,verbose=0)\nprint(model.predict([10.]))\n\n[[18.981386]]"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#model-example-residual-networks",
    "href": "posts/2022-10-10-Tensorflow-CustomLayersModels.html#model-example-residual-networks",
    "title": "ThomasHSimm",
    "section": "Model example Residual Networks",
    "text": "Model example Residual Networks\n\n\nfrom tensorflow.keras.layers import Conv2D, Dense, Layer\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\n\nclass CNNResidual(Layer):\n    def __init__(self, layers, filters, **kwargs):\n        super(**kwargs).__init__()\n        self.hidden = [Conv2D(filters, (3,3), activation='relu') for _ in range(layers)]\n    def call(self, inputs):\n        x = inputs\n        for layer in self.hidden:\n            x = layer(x)\n        return inputs + x\n    \nclass DNNResidual(Layer):\n    def __init__(self, layers, neurons, **kwargs):\n        super(**kwargs).__init__()\n        self.hidden = [Dense(neurons, activation='relu') for _ in range(layers)]\n    def call(self, inputs):\n        x = inputs\n        for layer in self.hidden:\n            x = layer(x)\n        return inputs + x\n\nclass MyResidual(Model):\n    def __init(self, **kwargs):\n        self.hidden1 = Dense(30, activation='relu')\n        self.block1 = CNNResidual(2, 32)\n        self.block2 = DNNResidual(2, 64)\n        self.out = Dense(1)\n    def call(self, inputs):\n        x = self.hidden1(inputs)\n        x = self.block1(x)\n        for _ in range(1,4):\n            x = self.block2(x)\n        return self.out(x)"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#load-from-directory",
    "href": "posts/2022-10-10-Tensorflow-Images.html#load-from-directory",
    "title": "ThomasHSimm",
    "section": "Load from directory",
    "text": "Load from directory\nIf files are in folders can use flow_from_directory the files would need to be separated by class and training/validation as follows for a classification\ne.g. files in folders like this:\n\n/tmp/cats-v-dogs/validation/cats\n/tmp/cats-v-dogs/validation/dogs\n/tmp/cats-v-dogs/training/cats\n`/tmp/cats-v-dogs/training/dogs\n\n\ntrain_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n                                                      batch_size=256,\n                                                      class_mode='binary',\n                                                      target_size=(150, 150))\n# Test your generators\ntrain_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)\n\n# Put in the fit\nmodel.fit(train_generator,\n                    epochs=15,\n                    verbose=1,\n                    validation_data=validation_generator)"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#an-example-of-transfer-learning-on-images-with-inception",
    "href": "posts/2022-10-10-Tensorflow-Images.html#an-example-of-transfer-learning-on-images-with-inception",
    "title": "ThomasHSimm",
    "section": "An example of transfer learning on images with Inception",
    "text": "An example of transfer learning on images with Inception\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\n\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),                                   include_top = False,                                    weights = None)\nBetter to keep the same shape as the model uses and change your data to match it than to change input_shape to match your data.\ninclude_top=False removes top most layer of the model- the output layer\nweights=None just uses the model architecture- note the weights are loaded on a later line\n\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\nNote this uses the functional API\n\nMatch the image size of our images to that needed by the model\n\nOur model expects 150X150X3 but our data is 50X50. So we need to multiply our image size by 3. This is done by the UpSampling2D layer\nmodel = tf.keras.layers.UpSampling2D(size=(3,3))(model)\nor use resize if image is bigger tf.image.resize(image, (150, 150,))\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# 8. Increase input image sizes to match that needed by model using \n# a layer before the existing model starts\n\nmodel = tf.keras.layers.UpSampling2D(size=(3,3))(model)\n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#r-cnn",
    "href": "posts/2022-10-10-Tensorflow-Images.html#r-cnn",
    "title": "ThomasHSimm",
    "section": "R-CNN",
    "text": "R-CNN\nR-CNN (R=region) a region based CNN to implement selective search with neural networks.\n\nTakes input images\nExtract regions using selective search method (~2k)\nExtract features using CNN from each region\n\nwarped to match AlexNet inputs\n\nClassify with support vector machine (SVM) instead of dense layers\nPlus regression to get bounding box of images\nVery slow & computationally expensive\n\n\nRoss Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik, “Rich feature hierarchies for accurate object detection and semantic segmentation” 2014"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#fast-r-cnn",
    "href": "posts/2022-10-10-Tensorflow-Images.html#fast-r-cnn",
    "title": "ThomasHSimm",
    "section": "Fast R-CNN",
    "text": "Fast R-CNN\nThe aim was to improve issues above with RCNN.\n\nEntire image is fed into the ConvNet\n\nno selective search- computationally expensive\nthis Convnet is trained on finding features\nproduces a feature map of the image\n\nEach feature map can then be fed into fully connected dense layer\n\nget feature vector of image\n\nFeature vector fed into layers to do regression and classification\n\n\nRoss Girshick, Fast R-CNN, 2015"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#faster-r-cnn",
    "href": "posts/2022-10-10-Tensorflow-Images.html#faster-r-cnn",
    "title": "ThomasHSimm",
    "section": "Faster R-CNN",
    "text": "Faster R-CNN\n\nentire image into Convnet\nsliding window to find areas of interest\nsomething called a Region Proposed Network is used with data to find and create anchor boxes on image\nThe cropped and passed to Dense layers for classification and regression.\n\n Deep Learning for Computer Vision with Python"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#object-detection-in-tensorflow",
    "href": "posts/2022-10-10-Tensorflow-Images.html#object-detection-in-tensorflow",
    "title": "ThomasHSimm",
    "section": "Object detection in TensorFlow",
    "text": "Object detection in TensorFlow\nhttps://www.tensorflow.org/hub\n\nTensorFlow Hub is a repository of trained machine learning models ready for fine-tuning and deployable anywhere. Reuse trained models like BERT and Faster R-CNN with just a few lines of code.\n\nCopy url from hub page https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1 page for faster rcnn. And copy url is “https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1”\n\nimport tensorflow as tf\nimport tensorflow-hub as hub\n\nmodule_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n\ndetector = hub.load(module_handle).signatures['default']\n\n\nAn example can be found here https://www.tensorflow.org/hub/tutorials/object_detection"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-Images.html#object-detection-api",
    "href": "posts/2022-10-10-Tensorflow-Images.html#object-detection-api",
    "title": "ThomasHSimm",
    "section": "Object Detection API",
    "text": "Object Detection API\nhttps://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md https://github.com/tensorflow/models/tree/master/research/object_detection https://www.tensorflow.org/guide/checkpoint"
  },
  {
    "objectID": "posts/2022-10-10-Tensorflow-NLP.html",
    "href": "posts/2022-10-10-Tensorflow-NLP.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "TensorFlow NLP cheat sheet\n\nSome tips for tensorflow and keras in Natural Language Processing\n\n\ntoc: true\nbadges: true\ncomments: true\ncategories: [tensorflow; NLP]\n\n\n\n\nBasic Implementation\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\nmodel = tf.keras.Sequential([ \n    tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(5,'softmax')\n])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),\n\n\n\nText data Tokenizer\n\nCreate a Tokenizer instance\nFit tokenizer to text data with tokenizer.fit_on_texts(text_data)\nConvert text to sequences with sequences = tokenizer.texts_to_sequences(text_data)\n\nFor example, the following words have the indices: apple->1, brain->2, cat->3, that->4, is->5\nAnd a sequence of text within the data can be converted to a sequence: “that cat apple is brain” -> (4, 3, 1, 5, 2)\n\nGet the word index word_index = tokenizer.word_index\nGet the text back from the sequences text = tokenizer.sequences_to_texts(sequences)\n\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(oov_token=\"<OOV>\",num_words=10_000)\ntokenizer.fit_on_texts(text_data)\n\nsequences = label_tokenizer.texts_to_sequences(text_data)"
  },
  {
    "objectID": "posts/2022-10-14-AWS_terminology.html",
    "href": "posts/2022-10-14-AWS_terminology.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "AWS terminology\n\nA-Z of terms used in AWS\n\n\ntoc: false\nbadges: false\ncomments: true\ncategories: [AWS]\n\n\n\nOverview\n\nComing from a non-IT background a lot of the terminology used in AWS courses was over my head.\nFurthermore, like any discipline AWS has it’s own set of terminology that may be only defined once and assumed to be known thereafter.\nHence, a terminology page.\n\nContents\n\n\n General terms \n Summary of AWS Services \n AWS terms \n\n\nGeneral terms\n\n\n9s\n\n\nUsed to express the percentage of a variable. For example, X has 4 9s = X is 99.99%.\n\n\nACID (atomicity, consistency, isolation, durability) principle\n\n\nACID refers to the four key properties of a transaction: atomicity, consistency, isolation, and durability. Ensure data is persisted with high integrity.\n\n\nAccess control list ACL\n\n\nAn access control list (ACL) is a list of rules that specifies which users or systems are granted or denied access to a particular object or system resource. Access control lists are also installed in routers or switches, where they act as filters, managing which traffic can access the network.\n\n\nAPI call\n\n\nApplication programming interfaces (APIs) are a way for one program to interact with another. API calls are the medium by which they interact. An API call, or API request, is a message sent to a server asking an API to provide a service or information.\n\n\nAvailability\n\n\nThe availability of a system is typically expressed as a percentage of uptime in a given year or as a number of nines.\n\n\nBlock Storage\n\n\nA technology that controls data storage and storage devices. It takes any data, like a file or database entry, and divides it into blocks of equal sizes. The block storage system then stores the data block on underlying physical storage in a manner that is optimized for fast access and retrieval\n\n\nCache\n\n\nA cache is a special storage space for temporary files that makes a device, browser, or app run faster and more efficiently.\n\n\nCIDR Notation\n\n\nClassless Inter-Domain Routing (CIDR) notation is a compressed way of specifying a range of IP addresses. Specifying a range determines how many IP addresses are available to you.\n\n\nCloud\n\n\nCloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing\n\n\nData Lake\n\n\nA data lake is a centralized repository designed to store, process, and secure large amounts of structured, semistructured, and unstructured data. It can store data in its native format and process any variety of it, ignoring size limits.\n\n\nData Warehouse\n\n\nA data warehouse is a database optimized to analyze relational data coming from transactional systems and line of business applications. The data structure, and schema are defined in advance to optimize for fast SQL queries, where the results are typically used for operational reporting and analysis. Data is cleaned, enriched, and transformed so it can act as the “single source of truth” that users can trust.\n\n\nHadoop cluster\n\n\nA Hadoop cluster is a special type of computational cluster designed specifically for storing and analyzing huge amounts of unstructured data in a distributed computing environment. Such clusters run Hadoop’s open source distributed processing software on low-cost commodity computers.\n\n\nHypervisor\n\n\nA hypervisor is a piece of system software that provides virtual machines (VMs), on which users can run their operating system (OS) and applications. The hypervisor provides isolation between virtual machines (VMs), which run independent of each other, and allows different VMs to run their own OS.\n\n\nIAM\n\n\nIAM is a web service that enables you to manage access to your AWS account and resources. It also provides a centralized view of who and what are allowed inside your AWS account and their permissions.\n\n\nIntegrity\n\n\nA system’s ability to work as planned and deliver expected and non-deceptive results.\n\n\nIOPS\n\n\nInput/output operations per second, the standard unit of measurement for the maximum number of reads and writes to storage locations.\n\n\nIP Addresses\n\n\nAn Internet Protocol address (IP address) is a numerical label such as 192.0.2.1 that is connected to a computer network that uses the Internet Protocol for communication. An IP address serves two main functions: network interface identification and location addressing.\n\n\nIPv4 IPv6\n\n\nInternet Protocol version 4 (IPv4) defines an IP address as a 32-bit number (4 sets). IPv6 using 128 bits for the IP address, was standardized in 1998\n\n\nLatency\n\n\nLatency describes the time required for a sub-system to process a single data request or transaction.\n\n\nLow latency link\n\n\nLow latency describes a computer network that is optimized to process a very high volume of data messages with minimal delay (latency).\n\n\nMFA\n\n\nMFA or multi-factor authorisation, more than one form of authentication e.g. password and mobile app.\n\n\nNetworking\n\n\nNetworking is how you connect computers around the world and allow them to communicate with one another.\n\n\npre-signed URL\n\n\nRedundant\n\n\nFailover or Redundant routing is a network arrangement with several links and paths between the person who places a call and the call recipient. Should at any time a path or link in the network, the other links will automatically route the incoming call to a predetermined number, device or location.\n\n\nResiliency\n\n\nThe capability to recover when stressed by load (more requests for service), attacks (either accidental through a bug, or deliberate through intention), and failure of any component in the workload’s components.\n\n\nServers\n\n\nA server is a piece of computer hardware or software that provides functionality for other programs or devices. Servers can provide various functionalities, often called “services”, such as sharing data or resources among multiple clients, or performing computation for a client.\n\n\nThroughput\n\n\nWhereas IOPS is a count of the read/write operations per second, throughput is the actual measurement of read/write bits per second that are transferred over a network.\n\n\nAWS terms\n\n\nAMI Amazon Machine Image\n\n\nAn Amazon Machine Image (AMI) is a supported and maintained image provided by AWS that provides the information required to launch an instance. The AMI is how you model and define your instance, while the EC2 instance is the entity you interact with, where you can install your web server, and serve your content to users.\n\n\n(Amazon) Aurora\n\n\nCloud native relational database service option, Amazon Aurora, is a MySQL and PostgreSQL-compatible database built for the cloud. It is more durable, more available, and provides faster performance than the Amazon RDS version of MySQL and PostgreSQL.\n\n\nAvailability Zones AZs\n\n\nInside every Region is a cluster of Availability Zones (AZ). An AZ consists of one or more data centers with redundant power, networking, and connectivity.\n\n\n(Amazon) Cloudwatch\n\n\nA monitoring and observability service that collects data on AWS applications. CloudWatch provides actionable insights into your applications, and enables you to respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health.\n\n\nCluster\n\n\nA cluster is a group of servers and other resources that act like a single system and enable high availability, load balancing and parallel processing.\n\n\n(AWS) Command Line Interface (CLI)\n\n\nCommand line tool to manage AWS services: control multiple AWS services and automate them with scripts.\n\n\nContainer\n\n\nContainers provide a standard way to package your application’s code, configurations, and dependencies into a single object. Containers share an operating system installed on the server and run as resource-isolated processes, ensuring quick, reliable, and consistent deployments, regardless of environment.\n\n\nDocker\n\n\nDocker is a popular container runtime that simplifies the management of the entire operating system stack needed for container isolation, including networking and storage. Docker makes it easy to create, package, deploy, and run containers.\n\n\nDynamic Host Configuration Protocol (DHCP) option sets\n\n\nA DHCP option set is a group of network configurations used by EC2 instances in your VPC to communicate over your virtual network. Each VPC in a Region uses the same default DHCP option set unless you choose to create a custom DHCP option set, or if you disassociate all option sets from your VPC.\n\n\nAmazon Elastic Block Storage (EBS)\n\n\nA block-level storage device that you can attach to an Amazon EC2 instance. EBS volumes act similarly to external drive.\n\n\nElastic Compute Cloud (EC2)\n\n\nAmazon EC2 is a web service that provides secure, resizable compute capacity in the cloud. It allows you to provision virtual servers called EC2 instances.\n\n\nElastic Container Service (ECS)\n\n\nAmazon ECS is an end-to-end container orchestration service that allows you to quickly spin up new containers and manage them across a cluster of EC2 instances.\n\n\nElastic Network Interfaces (ENIs)\n\n\nENIs are virtual network cards you can attach to your EC2 instances. They are used to enable network connectivity for your instances, and having more than one of them connected to your instance allows it to communicate on two different subnets.\n\n\n(AWS) Fargate\n\n\nAWS Fargate is a purpose-built serverless compute engine for containers. Fargate scales and manages the infrastructure. Fargate supports both Amazon ECS and Amazon EKS architecture and provides workload isolation and improved security by design.\n\n\nElastic Kubernetes Service (EKS)\n\n\nKubernetes is a portable, extensible, open source platform for managing containerized workloads and services. Amazon EKS is conceptually similar to Amazon ECS, but there are some differences.\n\n\nElastic Load Balancing (ELB)\n\n\nDistributes incoming application traffic across EC2 instances as well as containers, IP addresses, and AWS Lambda functions.\n\n\nGateway- Internet Gateway\n\n\nTo enable internet connectivity for your VPC. The internet gateway connects your VPC to the internet.\n\n\nGateway- Virtual Private Gateway\n\n\nA virtual private gateway allows you to connect your AWS VPC to another private network. On the other side of the connection, you’ll need to connect a customer gateway to the other private network.\n\n\nInstances\n\n\nA virtual computing environment\n\n\nIP- Public IP\n\n\nThis IP address is assigned from the addresses reserved by AWS and cannot be specified. This IP address is unique on the Internet, persists only while the instance is running, and cannot be transferred to another instance. See also Public DNS.\n\n\nIP- Elastic IP\n\n\nAn elastic IP address is an address unique on the Internet that you reserve independently and associate with an Amazon EC2 instance. While similar to a public IP, there are some key differences. This IP address persists until the customer releases it and is not tied to the lifetime or state of an individual instance. Because it can be transferred to a replacement instance in the event of an instance failure, it is a public address that can be shared externally without coupling clients to a particular instance\n\n\n(AWS) Lambda\n\n\nAWS Lambda lets you run code without provisioning or managing servers or containers (i.e. no need to manage EC2 instances, containers etc)\n\n\n(AWS) Management Console\n\n\nThe web-based console to manage cloud resources.\n\n\nPublic Domain Name System (DNS) Name\n\n\nWhen you launch an instance, AWS creates a DNS name that can be used to access the instance. This DNS name is generated automatically and cannot be specified by the customer. The name can be found in the Description tab of the AWS Management Console or via the Command Line Interface (CLI) or Application Programming Interface (API). This DNS name persists only while the instance is running and cannot be transferred to another instance.\n\n\nRoot User\n\n\nA single sign-in identity that has complete access to all AWS services and resources in the account.\n\n\nRegions\n\n\nRegions are geographic locations worldwide where AWS hosts its data centers.\n\n\nRelational database\n\n\nOrganizes data into tables. Data in one table can be linked to data in other tables to create relationships—hence, the relational part of the name. Relational Database Management System?\n\n\nRelational database management system (RDBMS)\n\n\nA relational database management system (RDBMS) lets you create, update, and administer a relational database. For example, MySQL or Amazon Aurora.\n\n\nReserved Instances (RIs)\n\n\nRIs are pricing options that provide a significant discount compared to On-Demand instance pricing but require commitments.\n\n\nRoute Table\n\n\nA route table contains a set of rules, called routes, that are used to determine where network traffic is directed. (created when create a VPC). N.B. Custom and Main.\n\n\nS3\n\n\nA standalone storage solution using object storage (flat structure).\n\n\nSecurity groups\n\n\nA security group controls the traffic that is allowed to reach and leave the resources that it is associated with. For example, after you associate a security group with an EC2 instance, it controls the inbound and outbound traffic for the instance. When you create a VPC, it comes with a default security group.\n\n\nServerless\n\n\nA serverless architecture is a way to build and run applications and services without having to manage infrastructure. Your application still runs on servers, but all the server management is done by AWS.\n\n\n(AWS) Software Development Kits (SDKs)\n\n\nSDKs are open-source tools for the most popular programming languages (e.g. C++, Python). Developers commonly use AWS SDKs to integrate their application source code with AWS services. For example, run everytime a photo is uploaded.\n\n\nSpot Instances\n\n\nA pricing option where you set a limit on how much you would like to pay for the instance hour. If the amount you pay is more than the current Spot price and there is capacity, then you will receive an instance.\n\n\n(AWS) SSO\n\n\nAWS SSO is similar to IAM, in that it offers a directory where you can create users, organize them in groups, and set permissions across those groups, and grant access to AWS resources. However, AWS SSO has some advantages over IAM. For example, if you’re using a third-party identity provider, you can sync your users and groups to AWS SSO.\n\n\nSubnet\n\n\nThink of subnets as smaller networks inside your base network (VPC)—or virtual area networks (VLANs). In AWS, subnets are used for high availability and providing different connectivity options for your resources. (EC2 instances are launched within a subnet, which will be located inside the Availability Zone you choose)\n\n\n(Amazon) VPC\n\n\nA VPC is an isolated network you create in the AWS cloud, similar to a traditional network in a data center. To define need: The name of your VPC, the region and an IP range for your VPC in CIDR notation. The physical host for EC2 instances.\n\n\nSummary of AWS Services\n\n\n1. Compute & Network\n\nAmazon Elastic Cloud Compute (EC2)\n\na web service that provides resizable compute capacity in the cloud\ndifferent OS and confiurations\nprovides virtual computing environment\n\nAWS Lambda\n\nzero-admin (severless) compute platform.\nruns your code for you on Ec2 instances\n\nAuto Scaling\n\nallows organizations to scale Amazon EC2 capacity up or down automatically according to conditions defined for the particular workload\noptimize costs and use only the capacity that is actually needed (not for peak use)\n\nElastic Load Balancing\n\nautomatically distribute incoming application traffic across multiple Amazon EC2 instances in the cloud.\nfault tolerance\n\nAWS Elastic Beanstalk\n\nthe fastest and simplest way to get a web application up and running on AWS.\ndevelopers can simply upload their application code, and the service automatically handles all the details, such as resource provisioning, load balancing, Auto Scaling, and monitoring.\nSupported by many platforms, including PHP, Java and Python,\norganizations retain full control over the AWS resources powering the application and can access the underlying resources at any time\nLambda is simpler and less expensive, while Elastic Beanstalk lets you run full applications and gives you control over their environment.\n\nVirtual Private Coud (Amazon VPC)\n\nlets organizations provision a logically isolated section of the AWS Cloud where they can launch AWS resources in a virtual network that they define.\n\nAWS Direct Connect\n\nallows organizations to establish a dedicated network connection from their data center to AWS.\n\nAmazon Route 53\n\na highly available and scalable Domain Name System (DNS) web service\ni.e. converting human readable names like www.website.com to 192.0.2.1\ncan also be used to purchase domains\n\n\n\n\n2. Storage and Content Delivery\n\nAmazon Simple Storage Service (S3)\n\nhighly durable and scalable object storage that handles virtually unlimited amounts of data and large numbers of concurrent users\nstored as objects\nincluding backup and recovery, nearline archive, big data analytics, disaster recovery, cloud applications, and content distribution.\n\nAmazon Glacier\n\nis a secure, durable, and extremely low-cost storage service for data archiving and long-term backup\nseveral hours to access data\n\nAmazon Elastic Block Storage (EBS)\n\npersistent block-level storage volumes for use with Amazon EC2 instances.\nEach Amazon EBS volume is automatically replicated within its Availability Zone to protect organizations from component failure\n\nAWS Storage Gateway\n\na service connecting an on-premises software appliance with cloudbased storage\n\nAmazon CloudFront\n\na content delivery web service.\nintegrates with other AWS Cloud services\nan easy way to distribute content to users across the world with low latency, high data transfer speeds, and no minimum usage commitments\n\n\n\n\n3. Database Services\n\nAmazon Relational Database Service (Amazon RDS)\n\na fully managed relational database with support for many database engines\nmanages administration tasks, including backups, software patching, monitoring, scaling, and replication\n\nAmazon DynamoDB\n\na fast and flexible NoSQL database service\nconsistent, single-digit millisecond latency at any scale\ngreat fit for mobile, web, gaming, ad-tech, Internet of Things\n\nAmazon Redshift\n\na fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost effective to analyze structured data.\nstandard SQL interface\nallows organizations to automate most of the common administrative tasks associated with provisioning, configuring, and monitoring a cloud data warehouse.\n\nAmazon ElastiCache\n\na web service that simplifies deployment, operation, and scaling of an in-memory cache in the cloud\nimproves the performance of web applications by allowing organizations to retrieve information from fast, managed, in-memory caches\n\n\n\n\n4. Management tools\n\nAmazon CloudWatch\n\na monitoring service for AWS Cloud resources and the applications running on AWS\n\nAWS CloudFormation\n\ngives developers and systems administrators an effective way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\n\nAWS CloudTrail\n\na web service that records AWS API calls for an account and delivers log files for audit and review.\nIncludes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the service.\n\nAWS config\n\ndiscover existing AWS resources\ndetermine how a resource was configured at any point in time.\nenables compliance auditing, security analysis, resource change tracking, and troubleshooting.\n\n\n\n\n5. Security and Identity\n\nAWS Identity and Access Management (IAM)\n\nenables organizations to securely control access to AWS Cloud services and resources for their users\n\nAWS Key Management Service (KMS)\n\na managed service that makes it easy for organizations to create and control the encryption keys used to encrypt their data\n\nAWS Directory Service\n\nallows organizations to set up and run Microsoft Active Directory on the AWS Cloud or connect their AWS resources with an existing on-premises Microsoft Active Directory.\n\nAWS Certificate Manager\n\na service that lets organizations easily provision, manage, and deploy Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS Cloud services\n\nAWS Web Application Firewall (WAF)\n\nhelps protect web applications from common attacks and exploits that could affect application availability, compromise security, or consume excessive resources.\n\n\n\n\n6. Application Service\n\nAmazon API Gateway\n\na fully managed service for developers to create, publish, maintain, monitor, and secure APIs at any scale.\nAmazon API Gateway handles all the tasks involved in accepting and processing concurrent API calls,\n\nAmazon Elastic Transcoder\n\nmedia transcoding in the cloud, to convert (or transcode) media files from their source formats into versions that will play back on devices like smartphones,tablets, and PCs.\n\nAmazon Simple Notification Service (Amazon SNS)\n\na web service that coordinates and manages the delivery or sending of messages to recipients.\nthere are two types of clients, publishers and subscribers (or producers/consumers)\n\nAmazon Simple Email Service (Amazon SES)\n\na cost-effective email service to send transactional email,\nFor marketing messages, customer contact, receive messages, deliver them to an Amazon S3 bucket, call custom code via an AWS Lambda function, or publish notifications to Amazon SNS.\n\nAmazon Simple Workflow Service (Amazon SWF)\n\nhelps developers build, run, and scale background jobs that have parallel or sequential steps.\ncommonly, if your application’s steps take more than 500 milliseconds to complete, it is vitally important to track the state of processing and to provide the ability to recover or retry if a task fails. Amazon SWF helps organizations achieve this reliability.\n\nAmazon Simple Queue Service (Amazon SQS)\n\na fast, reliable, scalable, fully managed message queuing service\nallowing transmission of any volume of data, at any level of throughput, without losing messages or requiring other services to be always available"
  },
  {
    "objectID": "posts/2022-9-28-Data-Science.html",
    "href": "posts/2022-9-28-Data-Science.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "Data Science\n\nOnline courses I’ve completed\n\n\ntoc: true\nbadges: true\nauthor: Thomas H. Simm\ncategories: [coursera, mooc, data science, AI, Thomas Simm]"
  },
  {
    "objectID": "posts/AWS II.html#what-is-the-cloud",
    "href": "posts/AWS II.html#what-is-the-cloud",
    "title": "ThomasHSimm",
    "section": "What is the Cloud?",
    "text": "What is the Cloud?\nIn the past, companies and organizations hosted and maintained hardware such as Cloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing. You no longer have to manage and maintain your own hardware in your own data centers. Companies like AWS own and maintain these data centers and provide virtualized data center technologies and services to users over the internet."
  },
  {
    "objectID": "posts/AWS II.html#the-six-benefits-of-cloud-computing",
    "href": "posts/AWS II.html#the-six-benefits-of-cloud-computing",
    "title": "ThomasHSimm",
    "section": "The Six Benefits of Cloud Computing",
    "text": "The Six Benefits of Cloud Computing\n\nPay as you go. Instead of investing in data centers and hardware before you know how you are going to use them, you pay only when you use computing resources, and pay only for how much you use.\nBenefit from massive economies of scale. By using cloud computing, you can achieve a lower cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, AWS can achieve higher economies of scale, which translates into lower pay as-you-go prices.\nStop guessing capacity. Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes notice.\nIncrease speed and agility. IT resources are only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization since the cost and time it takes to experiment and develop is significantly lower.\nStop spending money running and maintaining data centers. Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your customers, rather than on the heavy lifting of racking, stacking, and powering physical infrastructure. This is often referred to as undifferentiated heavy lifting.\nGo global in minutes. Easily deploy your application in multiple Regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at a minimal cost.\n\n\nhttps://aws.amazon.com/what-is-cloud-computing/\nhttps://aws.amazon.com/what-is-aws/\n\n\nCloud Deployment Models\n\nall-in cloud-based application is fully deployed in the cloud\nhybrid deployment using cloud based resources and existing resources such as a data center"
  },
  {
    "objectID": "posts/AWS II.html#aws-global-infrastructure",
    "href": "posts/AWS II.html#aws-global-infrastructure",
    "title": "ThomasHSimm",
    "section": "AWS Global Infrastructure",
    "text": "AWS Global Infrastructure\nAWS serves over 1 million customers in over 190 countries.\nInfrastructure, like data centers and networking connectivity, still exists as the foundation of every cloud application. In AWS, this physical infrastructure makes up the AWS Global Infrastructure, in the form of Availability Zones and Regions.\nRegions - geographic locations worldwide where AWS hosts its data centers - named after the location where they reside. For example, in the United States, there is a Region in Northern Virginia called the Northern Virginia Region - Each AWS Region is associated with a geographical name and a Region code. - Each region is completely independent and isolated from other regions\nInside every Region is a cluster of Availability Zones (AZ). - An AZ consists of one or more data centers with redundant power, networking, and connectivity. - These data centers operate in discrete facilities with undisclosed locations. - They are connected using redundant high-speed and low-latency links. - i.e. geographically isolated but connected by low-latency (quick) links - placing application in multiple AZs helps prevent service disruption higher availability (different utility, power supply, location etc) - us-east-1a: an AZ in us-east-1 (Northern Virginia Region) - At a minimum, you should use two AZs. If one entire AZ fails, your application will have infrastructure up and running in at least a second AZ to take over the traffic\n\nChoose the Right AWS Region\nConsider four main aspects when deciding which AWS Region to host your applications and workloads: latency, price, service availability, and compliance.\n\nLatency. If your application is sensitive to latency, choose a Region that is close to your user base. This helps prevent long wait times for your customers. Synchronous applications such as gaming, telephony, WebSockets, and IoT are significantly affected by higher latency, but even asynchronous workloads, such as ecommerce applications, can suffer from an impact on user connectivity.\nPrice. Due to the local economy and the physical nature of operating data centers, prices may vary from one Region to another. The pricing in a Region can be impacted by internet connectivity, prices of imported pieces of equipment, customs, real estate, and more. Instead of charging a flat rate worldwide, AWS charges based on the financial factors specific to the location.\n\nService availability. Some services may not be available in some Regions. The AWS documentation provides a table containing the Regions and the available services within each one.\nData compliance. Enterprise companies often need to comply with regulations that require customer data to be stored in a specific geographic territory. If applicable, you should choose a Region that meets your compliance requirements."
  },
  {
    "objectID": "posts/AWS II.html#accessing-aws",
    "href": "posts/AWS II.html#accessing-aws",
    "title": "ThomasHSimm",
    "section": "Accessing AWS",
    "text": "Accessing AWS\n\nAWS Management console. Web-based application\nAWS Command Line Interface (CLI). A tool control services with command line interface and scripts\nAWS Software Development Kits (SDKs). Programming interface to interact with AWS. e.g. Python"
  },
  {
    "objectID": "posts/AWS II.html#summary-of-services",
    "href": "posts/AWS II.html#summary-of-services",
    "title": "ThomasHSimm",
    "section": "Summary of Services",
    "text": "Summary of Services\n\n1. Compute & Network\n\nAmazon Elastic Cloud Compute (EC2)\n\na web service that provides resizable compute capacity in the cloud\ndifferent OS and confiurations\nprovides virtual computing environment\n\nAWS Lambda\n\nzero-admin (severless) compute platform.\nruns your code for you on Ec2 instances\n\nAuto Scaling\n\nallows organizations to scale Amazon EC2 capacity up or down automatically according to conditions defined for the particular workload\noptimize costs and use only the capacity that is actually needed (not for peak use)\n\nElastic Load Balancing\n\nautomatically distribute incoming application traffic across multiple Amazon EC2 instances in the cloud.\nfault tolerance\n\nAWS Elastic Beanstalk\n\nthe fastest and simplest way to get a web application up and running on AWS.\ndevelopers can simply upload their application code, and the service automatically handles all the details, such as resource provisioning, load balancing, Auto Scaling, and monitoring.\nSupported by many platforms, including PHP, Java and Python,\norganizations retain full control over the AWS resources powering the application and can access the underlying resources at any time\nLambda is simpler and less expensive, while Elastic Beanstalk lets you run full applications and gives you control over their environment.\n\nVirtual Private Coud (Amazon VPC)\n\nlets organizations provision a logically isolated section of the AWS Cloud where they can launch AWS resources in a virtual network that they define.\n\nAWS Direct Connect\n\nallows organizations to establish a dedicated network connection from their data center to AWS.\n\nAmazon Route 53\n\na highly available and scalable Domain Name System (DNS) web service\ni.e. converting human readable names like www.website.com to 192.0.2.1\ncan also be used to purchase domains\n\n\n\n\n2. Storage and Content Delivery\n\nAmazon Simple Storage Service (S3)\n\nhighly durable and scalable object storage that handles virtually unlimited amounts of data and large numbers of concurrent users\nstored as objects\nincluding backup and recovery, nearline archive, big data analytics, disaster recovery, cloud applications, and content distribution.\n\nAmazon Glacier\n\nis a secure, durable, and extremely low-cost storage service for data archiving and long-term backup\nseveral hours to access data\n\nAmazon Elastic Block Storage (EBS)\n\npersistent block-level storage volumes for use with Amazon EC2 instances.\nEach Amazon EBS volume is automatically replicated within its Availability Zone to protect organizations from component failure\n\nAWS Storage Gateway\n\na service connecting an on-premises software appliance with cloudbased storage\n\nAmazon CloudFront\n\na content delivery web service.\nintegrates with other AWS Cloud services\nan easy way to distribute content to users across the world with low latency, high data transfer speeds, and no minimum usage commitments\n\n\n\n\n3. Database Services\n\nAmazon Relational Database Service (Amazon RDS)\n\na fully managed relational database with support for many database engines\nmanages administration tasks, including backups, software patching, monitoring, scaling, and replication\n\nAmazon DynamoDB\n\na fast and flexible NoSQL database service\nconsistent, single-digit millisecond latency at any scale\ngreat fit for mobile, web, gaming, ad-tech, Internet of Things\n\nAmazon Redshift\n\na fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost effective to analyze structured data.\nstandard SQL interface\nallows organizations to automate most of the common administrative tasks associated with provisioning, configuring, and monitoring a cloud data warehouse.\n\nAmazon ElastiCache\n\na web service that simplifies deployment, operation, and scaling of an in-memory cache in the cloud\nimproves the performance of web applications by allowing organizations to retrieve information from fast, managed, in-memory caches\n\n\n\n\n4. Management tools\n\nAmazon CloudWatch\n\na monitoring service for AWS Cloud resources and the applications running on AWS\n\nAWS CloudFormation\n\ngives developers and systems administrators an effective way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\n\nAWS CloudTrail\n\na web service that records AWS API calls for an account and delivers log files for audit and review.\nIncludes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the service.\n\nAWS config\n\ndiscover existing AWS resources\ndetermine how a resource was configured at any point in time.\nenables compliance auditing, security analysis, resource change tracking, and troubleshooting.\n\n\n\n\n5. Security and Identity\n\nAWS Identity and Access Management (IAM)\n\nenables organizations to securely control access to AWS Cloud services and resources for their users\n\nAWS Key Management Service (KMS)\n\na managed service that makes it easy for organizations to create and control the encryption keys used to encrypt their data\n\nAWS Directory Service\n\nallows organizations to set up and run Microsoft Active Directory on the AWS Cloud or connect their AWS resources with an existing on-premises Microsoft Active Directory.\n\nAWS Certificate Manager\n\na service that lets organizations easily provision, manage, and deploy Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS Cloud services\n\nAWS Web Application Firewall (WAF)\n\nhelps protect web applications from common attacks and exploits that could affect application availability, compromise security, or consume excessive resources.\n\n\n\n\n6. Application Service\n\nAmazon API Gateway\n\na fully managed service for developers to create, publish, maintain, monitor, and secure APIs at any scale.\nAmazon API Gateway handles all the tasks involved in accepting and processing concurrent API calls,\n\nAmazon Elastic Transcoder\n\nmedia transcoding in the cloud, to convert (or transcode) media files from their source formats into versions that will play back on devices like smartphones,tablets, and PCs.\n\nAmazon Simple Notification Service (Amazon SNS)\n\na web service that coordinates and manages the delivery or sending of messages to recipients.\nthere are two types of clients, publishers and subscribers (or producers/consumers)\n\nAmazon Simple Email Service (Amazon SES)\n\na cost-effective email service to send transactional email,\nFor marketing messages, customer contact, receive messages, deliver them to an Amazon S3 bucket, call custom code via an AWS Lambda function, or publish notifications to Amazon SNS.\n\nAmazon Simple Workflow Service (Amazon SWF)\n\nhelps developers build, run, and scale background jobs that have parallel or sequential steps.\ncommonly, if your application’s steps take more than 500 milliseconds to complete, it is vitally important to track the state of processing and to provide the ability to recover or retry if a task fails. Amazon SWF helps organizations achieve this reliability.\n\nAmazon Simple Queue Service (Amazon SQS)\n\na fast, reliable, scalable, fully managed message queuing service\nallowing transmission of any volume of data, at any level of throughput, without losing messages or requiring other services to be always available\n\n\n\n\nMaintain Resiliency\n\nWhat is resiliency? The capability to recover when stressed by load (more requests for service), attacks (either accidental through a bug, or deliberate through intention), and failure of any component in the workload’s components.\n\nTo keep your application available, you need to maintain high availability and resiliency. A well-known best practice for cloud architecture is to use Region-scoped, managed services. These services come with availability and resiliency built in.\nWhen that is not possible, make sure the workload is replicated across multiple AZs. At a minimum, you should use two AZs. If one entire AZ fails, your application will have infrastructure up and running in at least a second AZ to take over the traffic.\nCloud computing virtualization (virtualized environment) is used to replace physical files, servers, etc with computer generated versions\n\nuses a hypervisor that allows a single computer to host many virtual machines\nVMs are software cotainers that run their own OS and act like standalone computers\n\nCharacteristics of virtualization - Resource Sharing - Build many computing from a single host/connected servers - Isolation - Availability - Aggregation - combine many resources - Reliability - load balancing which runs redundant servers on different host machines to prevent disruptions and ensure continual uptime"
  },
  {
    "objectID": "posts/AWS Qs.html",
    "href": "posts/AWS Qs.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "You should consider four main aspects when deciding which AWS Region to host your applications and workloads: - latency, - price, - service availability,\n- compliance.\nFocusing on these factors will enable you to make the right decision when choosing an AWS Region. You can find this content in the AWS Global Infrastructure video.\nRegions are clusters of Availability Zones. Availability Zones are clusters of data centers.\nThe AWS Global Infrastructure is nested for high availability and redundancy.\n- AWS Regions are clusters of Availability Zones that are connected through highly availably and redundant high-speed links and - Availability Zones are clusters of data centers that are also connected through highly available and redundant high-speed links.\nThere are six benefits of cloud computing. The correct answer for this question is “go global in minutes.” Going global in minutes means you can easily deploy your applications in multiple Regions around the world with just a few clicks. Check out the reading “What is AWS?”\nIn AWS, every action you make is an API call that is authenticated and authorized. You can make API calls to services and resources through the AWS Management Console, the AWS Command Line Interface (CLI), or the AWS Software Development Kits (SDKs). This content is covered in Interacting with AWS.\nWith the cloud, you no longer have to manage and maintain your own hardware in your own data centers. Companies like AWS own and maintain these data centers and provide virtualized data center technologies and services to users over the internet. This content is covered in the reading “What is AWS?\nYou use an access key (an access key ID and secret access key) to make programmatic requests to AWS. However, do not use your AWS account root user access key. The access key for your AWS account root user gives full access to all your resources for all AWS services, including your billing information. You cannot reduce the permissions associated with your AWS account root user access key. Therefore, protect your root user access key like you would your credit card numbers or any other sensitive secret. You should disable to delete any access keys associated with the root user, and you should also enable MFA for the root user. This information can be found in the video Protect the AWS Root User and Reading 1.6.\nUsers in your company are authenticated in your corporate network and want to be able to use AWS without having to sign in again. Which AWS authentication option should you use?\nInstead of creating an IAM User for each employee that needs access to the AWS account, you should use IAM Roles to federate users. Read more here: https://aws.amazon.com/identity/federation/ This information can be found in the video Role Based Access in AWS or Reading 1.8\n\nIAM policy\nA policy is an object in AWS that, when associated with an identity or resource, defines their permissions. AWS evaluates these policies when an IAM principal (user or role) makes a request. Permissions in the policies determine whether the request is allowed or denied. Most policies are stored in AWS as JSON documents that are attached to an IAM identity (user, group of users, or role). The information in a policy statement is contained within a series of elements:\n\nVersion – Specify the version of the policy language that you want to use. As a best practice, use the latest 2012-10-17 version.\nStatement – Use this main policy element as a container for the following elements. You can include more than one statement in a policy.\nSid (Optional) – Include an optional statement ID to differentiate between your statements.\nEffect – Use Allow or Deny to indicate whether the policy allows or denies access.\nPrincipal (Required in only some circumstances) – If you create a resource-based policy, you must indicate the account, user, role, or federated user to which you would like to allow or deny access. If you are creating an IAM permissions policy to attach to a user or role, you cannot include this element. The principal is implied as that user or role.\nAction – Include a list of actions that the policy allows or denies.\nResource (Required in only some circumstances) – If you create an IAM permissions policy, you must specify a list of resources to which the actions apply. If you create a resource-based policy, this element is optional. If you do not include this element, then the resource to which the action applies is the resource to which the policy is attached.\nCondition (Optional) – Specify the circumstances under which the policy grants permission.\n\nThe AWS account root user gives full access to all your resources for all AWS services, including your billing information. You cannot reduce the permissions associated with your AWS account root user access key. This information can be found in the video Protect the AWS Root User and Reading 1.6\nMulti-factor Authentication is an authentication method that requires the user to provide two or more verification factors to gain access to an AWS account. This information can be found in the video Protect the AWS Root User and Reading 1.6.\nCoursera\nExam Prep: AWS Certified Solutions Architect - Associate\nWeek 4\nBenchmark Assessment\nBenchmark Assessment Quiz1 hour • 1h Submit your assignment Due October 16, 11:59 PM BSTOct 16, 11:59 PM BST Receive grade To Pass 80% or higher Your grade\n-Not available Benchmark Assessment\nGraded Quiz. • 1h. • 31 total points available.31 total points DueOct 16, 11:59 PM BST 1. Question 1\nA company’s application allows users to upload image files to an Amazon S3 bucket. These files are accessed frequently for the first 30 days. After 30 days, these files are rarely accessed, but need to be durably stored and available immediately upon request. A solutions architect is tasked with configuring a lifecycle policy that minimizes the overall cost while meeting the application requirements. Which action will accomplish this?\n4.1 Identify cost-effective storage solutions 1 point\nConfigure a lifecycle policy to move the files to S3 Glacier after 30 days.\nConfigure a lifecycle policy to move the files to S3 Glacier Deep Archive after 30 days.\nConfigure a lifecycle policy to move the files to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.\nConfigure a lifecycle policy to move the files to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days. 2. Question 2\nA company needs to implement a secure data encryption solution to meet regulatory requirements. The solution must provide security and durability in generating, storing, and controlling cryptographic data keys. Which action should be taken to provide the MOST secure solution?\n3.3 Select appropriate data security options 1 point\nUse AWS Key Management Service (AWS KMS) to generate AWS KMS keys and data keys. Use AWS KMS key policies to control access to the KMS keys.\nUse AWS Key Management Service (AWS KMS) to generate cryptographic keys and import the keys to AWS Certificate Manager. Use IAM policies to control access to the keys.\nUse a third-party solution from AWS Marketplace to generate the cryptographic keys and store them on encrypted instance store volumes. Use IAM policies to control access to the encryption key APIs.\nUse OpenSSL to generate the cryptographic keys and upload the keys to an Amazon S3 bucket with encryption enabled. Apply AWS Key Management Service (AWS KMS) key policies to control access to the keys. 3. Question 3\nA startup company is looking for a solution to cost-effectively run and access microservices without the operational overhead of managing infrastructure. The solution needs to be able scale quickly to accommodate rapid changes in the volume of requests and protect against common DDoS attacks. What is the MOST cost-effective solution that meets these requirements?\n4.2 Identify cost-effective compute and database services 1 point\nRun the microservices in containers using AWS Elastic Beanstalk.\nRun the microservices in AWS Lambda behind an Amazon API Gateway.\nRun the microservices on Amazon EC2 instances in an Auto Scaling group.\nRun the microservices in containers using Amazon Elastic Container Service (Amazon ECS) backed by EC2 instances. 4. Question 4\nA solutions architect needs to design a secure environment for AWS resources that are being deployed to Amazon EC2 instances in a VPC. The solution should support for a three-tier architecture consisting of web servers, application servers, and a database cluster. The VPC needs to allow resources in the web tier to be accessible from the internet with only the HTTPS protocol. Which combination of actions would meet these requirements? (Select TWO.)\n3.2 Design secure application tiers 1 point\nAttach Amazon API Gateway to the VPC. Create private subnets for the web, application, and database tiers.\nAttach an internet gateway to the VPC. Create public subnets for the web tier. Create private subnets for the application and database tiers.\nAttach a virtual private gateway to the VPC. Create public subnets for the web and application tiers. Create private subnets for the database tier.\nCreate a web server security group that allows all traffic from the internet. Create an application server security group that allows requests from only the Amazon API Gateway on the application port. Create a database cluster security group that allows TCP connections from the application security group on the database port only.\nCreate a web server security group that allows HTTPS requests from the internet. Create an application server security group that allows requests from the web security group only. Create a database cluster security group that allows TCP connections from the application security group on the database port only. 5. Question 5\nA solutions architect has been given a large number of video files to upload to an Amazon S3 bucket. The file sizes are 100–500 MB. The solutions architect also wants to easily resume failed upload attempts. How should the solutions architect perform the uploads in the LEAST amount of time?\n2.2 Select high-performing and scalable storage solutions for a workload 1 point\nSplit each file into 5-MB parts. Upload the individual parts normally and use S3 multipart upload to merge the parts into a complete object.\nUsing the AWS CLI, copy individual objects into the S3 bucket with the aws s3 cp command.\nFrom the Amazon S3 console, select the S3 bucket. Upload the S3 bucket, and drag and drop items into the bucket.\nUpload the files with SFTP and the AWS Transfer Family. 6. Question 6\nA gaming company is experiencing exponential growth. On multiple occasions, customers have been unable to access resources. To keep up with the increased demand, Management is considering deploying a cloud-based solution. The company is looking for a solution that can match the on-premises resilience of multiple data centers, and is robust enough to withstand the increased growth activity. Which configuration should a Solutions Architect implement to deliver the desired results?\n1.2 Design highly available and/or fault-tolerant architectures 1 point\nA VPC configured with an ELB Application Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances in one Availability Zone\nMultiple Amazon EC2 instances configured within peered VPCs across two Availability Zones\nA VPC configured with an ELB Network Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances spanning two Availability Zones\nA VPC configured with an ELB Application Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances spanning two AWS Regions 7. Question 7\nA Solutions Architect must secure the network traffic for two applications running on separate Amazon EC2 instances in the same subnet. The applications are called Application A and Application B. Application A requires that inbound HTTP requests be allowed and all other inbound traffic be blocked. Application B requires that inbound HTTPS traffic be allowed and all other inbound traffic be blocked, including HTTP traffic. What should the Solutions Architect use to meet these requirements?\n3.2 Design secure application tiers 1 point\nConfigure the access with network access control lists (network ACLs).\nConfigure the access with security groups.\nConfigure the network connectivity with VPC peering.\nConfigure the network connectivity with route tables. 8. Question 8\nA data processing facility wants to move a group of Microsoft Windows servers to the AWS Cloud. Theses servers require access to a shared file system that can integrate with the facility’s existing Active Directory infrastructure for file and folder permissions. The solution needs to provide seamless support for shared files with AWS and on-premises servers and allow the environment to be highly available. The chosen solution should provide added security by supporting encryption at rest and in transit. Which storage solution would meet these requirements?\n4.1 Identify cost-effective storage solutions 1 point\nAn Amazon S3 File Gateway joined to the existing Active Directory domain\nAn Amazon FSx for the Windows File Server file system joined to the existing Active Directory domain\nAn Amazon Elastic File System (Amazon EFS) file system joined to an AWS Managed Microsoft AD domain\nAn Amazon S3 bucket mounted on Amazon EC2 instances in multiple Availability Zones running Windows Server 9. Question 9\nA Solutions Architect notices an abnormal amount of network traffic coming from an Amazon EC2 instance. The traffic is determined to be malicious and the destination needs to be determined. What tool can the Solutions Architect use to identify the destination of the malicious network traffic?\n3.2 Design secure application tiers 1 point\nEnable AWS CloudTrail and filter the logs.\nEnable VPC Flow Logs and filter the logs.\nConsult the AWS Personal Health Dashboard.\nFilter the logs from Amazon CloudWatch. 10. Question 10\nA company is deploying an environment for a new data processing application. This application will be frequently accessed by 20 different departments across the globe seeking to run analytics. The company plans to charge each department for the cost of that department’s access. Which solution will meet these requirements with the LEAST effort?\n2.2 Select high-performing and scalable storage solutions for a workload 1 point\nAmazon Aurora with global databases. Each department will query a database in a different Region, and the Region is tagged in the billing console.\nPostgreSQL on Amazon RDS, with read replicas for each department. Each department will query the read replica tagged for their team in the billing console.\nAmazon Redshift, with clusters set up for each department. Each department will query the cluster tagged for their team in the billing console.\nAmazon Athena with workgroups set up for each department. Each department will query via the workgroup tagged for their team in the billing console. 11. Question 11\nA company is migrating its on-premises application to Amazon Web Services and refactoring its design. The design will consist of frontend Amazon EC2 instances that receive requests, backend EC2 instances that process the requests, and a message queuing service to address decoupling the application. The Solutions Architect has been informed that a key aspect of the application is that requests are processed in the order in which they are received. Which AWS service should the Solutions Architect to decouple the application?\n1.3 Design decoupling mechanisms using AWS services 1 point\nAmazon Simple Queue Service (Amazon SQS) standard queue\nAmazon Simple Notification Service (Amazon SNS)\nAmazon Simple Queue Service (Amazon SQS) FIFO queue\nAmazon Kinesis 12. Question 12\nAn API receives a high volume of sensor data. The data is written to a queue before being processed to produce trend analysis and forecasting reports. With the current architecture, some data records are being received and processed more than once. How can a solutions architect modify the architecture to ensure that duplicate records are not processed?\n1.3 Design decoupling mechanisms using AWS services 1 point\nConfigure the API to send the records to Amazon Kinesis Data Streams.\nConfigure the API to send the records to Amazon Kinesis Data Firehose.\nConfigure the API to send the records to Amazon Simple Notification Service (Amazon SNS).\nConfigure the API to send the records to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. 13. Question 13\nAfter reviewing the cost optimization checks in AWS Trusted Advisor, a team finds that it has 10,000 Amazon Elastic Block Store (Amazon EBS) snapshots in its account that are more than 30 days old. The team has determined that it needs to implement better governance for the lifecycle of its resources. Which actions should the team take to automate the lifecycle management of the EBS snapshots with the LEAST effort? (Select TWO.)\n4.1 Identify cost-effective storage solutions 1 point\nCreate and schedule a backup plan with AWS Backup.\nCopy the EBS snapshots to Amazon S3, and then create lifecycle configurations in the S3 bucket.\nUse Amazon Data Lifecycle Manager (Amazon DLM).\nUse a scheduled event in Amazon EventBridge (Amazon CloudWatch Events) and invoke AWS Step Functions to manage the snapshots.\nSchedule and run backups in AWS Systems Manager. 14. Question 14\nA company is deploying a production portal application on AWS. The database tier runs on a MySQL database. The company requires a highly available database solution that maximizes ease of management. How can the company meet these requirements?\n1.2 Design highly available and/or fault-tolerant architectures 1 point\nDeploy the database on multiple Amazon EC2 instances that are backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones. Schedule periodic EBS snapshots.\nUse Amazon RDS with a Multi-AZ deployment. Schedule periodic database snapshots.\nUse Amazon RDS with a Single-AZ deployment. Schedule periodic database snapshots.\nUse Amazon DynamoDB with an Amazon DynamoDB Accelerator (DAX) cluster. Create periodic on-demand backups. 15. Question 15\nA company requires operating system permissions on a relational database server. What should a solutions architect suggest as a configuration for a highly available database architecture?\n1.2 Design highly available and/or fault-tolerant architectures 1 point\nMultiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones\nA database installed on a single Amazon EC2 instance in an Availability Zone\nAmazon RDS in a Multi-AZ configuration with Provisioned IOPS\nMultiple Amazon EC2 instances in a replication configuration that uses a placement group 16. Question 16\nA company has developed an application that processes photos and videos. When users upload photos and videos, a job processes the files. The job can take up to 1 hour to process long videos. The company is using Amazon EC2 On-Demand Instances to run web servers and processing jobs. The web layer and the processing layer have instances that run in an Auto Scaling group behind an Application Load Balancer. During peak hours, users report that the application is slow and that the application does not process some requests at all. During evening hours, the systems are idle. What should a solutions architect do so that the application will process all jobs in the MOST cost-effective manner?\n2.1 Identify elastic and scalable compute solutions for a workload 1 point\nUse a larger instance size in the Auto Scaling groups of the web layer and the processing layer.\nUse Spot Instances for the Auto Scaling groups of the web layer and the processing layer.\nUse an Amazon Simple Queue Service (Amazon SQS) standard queue between the web layer and the processing layer. Use a custom queue metric to scale the Auto Scaling group in the processing layer.\nUse AWS Lambda functions instead of EC2 instances and Auto Scaling groups. Increase the service quota so that sufficient concurrent functions can run at the same time. 17. Question 17\nA company is developing an application that runs on Amazon EC2 instances in a private subnet. The EC2 instances use a NAT gateway to access the internet. A solutions architect must provide a secure option so that developers can log in to the instances. Which solution meets these requirements MOST cost-effectively?\n4.3 Design cost-optimized network architectures 1 point\nConfigure AWS Systems Manager Session Manager for the EC2 instances to enable login.\nConfigure a bastion host in a public subnet to log in to the EC2 instances in a private subnet.\nUse the existing NAT gateway to log in to the EC2 instances in a private subnet.\nConfigure AWS Site-to-Site VPN to log in directly to the EC2 instances. 18. Question 18\nA company is using an Amazon S3 bucket to store archived data for audits. The company needs long-term storage for the data. The data is rarely accessed and must be available for retrieval the next business day. After a quarterly review, the company wants to reduce the storage cost for the S3 bucket. A solutions architect must recommend the most cost-effective solution to store the archived data. Which solution will meet these requirements?\n4.1 Identify cost-effective storage solutions 1 point\nStore the data on an Amazon EC2 instance that uses Amazon Elastic Block Store (Amazon EBS).\nUse an S3 Lifecycle configuration rule to move the data to S3 Standard-Infrequent Access (S3 Standard-IA).\nStore the data in S3 Glacier.\nStore the data in another S3 bucket in a different AWS Region. 19. Question 19\nA solutions architect must create a disaster recovery (DR) solution for a company’s business-critical applications. The DR site must reside in a different AWS Region than the primary site. The solution requires a recovery point objective (RPO) in seconds and a recovery time objective (RTO) in minutes. The solution also requires the deployment of a completely functional, but scaled-down version of the applications. Which DR strategy will meet these requirements?\n1.2 Design highly available and/or fault-tolerant architectures 1 point\nMulti-site active-active\nBackup and restore\nPilot light\nWarm standby 20. Question 20\nA financial services company is migrating its multi-tier web application to AWS. The application architecture consists of a fleet of web servers, application servers, and an Oracle database. The company must have full control over the database’s underlying operating system, and the database must be highly available. Which approach should a solutions architect use for the database tier to meet these requirements?\n1.2 Design highly available and/or fault-tolerant architectures 1 point\nMigrate the database to an Amazon RDS for Oracle DB Single-AZ DB instance.\nMigrate the database to an Amazon RDS for Oracle Multi-AZ DB instance.\nMigrate to Amazon EC2 instances in two Availability Zones. Install Oracle Database and configure the instances to operate as a cluster.\nMigrate to Amazon EC2 instances in a single Availability Zone. Install Oracle Database and configure the instances to operate as a cluster. 21. Question 21\nA hospital client is migrating from another cloud provider to AWS and is looking for advice on modernizing as they migrate. They have containerized applications that run on tablets. During spikes caused by increases in patient visits, the communications from the applications to the central database occasionally fail. As a result, the client currently has the applications try to write to the central database once, and if that write fails, it writes to a dedicated application PostgreSQL database run by the hospital IT team on premises. Each of those PostgreSQL databases then sends batch information on to the central database. The client is asking for recommendations for migrating or refactoring the database write process to decrease operational overhead. What should the solutions architect recommend? (Select TWO.)\n4.2 Identify cost-effective compute and database services 1 point\nMigrate the containerized applications to AWS Fargate.\nMigrate the local databases to Aurora Serverless for PostgreSQL.\nMigrate the PostgreSQL databases to an RDS instance with a read replica that replaces each of the local databases.\nRefactor the applications to use Amazon Simple Queue Service and eliminate the local PostgreSQL databases.\nRefactor the central database to add an Amazon ElastiCache lazy loading cache in front of the database. 22. Question 22\nA large international company has a management account in AWS Organizations, and over 50 individual accounts for each country they operate in. Each of the country accounts has least four VPCs set up for functional divisions. There is a high amount of trust across the accounts, and communication among all of the VPCs should be allowed. Each of the individual VPCs throughout the entire global organization will need to access an account and VPC that provide shared services to all the other accounts. How can the member accounts access the shared services VPC with the LEAST operational overhead?\n2.3 Select high-performing networking solutions for a workload 1 point\nCreate an Application Load Balancer, with a target of the private IP address of the shared services VPC. Add a Certification Authority Authorization (CAA) record for the Application Load Balancer to Amazon Route 53. Point all requests for shared services in the routing tables of the VPCs to the CAA record.\nCreate a peering connection between each of the VPCs and the shared services VPC.\nCreate a Network Load Balancer across the Availability Zones in the shared services VPC. Create service consumer roles in IAM, and set endpoint connection acceptance to automatically accept. Create consumer endpoints in each division VPC and point to the Network Load Balancer.\nCreate a VPN connection between each of the VPCs and the shared service VPC. 23. Question 23\nA SysOps administrator is looking into a way to automate the deployment of new SSL/TLS certificates to their web servers, and a centralized way to track and manage the deployed certificates. Which AWS service can the administrator use to fulfill the above-mentioned needs?\n3.2 Design secure application tiers 1 point\nAWS Key Management Service\nAWS Certificate Manager\nConfigure AWS Systems Manager Run Command\nAWS Systems Manager Parameter Store 24. Question 24\nA client has created a website (www.example.com), with an Application Load Balancer in a public subnet. The load balancer targets an application hosted on EC2 instances in private subnets, which rely on an Amazon Aurora PostgreSQL-Compatible Edition DB instance in separate private subnets. When testing the website, static content from the EC2 instance is displayed, but any content driven by database queries fails to load. What should the administrator check?\n1.1 Design a multi-tier architecture solution 1 point\nCheck the Amazon Route 53 CNAME record to ensure that www.example.com points to the top-level domain (example.com).\nCheck the network access control list (network ACL) of the application subnets for an outbound allow statement.\nCheck that the route table for the database subnets includes a default route to the internet gateway for the VPC.\nCheck if the security group of the database subnet allows inbound traffic from the EC2 subnets. 25. Question 25\nA solutions architect has been tasked with designing a three-tier application for deployment in AWS. There will be a web tier as the frontend, a backend application tier for data processing, and a database that will be hosted on Amazon RDS. The application frontend will be distributed to end users by CloudFront. Following best practices, it is decided that there should not be any point-to-point dependencies between the different layers of the infrastructure. How many Elastic Load Balancing load balancers should the architect deploy in the architecture so that this application’s design follows best practices?\n1.1 Design a multi-tier architecture solution 1 point\nZero. Use the load balancer that is automatically enabled when CloudFront is deployed.\nOne load balancer. This load balancer would be between the web tier and the application tier.\nTwo load balancers. One public load balancer would direct traffic to the web tier, and one private load balancer would direct traffic to the application tier.\nThree load balancers. One public load balancer would direct traffic to the web tier. One private load balancer would direct traffic to the application tier. Another private load balancer would direct traffic to the Amazon RDS database. 26. Question 26\nThe CIO of a company is concerned about the security of the account root user of their AWS account. How can the CIO ensure that the AWS account follows the best practices for logging in securely? (Select TWO.)\n3.1 Design secure access to AWS resources 1 point\nEnforce the use of an access key ID and secret access key for the account root user logins.\nEnforce the use of MFA for the account root user logins.\nEnforce the account root user to assume a role to access the root user’s own resources.\nEnforce the use of complex passwords for member account root user logins.\nEnforce the deletion of the AWS account so that it cannot be used. 27. Question 27\nA Solutions Architect has been tasked with creating a data store location that will be able to handle different file formats of unknown sizes. It is required that this data be highly available and protected from being accidentally deleted. What solution meets the requirements and is the MOST cost-effective?\n3.3 Select appropriate data security options 1 point\nDeploy an Amazon S3 bucket and enable Cross-Region Replication.\nDeploy an Amazon DynamoDB table and enable Global Tables.\nDeploy an Amazon S3 bucket and enable Object Versioning.\nDeploy a database using Amazon RDS and configure a Multi-AZ deployment for that database. 28. Question 28\nAn organization is planning to migrate from an on-premises data center to an AWS environment that spans multiple Availability Zones. A migration engineer has been tasked to plan how to transfer the home directories and other shared network attached storage from the data center to AWS. The migration design should support connections from multiple Amazon EC2 instances running the Linux operating system to this common shared storage platform. What storage option best fits their design?\n1.4 Choose appropriate resilient storage 1 point\nTransfer the files to Amazon S3 and access that data from the EC2 instances.\nTransfer the files to the EC2 Instance Store attached to the EC2 instances.\nTransfer the files to Amazon EFS and mount that file system to the EC2 instances.\nTransfer the files to one EBS volume and mount that volume to the EC2 instances. 29. Question 29\nA company is designing a human genome application using multiple Amazon EC2 Linux instances. The high performance computing (HPC) application requires low latency and high performance network communication between the instances. Which solution provides the LOWEST latency between the instances?\n1.1 Design a multi-tier architecture solution 1 point\nLaunch the EC2 instances in a cluster placement group.\nLaunch the EC2 instances in a spread placement group.\nLaunch the EC2 instances in an Auto Scaling group spanning multiple Regions.\nLaunch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones within a Region. 30. Question 30\nA company has a web application in which customers can log in and read near-real-time status updates about their orders. The company hosts the application on Amazon EC2 instances and is expanding the application from the eu-west-1 Region into the us-east-1 Region. The application relies on an Amazon RDS for MySQL database. The company already has provisioned the necessary EC2 instances in the new Region. The company needs to deploy the application in us-east-1 with the least possible change to the application. The company also needs fast, local database queries in both Regions. Which modification of the database will meet these requirements?\n2.4 Choose high-performing database solutions for a workload. 1 point\nMigrate the RDS database to an Amazon Aurora global database. Add a secondary cluster in us-east-1.\nMigrate the RDS database to an Amazon Aurora Serverless database. Configure automatic scaling in us-east-1.\nMigrate the RDS database to an Amazon DynamoDB table. Create global tables for us-east-1.\nPlace an accelerator from AWS Global Accelerator in front of the RDS database to reduce the network latency from us-east-1. 31. Question 31\nA company is building a distributed application, which will send sensor IoT data– including weather conditions and wind speed from wind turbines–to the AWS Cloud for further processing. Because the nature of the data is spiky, the application needs to be able to scale. It is important to store the streaming data in a key-value database and then send it over to a centralized data lake, where it can be transformed, analyzed, and combined with diverse organizational datasets to derive meaningful insights and make predictions. Which combination of solutions would accomplish the business need with minimal operational overhead? (Select TWO.)\n2.4 Choose high-performing database solutions for a workload. 1 point\nConfigure Amazon Kinesis to deliver streaming data to an Amazon S3 data lake.\nUse Amazon DocumentDB to store IoT sensor data.\nWrite AWS Lambda functions to deliver streaming data to Amazon S3.\nUse Amazon DynamoDB to store the IoT sensor data, and enable DynamoDB Streams.\nUse Amazon Kinesis to deliver streaming data to Amazon Redshift, and enable Amazon Redshift Spectrum."
  },
  {
    "objectID": "posts/AWS questions.html",
    "href": "posts/AWS questions.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "Chapter 3\n\nYour web application needs four instances to support steady traffic nearly all of the time. On the last day of each month, the traffic triples. What is a cost-effective way to handle this traffic pattern?\n\n\nRun 12 Reserved Instances all of the time.\nRun four On-Demand Instances constantly, then add eight more On-Demand Instances on the last day of each month.\nRun four Reserved Instances constantly, then add eight On-Demand Instances on the last day of each month.\nRun four On-Demand Instances constantly, then add eight Reserved Instances on the last day of each month.\n\n\nYour order-processing application processes orders extracted from a queue with two Reserved Instances processing 10 orders/minute. If an order fails during processing, then it is returned to the queue without penalty. Due to a weekend sale, the queues have several hundred orders backed up. While the backup is not catastrophic, you would like to drain it so that customers get their confirmation emails faster. What is a cost-effective way to drain the queue for orders?\n\n\nCreate more queues.\nDeploy additional Spot Instances to assist in processing the orders.\nDeploy additional Reserved Instances to assist in processing the orders.\nDeploy additional On-Demand Instances to assist in processing the orders.\n\n\nWhich of the following must be specified when launching a new Amazon Elastic Compute Cloud (Amazon EC2) Windows instance? (Choose 2 answers)\n\n\nThe Amazon EC2 instance ID\nPassword for the administrator account\nAmazon EC2 instance type\nAmazon Machine Image (AMI)\n\n\nYou have purchased an m3.xlarge Linux Reserved instance in us-east-1a. In which ways can you modify this reservation? (Choose 2 answers)\n\n\nChange it into two m3.large instances.\nChange it to a Windows instance.\nMove it to us-east-1b.\nChange it to an m4.xlarge.\n\n\nYour instance is associated with two security groups. The first allows Remote Desktop Protocol (RDP) access over port 3389 from Classless Inter-Domain Routing (CIDR) block 72.14.0.0/16. The second allows HTTP access over port 80 from CIDR block0.0.0.0/0. What traffic can reach your instance?\n\n\nRDP and HTTP access from CIDR block 0.0.0.0/0\nNo traffic is allowed.\nRDP and HTTP traffic from 72.14.0.0/16\nRDP traffic over port 3389 from 72.14.0.0/16 and HTTP traffic over port 80 from 0.0.00/0\n\n\nWhich of the following are features of enhanced networking? (Choose 3 answers)\n\n\nMore Packets Per Second (PPS)\nLower latency\nMultiple network interfaces\nBorder Gateway Protocol (BGP) routing\nLess jitter\n\n\nYou are creating a High-Performance Computing (HPC) cluster and need very low latency and high bandwidth between instances. What combination of the following will allow this? (Choose 3 answers)\n\n\nUse an instance type with 10 Gbps network performance.\nPut the instances in a placement group.\nUse Dedicated Instances.\nEnable enhanced networking on the instances.\nUse Reserved Instances.\n\n\nWhich Amazon Elastic Compute Cloud (Amazon EC2) feature ensures that your instances will not share a physical host with instances from any other AWS customer?\n\n\nAmazon Virtual Private Cloud (VPC)\nPlacement groups\nDedicated Instances\nReserved Instances\n\n\nWhich of the following are true of instance stores? (Choose 2 answers)\n\n\nAutomatic backups\nData is lost when the instance stops.\nVery high IOPS\nCharge is based on the total amount of storage provisioned.\n\n\nWhich of the following are features of Amazon Elastic Block Store (Amazon EBS)? (Choose 2 answers)\n\n\nData stored on Amazon EBS is automatically replicated within an Availability Zone.\nAmazon EBS data is automatically backed up to tape.\nAmazon EBS volumes can be encrypted transparently to workloads on the attached instance.\nData on an Amazon EBS volume is lost when the attached instance is stopped.\n\n\nYou need to take a snapshot of an Amazon Elastic Block Store (Amazon EBS) volume. How long will the volume be unavailable?\n\n\nIt depends on the provisioned size of the volume.\nThe volume will be available immediately.\nIt depends on the amount of data stored on the volume.\nIt depends on whether the attached instance is an Amazon EBS-optimized instance.\n\n\nYou are restoring an Amazon Elastic Block Store (Amazon EBS) volume from a snapshot. How long will it be before the data is available?\n\n\nIt depends on the provisioned size of the volume.\nThe data will be available immediately.\nIt depends on the amount of data stored on the volume.\nIt depends on whether the attached instance is an Amazon EBS-optimized instance.\n\n\nYou have a workload that requires 15,000 consistent IOPS for data that must be durable. What combination of the following steps do you need? (Choose 2 answers)\n\n\nUse an Amazon Elastic Block Store (Amazon EBS)-optimized instance.\nUse an instance store.\nUse a Provisioned IOPS SSD volume.\nUse a magnetic volume.\n\n\nWhich of the following can be accomplished through bootstrapping?\n\n\nInstall the most current security updates.\nInstall the current version of the application.\nConfigure Operating System (OS) services.\nAll of the above.\n\n\nHow can you connect to a new Linux instance using SSH?\n\n\nDecrypt the root password.\nUsing a certificate\nUsing the private half of the instance’s key pair\nUsing Multi-Factor Authentication (MFA)\n\n\nVM Import/Export can import existing virtual machines as: (Choose 2 answers)\n\n\nAmazon Elastic Block Store (Amazon EBS) volumes- Amazon Elastic Compute Cloud (Amazon EC2) instances\nAmazon Machine Images (AMIs)\nSecurity groups\n\n\nWhich of the following can be used to address an Amazon Elastic Compute Cloud (Amazon EC2) instance over the web? (Choose 2 answers)\n\n\nWindows machine name\nPublic DNS name\nAmazon EC2 instance ID\nElastic IP address\n\n\nUsing the correctly decrypted Administrator password and RDP, you cannot log in to a Windows instance you just launched- Which of the following is a possible reason?\n\n\nThere is no security group rule that allows RDP access over port 3389 from your IP address.\nThe instance is a Reserved Instance.\nThe instance is not using enhanced networking.\nThe instance is not an Amazon EBS-optimized instance.\n\n\nYou have a workload that requires 1 TB of durable block storage at 1,500 IOPS during normal use. Every night there is an Extract, Transform, Load (ETL) task that requires 3,000 IOPS for 15 minutes. What is the most appropriate volume type for this workload?\n\n\nUse a Provisioned IOPS SSD volume at 3,000 IOPS.\nUse an instance store.\nUse a general-purpose SSD volume.\nUse a magnetic volume.\n\n\nHow are you billed for elastic IP addresses?\n\n\nHourly when they are associated with an instance\nHourly when they are not associated with an instance\nBased on the data that flows through them\nBased on the instance type to which they are attached"
  },
  {
    "objectID": "posts/class.html",
    "href": "posts/class.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "class FirstClass: # Define a class object\n    def setdata(self, value): # Define class methods\n        self.data = value # self is the instance\n    def display(self):\n        print(self.data)\n        \nxx = FirstClass()\nxx.setdata(90)\nxx.display()\n\n90\n\n\n\nclass SecondClass(FirstClass):\n    def __init__(self,value):\n        self.data = value\n    def __str__(self):# overwrites print\n        return \"Current value ='%s'\" % self.data\n    def __mul__(self, other):\n        self.data *= other\n    def __add__(self,other):# overwrites + N.B. uses __init__ value\n        return SecondClass(self.data + other)\n        \nwe = SecondClass(909)\nwe.name='opop'\nwe.setdata(9090)\nwe.display()\nprint(we)\nwewe = we+9\nwewe.display()\n\n# attach attributes outside class call\nSecondClass.ts ='ts'\n\nyou = SecondClass(909)\nyou.ts, we.ts\n\n9090\nCurrent value ='9090'\n9099\n\n\n('ts', 'ts')\n\n\n\n## get the attributes of a class\nprint(SecondClass.__dict__.keys())\n\n## get the attributes of a class instance note only ones assigned are listed not just inherited\nprint(we.__dict__.keys())\n\nwe.__class__\n\ndict_keys(['__module__', '__init__', '__str__', '__mul__', '__add__', '__doc__', 'ts'])\ndict_keys(['data', 'name'])\n\n\n__main__.SecondClass\n\n\n\ndef upperName(self):\n    return self.name.upper()\n\nprint( upperName(we) )\n\n## Attach the function to the class SecondClass\nSecondClass.upsy = upperName\n\nprint( we.name, we.upsy() )\n\nOPOP\nopop OPOP\n\n\n\nfrom data.mod3 import * #data.mod == ./data/mod.py\n\ntry:\n    print(f\"val a is {a}\")\nexcept:\n    print(f\"no value a\")\ntry:\n    print(f\"val b is {b}\")\nexcept:\n    print(f\"no value b\")\ntry:\n    print(f\"val c is {c}\")\nexcept:\n    print(f\"no value c\")\ntry:\n    print(f\"val d is {d}\")\nexcept:\n    print(f\"no value d\")\n\n# wayne(b)\n\nval a is 1\nno value b\nno value c\nval d is 4"
  },
  {
    "objectID": "posts/data/Basics.html",
    "href": "posts/data/Basics.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "# Reading in the initial data\n\nimport pandas as pd\n\nmatches = pd.read_csv(\"matches.csv\", index_col=0)"
  },
  {
    "objectID": "posts/GolfSwingPart4.html#modifications-to-code-for-separating-swing-video",
    "href": "posts/GolfSwingPart4.html#modifications-to-code-for-separating-swing-video",
    "title": "ThomasHSimm",
    "section": "Modifications to code for separating swing video",
    "text": "Modifications to code for separating swing video\n\n- Imported files are not saved to a location\nThis means can’t pass ‘path’ when creating the Dataset. So that line is removed from the __init__\nIn theory the video could then be loaded with cap = cv2.VideoCapture(self) but this doesn’t work as openCV requires a file. So a get around for this is create a temp file https://discuss.streamlit.io/t/how-to-access-uploaded-video-in-streamlit-by-open-cv/5831/4\nf = st.file_uploader(\"Upload file\")\ntfile = tempfile.NamedTemporaryFile(delete=False)\ntfile.write(f.read())\nvf = cv.VideoCapture(tfile.name)\nFor the same reason the image files are not saved as a file\n\n\n- Video load issue\nIf the video is loaded a second time ret, img = cv2.VideoCapture there are problems receieving the video i.e. ret=False.\nA get around used was to copy the imported file\nuploaded_filesCOPY = copy.copy( uploaded_files )\n\n\n- Using on a CPU instead of a GPU\nThe code needed modifying slightly to allow it to work using a CPU. Although it does have the following line, a few more changes were needed\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nAdding a description in the loads\ntorch.load('mobilenet_v2.pth.tar',map_location=torch.device('cpu'))\nRemoving the cdu() part at end of e.g. variables\nVariable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden).cuda()\n# to     \nVariable(torch.zeros(2*self.lstm_layers, batch_size, self.lstm_hidden)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/statistics.html#ab-testing",
    "href": "posts/statistics.html#ab-testing",
    "title": "ThomasHSimm",
    "section": "AB Testing",
    "text": "AB Testing\nA test is performed on a number of items. We’ll look at how the test influences the orders made of that item.\n\nFind orders within 6 months after test started\n\n\n\nimport pandas as pd\nfrom pandasql import sqldf \ndf = pd.read_csv('./data/abtesting.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      item_id\n      test_assignment\n      test_number\n      test_start_date\n    \n  \n  \n    \n      0\n      2512.0\n      1.0\n      item_test_1\n      2013-01-05 00:00:00\n    \n    \n      1\n      482.0\n      0.0\n      item_test_1\n      2013-01-05 00:00:00\n    \n    \n      2\n      2446.0\n      0.0\n      item_test_1\n      2013-01-05 00:00:00\n    \n    \n      3\n      1312.0\n      0.0\n      item_test_1\n      2013-01-05 00:00:00\n    \n    \n      4\n      3556.0\n      1.0\n      item_test_1\n      2013-01-05 00:00:00\n    \n  \n\n\n\n\n\ndf.describe(include='all')\n\n\n\n\n\n  \n    \n      \n      item_id\n      test_assignment\n      test_number\n      test_start_date\n    \n  \n  \n    \n      count\n      6594.000000\n      6594.000000\n      6594\n      6594\n    \n    \n      unique\n      NaN\n      NaN\n      3\n      3\n    \n    \n      top\n      NaN\n      NaN\n      item_test_3\n      2016-01-07 00:00:00\n    \n    \n      freq\n      NaN\n      NaN\n      2198\n      2198\n    \n    \n      mean\n      1991.293904\n      0.496967\n      NaN\n      NaN\n    \n    \n      std\n      1163.787869\n      0.500029\n      NaN\n      NaN\n    \n    \n      min\n      0.000000\n      0.000000\n      NaN\n      NaN\n    \n    \n      25%\n      981.000000\n      0.000000\n      NaN\n      NaN\n    \n    \n      50%\n      2008.000000\n      0.000000\n      NaN\n      NaN\n    \n    \n      75%\n      2995.000000\n      1.000000\n      NaN\n      NaN\n    \n    \n      max\n      3997.000000\n      1.000000\n      NaN\n      NaN\n    \n  \n\n\n\n\n\norders = pd.read_csv('./data/ab_orders.csv')\norders.head()\n\n\n\n\n\n  \n    \n      \n      invoice_id\n      line_item_id\n      user_id\n      item_id\n      item_name\n      item_category\n      price\n      created_at\n      paid_at\n    \n  \n  \n    \n      0\n      192320.0\n      83118.0\n      178481.0\n      3526.0\n      digital apparatus\n      apparatus\n      330.0\n      2017-06-28 21:14:25\n      2017-06-27 21:19:39\n    \n    \n      1\n      192320.0\n      207309.0\n      178481.0\n      1514.0\n      miniature apparatus cleaner\n      apparatus\n      99.0\n      2017-06-28 21:14:25\n      2017-06-27 21:19:39\n    \n    \n      2\n      192320.0\n      392027.0\n      178481.0\n      3712.0\n      miniature apparatus cleaner\n      apparatus\n      99.0\n      2017-06-28 21:14:25\n      2017-06-27 21:19:39\n    \n    \n      3\n      80902.0\n      243831.0\n      154133.0\n      3586.0\n      reflective instrument\n      instrument\n      57.2\n      2016-10-09 06:57:30\n      2016-10-07 10:08:10\n    \n    \n      4\n      80902.0\n      399806.0\n      154133.0\n      1061.0\n      extra-strength instrument charger\n      instrument\n      17.6\n      2016-10-09 06:57:30\n      2016-10-07 10:08:10\n    \n  \n\n\n\n\n\nd1 = sqldf(\"\\\n            SELECT                                                                                                            \\\n                orders.item_id, test.test_start_date, orders.created_at, test.test_assignment,                                                     \\\n                (strftime('%s',orders.created_at) - strftime('%s',test.test_start_date) )/(3600*24) as days                \\\n            FROM df AS test                                                                                                   \\\n            LEFT JOIN                                                                                                         \\\n                orders AS orders                                                                                              \\\n            ON                                                                                                                \\\n                orders.item_id = test.item_id                                                                                 \\\n            WHERE                                                                                                             \\\n                test.test_number = 'item_test_3'                                                                              \\\n            ORDER BY orders.item_id                                                                                             \\\n           \")\nd1\n\n\n\n\n\n  \n    \n      \n      item_id\n      test_start_date\n      created_at\n      test_assignment\n      days\n    \n  \n  \n    \n      0\n      0.0\n      2016-01-07 00:00:00\n      2014-03-21 06:08:48\n      1.0\n      -656\n    \n    \n      1\n      0.0\n      2016-01-07 00:00:00\n      2014-04-08 09:43:38\n      1.0\n      -638\n    \n    \n      2\n      0.0\n      2016-01-07 00:00:00\n      2015-01-21 15:51:14\n      1.0\n      -350\n    \n    \n      3\n      0.0\n      2016-01-07 00:00:00\n      2015-03-04 18:06:07\n      1.0\n      -308\n    \n    \n      4\n      0.0\n      2016-01-07 00:00:00\n      2015-04-08 00:42:57\n      1.0\n      -273\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      47397\n      3997.0\n      2016-01-07 00:00:00\n      2018-01-29 10:07:14\n      1.0\n      753\n    \n    \n      47398\n      3997.0\n      2016-01-07 00:00:00\n      2018-03-31 23:12:01\n      1.0\n      814\n    \n    \n      47399\n      3997.0\n      2016-01-07 00:00:00\n      2018-05-02 06:47:29\n      1.0\n      846\n    \n    \n      47400\n      3997.0\n      2016-01-07 00:00:00\n      2018-05-20 08:30:34\n      1.0\n      864\n    \n    \n      47401\n      3997.0\n      2016-01-07 00:00:00\n      2018-05-24 04:40:57\n      1.0\n      868\n    \n  \n\n47402 rows × 5 columns\n\n\n\n\nd2 = sqldf(\"\\\n            SELECT                                       \\\n               item_id, test_assignment,                 \\\n               MAX(CASE                                  \\\n                   WHEN days>0 AND days<=30              \\\n                   THEN 1                                \\\n                   ELSE 0 END) AS order_test             \\\n             FROM                                        \\\n                d1                                       \\\n            GROUP BY                                     \\\n                item_id, test_assignment                 \\\n                \")\nd2\n\n\n\n\n\n  \n    \n      \n      item_id\n      test_assignment\n      order_test\n    \n  \n  \n    \n      0\n      0.0\n      1.0\n      0\n    \n    \n      1\n      1.0\n      0.0\n      0\n    \n    \n      2\n      2.0\n      0.0\n      1\n    \n    \n      3\n      3.0\n      1.0\n      1\n    \n    \n      4\n      4.0\n      1.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      2193\n      3992.0\n      1.0\n      1\n    \n    \n      2194\n      3993.0\n      0.0\n      0\n    \n    \n      2195\n      3994.0\n      1.0\n      0\n    \n    \n      2196\n      3996.0\n      0.0\n      0\n    \n    \n      2197\n      3997.0\n      1.0\n      0\n    \n  \n\n2198 rows × 3 columns\n\n\n\n\nfrom scipy.stats import chi2_contingency, chi2 \nacceptance_criteria = 0.05\n\nobserved_values  = pd.crosstab(d2.test_assignment,d2.order_test).values\n\nmakesame = 1\nif makesame==1:\n    observed_values[1]=observed_values[0]*2\n\n\nov=pd.DataFrame(observed_values)\nov['tots']=ov.iloc[:,0]+ov.iloc[:,1]\nov['success_rate']=100*ov.iloc[:,1]/ov.iloc[:,2]\nov\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      tots\n      success_rate\n    \n  \n  \n    \n      0\n      715\n      360\n      1075\n      33.488372\n    \n    \n      1\n      1430\n      720\n      2150\n      33.488372\n    \n  \n\n\n\n\n\n#hide\nchi2_statistic, p_value, dof, expected_values = chi2_contingency(observed_values, correction = False)\n\nprint(f\"The chi2_statistic is {chi2_statistic:.2f}, and the p value is  {p_value:.2f}\")\n\n# find the critical value for our test\ncritical_value = chi2.ppf(1 - acceptance_criteria, dof)\nprint(critical_value)\n\nThe chi2_statistic is 0.00, and the p value is  1.00\n3.841458820694124\n\n\n\ncount = Successes if Null Hypothesis is True. (P * nobs)\nnobs = The number of trails/sample\nvalue = Observed Proportion\nalternative = Type of test(2-tailed or 1-tailed)\n\n\nfrom statsmodels.stats.proportion import proportions_ztest, proportion_confint\n\nz_stat, pval= proportions_ztest(count=ov.iloc[:,1],nobs=ov['tots'].values, alternative='two-sided')\n\nprint(f\"z test stat = {z_stat:.2f} and p-value = {pval:.2f}\")\n\nz test stat = 0.00 and p-value = 1.00\n\n\n\n(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(ov.iloc[:,1],nobs=ov['tots'].values,alpha=0.05)\n\nprint(f'conf ind 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\nprint(f'conf ind 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')\n\nconf ind 95% for control group: [0.307, 0.363]\nconf ind 95% for treatment group: [0.279, 0.333]\n\n\n\nWhen your p-value is less than or equal to your significance level, you reject the null hypothesis. The data favors the alternative hypothesis. Congratulations! Your results are statistically significant.\nWhen your p-value is greater than your significance level, you fail to reject the null hypothesis. Your results are not significant. You’ll learn more about interpreting this outcome later in this post.\n\nFailed to reject the null hypothesis (that changes are due to chance alone), since p-value is over 0.05"
  },
  {
    "objectID": "posts/statistics.html#laws-of-probability",
    "href": "posts/statistics.html#laws-of-probability",
    "title": "ThomasHSimm",
    "section": "Laws of Probability",
    "text": "Laws of Probability\nIn the next few sections, we’ll derive three relationships between conjunction and conditional probability:\n\nTheorem 1: Using a conjunction to compute a conditional probability.\nTheorem 2: Using a conditional probability to compute a conjunction.\nTheorem 3: Using conditional(A, B) to compute conditional(B, A).\n\nTheorem 3 is also known as Bayes’s Theorem.\nI’ll write these theorems using mathematical notation for probability:\n\n\\(P(A)\\) is the probability of proposition \\(A\\).\n\\(P(A~\\mathrm{and}~B)\\) is the probability of the conjunction of \\(A\\) and \\(B\\), that is, the probability that both are true.\n\\(P(A | B)\\) is the conditional probability of \\(A\\) given that \\(B\\) is true. The vertical line between \\(A\\) and \\(B\\) is pronounced “given”.\n\nWith that, we are ready for Theorem 1.\n\n#hide\n# Load the data file\n\nfrom os.path import basename, exists\n\ndef download(url):\n    filename = basename(url)\n    if not exists(filename):\n        from urllib.request import urlretrieve\n        local, _ = urlretrieve(url, filename)\n        print('Downloaded ' + local)\n    \ndownload('https://github.com/AllenDowney/BiteSizeBayes/raw/master/gss_bayes.csv')\nimport pandas as pd\n\ngss = pd.read_csv('gss_bayes.csv', index_col=0)\n\nDownloaded gss_bayes.csv\n\n\n\ngss.describe()\n\n\n\n\n\n  \n    \n      \n      year\n      age\n      sex\n      polviews\n      partyid\n      indus10\n    \n  \n  \n    \n      count\n      49290.000000\n      49290.000000\n      49290.000000\n      49290.000000\n      49290.000000\n      49290.000000\n    \n    \n      mean\n      1995.364050\n      46.143132\n      1.537858\n      4.105052\n      2.753905\n      5993.666504\n    \n    \n      std\n      12.336592\n      17.111420\n      0.498570\n      1.377160\n      2.048108\n      2796.295069\n    \n    \n      min\n      1974.000000\n      18.000000\n      1.000000\n      1.000000\n      0.000000\n      170.000000\n    \n    \n      25%\n      1985.000000\n      32.000000\n      1.000000\n      3.000000\n      1.000000\n      3890.000000\n    \n    \n      50%\n      1996.000000\n      44.000000\n      2.000000\n      4.000000\n      3.000000\n      6990.000000\n    \n    \n      75%\n      2006.000000\n      59.000000\n      2.000000\n      5.000000\n      5.000000\n      8190.000000\n    \n    \n      max\n      2016.000000\n      89.000000\n      2.000000\n      7.000000\n      7.000000\n      9870.000000\n    \n  \n\n\n\n\n\nmale = gss.sex==1\nbanker = gss.indus10==6870\nyear1990 = gss.year<1990\n\nprint(f\"Percentage male = {male.mean():.3f}\")\nprint(f\"Percentage banker = {banker.mean():.3f}\")\nprint(f\"Percentage year1990 = {year1990.mean():.3f}\")\nprint()\nprint(f\"first few rows of male = {male.head()}\")\n\nPercentage male = 0.462\nPercentage banker = 0.015\nPercentage year1990 = 0.362\n\nfirst few rows of male = caseid\n1     True\n2     True\n5    False\n6     True\n7     True\nName: sex, dtype: bool\n\n\n\nprob = lambda x : x.mean()\nprint(f'Conjunction: Probability person is male & year1990 = {prob(male & year1990):.2f}')\nprint()\n\nprob_cond = lambda x,given : prob(x[given])\nprint(f'Conditional: Given person is a banker what is the probability they are female?\\\n      \\n{prob_cond(~male,banker):.2f}')\n\nprint(f'Conditional: Given person is female what is the probability they are a banker?\\\n      \\n{prob_cond(banker, ~male):.2f}')\nprint()\nprint('N.B. x[given] is a list of x where given==True, i.e. has the length of given.sum()')\n\nConjunction: Probability person is male & year1990 = 0.17\n\nConditional: Given person is a banker what is the probability they are female?      \n0.77\nConditional: Given person is female what is the probability they are a banker?      \n0.02\n\nN.B. x[given] is a list of x where given==True, i.e. has the length of given.sum()\n\n\n\nTheorem 1\n\\[P(A|B) = \\frac{P(A~\\mathrm{and}~B)}{P(B)}\\]\nThe conditional probability of 𝐴 given that 𝐵 is true \\(P(A|B)\\) equals the probaility of A and B occuring divided by probability of B occuring.\n\nprint('A = female, B= banker')\nprint(f'P(B) = {prob(banker):.3f}')\nprint(f'P(A & B) = {prob( ~male & banker):.3f}')\nprint(f'P(A | B) = {prob_cond(~male, banker):.3f}')\nprint(f'P(A & B)/P(B) = {prob( ~male & banker)/prob(banker):.3f}')\n\n\nA = female, B= banker\nP(B) = 0.015\nP(A & B) = 0.011\nP(A | B) = 0.771\nP(A & B)/P(B) = 0.771\n\n\n\n\nTheorem 2\nIf we start with Theorem 1 and multiply both sides by \\(P(B)\\), we get Theorem 2.\n\\[P(A~\\mathrm{and}~B) = P(B) ~ P(A|B)\\]\nThis formula suggests a second way to compute a conjunction: instead of using the & operator, we can compute the product of two probabilities.\n\nprint(f'P(B)*P(A|B) = {prob(banker)*prob_cond(~male,banker):.3f}')\nprint(f'P(A & B) = {prob( ~male & banker):.3f}')\n\nP(B)*P(A|B) = 0.011\nP(A & B) = 0.011\n\n\n\n\nTheorem 3\nWe have established that conjunction is commutative. In math notation, that means:\n\\[P(A~\\mathrm{and}~B) = P(B~\\mathrm{and}~A)\\]\nIf we apply Theorem 2 to both sides, we have\n\\[P(B) P(A|B) = P(A) P(B|A)\\]\nHere’s one way to interpret that: if you want to check \\(A\\) and \\(B\\), you can do it in either order:\n\nYou can check \\(B\\) first, then \\(A\\) conditioned on \\(B\\), or\nYou can check \\(A\\) first, then \\(B\\) conditioned on \\(A\\).\n\nIf we divide through by \\(P(B)\\), we get Theorem 3:\n\\[P(A|B) = \\frac{P(A) P(B|A)}{P(B)}\\]\nAnd that, my friends, is Bayes’s Theorem.\n\nprint(f'P(A)*P(B|A)/P(B) = {prob(~male)*prob_cond(banker, ~male)/prob(banker):.3f}')\nprint(f'P(A | B) = {prob_cond( ~male , banker):.3f}')\n\nP(A)*P(B|A)/P(B) = 0.771\nP(A | B) = 0.771\n\n\n\n\nThe Law of Total Probability\nIn addition to these three theorems, there’s one more thing we’ll need to do Bayesian statistics: the law of total probability. Here’s one form of the law, expressed in mathematical notation:\n\\[P(A) = P(B_1 \\mathrm{and} A) + P(B_2 \\mathrm{and} A)\\]\nIn words, the total probability of \\(A\\) is the sum of two possibilities: either \\(B_1\\) and \\(A\\) are true or \\(B_2\\) and \\(A\\) are true. But this law applies only if \\(B_1\\) and \\(B_2\\) are:\n\nMutually exclusive, which means that only one of them can be true, and\nCollectively exhaustive, which means that one of them must be true.\n\n\nprint(f'P(B) = {prob(banker):.3f}')\nprint(f'P(A1 & B) + P(A2 & B) = {prob(~male & banker) + prob(male & banker):.3f}')\n\nP(B) = 0.015\nP(A1 & B) + P(A2 & B) = 0.015\n\n\n\n\nThe Apple Problem\nWe’ll start with a thinly disguised version of an urn problem:\n\nSuppose there are two bowls of apples.\n\nBowl 1 contains 30 red apples and 10 green apples.\nBowl 2 contains 20 red apples and 20 green apples.\n\nNow suppose you choose one of the bowls at random and, without looking, choose an apple at random. If the apple is red, what is the probability that it came from Bowl 1?\n\n\\[P(A|B) = \\frac{P(A) P(B|A)}{P(B)}\\]\n\nprint('P(A) = probability apple is red, P(B) = probability bowl is bowl 1')\n\nprint('We want prob bowl 1 given apple is red or P(B|A)')\nPA=(30+20)/(30+20+10+20)\nprint(f'P(A)={PA:.3f}')\nPB=1/2\nprint(f'P(B)={PB:.3f}')\nPAgivenB=(30)/(30+10)\nprint(f'P(A|B)={PAgivenB:.3f}')\nprint(f'P(B|A)={PB*PAgivenB/PA:.3f}')\n\nP(A) = probability apple is red, P(B) = probability bowl is bowl 1\nWe want prob bowl 1 given apple is red or P(B|A)\nP(A)=0.625\nP(B)=0.500\nP(A|B)=0.750\nP(B|A)=0.600"
  },
  {
    "objectID": "posts/Untitled1.html",
    "href": "posts/Untitled1.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# from dtreeviz.trees import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nimport pandas as pd\n\n\ndf=pd.read_csv(\"C:\\\\Users\\\\44781\\\\Downloads\\\\epl2021_big(1).csv\")\ntry:\n    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\nexcept:\n    pass\ndf=df.drop(columns=[\"tkl+int\"])\n\n\nx=60\n#  cmp%_keeper avgdist       \nwith pd.option_context(\"display.max_columns\", None):\n    display(df.iloc[:,10+x:20+x].info())\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 740 entries, 0 to 739\nData columns (total 10 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   dead                 740 non-null    float64\n 1   fk_passing_types     740 non-null    float64\n 2   tb                   740 non-null    float64\n 3   press_passing_types  740 non-null    float64\n 4   sw                   740 non-null    float64\n 5   crs_passing_types    740 non-null    float64\n 6   ck                   740 non-null    float64\n 7   in                   740 non-null    float64\n 8   out                  740 non-null    float64\n 9   str                  740 non-null    float64\ndtypes: float64(10)\nmemory usage: 63.6 KB\n\n\nNone\n\n\n\ndf=df[df['round']>1]\n# sza=np.shape(df)[0]\n\n# randAr=np.random.randint(0,100, size=sza)\n# cond = randAr>=15\n\ncond=df['round']<29\n\ntrain_idx = np.where( cond)[0]\nvalid_idx = np.where(~cond)[0]\n\n\n\nsplits = (list(train_idx),list(valid_idx))\n\nvalid_idx.shape[0]/len(df)\n\n0.2702702702702703\n\n\n\ndep_var='Win'\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\ncat\n\n['venue', 'opponent', 'team']\n\n\n\ndf_=df.iloc[:,[3,174]]\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\fastai\\tabular\\core.py:116: RuntimeWarning: invalid value encountered in less_equal\n  new_t = next((r[0] for r in t if r[1]<=df[c].min() and r[2]>=df[c].max()), None)\n\n\n\n# [i for i,x in enumerate(df.columns) if x=='Win']\n# # df['Win']\n\n# [x for x in df.iloc[:,174] if x !=\"W\" and x!=\"L\" and x!='D']\nimport copy\ndf_=copy.copy(df)\n\n\nxx=df\nivals=[]\nii=0\nfor i in range(len(df.columns)):\n#     print(xx.iloc[:,i].isnull().values.any(), '----',df.columns[i])\n    if xx.iloc[:,i].isnull().values.any()==False:\n        ivals.append(i)\n        ii+=1\nprint(ii/len(df.columns))\n\n0.9766081871345029\n\n\n\ndf_=df_.iloc[:,ivals]\n\n\nmax(ivals)\n\n341\n\n\n\ncols=df_.columns\ncols\n\nIndex(['np:g-xg', 'np:g-xg', 'sota', 'saves', 'save%', 'cs', 'psxg',\n       'cmp%_keeper', 'Win'],\n      dtype='object')\n\n\n\ncont,cat = cont_cat_split(df_, 1, dep_var=\"Win\")\nto = TabularPandas(df_, procs, cat, cont, y_names=dep_var, splits=splits)\n\n\ndef rf(xs, y, n_estimators=150, max_samples=150,\n       max_features=0.4, min_samples_leaf=40, **kwargs):\n    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True,class_weight=\"balanced_subsample\").fit(xs, y)\n\n\n\nprocs = [Categorify, FillMissing]\nto = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\nm = rf(xs, y,n_estimators=100,max_samples=100,\n       max_features=.7, min_samples_leaf=4)\nprint(m.score(xs,y), m.score(valid_xs, valid_y) )\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\fastai\\tabular\\core.py:116: RuntimeWarning: invalid value encountered in less_equal\n  new_t = next((r[0] for r in t if r[1]<=df[c].min() and r[2]>=df[c].max()), None)\n\n\n0.7092592592592593 0.485"
  },
  {
    "objectID": "posts/Untitled2.html",
    "href": "posts/Untitled2.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "import pandas as pd\nimport os\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import KFold, cross_val_score\n\nfrom sklearn.cluster import KMeans\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\ncwd=os.getcwd()\n\n#hide\ncwd=os.getcwd()\nfolda=cwd+\"/data/epl/\"\ndira = os.listdir(folda)\ndira\n\n['dfEPL_2017.csv',\n 'dfEPL_2018.csv',\n 'dfEPL_2019.csv',\n 'dfEPL_2020.csv',\n 'dfEPL_2021.csv',\n 'epl2017-2021.csv',\n 'epl2017-2021_wivnetscore.csv',\n 'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv',\n 'epl2017-2021_wivnetscore_both-HA.csv']\n\n\n\ndict1={}\ndict1['ok']=5\ndict1['ps']=51\n\ndict1.keys()\n[x for x in dict1]\n\n['ok', 'ps']\n\n\n\n#collapse-output\n\ndfAll=pd.read_csv(folda+'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv')\ndfAll=dfAll.iloc[20:,:]\ndfAll=dfAll.drop(columns=['Unnamed: 0','opponent_y','team_y','Win_x','NetScore_x','GoalsAgainst_x'])\ndfAll=dfAll.dropna().reset_index(drop=True)\ndfAll\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n    \n  \n  \n    \n      0\n      2\n      21\n      Home\n      2.000000\n      2.000000\n      0.000000\n      Everton\n      1.000000\n      14.000000\n      4.000000\n      ...\n      12.000000\n      16.000000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      101.000000\n      25.000000\n      26.000000\n      49.000000\n    \n    \n      1\n      2\n      20\n      Home\n      2.000000\n      2.000000\n      0.000000\n      Chelsea\n      2.000000\n      18.000000\n      6.000000\n      ...\n      14.000000\n      9.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      92.000000\n      21.000000\n      31.000000\n      40.400000\n    \n    \n      2\n      2\n      19\n      Home\n      0.000000\n      3.000000\n      3.000000\n      Crystal Palace\n      3.000000\n      13.000000\n      4.000000\n      ...\n      13.000000\n      21.000000\n      13.000000\n      0.000000\n      0.000000\n      1.000000\n      100.000000\n      19.000000\n      19.000000\n      50.000000\n    \n    \n      3\n      2\n      20\n      Away\n      -1.000000\n      2.000000\n      3.000000\n      Tottenham Hotspur\n      2.000000\n      19.000000\n      6.000000\n      ...\n      14.000000\n      17.000000\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      75.000000\n      21.000000\n      19.000000\n      52.500000\n    \n    \n      4\n      2\n      19\n      Away\n      1.000000\n      4.000000\n      3.000000\n      Stoke City\n      4.000000\n      27.000000\n      10.000000\n      ...\n      9.000000\n      25.000000\n      12.000000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      26.000000\n      25.000000\n      51.000000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3755\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      11.666667\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n    \n    \n      3756\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      19.333333\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n    \n    \n      3757\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      11.000000\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n    \n    \n      3758\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      18.666667\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n    \n    \n      3759\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      14.333333\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n    \n  \n\n3760 rows × 342 columns\n\n\n\n\ndfAll.select_dtypes(['O']).columns,X.select_dtypes([\"category\"])\n\n(Index(['venue_x', 'opponent_x', 'team_x'], dtype='object'),\n Empty DataFrame\n Columns: []\n Index: [20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, ...]\n \n [3760 rows x 0 columns])\n\n\n\ndef impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df\n\ndfAll=impute(dfAll)\nX = dfAll.copy()\ny = X.pop(\"GoalsFor_x\")\n\n\n\ndef score_dataset(X, y, model=RandomForestRegressor()):\n    # Label encoding for categoricals\n    #\n    # Label encoding is good for XGBoost and RandomForest, but one-hot\n    # would be better for models like Lasso or Ridge. The `cat.codes`\n    # attribute holds the category levels.\n    for colname in X.select_dtypes([\"O\"]):\n        X[colname] = X[colname].astype(\"category\").cat.codes\n    \n    \n    model.fit(X,y)\n    score=model.score(X,y)\n    \n    return score\n\n\nscore_dataset(X, y)\n\n# mean_absolute_error\n\n0.8746216922762998\n\n\n\n# [(x,dfAll[x].isna().sum() ) for x in dfAll if dfAll[x].isna().sum()>0]\n\n\ndef make_mi_scores(X, y):\n    mi_scores=[]\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\n\nmi_scores = make_mi_scores(X, y)\n\nplot_mi_scores(mi_scores[0:20])\n\nprint(sum(mi_scores==0))\n\n106\n\n\n\n\n\n\nfrom dtreeviz.trees import *\nfrom fastbook import *\nfrom kaggle import api\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG\n\n\n# cluster_columns(X)\nX_=X.iloc[:,0:].copy()\ncorr = np.round(scipy.stats.spearmanr(X_).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\n## hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n# np.shape(X.columns),np.shape(z)\n\n\nfig,axes = plt.subplots(1,1,figsize=(10,100))\n# truncate_mode='lastp',p=30\nhc.dendrogram(z,ax=axes, labels=X_.columns, show_contracted=True,\n                    orientation='right', leaf_font_size=12);\n\n\n\n\n\n\ndef get_oob(df):\n    m = RandomForestRegressor(n_estimators=40, min_samples_leaf=15,\n        max_samples=2_000, max_features=0.5, n_jobs=-1, oob_score=True)\n    m.fit(df, y)\n    return m.oob_score_\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\nfi = rf_feat_importance(m, X)\nplot_fi(fi[:30]);\n\n\n\n\n\n# plt.plot(fi.imp,mi_scores,'ok')\n\nlen(fi.imp), len(mi_scores)\nmi_scores = mi_scores.reset_index()\nmi_scores=mi_scores.merge(fi,left_on='index', right_on='cols')\nmi_scores\n\n\n\n\n\n  \n    \n      \n      index\n      MI Scores\n      cols\n      imp\n    \n  \n  \n    \n      0\n      team_x\n      0.070002\n      team_x\n      0.005893\n    \n    \n      1\n      totdist_passing_x\n      0.063648\n      totdist_passing_x\n      0.001158\n    \n    \n      2\n      att_passing.2_x\n      0.052731\n      att_passing.2_x\n      0.004732\n    \n    \n      3\n      att_passing.1_x\n      0.052193\n      att_passing.1_x\n      0.009184\n    \n    \n      4\n      touches_x\n      0.050402\n      touches_x\n      0.008154\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      344\n      pksv_y\n      0.000000\n      pksv_y\n      0.000121\n    \n    \n      345\n      pkm_y\n      0.000000\n      pkm_y\n      0.000000\n    \n    \n      346\n      cmp_keeper_y\n      0.000000\n      cmp_keeper_y\n      0.001771\n    \n    \n      347\n      #opa_y\n      0.000000\n      #opa_y\n      0.001269\n    \n    \n      348\n      cluster_misc\n      0.000000\n      cluster_misc\n      0.002623\n    \n  \n\n349 rows × 4 columns\n\n\n\n\nplt.plot(mi_scores.imp, mi_scores['MI Scores'],'ok')\nto_keep = mi_scores[mi_scores.imp>0.001].cols\nto_keep2 = mi_scores.loc[mi_scores['MI Scores']>0.00,'index']\nXimp=X.copy()\n\n\n\n\n\n\n\n(0.3037249283667621, 0.15759312320916907)\n\n\n\nXimp=X.copy()\nXimp = Ximp[to_keep]\nXimp=X.copy()\nXimp2 = Ximp[to_keep2]\n\nXimp3 = Ximp[pd.concat([to_keep,to_keep2]).unique()]\n\nrat3=1-len(Ximp3.columns)/len(X.columns) \nrat2=1-len(to_keep2)/len(X.columns) \nrat1=1-len(to_keep)/len(X.columns)\n\nprint(f\"All: {get_oob(X):.3f},\\\n\\nRemove low on RF {get_oob(Ximp):.3f},  {rat1:.2f}\\\n\\nRemove low on MI scores =0: {get_oob(Ximp2):.3f},  {rat2:.2f}\\\n\\nIn both: {get_oob(Ximp3):.3f},  {rat3:.2f}\" )\n\n# Ximp = Ximp[to_keep2]\n\nAll: 0.097,\nRemove low on RF 0.094,  0.16\nRemove low on MI scores =0: 0.105,  0.30\nIn both: 0.100,  0.08\n\n\n\n0.3*len(X.columns)\n\n104.7\n\n\n\ndef impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    for name in df.select_dtypes(\"O\"):\n        df[name] = df[name].fillna(\"None\")\n    return df\n\ndef catego(df):\n    for x in df:\n        if df[x].dtype=='O':\n            df[x]=df[x].astype('category').cat.codes\n    return df\ndef rf(xs, y, n_estimators=40, max_samples=2_000,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)\n\n\nX=impute(X_)\nX=catego(X)\nm = rf(X,y)\n\n\nfrom sklearn.inspection import plot_partial_dependence\n\nfig,ax = plt.subplots(figsize=(12, 4))\nplot_partial_dependence(m, X, [mi_scores.index[3],X.columns[10]],\n                        grid_resolution=20, ax=ax);\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_partial_dependence is deprecated; Function `plot_partial_dependence` is deprecated in 1.0 and will be removed in 1.2. Use PartialDependenceDisplay.from_estimator instead\n  warnings.warn(msg, category=FutureWarning)\n\n\n\n\n\n\nimport warnings\nwarnings.simplefilter('ignore', FutureWarning)\n\nfrom treeinterpreter import treeinterpreter\nfrom waterfall_chart import plot as waterfall\n\n\ncolNo=10\nrow = X.iloc[:1]\n\nprediction,bias,contributions = treeinterpreter.predict(m, row.values)\n\n# limitval=0.04\n\n# boola = abs(contributions[0])>limitval\n# cols_use = np.array(sorted(zip(abs(contributions[0]), X.columns), reverse=True)[:colNo])\n\ndef sort_index(lst, rev=True):\n    index = range(len(lst))\n    s = sorted(index, reverse=rev, key=lambda i: abs(lst[i]))\n    return s\n\nindas = sort_index(contributions[0], rev=True)\n\ncont_use=contributions[0][indas[0:colNo]]\ncols_use=X.columns[indas[0:colNo]]\n\nwaterfall(cols_use, cont_use, #threshold=0.08, \n          rotation_value=90,formatting='{:,.3f}');\n\nNameError: name 'X' is not defined\n\n\n\n[x for x in zip(contributions[0][0:4], X.columns[0:4])]\n\n[(0.0, 'round'),\n (0.0, 'day'),\n (0.027085849626415467, 'venue_x'),\n (0.0, 'result_x')]\n\n\n\nlen(hcd['dcoord'])\n\n11\n\n\n\nmi_scores[['team_x',\n'cluster_shoot',\n'cluster_keeper',\n'cluster_passing',\n'cluster_passtype',\n'cluster_shotcreate',\n'cluster_tackle',\n'cluster_possession']]#,\n# 'cluster_misc']]\n\nteam_x                0.056959\ncluster_shoot         0.024236\ncluster_keeper        0.036972\ncluster_passing       0.049058\ncluster_passtype      0.036873\ncluster_shotcreate    0.031788\ncluster_tackle        0.031476\ncluster_possession    0.038912\nName: MI Scores, dtype: float64\n\n\n\nprint(np.shape(X))\nprint(sum(mi_scores==0))\ndel_col = mi_scores[mi_scores==0].index\nprint(del_col[0:3].values)\nX=X.drop(columns=del_col)\nprint(np.shape(X))\n\n(3760, 191)\n28\n['tklw_misc_y' 'opp_y' 'succ_defense_x']\n(3760, 163)\n\n\n\nscore_dataset(X, y)\n\n# mean_absolute_error\n\n0.8745083521817236\n\n\n\nX\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n    \n  \n  \n    \n      0\n      2\n      21\n      Home\n      2.000000\n      2.000000\n      0.000000\n      Everton\n      1.000000\n      14.000000\n      4.000000\n      ...\n      12.000000\n      16.000000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      101.000000\n      25.000000\n      26.000000\n      49.000000\n    \n    \n      1\n      2\n      20\n      Home\n      2.000000\n      2.000000\n      0.000000\n      Chelsea\n      2.000000\n      18.000000\n      6.000000\n      ...\n      14.000000\n      9.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      92.000000\n      21.000000\n      31.000000\n      40.400000\n    \n    \n      2\n      2\n      19\n      Home\n      0.000000\n      3.000000\n      3.000000\n      Crystal Palace\n      3.000000\n      13.000000\n      4.000000\n      ...\n      13.000000\n      21.000000\n      13.000000\n      0.000000\n      0.000000\n      1.000000\n      100.000000\n      19.000000\n      19.000000\n      50.000000\n    \n    \n      3\n      2\n      20\n      Away\n      -1.000000\n      2.000000\n      3.000000\n      Tottenham Hotspur\n      2.000000\n      19.000000\n      6.000000\n      ...\n      14.000000\n      17.000000\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      75.000000\n      21.000000\n      19.000000\n      52.500000\n    \n    \n      4\n      2\n      19\n      Away\n      1.000000\n      4.000000\n      3.000000\n      Stoke City\n      4.000000\n      27.000000\n      10.000000\n      ...\n      9.000000\n      25.000000\n      12.000000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      26.000000\n      25.000000\n      51.000000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3755\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      11.666667\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n    \n    \n      3756\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      19.333333\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n    \n    \n      3757\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      11.000000\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n    \n    \n      3758\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      18.666667\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n    \n    \n      3759\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      14.333333\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n    \n  \n\n3760 rows × 341 columns\n\n\n\n\ndef corrplot(df, method=\"pearson\", annot=True, **kwargs):\n    sns.clustermap(\n        df.corr(method),\n#         metric='correlation',\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n#         method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\n\ncol_x=[x for x in X if ((x[-1]!='y') and (x[-1]!='y') )]\ncols=cluster_features_passingAll\n\n[cols.append(x) for x in cluster_features_shootingAll]\ncols\ncorrplot(X[col_x[::-1]], annot=None)\n\n\n\nC:\\Users\\44781\\anaconda3\\lib\\site-packages\\seaborn\\matrix.py:649: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n  warnings.warn(msg)\n\n\n\n\n\n\n\ncluster_features_shootingAll = [\n    \"gls_x\",\"sh_shooting_x\",\n    \"sot_x\",\"sot%_x\",\"g/sh_x\",\n    \"dist_x\",\"pk_x\",\"pkatt_shooting_x\",\n    'xg_x','npxg_x','npxg/sh_x','g-xg_x','np:g-xg_x'\n]\n\ncluster_features_keeperAll=[\n    'sota_x','saves_x','save%_x','cs_x',\n 'psxg_x','psxg+/-_x','pkatt_keeper_x','pka_x',\n 'pksv_x','pkm_x','cmp_keeper_x','att_keeper_x','cmp%_keeper_x',\n'cmp%_keeper_x','att_keeper.1_x','thr_x','launch%_x','avglen_x',\n'att_keeper.2_x','launch%.1_x','avglen.1_x','opp_x','stp_x','stp%_x',\n    '#opa_x','avgdist_x'\n]\n\ncluster_features_passingAll=[\n 'cmp_passing_x',\n 'att_passing_x',\n 'cmp%_passing_x',\n 'totdist_passing_x',\n 'prgdist_passing_x',\n 'cmp_passing.1_x',\n 'att_passing.1_x',\n 'cmp%_passing.1_x',\n 'cmp_passing.2_x',\n 'att_passing.2_x',\n 'cmp%_passing.2_x',\n 'cmp_passing.3_x',\n 'att_passing.3_x',\n 'cmp%_passing.3_x',\n 'ast_x',\n 'xa_x',\n 'kp_x',\n '1/3_passing_x',\n 'ppa_x',\n 'crspa_x',\n 'prog_passing_x']\n\ncluster_features_passtypeAll=[\n 'att_passing_types_x',\n 'live_passing_types_x',\n 'dead_x',\n 'fk_passing_types_x',\n 'tb_x',\n 'press_passing_types_x',\n 'sw_x',\n 'crs_passing_types_x',\n 'ck_x',\n 'in_x',\n 'out_x',\n 'str_x',\n 'ground_x',\n 'low_x',\n 'high_x',\n 'left_x',\n 'right_x',\n 'head_x',\n 'ti_x',\n 'other_x',\n 'cmp_passing_types_x',\n 'off_passing_types_x',\n 'out.1_x',\n 'int_passing_types_x',\n 'blocks_passing_types_x']\n\ncluster_features_shotcreateAll=[\n 'sca_x',\n 'passlive_x',\n 'passdead_x',\n 'drib_x',\n 'sh_gca_x',\n 'fld_gca_x',\n 'def_x',\n 'gca_x',\n 'passlive.1_x',\n 'passdead.1_x',\n 'drib.1_x',\n 'sh_gca.1_x',\n 'fld_gca.1_x',\n 'def.1_x']\n\ncluster_features_tackleAll=[\n 'tkl_x',\n 'tklw_defense_x',\n 'def 3rd_defense_x',\n 'mid 3rd_defense_x',\n 'att 3rd_defense_x',\n 'tkl.1_x',\n 'att_defense_x',\n 'tkl%_x',\n 'past_x',\n 'press_defense_x',\n 'succ_defense_x',\n '%_x',\n 'def 3rd_defense.1_x',\n 'mid 3rd_defense.1_x',\n 'att 3rd_defense.1_x',\n 'blocks_defense_x',\n 'sh_defense_x',\n 'shsv_x',\n 'pass_x',\n 'int_defense_x',\n 'clr_x',\n 'err_x']\n\ncluster_features_possessionAll=[\n 'poss_x',\n 'touches_x',\n 'def pen_x',\n 'def 3rd_possession_x',\n 'mid 3rd_possession_x',\n 'att 3rd_possession_x',\n 'att pen_x',\n 'live_possession_x',\n 'succ_possession_x',\n 'att_possession_x',\n 'succ%_x',\n '#pl_x',\n 'megs_x',\n 'carries_x',\n 'totdist_possession_x',\n 'prgdist_possession_x',\n 'prog_possession_x',\n '1/3_possession_x',\n 'cpa_x',\n 'mis_x',\n 'dis_x',\n 'targ_x',\n 'rec_x',\n 'rec%_x',\n 'prog_possession.1_x']\n\ncluster_features_miscAll=[\n 'crdr_x',\n '2crdy_x',\n 'fls_x',\n 'fld_misc_x',\n 'off_misc_x',\n 'crs_misc_x',\n 'int_misc_x',\n 'tklw_misc_x',\n 'pkwon_x',\n 'pkcon_x',\n 'og_x',\n 'recov_x',\n 'won_x',\n 'lost_x',\n 'won%_x']\n\ndef cluster_labels(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    X_new = pd.DataFrame()\n    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n    return X_new\n\n\ndef cluster_distance(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n    X_cd = kmeans.fit_transform(X_scaled)\n    # Label features and join to dataset\n    X_cd = pd.DataFrame(\n        X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])]\n    )\n    return X_cd\n\n\n\nX['cluster_shoot'] =cluster_labels(X, cluster_features_shootingAll, n_clusters=10)\nX['cluster_keeper'] =cluster_labels(X, cluster_features_keeperAll, n_clusters=10)\n\nX['cluster_passing'] =cluster_labels(X, cluster_features_passingAll, n_clusters=10)\nX['cluster_passtype'] =cluster_labels(X, cluster_features_passtypeAll, n_clusters=10)\nX['cluster_shotcreate'] =cluster_labels(X, cluster_features_shotcreateAll, n_clusters=10)\nX['cluster_tackle'] =cluster_labels(X, cluster_features_tackleAll, n_clusters=10)\nX['cluster_possession'] =cluster_labels(X, cluster_features_possessionAll, n_clusters=10)\nX['cluster_misc'] =cluster_labels(X, cluster_features_miscAll, n_clusters=10)\n\n\n\n\nscore_dataset(X, y)\n\n# mean_absolute_error\n\n0.8744429248631561\n\n\n\n# cd = cluster_distance(X, cluster_features_keeperAll, n_clusters=20)\n# cd\n\n\n# a=0\n# col_use=[]\n# for cols in X.columns:\n#     if a!=0:\n#         col_use.append(cols)\n#     elif cols=='crdr_x':\n#         a=1\n#         col_use.append(cols)\n#     if cols=='prog_possession.1_x':\n#         print(a)\n#         a=0\n# col_use\nX\n\n\n\n\n\n  \n    \n      \n      round\n      day\n      venue_x\n      result_x\n      gf_x\n      ga_x\n      opponent_x\n      gls_x\n      sh_shooting_x\n      sot_x\n      ...\n      crs_misc_y\n      int_misc_y\n      tklw_misc_y\n      pkwon_y\n      pkcon_y\n      og_y\n      recov_y\n      won_y\n      lost_y\n      won%_y\n    \n  \n  \n    \n      0\n      2\n      21\n      Home\n      2.000000\n      2.000000\n      0.000000\n      Everton\n      1.000000\n      14.000000\n      4.000000\n      ...\n      12.000000\n      16.000000\n      9.000000\n      0.000000\n      0.000000\n      0.000000\n      101.000000\n      25.000000\n      26.000000\n      49.000000\n    \n    \n      1\n      2\n      20\n      Home\n      2.000000\n      2.000000\n      0.000000\n      Chelsea\n      2.000000\n      18.000000\n      6.000000\n      ...\n      14.000000\n      9.000000\n      8.000000\n      0.000000\n      0.000000\n      0.000000\n      92.000000\n      21.000000\n      31.000000\n      40.400000\n    \n    \n      2\n      2\n      19\n      Home\n      0.000000\n      3.000000\n      3.000000\n      Crystal Palace\n      3.000000\n      13.000000\n      4.000000\n      ...\n      13.000000\n      21.000000\n      13.000000\n      0.000000\n      0.000000\n      1.000000\n      100.000000\n      19.000000\n      19.000000\n      50.000000\n    \n    \n      3\n      2\n      20\n      Away\n      -1.000000\n      2.000000\n      3.000000\n      Tottenham Hotspur\n      2.000000\n      19.000000\n      6.000000\n      ...\n      14.000000\n      17.000000\n      6.000000\n      0.000000\n      0.000000\n      0.000000\n      75.000000\n      21.000000\n      19.000000\n      52.500000\n    \n    \n      4\n      2\n      19\n      Away\n      1.000000\n      4.000000\n      3.000000\n      Stoke City\n      4.000000\n      27.000000\n      10.000000\n      ...\n      9.000000\n      25.000000\n      12.000000\n      0.000000\n      0.000000\n      0.000000\n      91.000000\n      26.000000\n      25.000000\n      51.000000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3755\n      38\n      22\n      Away\n      0.333333\n      1.666667\n      1.333333\n      Arsenal\n      1.666667\n      9.333333\n      4.000000\n      ...\n      11.666667\n      10.000000\n      9.666667\n      0.000000\n      0.000000\n      0.333333\n      74.333333\n      14.666667\n      16.666667\n      46.466667\n    \n    \n      3756\n      38\n      22\n      Away\n      -1.666667\n      0.666667\n      2.333333\n      Brentford\n      0.666667\n      9.666667\n      2.333333\n      ...\n      19.333333\n      11.666667\n      6.666667\n      0.000000\n      0.666667\n      0.000000\n      80.333333\n      15.333333\n      15.666667\n      48.333333\n    \n    \n      3757\n      38\n      22\n      Home\n      -0.666667\n      1.000000\n      1.666667\n      Newcastle United\n      1.000000\n      13.000000\n      4.333333\n      ...\n      11.000000\n      14.666667\n      13.000000\n      0.000000\n      0.000000\n      0.000000\n      64.333333\n      20.000000\n      19.000000\n      48.766667\n    \n    \n      3758\n      38\n      22\n      Away\n      -2.000000\n      0.666667\n      2.666667\n      Chelsea\n      0.333333\n      10.666667\n      2.666667\n      ...\n      18.666667\n      11.666667\n      11.666667\n      0.333333\n      0.000000\n      0.000000\n      88.000000\n      17.666667\n      13.666667\n      57.066667\n    \n    \n      3759\n      38\n      22\n      Home\n      -2.000000\n      0.333333\n      2.333333\n      Tottenham Hotspur\n      0.333333\n      9.666667\n      2.333333\n      ...\n      14.333333\n      12.000000\n      9.666667\n      0.000000\n      0.000000\n      0.000000\n      81.666667\n      23.666667\n      17.000000\n      57.633333\n    \n  \n\n3760 rows × 341 columns\n\n\n\n\nXt=X.groupby(['team_x','season']).mean().reset_index()\n\nclt =cluster_labels(Xt, cluster_features_shootingAll, n_clusters=7)\n\nXt['cluster']=clt\n\n\n[(x, Xt.loc[( (Xt.cluster==x) & (Xt.season==2020) ),'team_x'].values ) for x in Xt['cluster'].unique()]\n\n\nXt=X.groupby(['team_x','season']).mean().reset_index()\n\nclt =cluster_labels(Xt, cluster_features_keeperAll, n_clusters=7)\n\nXt['cluster']=clt\n\n\n[(x, Xt.loc[( (Xt.cluster==x) & (Xt.season==2021) ),'team_x'].values ) for x in Xt['cluster'].unique()]\n\n[(2,\n  array(['Arsenal', 'Brighton and Hove Albion', 'Crystal Palace'],\n        dtype=object)),\n (6,\n  array(['Brentford', 'Leeds United', 'Leicester City', 'Norwich City',\n         'Wolverhampton Wanderers'], dtype=object)),\n (5,\n  array(['Newcastle United', 'Southampton', 'West Ham United'], dtype=object)),\n (1,\n  array(['Aston Villa', 'Chelsea', 'Manchester United', 'Tottenham Hotspur'],\n        dtype=object)),\n (0, array([], dtype=object)),\n (4, array(['Burnley', 'Everton', 'Watford'], dtype=object)),\n (3, array(['Liverpool', 'Manchester City'], dtype=object))]\n\n\n\n# Xy = X.copy()\n# Xy[\"Cluster\"] = cl.astype(\"category\")\n# Xy[\"XX\"] = y\n# sns.relplot(\n#     x=\"value\", y=\"XX\", hue=\"Cluster\", col=\"variable\",\n#     height=4, aspect=1, facet_kws={'sharex': False}, col_wrap=3,\n#     data=Xy.melt(\n#         value_vars=cluster_features, id_vars=[\"XX\", \"Cluster\"],\n#     ),\n# );\n\n\n# Xy[['team_x','Cluster','XX']]\n# # np.shape(X),np.shape(Xy)\n\n# sns.histplot(Xy.loc[Xy.team_x==\"Manchester City\"].XX,fill=False)\n# sns.histplot(Xy.loc[Xy.team_x==\"Manchester United\"].XX,fill=False)\n# sns.histplot(Xy.loc[Xy.team_x==\"Newcastle United\"].XX,fill=False)\n\n\n\n# # # sns.histplot(Xy, x=\"team_x\", y=\"Cluster\")\n\n# # Xyy=Xy[['team_x','Cluster','XX']]\n# # # dfAll['team_x'].unique()\n\n# # Xyyy=Xyy.groupby(by=['team_x','Cluster']).count()\n\n# sns.histplot(Xt, x=\"team_x\", y=\"cluster\",cbar=True)\n\n\n# # Xyyy.droplevel(level=0)\n# Xyyy.loc['Arsenal']\n# # .median(level=0,axis=0)\n\n# sns.histplot(Xyyy.loc['Arsenal'])\n# Xyyy.loc['Arsenal']"
  },
  {
    "objectID": "posts/Untitled5.html",
    "href": "posts/Untitled5.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "Neural Network Maths\n\nBasic fundamentals of machine learning\n\n\nuse_math: true\n\n\\[\n\\hat{Y}= mX +b  \\\\\nError = \\hat{Y} - Y \\\\\nJ(m,b) = Error^2 \\\\\nError = mX + b - Y \\\\\n\\]\n[% = mX +b %]\n\\(\\hat{Y}= mX +b^2\\)\n\n# #hide_input\n# from IPython.display import Latex\n# Latex(r\"\"\"\\begin{eqnarray}\n# \\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n# \\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n# \\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n# \\nabla \\cdot \\vec{\\mathbf{B}} & = 0 \n# \\end{eqnarray}\"\"\")\n\n\n# %%latex\n# \\begin{align}\n# \\hat{Y}= mX +b  \\\\\n# Error = \\hat{Y} - Y \\\\\n# J(m,b) = Error^2 \\\\\n# Error = mX + b - Y \\\\\n# \\end{align}\n\n\\[\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\\]"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#gradient-descent",
    "href": "posts/NeuralNetworksMaths.html#gradient-descent",
    "title": "Neural Network Maths",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\nAn optimization method in machine learning\n\nGradient descent is an algroithm used to determine the value of parameters that are used to map input variables to target variables. The steps are:\n\nDetermine a loss function that relates predictions and actual values, i.e. a function that determines how good the predictions are\n\nN.B. the function needs to be of a form to encourage gradient descent\n\nFind the gradient of the loss function with respect to the parameters\nUpdate the weights based on this gradient\n\n\nGradient descent is not the only optimisation method to determine parameters but is an easy one to understand."
  },
  {
    "objectID": "posts/Tensorflow.html#general",
    "href": "posts/Tensorflow.html#general",
    "title": "ThomasHSimm",
    "section": "General",
    "text": "General\nLibrary websites:\nhttps://keras.io/\nhttps://www.tensorflow.org/"
  },
  {
    "objectID": "posts/Tensorflow.html#courses",
    "href": "posts/Tensorflow.html#courses",
    "title": "ThomasHSimm",
    "section": "Courses",
    "text": "Courses\nI have tried both of the following courses: DeepLearning.AI TensorFlow Developer Professional Certificate and TensorFlow 2 for Deep Learning Specialization.\n\nDeepLearning.AI TensorFlow Developer Professional Certificate\nTensorFlow 2 for Deep Learning Specialization\n\nThe Tensorflow2 course is a bit longer and goes into more depth, although there are additional extended courses for the deeplearning one. The deeplearning one can be done within the current 7 days trail period of coursera. The Tensorflow2 course is tricky to do in this timeframe. This is due to more material, the harder coursework, and waiting for capstone projects to be marked.\nIn the end I only did the first course of Tensorflow2 as I found the tests had material that wasn’t explained within the course and I found the lectures lacking in detail and the instructors became increasingly boring. I gave up after getting to the capstone in course 2 (of 3) when they asked a question about an NLP network that was never explained anywhere. However, the coursework is a good challenge, so it may be worth doing the course for this alone and learning from other sources in addition to this one.\nI prefered the DeepLearning courses as they were more in depth and didn’t assume as much prior knowledge, and the presentation was better. I am currently working through the follow-up course TensorFlow: Advanced Techniques Specialization and given time will do the NLP and MLOps courses.\nSome Others:\nOne by Udacity Intro to TensorFlow for Deep Learning is being offered for free and looks okay too.\nTensorFlow example tutorials written as Jupyter notebooks and run directly in Google Colab—a hosted notebook environment that requires no setup. Click the Run in Google Colab button. Part of the TensorFlow resources."
  },
  {
    "objectID": "posts/Tensorflow.html#resources",
    "href": "posts/Tensorflow.html#resources",
    "title": "ThomasHSimm",
    "section": "Resources",
    "text": "Resources\n\nTensorFlow’s website recommendations\nFrançois Chollet\n\nHis book Deep Learning with Python, Second Edition can be read online.\n\nDeep learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville\n\navailable free online\n\nProbabilistic Programming & Bayesian Methods for Hackers\n\navailable online"
  },
  {
    "objectID": "posts/Tensorflow.html#model-creations",
    "href": "posts/Tensorflow.html#model-creations",
    "title": "ThomasHSimm",
    "section": "Model creations",
    "text": "Model creations\nThe easiest way to create a model in Keras is through keras.Sequential, which creates a neural network as a stack of layers.\nSo in the examplel below - the 1st layer has units = 4 and input_shape=2 with a relu activation function - the 2nd layer has units = 3 with a relu activation function - the 3rd layer has units = 1\nThe 3rd layer is the output layer. Since there is no activation function this would be a regression problem to predict one value.\n\nFor non sequential models or with multiple inputs/outputs see functional API\n\nTabular Data\nhttps://www.kaggle.com/code/thomassimm/premier-league-predictions-using-tensorflow\n\nmodel = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(512//8,activation='relu'),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\n\n\nImage Data\n\nmodel = tf.keras.models.Sequential([ \n          tf.keras.layers.Convolution2D( 64,(3,3),activation='relu',input_shape=(28,28,1) ),\n          tf.keras.layers.MaxPool2D(2,2),\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(256//2,activation='relu'),\n          tf.keras.layers.Dense(1,activation='sigmoid') ])\n\n\n\nLanguage Data\nThe standard language model starts with an embedding layer, this then needs to be flattened to a vector, then we can add a dense layer before an output layer.\nThe Embedding layer creates a vector-space for the text data. So for example, the words beautiful and ugly may be in opposite directions. And words such as cat and kitten may be close together in vector space.\nGlobalAveragePooling1Dcan be replaced by Flatten()\n\n    model = tf.keras.Sequential([ \n        tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n        tf.keras.layers.GlobalAveragePooling1D(),\n        tf.keras.layers.Dense(24,activation='relu'),\n        tf.keras.layers.Dense(5,'softmax')\n    ])\n\nThe model above does not take account for the order of words,\nIf we want to do this we can insert an additional layer after the embedding layer. For example, by using the LSTM model as below\n\nmodel_lstm= tf.keras.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE,EMBEDDING_DIM,input_length=MAXLEN),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(24,activation='relu'),\n    tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')   \n])\n\nWe can even insert a conolution layer after the embedding instead\ntf.keras.layers.Conv1D(128,5,activation='relu')\nFor two consecutive layers of RNNs use return_sequences=True\n\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\ntf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),"
  },
  {
    "objectID": "posts/Tensorflow.html#compile-the-model",
    "href": "posts/Tensorflow.html#compile-the-model",
    "title": "ThomasHSimm",
    "section": "Compile the model",
    "text": "Compile the model\nTo compile the model, need to define the following:\n\nthe optimizer to use, i.e. how to update the parameters to improve model during fitting\nthe loss, i.e. what defines the goodness of the fit\nany metrics to record\n\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(\n    optimizer=opt,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)"
  },
  {
    "objectID": "posts/Tensorflow.html#evaluate-predict-the-model",
    "href": "posts/Tensorflow.html#evaluate-predict-the-model",
    "title": "ThomasHSimm",
    "section": "Evaluate / Predict the model",
    "text": "Evaluate / Predict the model\ntest_loss, test_accuracy = model.evaluate(scaled_test_images,\ntf.keras.utils.to_categorical(test_labels),\nverbose=0)\nand more or less outputs depending on metrics used\npred = model.predict(X_sample)"
  },
  {
    "objectID": "posts/Tensorflow.html#saving-and-loading",
    "href": "posts/Tensorflow.html#saving-and-loading",
    "title": "ThomasHSimm",
    "section": "Saving and Loading",
    "text": "Saving and Loading\n\nSaving / Loading weights\n\nmodel_weights_file='my_file'\n\nmodel.save_weights(model_weights_file)\n\nmodel.load_weights(model_weights_file)\n\n\n# All the model\n\nmodel.save('saved_model/my_model')\n\nnew_model = tf.keras.models.load_model('saved_model/my_model')"
  },
  {
    "objectID": "posts/Tensorflow.html#callbacks",
    "href": "posts/Tensorflow.html#callbacks",
    "title": "ThomasHSimm",
    "section": "Callbacks",
    "text": "Callbacks\nwithin model.fit(....)\ncallbacks=[callback_function]\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n\nEarlyStopping\n\nto stop the model early if some conditions are met\n\nModelCheckpoint\n\nsave the model/model weights (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\nmain data stored similar to ‘.data-00000-of-00001’\nhttps://www.tensorflow.org/tutorials/keras/save_and_load#what_are_these_files\nCan give file names with variables using {}\n\nval_loss\nval_accuracy\nbatch\nepoch\n\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor='val_binary_accuracy',\n)\n\nfilepath = os.path.join(cwd,'checkpoints_every_epoch/checkpoint.{epoch}.{batch}')\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n        save_weights_only=True,\n        save_best_only=True,\n        filepath=filepath,\n    )"
  },
  {
    "objectID": "posts/Tensorflow.html#overfitting-strategies",
    "href": "posts/Tensorflow.html#overfitting-strategies",
    "title": "ThomasHSimm",
    "section": "Overfitting strategies",
    "text": "Overfitting strategies\n\nDropout\nThe idea behind dropout is to randomly drop out some fraction of a layer’s input units every step of training, making it much harder for the network to learn those spurious patterns in the training data that leads to overfitting.\nInstead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\nYou could also think about dropout as creating a kind of ensemble of networks like with RandomForests.\nExample useage, apply 30% dropout to the next layer\nlayers.Dropout(rate=0.3),\nlayers.Dense(16)\nExample taken from kaggle https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization\n\n\n\nBatch Normalization\nNormalization is important in neural networks, it can really significantly improve the results of the values of the input and output are between 0 and 1.\nIn contrast, it is not important in other models such as random forests. Hence, the input data is often normalised such as train_datagen = ImageDataGenerator(rescale=1./255.) in image models.\nSo if it is good to normalize the input data it can also be good to normalize the layers of the network. This can be done with a BatchNormalization layer.A batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.\nAs stated in https://www.kaggle.com/code/ryanholbrook/dropout-and-batch-normalization batchnorm: - batchnorm is most often added as an aid to the optimization process - but it can sometimes also help prediction performance - Models with batchnorm tend to need fewer epochs to complete training. - And can fix various problems that can cause the training to get “stuck”. - it can be used at almost any point in a network.\nlayers.Dense(16, activation='relu'),\nlayers.BatchNormalization(),\n… or between a layer and its activation function:\nlayers.Dense(16),\nlayers.BatchNormalization(),\nlayers.Activation('relu'),\n… Or if you add it as the first layer of your network it can act as a kind of adaptive preprocessor like Sci-Kit Learn’s StandardScaler."
  },
  {
    "objectID": "posts/Tensorflow.html#multiple-inputs-and-outputs",
    "href": "posts/Tensorflow.html#multiple-inputs-and-outputs",
    "title": "ThomasHSimm",
    "section": "Multiple inputs and outputs",
    "text": "Multiple inputs and outputs\n3 inputs and 2 outputs. Simple model\nInputs: - temp_train - nocc_train - lumbp_train\nOutputs: - out1_train - out2_train\nThings to note: - inputs in the model is a list of the Input() parts - concatentate is used with the input list to provide input to the next layers of the model - outputs in the model is a list of the output layers - When compiling use dictionary to set loss and metrics to each output - or lists ['binary_crossentropy','binary_crossentropy'] - When fitting, for the inputs/outputs either: - provide a list of the inputs [temp_train,nocc_train, lumbp_train] - give as a dict {'layer_name':variable_name}\n\n## Functional: multiple inputs\n# N.B. lowercase 'c' concatenate\nimport tensorflow as tf \nfrom tensorflow.keras.layers import Input, Dense, concatenate\ninput_shape=(1,)\n\n# get individual inputs\ninputs_temp = Input(shape=input_shape,name='temp')\ninputs_nocc = Input(shape=input_shape,name='nocc')\ninputs_lumbp = Input(shape=input_shape,name='lumbp')\n\n# combine them\ninput_list = [inputs_temp,inputs_nocc,inputs_lumbp]\ninput_layer =concatenate(input_list)\n\n# add inputs to the model for two outputs\noutput_pred1  = Dense(2,activation='sigmoid',name='out_1')(input_layer)\noutput_pred2 = Dense(2,activation='sigmoid',name='out_2')(input_layer)\n\n# output layer\noutput_list = [output_pred1, output_pred2]\n\n# create the model object\nmodel = tf.keras.Model(inputs=input_list, outputs=output_list )\n\n# show the model\nmodel.summary()\n\n# Compile\nmodel.compile(\n        optimizer='SGD',\n        loss={'out_1':'binary_crossentropy',\n              'out_2':'binary_crossentropy'},\n        metrics={'out_1':['accuracy'],\n                 'out_2':['accuracy']},\n        loss_weights=[1,0.2]\n        )\n\ntf.keras.utils.plot_model(model)\n\n\n# Define training inputs and outputs\ninputs_train = {'temp': temp_train, 'nocc': nocc_train, 'lumbp': lumbp_train}\noutputs_train = {'out_1': out1_train, 'out_2': out2_train}\n\n# fit the model\nmodel.fit(inputs_train,outputs_train)"
  },
  {
    "objectID": "posts/Tensorflow.html#inception-images",
    "href": "posts/Tensorflow.html#inception-images",
    "title": "ThomasHSimm",
    "section": "Inception (images)",
    "text": "Inception (images)\n\nLoad the model pre-trained weights\nImport the model architecture\nGive the model the input shape for data\nLoad the weights into the model\nFreeze all the layers\nPick out the front part of the model, as the layers to the end are more specialized\nAdd extra layers to the model that can be fitted to\n\n\n# 1- Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# 2- Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 3- create the model and load in the weights\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                  include_top = False, \n                                  weights = None) \n\n# 4- load weights into the model\npre_trained_model.load_weights(local_weights_file)\n\n# 5- Make all the layers in the pre-trained model non-trainable\nfor layers in pre_trained_model.layers:\n    layers.trainable = False\n    \n# 6- Pick out part of the model\nlast_desired_layer = pre_trained_model.get_layer('mixed7')    \nlast_output = last_desired_layer.output\n\n# 7- Add extra layers to the model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)  \n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x) \n\n# Create the complete model by using the Model class\nmodel = Model(inputs=pre_trained_model.input, outputs=x)\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])"
  },
  {
    "objectID": "posts/Tensorflow.html#summary-info-of-model",
    "href": "posts/Tensorflow.html#summary-info-of-model",
    "title": "ThomasHSimm",
    "section": "Summary / info of model",
    "text": "Summary / info of model\nmodel.summary()\nGet summary of the model"
  },
  {
    "objectID": "posts/Tensorflow.html#class-or-function---metrics-and-losses",
    "href": "posts/Tensorflow.html#class-or-function---metrics-and-losses",
    "title": "ThomasHSimm",
    "section": "Class or Function - Metrics and Losses",
    "text": "Class or Function - Metrics and Losses\nIn general, classes use camel formatting CategoricalAccuracy whereas function use underscores and lower case categorical_accuracy and sometimes initials MAE\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics"
  },
  {
    "objectID": "posts/Tensorflow.html#low-level-handling-of-metrics",
    "href": "posts/Tensorflow.html#low-level-handling-of-metrics",
    "title": "ThomasHSimm",
    "section": "Low level handling of metrics",
    "text": "Low level handling of metrics\n\nmetric.update_state() to accumulate metric stats after each batch\nmetric.result get current value of metric to display\nmetric.reset_state() to reset metric value typically at the end of epoch"
  },
  {
    "objectID": "posts/Tensorflow.html#categorical-binary-versus-multiple",
    "href": "posts/Tensorflow.html#categorical-binary-versus-multiple",
    "title": "ThomasHSimm",
    "section": "Categorical: Binary versus Multiple",
    "text": "Categorical: Binary versus Multiple\nFor categorical data there is a slight difference between if there are only 2 categories or more.\nGoing from binary to multiple: - We need to change activation in model from sigmoid to softmax in final Dense layer - Change loss function from binary_crossentropy to categorical_crossentropy in compile - Making data one-hot encoded, i.e. columns for each outcome - Or use SparseCategoricalCrossentropy\n\nmodel_binary = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(1,activation='sigmoid')        \n    ])\n\nmodel_multi = tf.keras.Sequential([\n        tf.keras.layers.Dense(512//8,activation='relu',input_shape=[input_shape]),\n        tf.keras.layers.Dense(4,activation='softmax')        \n    ])\n\n\nmodel_binary.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\nmodel_multi.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n\n\n# One-hot encoding method\n\ny_binary =[1,0,0,0,0,0,1,1,1,1,0,1,0,1]\n\ny_multi=[1,2,4,6,1,3,4,2,4,2,5,2,1,4,2,1]\ny_multi=tf.keras.utils.to_categorical(y_multi)\ny_multi\n\narray([[0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)\n\n\nAlternatively, with output data like [0, 1, 4, 0, 2, 3, 3, 0, …]\nuse: - SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(\n                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer='adam',\n                 metrics=['accuracy'])"
  },
  {
    "objectID": "posts/Tensorflow.html#learning-rate",
    "href": "posts/Tensorflow.html#learning-rate",
    "title": "ThomasHSimm",
    "section": "Learning rate",
    "text": "Learning rate\nFind the best learning rate by using callbacks\nThe learning rate to use on the data below would be where the loss is low (y-axis) but not too close to where it increases or is unstable.\nSo for this on the downward part of the curve between 10E-6 and 10E-5\n\n# Set the learning rate scheduler\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch / 20) )\n    \n# Set the training parameters\nmodel_tune.compile(loss=\"mse\", optimizer=optimizer)\n    \n# train the model\nhistory = model_tune.fit(dataset, epochs=100, callbacks=[lr_schedule])\n\n# plot the results\n# Define the learning rate array\nlrs = 1e-8 * (10 ** (np.arange(100) / 20))\n\n# Plot the loss in log scale\nplt.semilogx(lrs, history.history[\"loss\"])"
  },
  {
    "objectID": "posts/Tensorflow.html#lambda-functions",
    "href": "posts/Tensorflow.html#lambda-functions",
    "title": "ThomasHSimm",
    "section": "lambda functions",
    "text": "lambda functions\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda\ntf.keras.layers.Lambda(     function, output_shape=None, mask=None, arguments=None, **kwargs )\nAdd a function that works on the data within the model\n\n# expand the dimensions\ntf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n                      input_shape=[window_size])\n\n# make the output larger (can be useful if predicting to large values, but previous layer have activation function so values are close to 1)\ntf.keras.layers.Lambda(lambda x: x * 100.0)"
  },
  {
    "objectID": "posts/Tensorflow.html#force-cpugpu",
    "href": "posts/Tensorflow.html#force-cpugpu",
    "title": "ThomasHSimm",
    "section": "Force CPU/GPU",
    "text": "Force CPU/GPU\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\n\n# Check available CPU/GPU devices\n\nprint(tf.config.list_physical_devices('CPU'))\n\nprint(tf.config.list_physical_devices('GPU'))\n\nwith tf.device(\"CPU:0\"):\n    model.fit(....)\n    \nwith tf.device(\"GPU:0\"):\n    model.fit(....)"
  },
  {
    "objectID": "posts/SQL.html#select-from",
    "href": "posts/SQL.html#select-from",
    "title": "ThomasHSimm",
    "section": "Select, From",
    "text": "Select, From\nThe general syntax of SELECT statments is:\nselect FirstName, LastName from Employees ;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nNancy\nEdwards\n\n\nJane\nPeacock\n\n\nMargaret\nPark\n\n\nSteve\nJohnson\n\n\nMichael\nMitchell\n\n\nRobert\nKing\n\n\nLaura\nCallahan\n\n\n\nTo retrieve all columns from the Employees table we could use “*” instead of specifying individual column names:\nselect * from Employees ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n5\nJohnson\nSteve\nSales Support Agent\n2\n1965-03-03 00:00:00\n2003-10-17 00:00:00\n7727B 41 Ave\nCalgary\nAB\nCanada\nT3B 1Y7\n1 (780) 836-9987\n1 (780) 836-9543\nsteve@chinookcorp.com\n\n\n6\nMitchell\nMichael\nIT Manager\n1\n1973-07-01 00:00:00\n2003-10-17 00:00:00\n5827 Bowness Road NW\nCalgary\nAB\nCanada\nT3B 0C5\n+1 (403) 246-9887\n+1 (403) 246-9899\nmichael@chinookcorp.com\n\n\n7\nKing\nRobert\nIT Staff\n6\n1970-05-29 00:00:00\n2004-01-02 00:00:00\n590 Columbia Boulevard West\nLethbridge\nAB\nCanada\nT1K 5N8\n+1 (403) 456-9986\n+1 (403) 456-8485\nrobert@chinookcorp.com\n\n\n8\nCallahan\nLaura\nIT Staff\n6\n1968-01-09 00:00:00\n2004-03-04 00:00:00\n923 7 ST NW\nLethbridge\nAB\nCanada\nT1H 1Y8\n+1 (403) 467-3351\n+1 (403) 467-8772\nlaura@chinookcorp.com"
  },
  {
    "objectID": "posts/SQL.html#where",
    "href": "posts/SQL.html#where",
    "title": "ThomasHSimm",
    "section": "Where",
    "text": "Where\nThe WHERE clause can be added to your query to filter results or get specific rows of data. To retrieve data for all rows in the Employees table where the ID is less than 5:\nselect * from Employees where EmployeeID < 5 ;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployeeId\nLastName\nFirstName\nTitle\nReportsTo\nBirthDate\nHireDate\nAddress\nCity\nState\nCountry\nPostalCode\nPhone\nFax\nEmail\n\n\n\n\n1\nAdams\nAndrew\nGeneral Manager\nNone\n1962-02-18 00:00:00\n2002-08-14 00:00:00\n11120 Jasper Ave NW\nEdmonton\nAB\nCanada\nT5K 2N1\n+1 (780) 428-9482\n+1 (780) 428-3457\nandrew@chinookcorp.com\n\n\n2\nEdwards\nNancy\nSales Manager\n1\n1958-12-08 00:00:00\n2002-05-01 00:00:00\n825 8 Ave SW\nCalgary\nAB\nCanada\nT2P 2T3\n+1 (403) 262-3443\n+1 (403) 262-3322\nnancy@chinookcorp.com\n\n\n3\nPeacock\nJane\nSales Support Agent\n2\n1973-08-29 00:00:00\n2002-04-01 00:00:00\n1111 6 Ave SW\nCalgary\nAB\nCanada\nT2P 5M5\n+1 (403) 262-3443\n+1 (403) 262-6712\njane@chinookcorp.com\n\n\n4\nPark\nMargaret\nSales Support Agent\n2\n1947-09-19 00:00:00\n2003-05-03 00:00:00\n683 10 Street SW\nCalgary\nAB\nCanada\nT2P 5G3\n+1 (403) 263-4423\n+1 (403) 263-4289\nmargaret@chinookcorp.com\n\n\n\nIn case of character based columns the values of the predicates in the where clause need to be enclosed in single quotes. To retrieve the data for the Employees names with First Name “Jane” we would issue:\nselect LastName, FirstName from Employees where FirstName = 'Jane';\n\n\n\nLastName\nFirstName\n\n\n\n\nPeacock\nJane"
  },
  {
    "objectID": "posts/SQL.html#in-or-not",
    "href": "posts/SQL.html#in-or-not",
    "title": "ThomasHSimm",
    "section": "In, Or, Not",
    "text": "In, Or, Not\nIn is used when we want to specify a range of conditions.\nFor example, find values of employees with last name Adams or Park\nselect FirstName, LastName from Employees\nwhere LastName In ('Adams','Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nCan do a similar thing with the OR operator. When using OR it is often helpful to use with brackets ()\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park');\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nWhy the order matters and use of ()\nselect FirstName, LastName from Employees\nwhere LastName = 'Adams' OR LastName ='Park'\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nMargaret\nPark\n\n\n\nselect FirstName, LastName from Employees\nwhere (LastName = 'Adams' OR LastName ='Park')\nand reportsto=2;\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\n\nThis is because SQL processes AND before OR\nIn benefits over or - Long list of options - In is faster - Don’t have to consider order with IN - Can contain another select\nThe not command is represented as <>\nfor example select the titles not beginning with c\nselect title from albums\nwhere substr(title,1,1) <> 'C'\n\n\n\nTitle\n\n\n\n\nFor Those About To Rock We Salute You\n\n\nBalls to the Wall\n\n\nRestless and Wild\n\n\nLet There Be Rock\n\n\nBig Ones\n\n\nJagged Little Pill\n\n\nFacelift\n\n\nWarner 25 Anos\n\n\nPlays Metallica By Four Cellos\n\n\nAudioslave\n\n\n\nIf it is used with IN then we use NOT\nfor example cities names not starting with a vowel\nselect distinct city from station\nwhere substr(city,1,1) not in ('a','e','i','o','u')\n\n\n\nCity\n\n\n\n\nKissee Mills\n\n\nLoma Mar\n\n\nSandy Hook\n\n\nTipton\n\n\nTurner\n\n\nSlidell\n\n\nNegreet"
  },
  {
    "objectID": "posts/SQL.html#distinct",
    "href": "posts/SQL.html#distinct",
    "title": "ThomasHSimm",
    "section": "Distinct",
    "text": "Distinct\nFind unique values\nselect distinct artistid from albums\n\n\n\nAlbumId\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10"
  },
  {
    "objectID": "posts/SQL.html#wildcards",
    "href": "posts/SQL.html#wildcards",
    "title": "ThomasHSimm",
    "section": "Wildcards",
    "text": "Wildcards\nTo find parts within a string can use the % wildcard\n_ works in a similar way but matches a single character (not supported by DB2)\n\n\n\n\n\n\n\nWildcard\nAction\n\n\n\n\n‘%ly’\nFind all strings ending ‘ly’\n\n\n‘To%’\nFind all strings starting ‘To’\n\n\n‘t%@gmail.com’\nFind all gmail address strings starting ‘t’\n\n\n’_ill’\nFind all strings ending ill with one other chaharacter  e.g. Kill, Bill\n\n\n\nImplementation, to implement use where and like.\nFind Names ending in t\nselect FirstName, LastName from Employees\nwhere FirstName like '%t';\n\n\n\nFirstName\nLastName\n\n\n\n\nMargaret\nPark\n\n\nRobert\nKing\n\n\n\nDownsides of wildcards:\n\nTakes longer to run (particularly at end of pattern\nBetter to use another operator e.g. =,>,<"
  },
  {
    "objectID": "posts/SQL.html#order-data",
    "href": "posts/SQL.html#order-data",
    "title": "ThomasHSimm",
    "section": "Order Data",
    "text": "Order Data\norder by - take name of 1 or more columns - Can use a column not retrieved - The last clause in a statement - Can use a number to represent column number - Add dsc or asc after column name to order acending or descending\nOrder employee names by last name ascending then last name descending\n\n\n\nFirstName\nLastName\n\n\n\n\nAndrew\nAdams\n\n\nLaura\nCallahan\n\n\nNancy\nEdwards\n\n\nSteve\nJohnson\n\n\nRobert\nKing\n\n\nMichael\nMitchell\n\n\nMargaret\nPark\n\n\nJane\nPeacock"
  },
  {
    "objectID": "posts/SQL.html#aggregate-functions",
    "href": "posts/SQL.html#aggregate-functions",
    "title": "ThomasHSimm",
    "section": "Aggregate Functions",
    "text": "Aggregate Functions\n\naverage average of a column (avg)\ncount counts number of values\nmin finds the minimum value\nmax finds the maximum value\nsum sums the column values\n\nselect count(trackid) from tracks\nwhere albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14"
  },
  {
    "objectID": "posts/SQL.html#group-by-and-having",
    "href": "posts/SQL.html#group-by-and-having",
    "title": "ThomasHSimm",
    "section": "Group by and Having",
    "text": "Group by and Having\nDo the same command as above but with group by, instead of where need to use having after the group by statement\nwhere filters before data is grouped and having after data is grouped\nselect count(trackid) from tracks\ngroup by albumid\nhaving albumid = 10\n\n\n\ncount(trackid)\n\n\n\n\n14\n\n\n\nor could get the number of tracks in all albums\nselect count(trackid) from tracks\ngroup by albumid\n\n\n\ncount(trackid)\n\n\n\n\n10\n\n\n1\n\n\n3\n\n\n8\n\n\n15\n\n\n13\n\n\n12\n\n\n14\n\n\n8\n\n\n14"
  },
  {
    "objectID": "posts/SQL.html#windowing",
    "href": "posts/SQL.html#windowing",
    "title": "ThomasHSimm",
    "section": "Windowing",
    "text": "Windowing\n\nA window function performs a calculation across a set of table rows that are somehow related to the current row.\nComparable to the type of calculation that can be done with an aggregate function.\nUnlike regular aggregate functions, windowing does not cause rows to become grouped into a single output row — the rows retain their separate identities.\nBehind the scenes, the window function is able to access more than just the current row of the query result.\nhttps://www.postgresql.org/docs/9.1/tutorial-window.html\n\nFor example, compare each song track’s length to the average salength for each composer\nselect composer, name,\nmilliseconds/(1000*60)                                    AS track_length,\navg(milliseconds/(1000*60)) over (partition by composer)  AS avg_track_length\nfrom ah_uyekita.chinook_track\n\n\n\ncomposer\nname\ntrack_length\navg_track_length\n\n\n\n\nAaron Copland\nFanfare for the Common Man\n3.3011\n3.3011\n\n\nAaron Goldberg\nOAM’s Blues\n4.4489\n4.4489\n\n\nA.Bouchard/J.Bouchard/S.Pearlman\nAstronomy\n6.6255\n6.6255\n\n\nAC/DC\nLet There Be Rock\n6.1109\n5.1110\n\n\nAC/DC\nOverdose\n6.1553 5.1110\n\n\n\nAC/DC\nProblem Child\n5.4173\n5.1110\n\n\nAC/DC\nBad Boy Boogie\n4.4621\n5.1110\n\n\nAC/DC\nGo Down\n5.5197\n5.1110\n\n\n\n\nWindow functions\n\nCUME_DIST Calculate the cumulative distribution of a value in a set of values\nDENSE_RANK Assign a rank value to each row within a partition of a result, with no gaps in rank values.\nFIRST_VALUE Get the value of the first row in an ordered partition of a result set.\nLAG Provide access to a row at a given physical offset that comes before the current row.\nLAST_VALUE Get the value of the last row in an ordered partition of a result set.\nLEAD Provide access to a row at a given physical offset that follows the current row.\nNTILE Distribute rows of an ordered partition into a number of groups or buckets\nPERCENT_RANK Calculate the percent rank of a value in a set of values.\nRANK Assign a rank value to each row within a partition of a result set\nROW_NUMBER Assign a unique sequential integer to rows within a partition of a result set, the first row starts from 1.\n\nhttps://www.sqlservertutorial.net/sql-server-window-functions/"
  },
  {
    "objectID": "posts/SQL.html#subqueries",
    "href": "posts/SQL.html#subqueries",
    "title": "ThomasHSimm",
    "section": "Subqueries",
    "text": "Subqueries\nThese are queries within other queries Which merge data from multiple sources together\nget customerid and city when their invoice total is more than 20\nselect CustomerID, City\nfrom customers\nwhere customerid in (select customerid\nfrom invoices\nwhere total>20)\n\n\n\nCustomerId\nCity\n\n\n\n\n6\nPrague\n\n\n26\nFort Worth\n\n\n45\nBudapest\n\n\n46\nDublin\n\n\n\nHow many albums does the band LEd Zeppelin have?\nselect count(*)\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Led Zeppelin')\n\n\n\ncount(*)\n\n\n\n\n14\n\n\n\nOr what are the name of the tracks for the artist Audioslave?\nselect Name\nfrom tracks\nwhere albumid IN\n(select albumid\nfrom albums\nwhere artistid IN\n(select artistid\nfrom artists\nwhere Name ='Audioslave'))\n\n\n\nName\n\n\n\n\nCochise\n\n\nShow Me How to Live\n\n\nGasoline\n\n\nWhat You Are\n\n\nLike a Stone\n\n\nSet It Off\n\n\nShadow on the Sun\n\n\nI am the Highway\n\n\nExploder\n\n\nHypnotize"
  },
  {
    "objectID": "posts/SQL.html#joins",
    "href": "posts/SQL.html#joins",
    "title": "ThomasHSimm",
    "section": "Joins",
    "text": "Joins\n\nefficient storage\neasier manipulation\ngreater scalability\nlogically models a process\ntables are related through common values or keys\ndata retrival from multiple tables in one query\nonly persist for the duration of the query\n\n\nCartesian cross joins\n\neach row from first table joins with all rows from the other table\noutput size of joins in A multiplied rows in B\ncomputationally taxing\nrarely used\n\n\nselect a.title, ar.name from albums as a\ncross join artists as ar\norder by a.title\n\n\n\nTitle\nName\n\n\n\n\n…And Justice For All\nAC/DC\n\n\n…And Justice For All\nAccept\n\n\n\ntotal rows = 95425\ntotal rows of albums = 347\ntotal rows of artists = 275\n\n\nInner join\n\nselect records that have matching values in both tables\nUse on to select what joining on\njoining more table affects database performance\nCan join multiple tables- no limit\n\n\nFor example get the artist name and title of each album. N.B. albums has columns AlbumID, Title and ArtistID only\nselect artists.Name, albums.Title\nfrom artists\nINNER JOIN albums\non artists.artistid = albums.artistID\n\n\n\nName\nTitle\n\n\n\n\nAC/DC\nFor Those About To Rock We Salute You\n\n\nAC/DC\nLet There Be Rock\n\n\nAccept\nBalls to the Wall\n\n\nAccept\nRestless and Wild\n\n\nAerosmith\nBig Ones\n\n\nAlanis Morissette\nJagged Little Pill\n\n\nAlice In Chains\nFacelift\n\n\nAntônio Carlos Jobim\nWarner 25 Anos\n\n\nAntônio Carlos Jobim\nChill: Brazil (Disc 2)\n\n\nApocalyptica\nPlays Metallica By Four Cellos\n\n\n\nOr as a multiple join\nSELECT o.orderId, c.CompanyName, e.LastName\nFROM ((orders o INNER JOIN customers c ON o.customerID = c.CustomerID)\n`INNER JOIN employees e ON o.EmployeeID = e.EmployeeID);\n\n\nSelf joins\n\nTakes the table and treats it like two separate tables\nJoin the original table to itself\n\nFor example, match cities from the same state\nselect A.city,A.state,B.city, B.state\nfrom station A, station B\nwhere A.city=B.city\nand A.state=B.state\norder by A.state;\n\n\n\ncity A\nstate A\ncity B\nstate B\n\n\n\n\nSeward\nAK\nSeward\nAK\n\n\nChignik Lagoon\nAK\nChignik Lagoon\nAK\n\n\nFive Points\nAL\nFive Points\nAL\n\n\nGroveoak\nAL\nGroveoak\nAL\n\n\nNotasulga\nAL\nNotasulga\nAL\n\n\nJackson\nAL\nJackson\nAL\n\n\n….\n….\n….\n…."
  },
  {
    "objectID": "posts/SQL.html#advanced-joins",
    "href": "posts/SQL.html#advanced-joins",
    "title": "ThomasHSimm",
    "section": "Advanced Joins",
    "text": "Advanced Joins\n\nLeft Joins\nReturns all records from the left table and the matched records from the righ table\nThe result is NULL from the right hand side if there is no match\nRight joins are the same but from the RHS. Can be converted to left join by reversing the order\n\nFor example, find all the customers who have an invoice\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nLEFT JOIN invoices i on c.customerid = i.customerid\norder by c.customerid\n\n\n\nFirstName\nLastName\nInvoiceId\n\n\n\n\nLuís\nGonçalves\n98\n\n\nLuís\nGonçalves\n121\n\n\nLuís\nGonçalves\n143\n\n\nLuís\nGonçalves\n195\n\n\nLuís\nGonçalves\n316\n\n\nLuís\nGonçalves\n327\n\n\nLuís\nGonçalves\n382\n\n\nLeonie\nKöhler\n1\n\n\nLeonie\nKöhler\n12\n\n\nLeonie\nKöhler\n67\n\n\nLeonie\nKöhler\n196\n\n\nLeonie\nKöhler\n219\n\n\nLeonie\nKöhler\n241\n\n\nLeonie\nKöhler\n293\n\n\nFrançois\nTremblay\n99\n\n\n\n\n\nFull outer join\nReturns all records where there is a match in either table\n“Give me everything”\nselect c.FirstNAme, c.LastName, i.InvoiceId\nfrom customers c\nFULL OUTER JOIN invoices i on c.customerid = i.customerid\norder by c.customerid"
  },
  {
    "objectID": "posts/SQL.html#unions",
    "href": "posts/SQL.html#unions",
    "title": "ThomasHSimm",
    "section": "Unions",
    "text": "Unions\nCombine two or more select statements - Each select must have the same number of columns - Columns must have similar data types - Columns in the same order - Less commonly used\ne.g. combine two string statements, the first a list of occupations and the second a summary of the above\n(select concat(name,'(',substr(occupation,1,1),')') from occupations)\nunion\n(select concat('There are a total number of ',count(*),' ',occupation,'s.')\nfrom occupations\ngroup by occupation\norder by count(occupation));"
  },
  {
    "objectID": "posts/SQL.html#substr",
    "href": "posts/SQL.html#substr",
    "title": "ThomasHSimm",
    "section": "Substr",
    "text": "Substr\nReturns part of a string\nsubstr(string name, string position, number of characters to return)\nIf string position is negative counts from the end\ne.g., find city names that start and end with a vowel\nselect city from station\nwhere substr(city,1,1) in ('a','e','i','o','u')\nand substr(city,-1,1) in ('a','e','i','o','u')"
  },
  {
    "objectID": "posts/SQL.html#others",
    "href": "posts/SQL.html#others",
    "title": "ThomasHSimm",
    "section": "Others",
    "text": "Others\nLimit 1 limit the results to 1\nconcat combine multiple parts\nselect concat(name, '(', substr(occupation,1,1), ')')\nfrom occupations\nround(X,5)\nrounds X to 5 decimal places\nor round(x) to nearest integer"
  },
  {
    "objectID": "posts/SQL.html#mode",
    "href": "posts/SQL.html#mode",
    "title": "ThomasHSimm",
    "section": "Mode",
    "text": "Mode\nMode seems like a good free way to perform SQL. I’ve yet to work out if the course provided me a link to access datasets or if these are freely available for everyone opeing a new account. The website is not easy to navigate and I only found access to my workspaces from a link I saved and not from links on the website.\nhttps://app.mode.com/thomassimm/reports/e9412b22b846/runs/c4e7c78695f3\n\nSpark SQL\n\nhttps://files.training.databricks.com/courses/ucdavis/Lessons.dbc\nSpark SQL and DataFrames and Datasets Guides -SQL Guide from Databricks\nLearning Spark, 2nd Edition (eBook compliments of Databricks).\nIntroduction - The Internals of Spark SQL (free gitbook)"
  },
  {
    "objectID": "posts/SQL.html#appendix",
    "href": "posts/SQL.html#appendix",
    "title": "ThomasHSimm",
    "section": "Appendix",
    "text": "Appendix\nhttps://dev.mysql.com/doc/refman/8.0/en/union.html\nhttps://www.w3schools.com/sql/default.asp\nhttps://blog.sqlauthority.com/category/sql-puzzle/\nhttps://sqlzoo.net/wiki/SQL_Tutorial\nhttps://mode.com/sql-tutorial/introduction-to-sql\nhttps://www.postgresql.org/docs/9.1/tutorial.html\nhttps://www.coursera.org/specializations/learn-sql-basics-data-science#courses"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html",
    "href": "posts/NeuralNetworksMaths.html",
    "title": "",
    "section": "",
    "text": "Basic maths of machine learning -\n\n\n\nGradient descent is an algroithm used to determine the value of parameters that are used to map input variables to target variables. The steps are: - Determine a loss function that relates predictions and actual values, i.e. a function that determines how good the predictions are - N.B. the function needs to be of a form to encourage gradient descent - Find the gradient of the loss function with respect to the parameters - Update the weights based on this gradient\nFor example, in the figure below - if the weight W=0 then the Loss is 1 and the gradient is -1.0. In this case we’d want to increase the value of the weight W towards it’s minimum 0.5 - if the weight W=1 then the Loss is also 1 but the gradient is +1.0. In this case we’d want to reduce the value of the weight W towards it’s minimum 0.5 - if the weight W=0.5 then the loss is close 0 and so is the garient, in this case we wouldn’t want to change the weights by much\ni.e. the weights can be updated by a formula of the form below to get the best fit:\n\\[W_{i+1} = W_i - const . \\frac{dJ}{dW}\\]\n\nGradient descent is not the only optimisation method to determine parameters but is an easy one to understand.\n\n\n\n\n\n\nSome definitions.\n\nX are the input variables\nY the target variables\n\\(\\hat{y}\\) is the prediction\nThe loss function J is what we are trying to minimise and is the sum of \\({Y-\\hat{y}^2}\\). For simplicity we’ll remove the summation below.\nm and b are the parameters we are looking to obtain\n\n\n\n\\(\\hat{Y}= mX +b\\)\n\\(Error = \\hat{Y} - Y\\)\n\\(J(m,b) = Error^2\\)\n\\(Error = mX + b - Y\\){#eq-stddev}\nWhat we want to do is update m and b so that J is reduced and the predictions is better. That is for m we obtain a new value (1) from the previous one (0) as follows:\n\\(m_1 = m_0 - \\frac{dJ}{dm} . \\alpha\\)\nWhere we have also included a learning rate (\\(\\alpha\\)<1) to make the changes smoother.\nSo to improve the predictions of the model we need to find and . Which involves a bit of differentiation and rearanging as follows.\nChain rule for differentiation to find db and dm\n\\(\\frac{dJ}{dm}\\ = \\frac{dJ}{dError}\\ \\frac{dError}{dm}\\)\n\\(\\frac{dJ}{db}\\ = \\frac{dJ}{dError}\\ \\frac{dError}{db}\\)\nfrom definition of J\n\\(\\frac{dJ}{dError}\\ = 2 . Error\\)\nfrom definition of Error\n\\(\\frac{dError}{dm} = X\\)\n\\(\\frac{dError}{db} = 1\\)\nSo\n\\(\\frac{dJ}{dm} = 2 . Error . X\\)\n\\(\\frac{dJ}{db} = 2 . Error . 1\\)\nAnd to account for the summation we divide by the length of the array.\nTo allow for matrix multiplication we create X as a matrix of two vectors one with just ones and the 2nd part the original X. This then allows us to have one variable for the weights m and b that we are fitting to.\nSo for each iteration (K) the weights W (j are the different parts to the weights e.g. b and m) are updated. Noting that there are N observations (length of y is N) we get:\n\\(W_j^{K+1} = W_j^{K} - [\\alpha . \\frac{1}{N}\\sum(\\hat{Y}-Y).X_j]\\)\n\ndef computeCost(X,y, theta):\n    Ypred = np.matmul(X,theta)\n    J =np.sum( (1/(2*len(y)))* (Ypred - y)**2 )\n    return J,Ypred\ndef computeGrad(X, y, theta,learningRate):\n    J,Ypred = computeCost(X,y, theta)\n    error = (Ypred - y)*learningRate/len(y)\n    return [np.sum(error),np.sum(X[:,1]*error)], J\n    \n\nCreate the variables to fit to\n\nX = np.ones((50,2))\nX[:,1]=np.arange(0,1,.02)\ntheta_act = [.5,3]\ny = np.matmul(X,theta_act)\nplt.plot(X[:,0],y,'.r')\nplt.plot(X[:,1],y,'.k')\nplt.grid(True)\nplt.title('Data')\nplt.legend(['bias b','m gradient']);\nplt.xlabel('X')\nplt.ylabel('y');\n\n\n\n\nUse the gradient descent iteration\n\ntheta_=np.array([0, 0])\nthetaALL=[]; jALL=[]\niterTot=100\nfor _ in range(iterTot):\n    thetaALL.append( theta_ )\n    (deltaTheta, J) =computeGrad(X, y, theta_,learningRate=.5)\n    theta_ = theta_ - deltaTheta\n    \n    jALL.append(J)\n\nplt.plot(range(iterTot),thetaALL,'.-')\nplt.plot(range(iterTot),np.ones((iterTot,2))*theta_act,'--',linewidth=4)\n# plt.plot(range(iterTot),jALL,':',linewidth=4)\nplt.grid(True)\nplt.legend(['b','m','actual values b','actual values m','Loss'])\nplt.xlabel('Iteration')\nplt.ylabel('Values');"
  },
  {
    "objectID": "index2.html",
    "href": "index2.html",
    "title": "ThomasHSimm",
    "section": "",
    "text": "AWS Cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nDecision Trees and Random Forests\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFastpages Notebook Blog Post\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAWS Cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nThe operating system\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSome Python Basics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBuilding a Classifier App on the web\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nRegular expressions RE\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGit and Github\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nData Viz\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nData Science\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nPython Imbedding Web\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nHow Does a Bike-Share Navigate Speedy Success\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nDeep Learning and Art Neural Style Transfer\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWeb scraping\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBody position recognition using FastAI\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWorking with videos\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPython Basics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSwansea House Prices- Part 2\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nCreating a property prediction App\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGolf Swing Part II- Separating Swing Positions\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGolf Swing Part III- Using pre-trained models- FiftyOne and Streamlit App\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFastAI CheatSheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nUsing NLP for text generation\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSpeech recognition\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTweepy\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nNatural Language Processing of Travel Tweets\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nDecision Trees and Random Forests\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- height weight and age\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- creating a country table\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- create the tables\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- GDP and population\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas- home games\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPresentation of Olympics data with SQL and pandas\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nOlympics data with SQL and pandas\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nNLP examples\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPredicting Premier League Matches- Prepare the data\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPredicting Premier League Matches\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow cheat sheet 2\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow Low-Level cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow Images cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nTensorFlow NLP cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nAWS terminology\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nData Science\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nAWS Cheat sheet\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nIAM policy\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nChapter 3\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nModifications to code for separating swing video\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nAB Testing\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Maths\n\n\nNeural Network Maths\n\n\n\n\nneural networks\n\n\nmaths\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nTensorFlow cheat sheet\n\n\nNeural Network Maths\n\n\n\n\nneural networks\n\n\ntensorflow\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nBasics SQL\n\n\nNeural Network Maths\n\n\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#with-tensorflow",
    "href": "posts/NeuralNetworksMaths.html#with-tensorflow",
    "title": "Neural Network Maths",
    "section": "With TensorFlow",
    "text": "With TensorFlow\nWe can do approximately the same thing with tensorflow: - input shape is 1 as the length 50 are treated as different inputs - one dense layer which is given by: - SGD or gradient descent - with a learning rate of 0.5 - and loss calculated by mean squared error - and fit over the same number of epochs = 100\n\nmodel=tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(1)),\n    tf.keras.layers.Dense(1)\n])\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.5),loss='mse')\n\nmodel.summary()\n\nModel: \"sequential_28\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_32 (Dense)             (None, 1)                 2         \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nXX=tf.reshape(X[:,1],(len(y),1))\nyy=tf.reshape(y,(len(y),1))\n\nhistory = model.fit(X[:,1],y,epochs=100,verbose=0)\nplt.plot(history.history[\"loss\"],'-k',linewidth=4)\nplt.plot(range(iterTot),jALL,'x',linewidth=4)\nplt.grid(True)\nplt.legend(['TensorFlow','ComputeGrad'])\nplt.xlabel('Iteration')\nplt.ylabel('Values');\nprint(f\"Predictions: m is {model.get_weights()[0][0][0]:.4f} and b is {model.get_weights()[1][0]:.4f}\")\n\nPredictions: m is 3.0000 and b is 0.5000"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#the-problem",
    "href": "posts/NeuralNetworksMaths.html#the-problem",
    "title": "Neural Network Maths",
    "section": "The Problem",
    "text": "The Problem\nCeate a simple problem whereby \\(y=0.5 + 3.X\\)\nAnd hence create the variable X and y. To allow for matrix multiplication to a form \\(y= bX + m\\) we’ll also make X a matrix with ones in the first column. So we can use np.matmul\n\nX = np.ones((50,2))\nX[:,1]=np.arange(0,1,.02)\ntheta_act = [.5,3]\ny = np.matmul(X,theta_act)\nplt.plot(X[:,0],y,'.r')\nplt.plot(X[:,1],y,'.k')\nplt.grid(True)\nplt.title('Data')\nplt.legend(['bias b','m gradient']);\nplt.xlabel('X')\nplt.ylabel('y');"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#the-maths",
    "href": "posts/NeuralNetworksMaths.html#the-maths",
    "title": "Neural Network Maths",
    "section": "The maths",
    "text": "The maths\nSome definitions.\n\nX are the input variables\nY the target variables\n\\(\\hat{y}\\) is the prediction\nThe loss function J is what we are trying to minimise and is the sum of \\({(Y-\\hat{y})^2}\\). For simplicity we’ll remove the summation below.\nm and b are the parameters we are looking to obtain\n\n\\(\\hat{Y}= mX +b\\)\n\\(Error = \\hat{Y} - Y\\)\n\\(J(m,b) = Error^2\\)\n\\(Error = mX + b - Y\\)\nWhat we want to do is update m and b so that J is reduced and the predictions is better. That is for m we obtain a new value (1) from the previous one (0) as follows:\n\\(m_1 = m_0 - \\frac{dJ}{dm} . \\alpha\\)\nWhere we have also included a learning rate (\\(\\alpha\\)<1) to make the changes smoother.\nSo to improve the predictions of the model we need to find and . Which involves a bit of differentiation and rearanging as follows.\nChain rule for differentiation to find db and dm\n\\(\\frac{dJ}{dm}\\ = \\frac{dJ}{dError}\\ \\frac{dError}{dm}\\)\n\\(\\frac{dJ}{db}\\ = \\frac{dJ}{dError}\\ \\frac{dError}{db}\\)\nfrom definition of J\n\\(\\frac{dJ}{dError}\\ = 2 . Error\\)\nfrom definition of Error\n\\(\\frac{dError}{dm} = X\\)\n\\(\\frac{dError}{db} = 1\\)\nSo\n\\(\\frac{dJ}{dm} = 2 . Error . X\\)\n\\(\\frac{dJ}{db} = 2 . Error . 1\\)\nAnd to account for the summation we divide by the length of the array.\nTo allow for matrix multiplication we create X as a matrix of two vectors one with just ones and the 2nd part the original X. This then allows us to have one variable for the weights m and b that we are fitting to.\nSo for each iteration (K) the weights W (j are the different parts to the weights e.g. b and m) are updated. Noting that there are N observations (length of y is N) we get:\n\\(W_j^{K+1} = W_j^{K} - [\\alpha . \\frac{1}{N}\\sum(\\hat{Y}-Y).X_j]\\)"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#the-fit",
    "href": "posts/NeuralNetworksMaths.html#the-fit",
    "title": "Neural Network Maths",
    "section": "The Fit",
    "text": "The Fit\nUse the gradient descent iteration\n\ntheta_=np.array([0, 0])\nthetaALL=[]; jALL=[]\niterTot=100\nfor _ in range(iterTot):\n    thetaALL.append( theta_ )\n    (deltaTheta, J) =computeGrad(X, y, theta_,learningRate=.5)\n    theta_ = theta_ - deltaTheta\n    \n    jALL.append(J)\n\nplt.plot(range(iterTot),thetaALL,'.-')\nplt.plot(range(iterTot),np.ones((iterTot,2))*theta_act,'--',linewidth=4)\nplt.plot(range(iterTot),jALL,':',linewidth=4)\nplt.grid(True)\nplt.legend(['b','m','actual values b','actual values m','Loss'])\nplt.xlabel('Iteration')\nplt.ylabel('Values');"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#an-example",
    "href": "posts/NeuralNetworksMaths.html#an-example",
    "title": "Neural Network Maths",
    "section": "An Example",
    "text": "An Example\nFor example, in the figure below:\n\nif the weight W=0 then the Loss is 1 and the gradient is -1.0. In this case we’d want to increase the value of the weight W towards it’s minimum 0.5\nif the weight W=1 then the Loss is also 1 but the gradient is +1.0. In this case we’d want to reduce the value of the weight W towards it’s minimum 0.5\nif the weight W=0.5 then the loss is close 0 and so is the garient, in this case we wouldn’t want to change the weights by much\n\ni.e. the weights can be updated by a formula of the form below to get the best fit:\n\\[W_{i+1} = W_i - const . \\frac{dJ}{dW}\\]"
  },
  {
    "objectID": "posts/NeuralNetworksMaths.html#section",
    "href": "posts/NeuralNetworksMaths.html#section",
    "title": "Neural Network Maths",
    "section": "",
    "text": "Create the variables to fit to\n\nX = np.ones((50,2))\nX[:,1]=np.arange(0,1,.02)\ntheta_act = [.5,3]\ny = np.matmul(X,theta_act)\nplt.plot(X[:,0],y,'.r')\nplt.plot(X[:,1],y,'.k')\nplt.grid(True)\nplt.title('Data')\nplt.legend(['bias b','m gradient']);\nplt.xlabel('X')\nplt.ylabel('y');\n\n\n\n\nUse the gradient descent iteration\n\ntheta_=np.array([0, 0])\nthetaALL=[]; jALL=[]\niterTot=100\nfor _ in range(iterTot):\n    thetaALL.append( theta_ )\n    (deltaTheta, J) =computeGrad(X, y, theta_,learningRate=.5)\n    theta_ = theta_ - deltaTheta\n    \n    jALL.append(J)\n\nplt.plot(range(iterTot),thetaALL,'.-')\nplt.plot(range(iterTot),np.ones((iterTot,2))*theta_act,'--',linewidth=4)\nplt.plot(range(iterTot),jALL,':',linewidth=4)\nplt.grid(True)\nplt.legend(['b','m','actual values b','actual values m','Loss'])\nplt.xlabel('Iteration')\nplt.ylabel('Values');"
  }
]