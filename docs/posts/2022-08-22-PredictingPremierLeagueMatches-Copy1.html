<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.258">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ThomasHSimm â€“ predictingpremierleaguematches-copy1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="..//posts/Picture3.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">ThomasHSimm</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ThomasHSimm"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ThomasHSimm"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><p><img src="../posts/header2.png" height="200"></p>



<section id="predicting-premier-league-matches" class="level1">
<h1>Predicting Premier League Matches</h1>
<blockquote class="blockquote">
<p>Using Python and Random Forests to predict football matches</p>
</blockquote>
<ul>
<li>toc: true</li>
<li>badges: true</li>
<li>comments: true</li>
<li>categories: [Random Forests, Football, Premier League,Python]</li>
</ul>
<p><img src="ghtop_images/header2.png" class="img-fluid"></p>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>Predicting results of <a href="https://en.wikipedia.org/wiki/Premier_League">English Premier League</a> using random forests for the 2017 to 2021 seasons. I will predict whether a result is a win, loss or draw, and then simplify as a binary question- is it a win?</p>
<p>From an article about pundit versus gambling company <a href="https://www.pinnacle.com/en/betting-articles/Soccer/Mark-Lawrenson-vs-Pinnacle-Sports/VGJ296E4BSYNURUB">Pinnacle vs.&nbsp;Mark Lawrenson</a> we have a benchmark to aim for from the 2012 season: - Mark Lawrenson = 52.6% accuracy - Pinnacle traders = 55.3% accuracy - Random guess = 33.3% accuracy</p>
</section>
<section id="method" class="level3">
<h3 class="anchored" data-anchor-id="method">Method</h3>
<p>In this data there are various parameters that can be used. The most important step is to not use data about a current match as a predictor, but for a prediction to be based on stats from previous matches. (A couple of slight exceptions to this are below like who is playing who and where)</p>
<p>The predictors used here include: - date of match - home or away - stats from previous matches - results - goals scored/conceded - possession/expected goals etc - who is playing who</p>
<p>Some details on the machine learning:</p>
<ul>
<li>A Random Forest <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Classifier</a> was the main model used for analysis.</li>
<li>Data is trained on years 2017 to 2020 with season 2021 used as validation
<ul>
<li>20% validation / 80% training</li>
</ul></li>
<li>Some data cleaning methods were performed and shown in the code</li>
</ul>
</section>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
<ul>
<li><p>Model accuracy = 52% (+-1%)</p>
<ul>
<li>So the model is comparable with the results of Mark Lawrenson</li>
</ul></li>
<li><p>The model is okay as it matches the accuracy from an expert pundit. But it does underperform gambing predictions.</p></li>
<li><p>Draws are under-represented by the model</p>
<ul>
<li>draws predicted was increased by adjusting the input parameter <code>class_weight</code> but the issue was only reduced</li>
</ul></li>
<li><p>Changing input parameters was done in a semi-manual manner, obtaining the best input parameters was not easy</p></li>
<li><p>The more data the better,</p>
<ul>
<li>but the increase from just using a basic four parameter fit to one with 300+ columns is relatively small (a difference of ~1-2% (based on values 50-65%))</li>
</ul></li>
<li><p>By searching for the best hyper parameters the results of a random forest (RF) model were increased from 49% accuracy to 52%</p></li>
<li><p>RF, XG boost and grad boost methods all performed similar</p>
<ul>
<li>Ridge model was the worst performing</li>
<li>Neural networks with fastai tabular data also performed poorly. <a href="https://www.kaggle.com/code/thomassimm/nlp-disaster-nn">NN analysis of EPL</a></li>
</ul></li>
<li><p>Similar results were obtained by using classification and regression methods</p>
<ul>
<li>Regression on the net score performed the best</li>
<li>Regression methods performed worse on predicting draws though</li>
</ul></li>
<li><p>Ensembling (combining results from different methods by adding them) can increase the overall results. The accuracy would need to be comparable and the results different enough for their to be a benefit</p></li>
</ul>
<p>A summary of the results is shown below</p>
<table class="table">
<colgroup>
<col style="width: 35%">
<col style="width: 30%">
<col style="width: 23%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th>Accuracy W/L/D</th>
<th>Accuracy Win</th>
<th>Classification/Regression</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.489</td>
<td>0.669</td>
<td>Classification</td>
<td>RF with all parameters</td>
</tr>
<tr class="even">
<td>0.479</td>
<td>0.661</td>
<td>Classification</td>
<td>RF with 43 parameters from feature imp</td>
</tr>
<tr class="odd">
<td>0.487</td>
<td>0.666</td>
<td>Classification</td>
<td>RF as above with basic features</td>
</tr>
<tr class="even">
<td>0.484</td>
<td>0.656</td>
<td>Classification</td>
<td>RF with 4 basic features</td>
</tr>
<tr class="odd">
<td>0.479</td>
<td>-</td>
<td>Classification</td>
<td>RF with 4 basic ones + balanced</td>
</tr>
<tr class="even">
<td>0.485</td>
<td>0.656</td>
<td>Classification</td>
<td>RF with 23 correlation parameters plus basic</td>
</tr>
<tr class="odd">
<td>0.451</td>
<td>0.678</td>
<td>Regression</td>
<td>RF with all parameters on net score</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.657</td>
<td>Regression</td>
<td>XGB with all parameters on net score</td>
</tr>
<tr class="odd">
<td>-</td>
<td>0.639</td>
<td>Regression</td>
<td>Ridge with all parameters on net score</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.666</td>
<td>Regression</td>
<td>Grad boost with all parameters on net score</td>
</tr>
<tr class="odd">
<td>0.427</td>
<td>0.670</td>
<td>Regression</td>
<td>RF with all parameters on GF/GA</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.670</td>
<td>Regression</td>
<td>XGB with all parameters on GF/GA score</td>
</tr>
<tr class="odd">
<td>-</td>
<td>0.665</td>
<td>Regression</td>
<td>RF+XGB+Grad boost on netscore</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.678</td>
<td>Regression</td>
<td>RF on netscore + RF on GF/GA</td>
</tr>
</tbody>
</table>
</section>
<section id="code--prepare-the-data" class="level3">
<h3 class="anchored" data-anchor-id="code--prepare-the-data">Code- Prepare the data</h3>
<p>Data is prepared in a separate page- <a href="https://thomashsimm.com/pandas/football/premier%20league/python/2022/08/11/PredictingPremierLeagueMatches-PrepareTheData.html#Save-the-data">Predicting Premier League Matches- Prepare the data</a></p>
</section>
</section>
</section>
<section id="possession-only" class="level1">
<h1>Possession Only</h1>
<section id="possession" class="level2">
<h2 class="anchored" data-anchor-id="possession">Possession</h2>
<ul>
<li><code>possession_poss</code> - percentage of passes attempted</li>
<li><code>possession_touches</code> - Number of times a player touched the ball</li>
<li><code>possession_def pen</code> - Touches in defensive penalty area</li>
<li><code>possession_def 3rd</code> - Touches in defensive 3rd</li>
<li><code>possession_mid 3rd</code> - Touches in mid 3rd</li>
<li><code>possession_att 3rd</code> - Touches in att 3rd</li>
<li><code>possession_att pen</code> - Touches in att penalty area</li>
<li><code>possession_live</code> - live ball touches</li>
<li><code>possession_rec%</code> - Passes Received Percentage</li>
</ul>
</section>
<section id="passing-type" class="level2">
<h2 class="anchored" data-anchor-id="passing-type">Passing Type</h2>
<ul>
<li><code>passingtype_tb</code> - Completed pass sent between back defenders into open space</li>
<li><code>passingtype_press</code> - Passes made while under pressure from opponent</li>
<li><code>passingtype_sw</code> - Passes that travel more than 40 yards of the width of the pitch</li>
<li><code>passingtype_crs</code> - crosses</li>
<li><code>passingtype_ground</code> - Ground passes</li>
<li><code>passingtype_low</code> - Passes that leave the ground, but stay below shoulder-level</li>
<li><code>passingtype_high</code> - Passes that are above shoulder-level at the peak height</li>
<li><code>passingtype_head</code> - Passes attempted using head</li>
<li><code>passingtype_cmp</code> - Passes Completed</li>
<li><code>passingtype_blocks</code> - Blocked by the opponent who was standing it the path</li>
</ul>
</section>
<section id="passing" class="level2">
<h2 class="anchored" data-anchor-id="passing">Passing</h2>
<ul>
<li><code>passing_pass_complete</code> - Passes Completed</li>
<li><code>passing_cmp%</code> - Passes Completed %</li>
<li><code>passing_PC_totdist</code> - Total distance, in yards, that completed passes have traveled in any direction divided by passes completed</li>
<li><code>passing_PC_prgdist</code> - Total progressive distance (towards opponent goal), in yards, that completed passes have traveled in any direction divided by passes completed</li>
<li><code>passing_PC_cmp_.1</code> - % Passes between 5 and 15 yards (of total completed passes)</li>
<li><code>passing_cmp%_.1</code> - Pass completion % for passes between 5 and 15 yards</li>
<li><code>passing_PC_cmp_.2</code> - % Passes between 15 and 30 yards (of total completed passes)</li>
<li><code>passing_cmp%_.2</code> - Pass completion % for passes between 15 and 30 yards</li>
<li><code>passing_PC_cmp_.3</code> - % Passes over 30 yards (of total completed passes)</li>
<li><code>passing_cmp%_.3</code> - Pass completion % for passes over 30 yards</li>
<li><code>passing_PC_1/3</code> - Completed passes that enter the 1/3 of the pitch closest to the goal as a % of completed passes</li>
<li><code>passing_PC_ppa</code> - Completed passes into the 18-yard box as a % of completed passes</li>
<li><code>passing_PC_crspa</code> - Completed crosses into the 18-yard box as a % of completed passes</li>
<li><code>passing_PC_prog</code> - Progressive Passes as a % of completed passes (Completed passes that move the ball towards the opponentâ€™s goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area. Excludes passes from the defending 40% of the pitch)</li>
</ul>
</section>
<section id="load-data-and-libraries" class="level2">
<h2 class="anchored" data-anchor-id="load-data-and-libraries">Load data and libraries</h2>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>cwd<span class="op">=</span>os.getcwd()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#hide</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>cwd<span class="op">=</span>os.getcwd()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>folda<span class="op">=</span>cwd<span class="op">+</span><span class="st">"/data/epl/"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>dira <span class="op">=</span> os.listdir(folda)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>dira</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>['dfEPL_2017.csv',
 'dfEPL_2018.csv',
 'dfEPL_2019.csv',
 'dfEPL_2020.csv',
 'dfEPL_2021.csv',
 'epl2017-2021.csv',
 'epl2017-2021_wivnetscore.csv',
 'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv',
 'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv',
 'epl2017-2021_wivnetscore_both-HA.csv']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse-output</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>pd.read_csv(folda<span class="op">+</span><span class="st">'epl2017-2021_wivnetscoreAndGFGA_both-HA_modPC.csv'</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>dfAll.iloc[<span class="dv">20</span>:,:]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>dfAll</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>round</th>
      <th>day</th>
      <th>venue_x</th>
      <th>result_x</th>
      <th>gf_x</th>
      <th>ga_x</th>
      <th>opponent_x</th>
      <th>shooting_gls_x</th>
      <th>shooting_sh__x</th>
      <th>shooting_sot_x</th>
      <th>...</th>
      <th>misc_int__y</th>
      <th>misc_tklw__y</th>
      <th>misc_pkwon_y</th>
      <th>misc_pkcon_y</th>
      <th>misc_og_y</th>
      <th>misc_recov_y</th>
      <th>misc_won_y</th>
      <th>misc_lost_y</th>
      <th>misc_won%_y</th>
      <th>team_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>44</th>
      <td>3</td>
      <td>27</td>
      <td>Home</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>Everton</td>
      <td>2.000000</td>
      <td>14.500000</td>
      <td>4.000000</td>
      <td>...</td>
      <td>13.000000</td>
      <td>12.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>94.500000</td>
      <td>19.500000</td>
      <td>27.000000</td>
      <td>41.150000</td>
      <td>Everton</td>
    </tr>
    <tr>
      <th>45</th>
      <td>3</td>
      <td>27</td>
      <td>Away</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>Liverpool</td>
      <td>2.000000</td>
      <td>23.000000</td>
      <td>8.500000</td>
      <td>...</td>
      <td>16.000000</td>
      <td>12.000000</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>114.000000</td>
      <td>28.500000</td>
      <td>20.500000</td>
      <td>57.450000</td>
      <td>Liverpool</td>
    </tr>
    <tr>
      <th>46</th>
      <td>3</td>
      <td>27</td>
      <td>Away</td>
      <td>0.000000</td>
      <td>1.500000</td>
      <td>1.500000</td>
      <td>Tottenham Hotspur</td>
      <td>1.500000</td>
      <td>15.000000</td>
      <td>3.000000</td>
      <td>...</td>
      <td>8.500000</td>
      <td>9.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>91.000000</td>
      <td>21.000000</td>
      <td>22.500000</td>
      <td>48.600000</td>
      <td>Tottenham Hotspur</td>
    </tr>
    <tr>
      <th>47</th>
      <td>3</td>
      <td>27</td>
      <td>Away</td>
      <td>0.500000</td>
      <td>1.000000</td>
      <td>0.500000</td>
      <td>Chelsea</td>
      <td>1.000000</td>
      <td>8.000000</td>
      <td>3.000000</td>
      <td>...</td>
      <td>7.000000</td>
      <td>14.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.500000</td>
      <td>92.000000</td>
      <td>23.500000</td>
      <td>26.000000</td>
      <td>47.850000</td>
      <td>Chelsea</td>
    </tr>
    <tr>
      <th>48</th>
      <td>3</td>
      <td>26</td>
      <td>Away</td>
      <td>0.500000</td>
      <td>2.500000</td>
      <td>2.000000</td>
      <td>Manchester United</td>
      <td>2.500000</td>
      <td>10.000000</td>
      <td>3.500000</td>
      <td>...</td>
      <td>16.000000</td>
      <td>10.500000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>91.000000</td>
      <td>21.500000</td>
      <td>19.500000</td>
      <td>50.300000</td>
      <td>Manchester United</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3795</th>
      <td>38</td>
      <td>22</td>
      <td>Away</td>
      <td>0.333333</td>
      <td>1.666667</td>
      <td>1.333333</td>
      <td>Arsenal</td>
      <td>1.666667</td>
      <td>9.333333</td>
      <td>4.000000</td>
      <td>...</td>
      <td>10.000000</td>
      <td>9.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.333333</td>
      <td>74.333333</td>
      <td>14.666667</td>
      <td>16.666667</td>
      <td>46.466667</td>
      <td>Arsenal</td>
    </tr>
    <tr>
      <th>3796</th>
      <td>38</td>
      <td>22</td>
      <td>Away</td>
      <td>-1.666667</td>
      <td>0.666667</td>
      <td>2.333333</td>
      <td>Brentford</td>
      <td>0.666667</td>
      <td>9.666667</td>
      <td>2.333333</td>
      <td>...</td>
      <td>11.666667</td>
      <td>6.666667</td>
      <td>0.000000</td>
      <td>0.666667</td>
      <td>0.000000</td>
      <td>80.333333</td>
      <td>15.333333</td>
      <td>15.666667</td>
      <td>48.333333</td>
      <td>Brentford</td>
    </tr>
    <tr>
      <th>3797</th>
      <td>38</td>
      <td>22</td>
      <td>Home</td>
      <td>-0.666667</td>
      <td>1.000000</td>
      <td>1.666667</td>
      <td>Newcastle United</td>
      <td>1.000000</td>
      <td>13.000000</td>
      <td>4.333333</td>
      <td>...</td>
      <td>14.666667</td>
      <td>13.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>64.333333</td>
      <td>20.000000</td>
      <td>19.000000</td>
      <td>48.766667</td>
      <td>Newcastle United</td>
    </tr>
    <tr>
      <th>3798</th>
      <td>38</td>
      <td>22</td>
      <td>Away</td>
      <td>-2.000000</td>
      <td>0.666667</td>
      <td>2.666667</td>
      <td>Chelsea</td>
      <td>0.333333</td>
      <td>10.666667</td>
      <td>2.666667</td>
      <td>...</td>
      <td>11.666667</td>
      <td>11.666667</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>88.000000</td>
      <td>17.666667</td>
      <td>13.666667</td>
      <td>57.066667</td>
      <td>Chelsea</td>
    </tr>
    <tr>
      <th>3799</th>
      <td>38</td>
      <td>22</td>
      <td>Home</td>
      <td>-2.000000</td>
      <td>0.333333</td>
      <td>2.333333</td>
      <td>Tottenham Hotspur</td>
      <td>0.333333</td>
      <td>9.666667</td>
      <td>2.333333</td>
      <td>...</td>
      <td>12.000000</td>
      <td>9.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>81.666667</td>
      <td>23.666667</td>
      <td>17.000000</td>
      <td>57.633333</td>
      <td>Tottenham Hotspur</td>
    </tr>
  </tbody>
</table>
<p>3740 rows Ã— 333 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse-output</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pd.option_context(<span class="st">"display.max_columns"</span>, <span class="va">None</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    display(dfAll.describe(include<span class="op">=</span><span class="st">'all'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>round</th>
      <th>day</th>
      <th>result_x</th>
      <th>gf_x</th>
      <th>ga_x</th>
      <th>shooting_gls_x</th>
      <th>shooting_sh__x</th>
      <th>shooting_sot_x</th>
      <th>shooting_sot%_x</th>
      <th>shooting_g/sh_x</th>
      <th>shooting_g/sot_x</th>
      <th>shooting_PC_dist_x</th>
      <th>shooting_fk__x</th>
      <th>shooting_pk_x</th>
      <th>shooting_pkatt__x</th>
      <th>shooting_xg_x</th>
      <th>shooting_npxg_x</th>
      <th>shooting_npxg/sh_x</th>
      <th>shooting_g-xg_x</th>
      <th>shooting_np:g-xg_x</th>
      <th>keeper_sota_x</th>
      <th>keeper_saves_x</th>
      <th>keeper_save%_x</th>
      <th>keeper_cs_x</th>
      <th>keeper_psxg_x</th>
      <th>keeper_psxg+/-_x</th>
      <th>keeper_pkatt__x</th>
      <th>keeper_pka_x</th>
      <th>keeper_pksv_x</th>
      <th>keeper_pkm_x</th>
      <th>keeper_cmp__x</th>
      <th>keeper_att__x</th>
      <th>keeper_cmp%__x</th>
      <th>keeper_att_.1_x</th>
      <th>keeper_thr_x</th>
      <th>keeper_launch%_x</th>
      <th>keeper_avglen_x</th>
      <th>keeper_att_.2_x</th>
      <th>keeper_launch%.1_x</th>
      <th>keeper_avglen.1_x</th>
      <th>keeper_opp_x</th>
      <th>keeper_stp_x</th>
      <th>keeper_stp%_x</th>
      <th>keeper_#opa_x</th>
      <th>keeper_avgdist_x</th>
      <th>passing_pass_complete_x</th>
      <th>passing_cmp%__x</th>
      <th>passing_PC_totdist__x</th>
      <th>passing_PC_prgdist__x</th>
      <th>passing_PC_cmp_.1_x</th>
      <th>passing_cmp%_.1_x</th>
      <th>passing_PC_cmp_.2_x</th>
      <th>passing_cmp%_.2_x</th>
      <th>passing_PC_cmp_.3_x</th>
      <th>passing_cmp%_.3_x</th>
      <th>passing_ast_x</th>
      <th>passing_xa_x</th>
      <th>passing_kp_x</th>
      <th>passing_PC_1/3__x</th>
      <th>passing_PC_ppa_x</th>
      <th>passing_PC_crspa_x</th>
      <th>passing_PC_prog__x</th>
      <th>passing_PC_types_live__x</th>
      <th>passing_PC_types_dead_x</th>
      <th>passing_PC_types_fk__x</th>
      <th>passing_PC_types_tb_x</th>
      <th>passing_PC_types_press__x</th>
      <th>passing_PC_types_sw_x</th>
      <th>passing_PC_types_crs__x</th>
      <th>passing_PC_types_ck_x</th>
      <th>passing_PC_types_in_x</th>
      <th>passing_PC_types_out_x</th>
      <th>passing_PC_types_str_x</th>
      <th>passing_PC_types_ground_x</th>
      <th>passing_PC_types_low_x</th>
      <th>passing_PC_types_high_x</th>
      <th>passing_PC_types_left_x</th>
      <th>passing_PC_types_right_x</th>
      <th>passing_PC_types_head_x</th>
      <th>passing_PC_types_ti_x</th>
      <th>passing_PC_types_other_x</th>
      <th>passing_PC_types_cmp__x</th>
      <th>passing_PC_types_off__x</th>
      <th>passing_PC_types_out.1_x</th>
      <th>passing_PC_types_int__x</th>
      <th>passing_PC_types_blocks__x</th>
      <th>shotcreate_sca_x</th>
      <th>shotcreate_passlive_x</th>
      <th>shotcreate_passdead_x</th>
      <th>shotcreate_drib_x</th>
      <th>shotcreate_sh_gca_x</th>
      <th>shotcreate_fld_gca_x</th>
      <th>shotcreate_def_x</th>
      <th>shotcreate_gca_x</th>
      <th>shotcreate_passlive.1_x</th>
      <th>shotcreate_passdead.1_x</th>
      <th>shotcreate_drib.1_x</th>
      <th>shotcreate_sh_gca.1_x</th>
      <th>shotcreate_fld_gca.1_x</th>
      <th>shotcreate_def.1_x</th>
      <th>tackle_tkl_x</th>
      <th>tackle_PC_tklw_defense_x</th>
      <th>tackle_PC_def 3rd_defense_x</th>
      <th>tackle_PC_mid 3rd_defense_x</th>
      <th>tackle_PC_att 3rd_defense_x</th>
      <th>tackle_PC_tkl_dribble_x</th>
      <th>tackle_dribble%_x</th>
      <th>tackle_dribllepast_x</th>
      <th>tackle_press_defense_x</th>
      <th>tackle_%_x</th>
      <th>tackle_PC_press_def3rd_x</th>
      <th>tackle_PC_press_mid3rd_x</th>
      <th>tackle_PC_press_att3rd_x</th>
      <th>tackle_blocks_defense_x</th>
      <th>tackle_PC_sh_defense_x</th>
      <th>tackle_PC_shsv_x</th>
      <th>tackle_PC_pass_x</th>
      <th>tackle_int_defense_x</th>
      <th>tackle_clr_x</th>
      <th>tackle_err_x</th>
      <th>possession_poss_x</th>
      <th>possession_touches_x</th>
      <th>possession_PC_def pen_x</th>
      <th>possession_PC_def 3rd__x</th>
      <th>possession_PC_mid 3rd__x</th>
      <th>possession_PC_att 3rd__x</th>
      <th>possession_PC_att pen_x</th>
      <th>possession_PC_live__x</th>
      <th>possession_dribblesucc__x</th>
      <th>possession_dribbleatt__x</th>
      <th>possession_dribblesucc%_x</th>
      <th>possession_dribblepast_x</th>
      <th>possession_megs_x</th>
      <th>possession_carries_x</th>
      <th>possession_totdist__x</th>
      <th>possession_PC_prgdist__x</th>
      <th>possession_PC_prog__x</th>
      <th>possession_PC_1/3__x</th>
      <th>possession_PC_cpa_x</th>
      <th>possession_PC_mis_x</th>
      <th>possession_PC_dis_x</th>
      <th>possession_targ_x</th>
      <th>possession_rec_x</th>
      <th>possession_rec%_x</th>
      <th>possession_prog_.1_x</th>
      <th>misc_crdy_x</th>
      <th>misc_crdr_x</th>
      <th>misc_2crdy_x</th>
      <th>misc_fls_x</th>
      <th>misc_fld__x</th>
      <th>misc_off__x</th>
      <th>misc_crs__x</th>
      <th>misc_int__x</th>
      <th>misc_tklw__x</th>
      <th>misc_pkwon_x</th>
      <th>misc_pkcon_x</th>
      <th>misc_og_x</th>
      <th>misc_recov_x</th>
      <th>misc_won_x</th>
      <th>misc_lost_x</th>
      <th>misc_won%_x</th>
      <th>season</th>
      <th>month</th>
      <th>year</th>
      <th>weekday</th>
      <th>Win_x</th>
      <th>result_y</th>
      <th>gf_y</th>
      <th>ga_y</th>
      <th>shooting_gls_y</th>
      <th>shooting_sh__y</th>
      <th>shooting_sot_y</th>
      <th>shooting_sot%_y</th>
      <th>shooting_g/sh_y</th>
      <th>shooting_g/sot_y</th>
      <th>shooting_PC_dist_y</th>
      <th>shooting_fk__y</th>
      <th>shooting_pk_y</th>
      <th>shooting_pkatt__y</th>
      <th>shooting_yg_y</th>
      <th>shooting_npxg_y</th>
      <th>shooting_npxg/sh_y</th>
      <th>shooting_g-xg_y</th>
      <th>shooting_np:g-xg_y</th>
      <th>keeper_sota_y</th>
      <th>keeper_saves_y</th>
      <th>keeper_save%_y</th>
      <th>keeper_cs_y</th>
      <th>keeper_psxg_y</th>
      <th>keeper_psxg+/-_y</th>
      <th>keeper_pkatt__y</th>
      <th>keeper_pka_y</th>
      <th>keeper_pksv_y</th>
      <th>keeper_pkm_y</th>
      <th>keeper_cmp__y</th>
      <th>keeper_att__y</th>
      <th>keeper_cmp%__y</th>
      <th>keeper_att_.1_y</th>
      <th>keeper_thr_y</th>
      <th>keeper_launch%_y</th>
      <th>keeper_avglen_y</th>
      <th>keeper_att_.2_y</th>
      <th>keeper_launch%.1_y</th>
      <th>keeper_avglen.1_y</th>
      <th>keeper_opp_y</th>
      <th>keeper_stp_y</th>
      <th>keeper_stp%_y</th>
      <th>keeper_#opa_y</th>
      <th>keeper_avgdist_y</th>
      <th>passing_pass_complete_y</th>
      <th>passing_cmp%__y</th>
      <th>passing_PC_totdist__y</th>
      <th>passing_PC_prgdist__y</th>
      <th>passing_PC_cmp_.1_y</th>
      <th>passing_cmp%_.1_y</th>
      <th>passing_PC_cmp_.2_y</th>
      <th>passing_cmp%_.2_y</th>
      <th>passing_PC_cmp_.3_y</th>
      <th>passing_cmp%_.3_y</th>
      <th>passing_ast_y</th>
      <th>passing_ya_y</th>
      <th>passing_kp_y</th>
      <th>passing_PC_1/3__y</th>
      <th>passing_PC_ppa_y</th>
      <th>passing_PC_crspa_y</th>
      <th>passing_PC_prog__y</th>
      <th>passing_PC_types_live__y</th>
      <th>passing_PC_types_dead_y</th>
      <th>passing_PC_types_fk__y</th>
      <th>passing_PC_types_tb_y</th>
      <th>passing_PC_types_press__y</th>
      <th>passing_PC_types_sw_y</th>
      <th>passing_PC_types_crs__y</th>
      <th>passing_PC_types_ck_y</th>
      <th>passing_PC_types_in_y</th>
      <th>passing_PC_types_out_y</th>
      <th>passing_PC_types_str_y</th>
      <th>passing_PC_types_ground_y</th>
      <th>passing_PC_types_low_y</th>
      <th>passing_PC_types_high_y</th>
      <th>passing_PC_types_left_y</th>
      <th>passing_PC_types_right_y</th>
      <th>passing_PC_types_head_y</th>
      <th>passing_PC_types_ti_y</th>
      <th>passing_PC_types_other_y</th>
      <th>passing_PC_types_cmp__y</th>
      <th>passing_PC_types_off__y</th>
      <th>passing_PC_types_out.1_y</th>
      <th>passing_PC_types_int__y</th>
      <th>passing_PC_types_blocks__y</th>
      <th>shotcreate_sca_y</th>
      <th>shotcreate_passlive_y</th>
      <th>shotcreate_passdead_y</th>
      <th>shotcreate_drib_y</th>
      <th>shotcreate_sh_gca_y</th>
      <th>shotcreate_fld_gca_y</th>
      <th>shotcreate_def_y</th>
      <th>shotcreate_gca_y</th>
      <th>shotcreate_passlive.1_y</th>
      <th>shotcreate_passdead.1_y</th>
      <th>shotcreate_drib.1_y</th>
      <th>shotcreate_sh_gca.1_y</th>
      <th>shotcreate_fld_gca.1_y</th>
      <th>shotcreate_def.1_y</th>
      <th>tackle_tkl_y</th>
      <th>tackle_PC_tklw_defense_y</th>
      <th>tackle_PC_def 3rd_defense_y</th>
      <th>tackle_PC_mid 3rd_defense_y</th>
      <th>tackle_PC_att 3rd_defense_y</th>
      <th>tackle_PC_tkl_dribble_y</th>
      <th>tackle_dribble%_y</th>
      <th>tackle_dribllepast_y</th>
      <th>tackle_press_defense_y</th>
      <th>tackle_%_y</th>
      <th>tackle_PC_press_def3rd_y</th>
      <th>tackle_PC_press_mid3rd_y</th>
      <th>tackle_PC_press_att3rd_y</th>
      <th>tackle_blocks_defense_y</th>
      <th>tackle_PC_sh_defense_y</th>
      <th>tackle_PC_shsv_y</th>
      <th>tackle_PC_pass_y</th>
      <th>tackle_int_defense_y</th>
      <th>tackle_clr_y</th>
      <th>tackle_err_y</th>
      <th>possession_poss_y</th>
      <th>possession_touches_y</th>
      <th>possession_PC_def pen_y</th>
      <th>possession_PC_def 3rd__y</th>
      <th>possession_PC_mid 3rd__y</th>
      <th>possession_PC_att 3rd__y</th>
      <th>possession_PC_att pen_y</th>
      <th>possession_PC_live__y</th>
      <th>possession_dribblesucc__y</th>
      <th>possession_dribbleatt__y</th>
      <th>possession_dribblesucc%_y</th>
      <th>possession_dribblepast_y</th>
      <th>possession_megs_y</th>
      <th>possession_carries_y</th>
      <th>possession_totdist__y</th>
      <th>possession_PC_prgdist__y</th>
      <th>possession_PC_prog__y</th>
      <th>possession_PC_1/3__y</th>
      <th>possession_PC_cpa_y</th>
      <th>possession_PC_mis_y</th>
      <th>possession_PC_dis_y</th>
      <th>possession_targ_y</th>
      <th>possession_rec_y</th>
      <th>possession_rec%_y</th>
      <th>possession_prog_.1_y</th>
      <th>misc_crdy_y</th>
      <th>misc_crdr_y</th>
      <th>misc_2crdy_y</th>
      <th>misc_fls_y</th>
      <th>misc_fld__y</th>
      <th>misc_off__y</th>
      <th>misc_crs__y</th>
      <th>misc_int__y</th>
      <th>misc_tklw__y</th>
      <th>misc_pkwon_y</th>
      <th>misc_pkcon_y</th>
      <th>misc_og_y</th>
      <th>misc_recov_y</th>
      <th>misc_won_y</th>
      <th>misc_lost_y</th>
      <th>misc_won%_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
      <td>3740.000000</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>top</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>L</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1444</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>19.789305</td>
      <td>15.910160</td>
      <td>-0.003342</td>
      <td>1.367870</td>
      <td>1.371212</td>
      <td>1.324242</td>
      <td>12.318806</td>
      <td>4.082620</td>
      <td>33.666230</td>
      <td>0.103205</td>
      <td>0.295620</td>
      <td>151.814870</td>
      <td>0.457487</td>
      <td>0.104055</td>
      <td>0.131684</td>
      <td>1.320134</td>
      <td>1.220357</td>
      <td>0.100935</td>
      <td>0.004109</td>
      <td>-0.000169</td>
      <td>4.084715</td>
      <td>2.817513</td>
      <td>68.905134</td>
      <td>0.285829</td>
      <td>1.332852</td>
      <td>0.005624</td>
      <td>0.134447</td>
      <td>0.104768</td>
      <td>0.022103</td>
      <td>0.007576</td>
      <td>6.711765</td>
      <td>17.383601</td>
      <td>41.413993</td>
      <td>24.147148</td>
      <td>4.075178</td>
      <td>51.061034</td>
      <td>42.502959</td>
      <td>7.459848</td>
      <td>66.906448</td>
      <td>52.437215</td>
      <td>8.755080</td>
      <td>0.661631</td>
      <td>7.543382</td>
      <td>0.649643</td>
      <td>14.412273</td>
      <td>390.931194</td>
      <td>77.247553</td>
      <td>1979.363069</td>
      <td>687.824335</td>
      <td>40.897515</td>
      <td>86.660709</td>
      <td>41.792130</td>
      <td>83.940147</td>
      <td>15.411750</td>
      <td>57.009621</td>
      <td>0.942959</td>
      <td>0.897821</td>
      <td>8.928030</td>
      <td>7.547074</td>
      <td>2.120160</td>
      <td>0.545131</td>
      <td>8.387274</td>
      <td>89.802235</td>
      <td>10.197765</td>
      <td>2.484955</td>
      <td>0.183265</td>
      <td>15.459547</td>
      <td>2.967840</td>
      <td>2.486263</td>
      <td>1.061565</td>
      <td>0.467084</td>
      <td>0.350791</td>
      <td>0.082297</td>
      <td>63.555635</td>
      <td>14.102166</td>
      <td>22.342199</td>
      <td>27.469285</td>
      <td>59.267074</td>
      <td>4.388067</td>
      <td>4.484950</td>
      <td>1.347329</td>
      <td>77.794521</td>
      <td>0.354085</td>
      <td>1.919054</td>
      <td>2.424604</td>
      <td>2.519446</td>
      <td>19.230080</td>
      <td>13.878342</td>
      <td>1.687032</td>
      <td>1.185428</td>
      <td>0.992647</td>
      <td>1.057353</td>
      <td>0.429278</td>
      <td>2.148217</td>
      <td>1.469563</td>
      <td>0.141355</td>
      <td>0.147816</td>
      <td>0.180793</td>
      <td>0.159358</td>
      <td>0.049332</td>
      <td>17.782130</td>
      <td>60.717652</td>
      <td>50.005406</td>
      <td>37.636636</td>
      <td>12.357958</td>
      <td>33.790802</td>
      <td>36.547767</td>
      <td>10.469430</td>
      <td>150.873797</td>
      <td>29.555771</td>
      <td>34.517406</td>
      <td>43.220499</td>
      <td>22.262095</td>
      <td>15.869519</td>
      <td>23.681976</td>
      <td>0.506995</td>
      <td>76.318024</td>
      <td>12.285829</td>
      <td>25.121970</td>
      <td>0.274911</td>
      <td>49.998217</td>
      <td>615.295811</td>
      <td>11.131009</td>
      <td>33.164347</td>
      <td>46.679487</td>
      <td>26.100825</td>
      <td>3.856162</td>
      <td>92.155582</td>
      <td>9.629144</td>
      <td>16.482531</td>
      <td>58.265330</td>
      <td>10.457442</td>
      <td>0.714572</td>
      <td>383.570811</td>
      <td>1960.431774</td>
      <td>53.252857</td>
      <td>10.944362</td>
      <td>3.339541</td>
      <td>1.091207</td>
      <td>3.437701</td>
      <td>3.274796</td>
      <td>465.705749</td>
      <td>390.931194</td>
      <td>82.527647</td>
      <td>34.576738</td>
      <td>1.634715</td>
      <td>0.058289</td>
      <td>0.023886</td>
      <td>12.389394</td>
      <td>11.971569</td>
      <td>1.868182</td>
      <td>12.004590</td>
      <td>12.285829</td>
      <td>10.759091</td>
      <td>0.110116</td>
      <td>0.128832</td>
      <td>0.044251</td>
      <td>90.116667</td>
      <td>19.210250</td>
      <td>19.209581</td>
      <td>49.993079</td>
      <td>2019.023529</td>
      <td>6.763636</td>
      <td>2019.533690</td>
      <td>4.360963</td>
      <td>NaN</td>
      <td>-0.001471</td>
      <td>1.368672</td>
      <td>1.370143</td>
      <td>1.324777</td>
      <td>12.322950</td>
      <td>4.084759</td>
      <td>33.665749</td>
      <td>0.103174</td>
      <td>0.295648</td>
      <td>151.783431</td>
      <td>0.457888</td>
      <td>0.104189</td>
      <td>0.131818</td>
      <td>1.320963</td>
      <td>1.221092</td>
      <td>0.100949</td>
      <td>0.003815</td>
      <td>-0.000504</td>
      <td>4.081640</td>
      <td>2.815374</td>
      <td>68.919652</td>
      <td>0.286364</td>
      <td>1.331836</td>
      <td>0.005677</td>
      <td>0.134447</td>
      <td>0.104768</td>
      <td>0.022103</td>
      <td>0.007576</td>
      <td>6.709358</td>
      <td>17.376381</td>
      <td>41.415183</td>
      <td>24.147549</td>
      <td>4.076114</td>
      <td>51.039416</td>
      <td>42.493012</td>
      <td>7.457843</td>
      <td>66.902732</td>
      <td>52.430985</td>
      <td>8.752540</td>
      <td>0.662701</td>
      <td>7.562781</td>
      <td>0.649777</td>
      <td>14.412968</td>
      <td>391.065285</td>
      <td>77.252794</td>
      <td>1979.240478</td>
      <td>687.729735</td>
      <td>40.898842</td>
      <td>86.663770</td>
      <td>41.792418</td>
      <td>83.941805</td>
      <td>15.409745</td>
      <td>57.018378</td>
      <td>0.943093</td>
      <td>0.898075</td>
      <td>8.930303</td>
      <td>7.547489</td>
      <td>2.119949</td>
      <td>0.544611</td>
      <td>8.387497</td>
      <td>89.804963</td>
      <td>10.195037</td>
      <td>2.483827</td>
      <td>0.183429</td>
      <td>15.457410</td>
      <td>2.966877</td>
      <td>2.485392</td>
      <td>1.061554</td>
      <td>0.466670</td>
      <td>0.351048</td>
      <td>0.082452</td>
      <td>63.562637</td>
      <td>14.102245</td>
      <td>22.335118</td>
      <td>27.463310</td>
      <td>59.275168</td>
      <td>4.386860</td>
      <td>4.484425</td>
      <td>1.347030</td>
      <td>77.799389</td>
      <td>0.353852</td>
      <td>1.918207</td>
      <td>2.423601</td>
      <td>2.519481</td>
      <td>19.238102</td>
      <td>13.884492</td>
      <td>1.687299</td>
      <td>1.185963</td>
      <td>0.993182</td>
      <td>1.058021</td>
      <td>0.429144</td>
      <td>2.149020</td>
      <td>1.470766</td>
      <td>0.141087</td>
      <td>0.147683</td>
      <td>0.180526</td>
      <td>0.159759</td>
      <td>0.049198</td>
      <td>17.784135</td>
      <td>60.719894</td>
      <td>50.000323</td>
      <td>37.647136</td>
      <td>12.352541</td>
      <td>33.783894</td>
      <td>36.543182</td>
      <td>10.470232</td>
      <td>150.897059</td>
      <td>29.560998</td>
      <td>34.512083</td>
      <td>43.224267</td>
      <td>22.263651</td>
      <td>15.867112</td>
      <td>23.665236</td>
      <td>0.506995</td>
      <td>76.334764</td>
      <td>12.288636</td>
      <td>25.107932</td>
      <td>0.274777</td>
      <td>50.007442</td>
      <td>615.434180</td>
      <td>11.127372</td>
      <td>33.157686</td>
      <td>46.683163</td>
      <td>26.103830</td>
      <td>3.856597</td>
      <td>92.157298</td>
      <td>9.633021</td>
      <td>16.488681</td>
      <td>58.268097</td>
      <td>10.461988</td>
      <td>0.714840</td>
      <td>383.703164</td>
      <td>1960.965196</td>
      <td>53.255401</td>
      <td>10.945468</td>
      <td>3.339802</td>
      <td>1.091572</td>
      <td>3.436512</td>
      <td>3.274502</td>
      <td>465.841176</td>
      <td>391.065285</td>
      <td>82.532513</td>
      <td>34.589305</td>
      <td>1.635918</td>
      <td>0.058422</td>
      <td>0.024020</td>
      <td>12.391800</td>
      <td>11.971836</td>
      <td>1.866979</td>
      <td>12.004055</td>
      <td>12.288636</td>
      <td>10.760561</td>
      <td>0.110250</td>
      <td>0.128832</td>
      <td>0.044251</td>
      <td>90.128164</td>
      <td>19.211854</td>
      <td>19.208779</td>
      <td>49.995499</td>
    </tr>
    <tr>
      <th>std</th>
      <td>10.812190</td>
      <td>9.082985</td>
      <td>1.260926</td>
      <td>0.808001</td>
      <td>0.774004</td>
      <td>0.794644</td>
      <td>3.597818</td>
      <td>1.608375</td>
      <td>9.614793</td>
      <td>0.063311</td>
      <td>0.160978</td>
      <td>54.846307</td>
      <td>0.401409</td>
      <td>0.189608</td>
      <td>0.213964</td>
      <td>0.539431</td>
      <td>0.499269</td>
      <td>0.028063</td>
      <td>0.548592</td>
      <td>0.545514</td>
      <td>1.536609</td>
      <td>1.192484</td>
      <td>17.268237</td>
      <td>0.271639</td>
      <td>0.620853</td>
      <td>0.426968</td>
      <td>0.218550</td>
      <td>0.189411</td>
      <td>0.089500</td>
      <td>0.052022</td>
      <td>2.673514</td>
      <td>6.831725</td>
      <td>11.779479</td>
      <td>5.578168</td>
      <td>1.668569</td>
      <td>20.032654</td>
      <td>9.608195</td>
      <td>2.134183</td>
      <td>24.745854</td>
      <td>13.899819</td>
      <td>2.799294</td>
      <td>0.530528</td>
      <td>6.377266</td>
      <td>0.567336</td>
      <td>3.132228</td>
      <td>119.477131</td>
      <td>6.127586</td>
      <td>108.661242</td>
      <td>122.423021</td>
      <td>3.621674</td>
      <td>3.653049</td>
      <td>3.620413</td>
      <td>5.360235</td>
      <td>2.776097</td>
      <td>8.948543</td>
      <td>0.660216</td>
      <td>0.400746</td>
      <td>2.878542</td>
      <td>1.266651</td>
      <td>0.599713</td>
      <td>0.297163</td>
      <td>1.457260</td>
      <td>2.574413</td>
      <td>2.574413</td>
      <td>0.758481</td>
      <td>0.151459</td>
      <td>3.983513</td>
      <td>0.780574</td>
      <td>0.691667</td>
      <td>0.342776</td>
      <td>0.294596</td>
      <td>0.231719</td>
      <td>0.116260</td>
      <td>9.270781</td>
      <td>2.990125</td>
      <td>7.202335</td>
      <td>6.437151</td>
      <td>7.071222</td>
      <td>1.538933</td>
      <td>1.257358</td>
      <td>0.410721</td>
      <td>6.000126</td>
      <td>0.218160</td>
      <td>0.703913</td>
      <td>0.971685</td>
      <td>0.625166</td>
      <td>6.158332</td>
      <td>5.057429</td>
      <td>0.842449</td>
      <td>0.768469</td>
      <td>0.696029</td>
      <td>0.600697</td>
      <td>0.406695</td>
      <td>1.383549</td>
      <td>1.122031</td>
      <td>0.214337</td>
      <td>0.251428</td>
      <td>0.253063</td>
      <td>0.238379</td>
      <td>0.133121</td>
      <td>3.479814</td>
      <td>7.282239</td>
      <td>9.782546</td>
      <td>7.986327</td>
      <td>5.688972</td>
      <td>8.586122</td>
      <td>8.484729</td>
      <td>2.904268</td>
      <td>27.877080</td>
      <td>3.933526</td>
      <td>6.492833</td>
      <td>3.781661</td>
      <td>5.400574</td>
      <td>3.425881</td>
      <td>8.158337</td>
      <td>1.101893</td>
      <td>8.158337</td>
      <td>4.887549</td>
      <td>7.802474</td>
      <td>0.332278</td>
      <td>9.573898</td>
      <td>112.341294</td>
      <td>3.073200</td>
      <td>5.869180</td>
      <td>4.246802</td>
      <td>4.196696</td>
      <td>0.939337</td>
      <td>1.639189</td>
      <td>2.899335</td>
      <td>4.097558</td>
      <td>8.885281</td>
      <td>3.039749</td>
      <td>0.565743</td>
      <td>109.013451</td>
      <td>560.207630</td>
      <td>3.728944</td>
      <td>1.931172</td>
      <td>0.714923</td>
      <td>0.444086</td>
      <td>1.165160</td>
      <td>1.051011</td>
      <td>119.023950</td>
      <td>119.477131</td>
      <td>5.138379</td>
      <td>10.830988</td>
      <td>0.746549</td>
      <td>0.138407</td>
      <td>0.089291</td>
      <td>2.524250</td>
      <td>2.591855</td>
      <td>0.956812</td>
      <td>3.444791</td>
      <td>4.887549</td>
      <td>2.295753</td>
      <td>0.195497</td>
      <td>0.211274</td>
      <td>0.118976</td>
      <td>11.267654</td>
      <td>5.659847</td>
      <td>5.813950</td>
      <td>6.294121</td>
      <td>1.407382</td>
      <td>3.969227</td>
      <td>1.520015</td>
      <td>1.798241</td>
      <td>NaN</td>
      <td>1.262519</td>
      <td>0.808628</td>
      <td>0.774343</td>
      <td>0.795351</td>
      <td>3.597067</td>
      <td>1.608762</td>
      <td>9.614106</td>
      <td>0.063220</td>
      <td>0.160880</td>
      <td>54.850292</td>
      <td>0.401701</td>
      <td>0.189711</td>
      <td>0.214038</td>
      <td>0.540175</td>
      <td>0.499985</td>
      <td>0.028062</td>
      <td>0.548811</td>
      <td>0.545793</td>
      <td>1.537276</td>
      <td>1.192771</td>
      <td>17.264720</td>
      <td>0.271814</td>
      <td>0.621129</td>
      <td>0.426749</td>
      <td>0.218550</td>
      <td>0.189411</td>
      <td>0.089500</td>
      <td>0.052022</td>
      <td>2.672028</td>
      <td>6.828191</td>
      <td>11.780052</td>
      <td>5.577480</td>
      <td>1.669308</td>
      <td>20.034401</td>
      <td>9.606079</td>
      <td>2.134818</td>
      <td>24.737701</td>
      <td>13.894690</td>
      <td>2.800754</td>
      <td>0.530705</td>
      <td>6.392757</td>
      <td>0.567242</td>
      <td>3.129257</td>
      <td>119.515735</td>
      <td>6.128051</td>
      <td>108.609872</td>
      <td>122.401336</td>
      <td>3.621302</td>
      <td>3.653428</td>
      <td>3.620178</td>
      <td>5.359233</td>
      <td>2.775348</td>
      <td>8.950187</td>
      <td>0.660886</td>
      <td>0.400693</td>
      <td>2.874659</td>
      <td>1.266934</td>
      <td>0.599507</td>
      <td>0.297272</td>
      <td>1.457096</td>
      <td>2.574378</td>
      <td>2.574378</td>
      <td>0.758191</td>
      <td>0.151427</td>
      <td>3.984765</td>
      <td>0.780327</td>
      <td>0.691138</td>
      <td>0.342928</td>
      <td>0.294658</td>
      <td>0.231838</td>
      <td>0.116712</td>
      <td>9.267060</td>
      <td>2.989201</td>
      <td>7.200972</td>
      <td>6.427083</td>
      <td>7.065863</td>
      <td>1.538999</td>
      <td>1.256937</td>
      <td>0.410498</td>
      <td>6.000922</td>
      <td>0.218247</td>
      <td>0.704214</td>
      <td>0.971906</td>
      <td>0.625276</td>
      <td>6.153878</td>
      <td>5.053910</td>
      <td>0.842469</td>
      <td>0.768861</td>
      <td>0.697474</td>
      <td>0.601022</td>
      <td>0.406260</td>
      <td>1.385009</td>
      <td>1.123701</td>
      <td>0.213889</td>
      <td>0.251374</td>
      <td>0.252460</td>
      <td>0.238531</td>
      <td>0.132919</td>
      <td>3.477123</td>
      <td>7.276880</td>
      <td>9.780540</td>
      <td>7.986417</td>
      <td>5.689568</td>
      <td>8.581289</td>
      <td>8.469441</td>
      <td>2.904276</td>
      <td>27.861281</td>
      <td>3.935946</td>
      <td>6.495629</td>
      <td>3.784094</td>
      <td>5.401501</td>
      <td>3.426921</td>
      <td>8.160210</td>
      <td>1.101893</td>
      <td>8.160210</td>
      <td>4.886419</td>
      <td>7.791726</td>
      <td>0.332288</td>
      <td>9.576615</td>
      <td>112.388551</td>
      <td>3.076070</td>
      <td>5.875037</td>
      <td>4.250795</td>
      <td>4.198132</td>
      <td>0.939326</td>
      <td>1.639047</td>
      <td>2.902260</td>
      <td>4.103303</td>
      <td>8.886728</td>
      <td>3.042843</td>
      <td>0.565759</td>
      <td>109.038437</td>
      <td>560.266760</td>
      <td>3.730208</td>
      <td>1.932012</td>
      <td>0.714515</td>
      <td>0.443880</td>
      <td>1.164719</td>
      <td>1.050918</td>
      <td>119.069075</td>
      <td>119.515735</td>
      <td>5.138246</td>
      <td>10.836724</td>
      <td>0.746286</td>
      <td>0.138592</td>
      <td>0.089629</td>
      <td>2.523003</td>
      <td>2.591213</td>
      <td>0.956610</td>
      <td>3.445064</td>
      <td>4.886419</td>
      <td>2.293386</td>
      <td>0.195592</td>
      <td>0.211274</td>
      <td>0.118976</td>
      <td>11.274286</td>
      <td>5.658357</td>
      <td>5.813577</td>
      <td>6.295669</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>-5.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>3.333333</td>
      <td>0.333333</td>
      <td>2.766667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>55.061728</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.200000</td>
      <td>0.166667</td>
      <td>0.033333</td>
      <td>-1.966667</td>
      <td>-1.700000</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>-25.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-1.833333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.666667</td>
      <td>2.333333</td>
      <td>9.333333</td>
      <td>10.000000</td>
      <td>0.000000</td>
      <td>7.933333</td>
      <td>22.033333</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>10.733333</td>
      <td>1.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>157.000000</td>
      <td>58.200000</td>
      <td>1690.290290</td>
      <td>421.044850</td>
      <td>28.197674</td>
      <td>68.133333</td>
      <td>31.100478</td>
      <td>63.566667</td>
      <td>8.301527</td>
      <td>32.133333</td>
      <td>0.000000</td>
      <td>0.100000</td>
      <td>1.666667</td>
      <td>3.724138</td>
      <td>0.126263</td>
      <td>0.000000</td>
      <td>3.750000</td>
      <td>78.957169</td>
      <td>3.957997</td>
      <td>0.732601</td>
      <td>0.000000</td>
      <td>5.770965</td>
      <td>1.133948</td>
      <td>0.632911</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>32.774674</td>
      <td>6.373355</td>
      <td>6.699548</td>
      <td>12.052117</td>
      <td>37.898687</td>
      <td>1.231423</td>
      <td>1.332795</td>
      <td>0.264901</td>
      <td>58.153846</td>
      <td>0.000000</td>
      <td>0.455581</td>
      <td>0.293255</td>
      <td>0.691017</td>
      <td>4.666667</td>
      <td>2.500000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.333333</td>
      <td>36.170213</td>
      <td>11.627907</td>
      <td>12.500000</td>
      <td>0.000000</td>
      <td>8.333333</td>
      <td>9.166667</td>
      <td>2.000000</td>
      <td>66.000000</td>
      <td>13.700000</td>
      <td>13.606911</td>
      <td>29.111842</td>
      <td>8.041237</td>
      <td>6.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>45.161290</td>
      <td>1.333333</td>
      <td>6.333333</td>
      <td>0.000000</td>
      <td>24.666667</td>
      <td>361.666667</td>
      <td>3.639121</td>
      <td>14.908854</td>
      <td>33.405172</td>
      <td>10.754098</td>
      <td>1.246334</td>
      <td>85.822785</td>
      <td>2.000000</td>
      <td>5.000000</td>
      <td>22.333333</td>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>157.000000</td>
      <td>778.000000</td>
      <td>41.276202</td>
      <td>5.420561</td>
      <td>1.097695</td>
      <td>0.000000</td>
      <td>0.894188</td>
      <td>0.889193</td>
      <td>219.333333</td>
      <td>157.000000</td>
      <td>61.866667</td>
      <td>10.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.333333</td>
      <td>3.666667</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>1.333333</td>
      <td>4.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>50.333333</td>
      <td>4.000000</td>
      <td>5.666667</td>
      <td>22.200000</td>
      <td>2017.000000</td>
      <td>1.000000</td>
      <td>2017.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>-5.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>3.333333</td>
      <td>0.333333</td>
      <td>2.766667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>55.061728</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.200000</td>
      <td>0.166667</td>
      <td>0.033333</td>
      <td>-1.966667</td>
      <td>-1.700000</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>-25.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-1.833333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.666667</td>
      <td>2.333333</td>
      <td>9.333333</td>
      <td>10.000000</td>
      <td>0.000000</td>
      <td>7.933333</td>
      <td>22.033333</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>10.733333</td>
      <td>1.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>157.000000</td>
      <td>58.200000</td>
      <td>1690.290290</td>
      <td>421.044850</td>
      <td>28.197674</td>
      <td>68.133333</td>
      <td>31.100478</td>
      <td>63.566667</td>
      <td>8.301527</td>
      <td>32.133333</td>
      <td>0.000000</td>
      <td>0.100000</td>
      <td>1.666667</td>
      <td>3.724138</td>
      <td>0.126263</td>
      <td>0.000000</td>
      <td>3.750000</td>
      <td>78.957169</td>
      <td>3.957997</td>
      <td>0.732601</td>
      <td>0.000000</td>
      <td>5.770965</td>
      <td>1.133948</td>
      <td>0.632911</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>32.774674</td>
      <td>6.373355</td>
      <td>6.699548</td>
      <td>12.052117</td>
      <td>37.898687</td>
      <td>1.231423</td>
      <td>1.332795</td>
      <td>0.264901</td>
      <td>58.153846</td>
      <td>0.000000</td>
      <td>0.455581</td>
      <td>0.293255</td>
      <td>0.691017</td>
      <td>4.666667</td>
      <td>2.500000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.333333</td>
      <td>36.170213</td>
      <td>11.627907</td>
      <td>12.500000</td>
      <td>0.000000</td>
      <td>8.333333</td>
      <td>9.166667</td>
      <td>2.000000</td>
      <td>66.000000</td>
      <td>13.700000</td>
      <td>13.606911</td>
      <td>29.111842</td>
      <td>8.041237</td>
      <td>6.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>45.161290</td>
      <td>1.333333</td>
      <td>6.333333</td>
      <td>0.000000</td>
      <td>24.666667</td>
      <td>361.666667</td>
      <td>3.639121</td>
      <td>14.908854</td>
      <td>33.405172</td>
      <td>10.754098</td>
      <td>1.246334</td>
      <td>85.822785</td>
      <td>2.000000</td>
      <td>5.000000</td>
      <td>22.333333</td>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>157.000000</td>
      <td>778.000000</td>
      <td>41.276202</td>
      <td>5.420561</td>
      <td>1.097695</td>
      <td>0.000000</td>
      <td>0.894188</td>
      <td>0.889193</td>
      <td>219.333333</td>
      <td>157.000000</td>
      <td>61.866667</td>
      <td>10.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.333333</td>
      <td>3.666667</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>1.333333</td>
      <td>4.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>50.333333</td>
      <td>4.000000</td>
      <td>5.666667</td>
      <td>22.200000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>10.000000</td>
      <td>8.000000</td>
      <td>-1.000000</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>9.666667</td>
      <td>3.000000</td>
      <td>27.200000</td>
      <td>0.060000</td>
      <td>0.176667</td>
      <td>114.758929</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.933333</td>
      <td>0.866667</td>
      <td>0.080000</td>
      <td>-0.366667</td>
      <td>-0.366667</td>
      <td>3.000000</td>
      <td>2.000000</td>
      <td>58.333333</td>
      <td>0.000000</td>
      <td>0.866667</td>
      <td>-0.266667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.666667</td>
      <td>12.000000</td>
      <td>33.258333</td>
      <td>20.333333</td>
      <td>3.000000</td>
      <td>34.625000</td>
      <td>34.666667</td>
      <td>6.000000</td>
      <td>48.000000</td>
      <td>41.300000</td>
      <td>6.666667</td>
      <td>0.333333</td>
      <td>3.033333</td>
      <td>0.333333</td>
      <td>12.233333</td>
      <td>302.000000</td>
      <td>73.000000</td>
      <td>1904.671024</td>
      <td>597.184442</td>
      <td>38.330073</td>
      <td>84.366667</td>
      <td>39.180032</td>
      <td>80.466667</td>
      <td>13.442505</td>
      <td>50.300000</td>
      <td>0.333333</td>
      <td>0.600000</td>
      <td>7.000000</td>
      <td>6.676949</td>
      <td>1.706103</td>
      <td>0.329083</td>
      <td>7.358874</td>
      <td>88.052077</td>
      <td>8.321893</td>
      <td>1.936060</td>
      <td>0.073233</td>
      <td>12.539702</td>
      <td>2.435745</td>
      <td>1.990478</td>
      <td>0.825466</td>
      <td>0.251375</td>
      <td>0.176815</td>
      <td>0.000000</td>
      <td>57.131288</td>
      <td>12.020757</td>
      <td>16.761444</td>
      <td>22.619711</td>
      <td>54.337558</td>
      <td>3.223610</td>
      <td>3.572207</td>
      <td>1.058524</td>
      <td>73.703910</td>
      <td>0.198840</td>
      <td>1.395349</td>
      <td>1.681482</td>
      <td>2.083333</td>
      <td>15.000000</td>
      <td>10.333333</td>
      <td>1.000000</td>
      <td>0.666667</td>
      <td>0.333333</td>
      <td>0.666667</td>
      <td>0.000000</td>
      <td>1.333333</td>
      <td>0.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>15.333333</td>
      <td>55.769231</td>
      <td>43.181818</td>
      <td>32.142857</td>
      <td>8.333333</td>
      <td>27.906977</td>
      <td>30.633333</td>
      <td>8.333333</td>
      <td>131.000000</td>
      <td>26.925000</td>
      <td>30.194872</td>
      <td>40.625000</td>
      <td>18.408045</td>
      <td>13.333333</td>
      <td>17.987179</td>
      <td>0.000000</td>
      <td>70.833333</td>
      <td>8.333333</td>
      <td>19.666667</td>
      <td>0.000000</td>
      <td>43.000000</td>
      <td>532.666667</td>
      <td>8.961050</td>
      <td>29.345463</td>
      <td>43.868450</td>
      <td>23.254724</td>
      <td>3.223858</td>
      <td>91.025962</td>
      <td>7.333333</td>
      <td>13.666667</td>
      <td>52.566667</td>
      <td>8.333333</td>
      <td>0.333333</td>
      <td>302.333333</td>
      <td>1531.333333</td>
      <td>50.769548</td>
      <td>9.595724</td>
      <td>2.845528</td>
      <td>0.782841</td>
      <td>2.597991</td>
      <td>2.543108</td>
      <td>377.333333</td>
      <td>302.000000</td>
      <td>79.166667</td>
      <td>26.666667</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>10.666667</td>
      <td>10.333333</td>
      <td>1.250000</td>
      <td>9.666667</td>
      <td>8.333333</td>
      <td>9.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>82.333333</td>
      <td>15.000000</td>
      <td>15.000000</td>
      <td>45.933333</td>
      <td>2018.000000</td>
      <td>3.000000</td>
      <td>2018.000000</td>
      <td>4.000000</td>
      <td>NaN</td>
      <td>-1.000000</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>9.666667</td>
      <td>3.000000</td>
      <td>27.200000</td>
      <td>0.060000</td>
      <td>0.176667</td>
      <td>114.708333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.933333</td>
      <td>0.866667</td>
      <td>0.080000</td>
      <td>-0.366667</td>
      <td>-0.366667</td>
      <td>3.000000</td>
      <td>2.000000</td>
      <td>58.333333</td>
      <td>0.000000</td>
      <td>0.866667</td>
      <td>-0.266667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.666667</td>
      <td>12.000000</td>
      <td>33.233333</td>
      <td>20.333333</td>
      <td>3.000000</td>
      <td>34.625000</td>
      <td>34.666667</td>
      <td>6.000000</td>
      <td>48.000000</td>
      <td>41.300000</td>
      <td>6.666667</td>
      <td>0.333333</td>
      <td>3.033333</td>
      <td>0.333333</td>
      <td>12.233333</td>
      <td>302.000000</td>
      <td>73.000000</td>
      <td>1904.671024</td>
      <td>597.103658</td>
      <td>38.327718</td>
      <td>84.366667</td>
      <td>39.180032</td>
      <td>80.466667</td>
      <td>13.441365</td>
      <td>50.325000</td>
      <td>0.333333</td>
      <td>0.600000</td>
      <td>7.000000</td>
      <td>6.676949</td>
      <td>1.706103</td>
      <td>0.328192</td>
      <td>7.358874</td>
      <td>88.054636</td>
      <td>8.307964</td>
      <td>1.935807</td>
      <td>0.073300</td>
      <td>12.535171</td>
      <td>2.435630</td>
      <td>1.990167</td>
      <td>0.824997</td>
      <td>0.250117</td>
      <td>0.176815</td>
      <td>0.000000</td>
      <td>57.140011</td>
      <td>12.020757</td>
      <td>16.756203</td>
      <td>22.619711</td>
      <td>54.346396</td>
      <td>3.221214</td>
      <td>3.573929</td>
      <td>1.058127</td>
      <td>73.710308</td>
      <td>0.198282</td>
      <td>1.394568</td>
      <td>1.681230</td>
      <td>2.083333</td>
      <td>15.000000</td>
      <td>10.333333</td>
      <td>1.000000</td>
      <td>0.666667</td>
      <td>0.333333</td>
      <td>0.666667</td>
      <td>0.000000</td>
      <td>1.333333</td>
      <td>0.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>15.333333</td>
      <td>55.769231</td>
      <td>43.181818</td>
      <td>32.142857</td>
      <td>8.333333</td>
      <td>27.906977</td>
      <td>30.633333</td>
      <td>8.333333</td>
      <td>131.000000</td>
      <td>26.933333</td>
      <td>30.183981</td>
      <td>40.625000</td>
      <td>18.408045</td>
      <td>13.333333</td>
      <td>17.948718</td>
      <td>0.000000</td>
      <td>70.909091</td>
      <td>8.333333</td>
      <td>19.666667</td>
      <td>0.000000</td>
      <td>43.000000</td>
      <td>532.916667</td>
      <td>8.957279</td>
      <td>29.333138</td>
      <td>43.868450</td>
      <td>23.260019</td>
      <td>3.225334</td>
      <td>91.027006</td>
      <td>7.333333</td>
      <td>13.666667</td>
      <td>52.566667</td>
      <td>8.333333</td>
      <td>0.333333</td>
      <td>302.333333</td>
      <td>1531.583333</td>
      <td>50.772488</td>
      <td>9.595724</td>
      <td>2.845528</td>
      <td>0.783429</td>
      <td>2.597186</td>
      <td>2.543108</td>
      <td>377.333333</td>
      <td>302.000000</td>
      <td>79.166667</td>
      <td>26.666667</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>10.666667</td>
      <td>10.333333</td>
      <td>1.000000</td>
      <td>9.666667</td>
      <td>8.333333</td>
      <td>9.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>82.333333</td>
      <td>15.000000</td>
      <td>15.000000</td>
      <td>45.933333</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>20.000000</td>
      <td>16.000000</td>
      <td>0.000000</td>
      <td>1.333333</td>
      <td>1.333333</td>
      <td>1.333333</td>
      <td>12.000000</td>
      <td>4.000000</td>
      <td>33.266667</td>
      <td>0.096667</td>
      <td>0.276667</td>
      <td>141.126984</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.233333</td>
      <td>1.133333</td>
      <td>0.096667</td>
      <td>-0.033333</td>
      <td>-0.033333</td>
      <td>4.000000</td>
      <td>2.666667</td>
      <td>70.000000</td>
      <td>0.333333</td>
      <td>1.266667</td>
      <td>0.033333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>6.333333</td>
      <td>17.666667</td>
      <td>40.133333</td>
      <td>23.666667</td>
      <td>4.000000</td>
      <td>51.233333</td>
      <td>41.983333</td>
      <td>7.333333</td>
      <td>70.883333</td>
      <td>53.866667</td>
      <td>8.666667</td>
      <td>0.666667</td>
      <td>6.533333</td>
      <td>0.666667</td>
      <td>14.200000</td>
      <td>369.666667</td>
      <td>77.533333</td>
      <td>1973.385792</td>
      <td>674.276172</td>
      <td>40.893394</td>
      <td>87.033333</td>
      <td>41.918119</td>
      <td>84.733333</td>
      <td>15.218688</td>
      <td>56.616667</td>
      <td>1.000000</td>
      <td>0.833333</td>
      <td>8.666667</td>
      <td>7.505258</td>
      <td>2.080172</td>
      <td>0.499085</td>
      <td>8.344460</td>
      <td>89.793788</td>
      <td>10.206212</td>
      <td>2.440634</td>
      <td>0.155159</td>
      <td>15.109299</td>
      <td>2.891967</td>
      <td>2.444716</td>
      <td>1.030131</td>
      <td>0.415153</td>
      <td>0.326624</td>
      <td>0.052673</td>
      <td>64.038769</td>
      <td>13.965784</td>
      <td>21.682644</td>
      <td>27.017143</td>
      <td>59.389146</td>
      <td>4.180029</td>
      <td>4.393993</td>
      <td>1.312780</td>
      <td>78.137796</td>
      <td>0.312337</td>
      <td>1.835510</td>
      <td>2.419147</td>
      <td>2.476006</td>
      <td>18.666667</td>
      <td>13.000000</td>
      <td>1.666667</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.333333</td>
      <td>2.000000</td>
      <td>1.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>17.666667</td>
      <td>60.606061</td>
      <td>50.000000</td>
      <td>37.500000</td>
      <td>11.764706</td>
      <td>33.333333</td>
      <td>36.333333</td>
      <td>10.333333</td>
      <td>148.666667</td>
      <td>29.500000</td>
      <td>34.422759</td>
      <td>43.166562</td>
      <td>21.661238</td>
      <td>16.000000</td>
      <td>23.076923</td>
      <td>0.000000</td>
      <td>76.923077</td>
      <td>12.333333</td>
      <td>24.333333</td>
      <td>0.333333</td>
      <td>49.333333</td>
      <td>598.000000</td>
      <td>10.956981</td>
      <td>33.231956</td>
      <td>46.543912</td>
      <td>25.917296</td>
      <td>3.799952</td>
      <td>92.101589</td>
      <td>9.333333</td>
      <td>16.333333</td>
      <td>58.266667</td>
      <td>10.333333</td>
      <td>0.666667</td>
      <td>365.000000</td>
      <td>1888.333333</td>
      <td>53.271144</td>
      <td>10.804122</td>
      <td>3.312019</td>
      <td>1.046910</td>
      <td>3.311880</td>
      <td>3.151388</td>
      <td>447.000000</td>
      <td>369.666667</td>
      <td>82.966667</td>
      <td>33.000000</td>
      <td>1.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>12.333333</td>
      <td>12.000000</td>
      <td>1.666667</td>
      <td>11.666667</td>
      <td>12.333333</td>
      <td>10.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>89.666667</td>
      <td>18.666667</td>
      <td>18.666667</td>
      <td>49.866667</td>
      <td>2019.000000</td>
      <td>7.000000</td>
      <td>2020.000000</td>
      <td>5.000000</td>
      <td>NaN</td>
      <td>0.000000</td>
      <td>1.333333</td>
      <td>1.333333</td>
      <td>1.333333</td>
      <td>12.000000</td>
      <td>4.000000</td>
      <td>33.266667</td>
      <td>0.096667</td>
      <td>0.276667</td>
      <td>141.096096</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.233333</td>
      <td>1.133333</td>
      <td>0.096667</td>
      <td>-0.033333</td>
      <td>-0.033333</td>
      <td>4.000000</td>
      <td>2.666667</td>
      <td>70.000000</td>
      <td>0.333333</td>
      <td>1.266667</td>
      <td>0.033333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>6.333333</td>
      <td>17.500000</td>
      <td>40.133333</td>
      <td>23.666667</td>
      <td>4.000000</td>
      <td>51.216667</td>
      <td>41.966667</td>
      <td>7.333333</td>
      <td>70.833333</td>
      <td>53.866667</td>
      <td>8.666667</td>
      <td>0.666667</td>
      <td>6.533333</td>
      <td>0.666667</td>
      <td>14.200000</td>
      <td>369.666667</td>
      <td>77.533333</td>
      <td>1973.299213</td>
      <td>674.203472</td>
      <td>40.902674</td>
      <td>87.033333</td>
      <td>41.918119</td>
      <td>84.733333</td>
      <td>15.216435</td>
      <td>56.633333</td>
      <td>1.000000</td>
      <td>0.833333</td>
      <td>8.666667</td>
      <td>7.505258</td>
      <td>2.080172</td>
      <td>0.499002</td>
      <td>8.344641</td>
      <td>89.807127</td>
      <td>10.192873</td>
      <td>2.438150</td>
      <td>0.155280</td>
      <td>15.107914</td>
      <td>2.891076</td>
      <td>2.442379</td>
      <td>1.030131</td>
      <td>0.414938</td>
      <td>0.326731</td>
      <td>0.052673</td>
      <td>64.054440</td>
      <td>13.965784</td>
      <td>21.676691</td>
      <td>27.017143</td>
      <td>59.397669</td>
      <td>4.179519</td>
      <td>4.393352</td>
      <td>1.312062</td>
      <td>78.145767</td>
      <td>0.312215</td>
      <td>1.833579</td>
      <td>2.418674</td>
      <td>2.476006</td>
      <td>18.666667</td>
      <td>13.000000</td>
      <td>1.666667</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.333333</td>
      <td>2.000000</td>
      <td>1.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>17.666667</td>
      <td>60.606061</td>
      <td>50.000000</td>
      <td>37.500000</td>
      <td>11.764706</td>
      <td>33.333333</td>
      <td>36.333333</td>
      <td>10.333333</td>
      <td>148.666667</td>
      <td>29.500000</td>
      <td>34.416938</td>
      <td>43.190925</td>
      <td>21.661853</td>
      <td>16.000000</td>
      <td>23.076923</td>
      <td>0.000000</td>
      <td>76.923077</td>
      <td>12.333333</td>
      <td>24.333333</td>
      <td>0.333333</td>
      <td>49.333333</td>
      <td>598.166667</td>
      <td>10.955386</td>
      <td>33.229361</td>
      <td>46.543912</td>
      <td>25.917765</td>
      <td>3.800716</td>
      <td>92.104505</td>
      <td>9.333333</td>
      <td>16.333333</td>
      <td>58.266667</td>
      <td>10.333333</td>
      <td>0.666667</td>
      <td>365.000000</td>
      <td>1889.166667</td>
      <td>53.272788</td>
      <td>10.807099</td>
      <td>3.312348</td>
      <td>1.047120</td>
      <td>3.311526</td>
      <td>3.150893</td>
      <td>447.000000</td>
      <td>369.666667</td>
      <td>82.966667</td>
      <td>33.000000</td>
      <td>1.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>12.333333</td>
      <td>12.000000</td>
      <td>1.666667</td>
      <td>11.666667</td>
      <td>12.333333</td>
      <td>10.666667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>89.666667</td>
      <td>18.666667</td>
      <td>18.666667</td>
      <td>49.866667</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>29.000000</td>
      <td>23.000000</td>
      <td>0.666667</td>
      <td>1.666667</td>
      <td>2.000000</td>
      <td>1.666667</td>
      <td>14.333333</td>
      <td>5.000000</td>
      <td>39.833333</td>
      <td>0.136667</td>
      <td>0.400000</td>
      <td>174.814815</td>
      <td>0.666667</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>1.633333</td>
      <td>1.500000</td>
      <td>0.116667</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>5.000000</td>
      <td>3.666667</td>
      <td>80.600000</td>
      <td>0.333333</td>
      <td>1.733333</td>
      <td>0.300000</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>8.666667</td>
      <td>22.333333</td>
      <td>48.008333</td>
      <td>27.333333</td>
      <td>5.000000</td>
      <td>66.608333</td>
      <td>49.875000</td>
      <td>9.000000</td>
      <td>88.900000</td>
      <td>63.800000</td>
      <td>10.666667</td>
      <td>1.000000</td>
      <td>11.100000</td>
      <td>1.000000</td>
      <td>16.233333</td>
      <td>462.666667</td>
      <td>81.866667</td>
      <td>2046.497928</td>
      <td>761.944411</td>
      <td>43.321740</td>
      <td>89.300000</td>
      <td>44.501404</td>
      <td>88.008333</td>
      <td>17.192269</td>
      <td>63.400000</td>
      <td>1.333333</td>
      <td>1.133333</td>
      <td>10.666667</td>
      <td>8.377245</td>
      <td>2.488849</td>
      <td>0.704380</td>
      <td>9.353610</td>
      <td>91.678107</td>
      <td>11.947923</td>
      <td>2.967121</td>
      <td>0.259875</td>
      <td>18.066159</td>
      <td>3.434564</td>
      <td>2.904000</td>
      <td>1.275412</td>
      <td>0.628931</td>
      <td>0.495488</td>
      <td>0.121175</td>
      <td>70.360031</td>
      <td>16.085472</td>
      <td>27.074844</td>
      <td>31.353094</td>
      <td>64.326950</td>
      <td>5.348022</td>
      <td>5.296737</td>
      <td>1.594533</td>
      <td>82.279813</td>
      <td>0.464769</td>
      <td>2.369317</td>
      <td>3.088833</td>
      <td>2.916504</td>
      <td>23.000000</td>
      <td>17.000000</td>
      <td>2.333333</td>
      <td>1.666667</td>
      <td>1.333333</td>
      <td>1.333333</td>
      <td>0.666667</td>
      <td>3.000000</td>
      <td>2.000000</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>20.000000</td>
      <td>65.724070</td>
      <td>56.818182</td>
      <td>43.083554</td>
      <td>15.733083</td>
      <td>39.404609</td>
      <td>42.108333</td>
      <td>12.333333</td>
      <td>168.083333</td>
      <td>32.166667</td>
      <td>38.637570</td>
      <td>45.792658</td>
      <td>25.485027</td>
      <td>18.000000</td>
      <td>29.166667</td>
      <td>0.000000</td>
      <td>82.012821</td>
      <td>15.666667</td>
      <td>29.666667</td>
      <td>0.333333</td>
      <td>56.666667</td>
      <td>684.416667</td>
      <td>13.116066</td>
      <td>37.014643</td>
      <td>49.525891</td>
      <td>28.669936</td>
      <td>4.423012</td>
      <td>93.340426</td>
      <td>11.333333</td>
      <td>19.000000</td>
      <td>64.233333</td>
      <td>12.333333</td>
      <td>1.000000</td>
      <td>450.541667</td>
      <td>2321.083333</td>
      <td>55.817291</td>
      <td>12.157871</td>
      <td>3.783117</td>
      <td>1.351732</td>
      <td>4.127864</td>
      <td>3.906409</td>
      <td>537.666667</td>
      <td>462.666667</td>
      <td>86.300000</td>
      <td>40.666667</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.000000</td>
      <td>13.666667</td>
      <td>2.333333</td>
      <td>14.000000</td>
      <td>15.666667</td>
      <td>12.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>97.666667</td>
      <td>22.666667</td>
      <td>23.000000</td>
      <td>54.000000</td>
      <td>2020.000000</td>
      <td>11.000000</td>
      <td>2021.000000</td>
      <td>6.000000</td>
      <td>NaN</td>
      <td>0.666667</td>
      <td>1.666667</td>
      <td>2.000000</td>
      <td>1.666667</td>
      <td>14.333333</td>
      <td>5.000000</td>
      <td>39.833333</td>
      <td>0.136667</td>
      <td>0.400000</td>
      <td>174.685847</td>
      <td>0.666667</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>1.633333</td>
      <td>1.500000</td>
      <td>0.116667</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>5.000000</td>
      <td>3.666667</td>
      <td>80.600000</td>
      <td>0.333333</td>
      <td>1.733333</td>
      <td>0.300000</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>8.666667</td>
      <td>22.333333</td>
      <td>48.008333</td>
      <td>27.333333</td>
      <td>5.000000</td>
      <td>66.600000</td>
      <td>49.866667</td>
      <td>9.000000</td>
      <td>88.900000</td>
      <td>63.800000</td>
      <td>10.666667</td>
      <td>1.000000</td>
      <td>11.100000</td>
      <td>1.000000</td>
      <td>16.233333</td>
      <td>463.000000</td>
      <td>81.875000</td>
      <td>2046.262466</td>
      <td>761.837938</td>
      <td>43.322443</td>
      <td>89.300000</td>
      <td>44.500754</td>
      <td>88.008333</td>
      <td>17.189260</td>
      <td>63.400000</td>
      <td>1.333333</td>
      <td>1.133333</td>
      <td>10.666667</td>
      <td>8.378284</td>
      <td>2.488688</td>
      <td>0.704225</td>
      <td>9.352675</td>
      <td>91.692036</td>
      <td>11.945364</td>
      <td>2.965807</td>
      <td>0.259898</td>
      <td>18.066159</td>
      <td>3.433541</td>
      <td>2.902260</td>
      <td>1.275691</td>
      <td>0.628931</td>
      <td>0.496003</td>
      <td>0.121230</td>
      <td>70.360031</td>
      <td>16.080614</td>
      <td>27.056263</td>
      <td>31.353094</td>
      <td>64.338108</td>
      <td>5.347347</td>
      <td>5.295715</td>
      <td>1.594285</td>
      <td>82.292768</td>
      <td>0.464563</td>
      <td>2.369200</td>
      <td>3.087634</td>
      <td>2.916504</td>
      <td>23.000000</td>
      <td>17.000000</td>
      <td>2.333333</td>
      <td>1.666667</td>
      <td>1.333333</td>
      <td>1.333333</td>
      <td>0.666667</td>
      <td>3.000000</td>
      <td>2.000000</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>20.000000</td>
      <td>65.714286</td>
      <td>56.756757</td>
      <td>43.103448</td>
      <td>15.733083</td>
      <td>39.393939</td>
      <td>42.100000</td>
      <td>12.333333</td>
      <td>168.083333</td>
      <td>32.166667</td>
      <td>38.637570</td>
      <td>45.795794</td>
      <td>25.485027</td>
      <td>18.000000</td>
      <td>29.090909</td>
      <td>0.000000</td>
      <td>82.051282</td>
      <td>15.666667</td>
      <td>29.666667</td>
      <td>0.333333</td>
      <td>56.666667</td>
      <td>684.750000</td>
      <td>13.116066</td>
      <td>37.014643</td>
      <td>49.526726</td>
      <td>28.669936</td>
      <td>4.423812</td>
      <td>93.342347</td>
      <td>11.333333</td>
      <td>19.000000</td>
      <td>64.233333</td>
      <td>12.333333</td>
      <td>1.000000</td>
      <td>450.666667</td>
      <td>2322.416667</td>
      <td>55.825288</td>
      <td>12.158055</td>
      <td>3.783784</td>
      <td>1.351732</td>
      <td>4.125392</td>
      <td>3.905096</td>
      <td>538.000000</td>
      <td>463.000000</td>
      <td>86.300000</td>
      <td>40.666667</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.000000</td>
      <td>13.666667</td>
      <td>2.333333</td>
      <td>14.000000</td>
      <td>15.666667</td>
      <td>12.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.000000</td>
      <td>97.666667</td>
      <td>22.666667</td>
      <td>23.000000</td>
      <td>54.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>38.000000</td>
      <td>31.000000</td>
      <td>5.333333</td>
      <td>5.666667</td>
      <td>5.666667</td>
      <td>5.666667</td>
      <td>27.666667</td>
      <td>11.666667</td>
      <td>75.000000</td>
      <td>0.500000</td>
      <td>1.000000</td>
      <td>708.000000</td>
      <td>2.333333</td>
      <td>1.666667</td>
      <td>1.666667</td>
      <td>3.833333</td>
      <td>3.733333</td>
      <td>0.240000</td>
      <td>2.400000</td>
      <td>2.400000</td>
      <td>13.000000</td>
      <td>8.000000</td>
      <td>100.000000</td>
      <td>1.333333</td>
      <td>3.933333</td>
      <td>1.600000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.666667</td>
      <td>17.666667</td>
      <td>42.000000</td>
      <td>95.233333</td>
      <td>50.333333</td>
      <td>10.666667</td>
      <td>100.000000</td>
      <td>71.666667</td>
      <td>18.666667</td>
      <td>100.000000</td>
      <td>85.850000</td>
      <td>21.333333</td>
      <td>3.666667</td>
      <td>44.766667</td>
      <td>3.666667</td>
      <td>40.666667</td>
      <td>846.333333</td>
      <td>91.066667</td>
      <td>2398.063380</td>
      <td>1296.830986</td>
      <td>54.207263</td>
      <td>95.100000</td>
      <td>52.490660</td>
      <td>94.633333</td>
      <td>25.879917</td>
      <td>83.633333</td>
      <td>5.000000</td>
      <td>2.833333</td>
      <td>21.666667</td>
      <td>13.935970</td>
      <td>4.793757</td>
      <td>2.348066</td>
      <td>14.285714</td>
      <td>96.042003</td>
      <td>21.042831</td>
      <td>5.673759</td>
      <td>1.083032</td>
      <td>30.942092</td>
      <td>6.671900</td>
      <td>5.632716</td>
      <td>2.524698</td>
      <td>2.195390</td>
      <td>1.541002</td>
      <td>0.920680</td>
      <td>84.874640</td>
      <td>26.916376</td>
      <td>47.310513</td>
      <td>49.404117</td>
      <td>78.316327</td>
      <td>11.080836</td>
      <td>10.986965</td>
      <td>3.247863</td>
      <td>91.125642</td>
      <td>2.006689</td>
      <td>5.189189</td>
      <td>6.269113</td>
      <td>4.973822</td>
      <td>46.333333</td>
      <td>38.000000</td>
      <td>5.333333</td>
      <td>5.666667</td>
      <td>5.666667</td>
      <td>3.666667</td>
      <td>2.333333</td>
      <td>10.666667</td>
      <td>8.666667</td>
      <td>1.333333</td>
      <td>2.000000</td>
      <td>1.333333</td>
      <td>1.666667</td>
      <td>1.000000</td>
      <td>32.000000</td>
      <td>91.666667</td>
      <td>79.487179</td>
      <td>62.790698</td>
      <td>42.857143</td>
      <td>71.428571</td>
      <td>66.266667</td>
      <td>25.333333</td>
      <td>268.333333</td>
      <td>45.566667</td>
      <td>58.685446</td>
      <td>56.675063</td>
      <td>48.812095</td>
      <td>30.666667</td>
      <td>54.838710</td>
      <td>7.894737</td>
      <td>100.000000</td>
      <td>31.666667</td>
      <td>62.666667</td>
      <td>2.666667</td>
      <td>78.333333</td>
      <td>1024.000000</td>
      <td>25.899281</td>
      <td>55.932203</td>
      <td>63.639323</td>
      <td>44.711111</td>
      <td>8.444444</td>
      <td>96.594982</td>
      <td>24.333333</td>
      <td>36.333333</td>
      <td>87.166667</td>
      <td>25.666667</td>
      <td>4.666667</td>
      <td>746.333333</td>
      <td>4209.000000</td>
      <td>64.982456</td>
      <td>18.909306</td>
      <td>6.168549</td>
      <td>3.206651</td>
      <td>9.473684</td>
      <td>9.362280</td>
      <td>914.666667</td>
      <td>846.333333</td>
      <td>94.300000</td>
      <td>78.333333</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>0.666667</td>
      <td>22.333333</td>
      <td>22.000000</td>
      <td>7.000000</td>
      <td>26.666667</td>
      <td>31.666667</td>
      <td>19.666667</td>
      <td>1.666667</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>126.666667</td>
      <td>50.333333</td>
      <td>45.333333</td>
      <td>75.766667</td>
      <td>2021.000000</td>
      <td>12.000000</td>
      <td>2022.000000</td>
      <td>6.000000</td>
      <td>NaN</td>
      <td>5.333333</td>
      <td>5.666667</td>
      <td>5.666667</td>
      <td>5.666667</td>
      <td>27.666667</td>
      <td>11.666667</td>
      <td>75.000000</td>
      <td>0.500000</td>
      <td>1.000000</td>
      <td>708.000000</td>
      <td>2.333333</td>
      <td>1.666667</td>
      <td>1.666667</td>
      <td>3.833333</td>
      <td>3.733333</td>
      <td>0.240000</td>
      <td>2.400000</td>
      <td>2.400000</td>
      <td>13.000000</td>
      <td>8.000000</td>
      <td>100.000000</td>
      <td>1.333333</td>
      <td>3.933333</td>
      <td>1.600000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.666667</td>
      <td>17.666667</td>
      <td>42.000000</td>
      <td>95.233333</td>
      <td>50.333333</td>
      <td>10.666667</td>
      <td>100.000000</td>
      <td>71.666667</td>
      <td>18.666667</td>
      <td>100.000000</td>
      <td>85.850000</td>
      <td>21.333333</td>
      <td>3.666667</td>
      <td>44.766667</td>
      <td>3.666667</td>
      <td>40.666667</td>
      <td>846.333333</td>
      <td>91.066667</td>
      <td>2398.063380</td>
      <td>1296.830986</td>
      <td>54.207263</td>
      <td>95.100000</td>
      <td>52.490660</td>
      <td>94.633333</td>
      <td>25.879917</td>
      <td>83.633333</td>
      <td>5.000000</td>
      <td>2.833333</td>
      <td>21.666667</td>
      <td>13.935970</td>
      <td>4.793757</td>
      <td>2.348066</td>
      <td>14.285714</td>
      <td>96.042003</td>
      <td>21.042831</td>
      <td>5.673759</td>
      <td>1.083032</td>
      <td>30.942092</td>
      <td>6.671900</td>
      <td>5.632716</td>
      <td>2.524698</td>
      <td>2.195390</td>
      <td>1.541002</td>
      <td>0.920680</td>
      <td>84.874640</td>
      <td>26.916376</td>
      <td>47.310513</td>
      <td>49.404117</td>
      <td>78.316327</td>
      <td>11.080836</td>
      <td>10.986965</td>
      <td>3.247863</td>
      <td>91.125642</td>
      <td>2.006689</td>
      <td>5.189189</td>
      <td>6.269113</td>
      <td>4.973822</td>
      <td>46.333333</td>
      <td>38.000000</td>
      <td>5.333333</td>
      <td>5.666667</td>
      <td>5.666667</td>
      <td>3.666667</td>
      <td>2.333333</td>
      <td>10.666667</td>
      <td>8.666667</td>
      <td>1.333333</td>
      <td>2.000000</td>
      <td>1.333333</td>
      <td>1.666667</td>
      <td>1.000000</td>
      <td>32.000000</td>
      <td>91.666667</td>
      <td>79.487179</td>
      <td>62.790698</td>
      <td>42.857143</td>
      <td>71.428571</td>
      <td>66.266667</td>
      <td>25.333333</td>
      <td>268.333333</td>
      <td>45.566667</td>
      <td>58.685446</td>
      <td>56.675063</td>
      <td>48.812095</td>
      <td>30.666667</td>
      <td>54.838710</td>
      <td>7.894737</td>
      <td>100.000000</td>
      <td>31.666667</td>
      <td>62.666667</td>
      <td>2.666667</td>
      <td>78.333333</td>
      <td>1024.000000</td>
      <td>25.899281</td>
      <td>55.932203</td>
      <td>63.639323</td>
      <td>44.711111</td>
      <td>8.444444</td>
      <td>96.594982</td>
      <td>24.333333</td>
      <td>36.333333</td>
      <td>87.166667</td>
      <td>25.666667</td>
      <td>4.666667</td>
      <td>746.333333</td>
      <td>4209.000000</td>
      <td>64.982456</td>
      <td>18.909306</td>
      <td>6.168549</td>
      <td>3.206651</td>
      <td>9.473684</td>
      <td>9.362280</td>
      <td>914.666667</td>
      <td>846.333333</td>
      <td>94.300000</td>
      <td>78.333333</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>0.666667</td>
      <td>22.333333</td>
      <td>22.000000</td>
      <td>7.000000</td>
      <td>26.666667</td>
      <td>31.666667</td>
      <td>19.666667</td>
      <td>1.666667</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>126.666667</td>
      <td>50.333333</td>
      <td>45.333333</td>
      <td>75.766667</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dtreeviz.trees <span class="im">import</span> <span class="op">*</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.api.types <span class="im">import</span> is_string_dtype, is_numeric_dtype, is_categorical_dtype</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.tabular.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.experimental <span class="im">import</span> enable_halving_search_cv  <span class="co"># noqa</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> HalvingRandomSearchCV</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="train-valid-split" class="level4">
<h4 class="anchored" data-anchor-id="train-valid-split">Train / Valid split</h4>
<p>In this case valid is actually test as train will be split by fits into train and valid</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>copy.copy(dfAll)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">## if want to do randomly</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># sza=np.shape(df)[0]</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># randAr=np.random.randint(0,100, size=sza)</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># cond = randAr&gt;=15</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>cond <span class="op">=</span> df.season<span class="op">&lt;</span><span class="dv">2021</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>train_idx <span class="op">=</span> np.where( cond)[<span class="dv">0</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>valid_idx <span class="op">=</span> np.where(<span class="op">~</span>cond)[<span class="dv">0</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>splits <span class="op">=</span> (<span class="bu">list</span>(train_idx),<span class="bu">list</span>(valid_idx))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>valid_idx.shape[<span class="dv">0</span>]<span class="op">/</span><span class="bu">len</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>0.20267379679144384</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.drop(columns<span class="op">=</span>[<span class="st">'NetScore_x'</span>,<span class="st">'venue_x'</span>,<span class="st">'opponent_y'</span>,<span class="st">'team_y'</span>,<span class="st">'GoalsAgainst_x'</span>,<span class="st">'GoalsFor_x'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>want_binary<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> want_binary<span class="op">==</span><span class="dv">1</span>:</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    df.loc[df[<span class="st">'Win_x'</span>]<span class="op">==</span><span class="st">'D'</span>,<span class="st">'Win_x'</span>]<span class="op">=</span><span class="st">'L'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-tabular-pandas-x-and-y-values" class="level4">
<h4 class="anchored" data-anchor-id="create-tabular-pandas-x-and-y-values">Create tabular pandas &amp; x and y values</h4>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>dep_var<span class="op">=</span><span class="st">'Win_x'</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>cont,cat <span class="op">=</span> cont_cat_split(df, <span class="dv">1</span>, dep_var<span class="op">=</span>dep_var)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>cat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>['opponent_x', 'team_x']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.dropna()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"opponent_x"</span>] <span class="op">=</span> df[<span class="st">"opponent_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"team_x"</span>] <span class="op">=</span> df[<span class="st">"team_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>df.loc[cond].copy()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>valid<span class="op">=</span>df.loc[<span class="op">~</span>cond].copy()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(valid)<span class="op">/</span><span class="bu">len</span>(df),(<span class="bu">len</span>(train)<span class="op">+</span><span class="bu">len</span>(valid))<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'Win_x'</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> train.columns <span class="cf">if</span> x <span class="op">!=</span> <span class="st">'Win_x'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> train[predictors]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>valid_xs <span class="op">=</span> valid[predictors]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train[target]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>valid_y <span class="op">=</span> valid[target]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="fit-the-data" class="level2">
<h2 class="anchored" data-anchor-id="fit-the-data">Fit the data</h2>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>clf.fit(xs,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestClassifier</label><div class="sk-toggleable__content"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>clf.score(xs,y),clf.score(valid_xs,valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(1.0, 0.521108179419525)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>3</td>
      <td>92</td>
      <td>81</td>
    </tr>
    <tr>
      <th>L</th>
      <td>5</td>
      <td>199</td>
      <td>87</td>
    </tr>
    <tr>
      <th>W</th>
      <td>4</td>
      <td>94</td>
      <td>193</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse-output</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rf_feat_importance(m, df):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame({<span class="st">'cols'</span>:df.columns, <span class="st">'imp'</span>:m.feature_importances_}</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                       ).sort_values(<span class="st">'imp'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># pred=rf.predict(train)</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_valid=best_random.predict(valid_xs)</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>fi <span class="op">=</span> rf_feat_importance(clf, xs)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_fi(fi):</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fi.plot(<span class="st">'cols'</span>, <span class="st">'imp'</span>, <span class="st">'barh'</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">25</span>), legend<span class="op">=</span><span class="va">False</span>,fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>plot_fi(fi[:<span class="dv">50</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-08-22-PredictingPremierLeagueMatches-Copy1_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(fi[fi[<span class="st">'imp'</span>]<span class="op">&gt;</span><span class="fl">0.0042</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>37</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>col_use <span class="op">=</span> fi[fi[<span class="st">'imp'</span>]<span class="op">&gt;</span><span class="fl">0.0042</span>].cols.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># xs,y = to.train.xs,to.train.y</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># valid_xs,valid_y = to.valid.xs,to.valid.y</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> do_fit_red_col(xs,valid_xs,y,valid_y,col_use,class_weight<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    xs_imp<span class="op">=</span> xs[col_use]</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    valid_xs_imp <span class="op">=</span>valid_xs[col_use]</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    clf_imp<span class="op">=</span>RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>,class_weight<span class="op">=</span>class_weight)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    clf_imp.fit(xs_imp,y)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Number of parameters = '</span>,<span class="bu">len</span>(col_use))</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Accuracy scores of train </span><span class="sc">{:.3f}</span><span class="st"> and validation </span><span class="sc">{:.3f}</span><span class="st"> sets'</span>.<span class="bu">format</span>(<span class="op">\</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    clf_imp.score(xs_imp,y),clf_imp.score(valid_xs_imp,valid_y)))</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> clf_imp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, col_use)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs[col_use])</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>crosstab</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  37
Accuracy scores of train 1.000 and validation 0.479 sets</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="57">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>11</td>
      <td>91</td>
      <td>74</td>
    </tr>
    <tr>
      <th>L</th>
      <td>15</td>
      <td>183</td>
      <td>93</td>
    </tr>
    <tr>
      <th>W</th>
      <td>16</td>
      <td>106</td>
      <td>169</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  4
Accuracy scores of train 0.994 and validation 0.484 sets</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="58">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>31</td>
      <td>73</td>
      <td>72</td>
    </tr>
    <tr>
      <th>L</th>
      <td>42</td>
      <td>171</td>
      <td>78</td>
    </tr>
    <tr>
      <th>W</th>
      <td>40</td>
      <td>86</td>
      <td>165</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,<span class="st">'balanced'</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  4
Accuracy scores of train 0.994 and validation 0.479 sets</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="59">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>31</td>
      <td>71</td>
      <td>74</td>
    </tr>
    <tr>
      <th>L</th>
      <td>44</td>
      <td>165</td>
      <td>82</td>
    </tr>
    <tr>
      <th>W</th>
      <td>41</td>
      <td>83</td>
      <td>167</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>[predictors_.append(x) <span class="cf">for</span> x <span class="kw">in</span> col_use]</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  41
Accuracy scores of train 1.000 and validation 0.468 sets</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="60">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>7</td>
      <td>88</td>
      <td>81</td>
    </tr>
    <tr>
      <th>L</th>
      <td>18</td>
      <td>177</td>
      <td>96</td>
    </tr>
    <tr>
      <th>W</th>
      <td>8</td>
      <td>112</td>
      <td>171</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>matchesC<span class="op">=</span>pd.read_csv(folda<span class="op">+</span><span class="st">'epl2017-2021_wivnetscore.csv'</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>X<span class="op">=</span>matchesC.corr()</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>val <span class="op">=</span>[ i <span class="cf">for</span> i,x <span class="kw">in</span> <span class="bu">enumerate</span>(X.columns) <span class="cf">if</span> x<span class="op">==</span><span class="st">'NetScore_x'</span>][<span class="dv">0</span>]</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>corrnetscore<span class="op">=</span>X.iloc[:,val:val<span class="op">+</span><span class="dv">1</span>].sort_values(by<span class="op">=</span><span class="st">"NetScore_x"</span>).reset_index()</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>corrnetscore<span class="op">=</span>corrnetscore.rename(columns<span class="op">=</span>{<span class="st">'index'</span>:<span class="st">'category'</span>})</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>corrnetscore</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>category</th>
      <th>NetScore_x</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NetScore_y</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ground_y</td>
      <td>-0.264919</td>
    </tr>
    <tr>
      <th>2</th>
      <td>cmp_passing.2_y</td>
      <td>-0.264773</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cmp_passing_y</td>
      <td>-0.263268</td>
    </tr>
    <tr>
      <th>4</th>
      <td>rec_y</td>
      <td>-0.263268</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>336</th>
      <td>att_passing_x</td>
      <td>0.307719</td>
    </tr>
    <tr>
      <th>337</th>
      <td>carries_x</td>
      <td>0.307754</td>
    </tr>
    <tr>
      <th>338</th>
      <td>live_passing_types_x</td>
      <td>0.307866</td>
    </tr>
    <tr>
      <th>339</th>
      <td>mid 3rd_possession_x</td>
      <td>0.309859</td>
    </tr>
    <tr>
      <th>340</th>
      <td>NetScore_x</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>341 rows Ã— 2 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>Xuse<span class="op">=</span>corrnetscore.loc[[x   <span class="cf">for</span> x <span class="kw">in</span> corrnetscore.index <span class="cf">if</span> ( (corrnetscore.loc[x,<span class="st">'category'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="op">==</span><span class="st">'x'</span>) <span class="op">&amp;</span> ( <span class="bu">abs</span>(corrnetscore.loc[x,<span class="st">'NetScore_x'</span>])<span class="op">&gt;</span><span class="fl">0.26</span>) )]]</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if ( (corrnetscore.loc[x,'category'][-1]=='y') &amp; ( abs(corrnetscore.loc[x,'NetScore_x'])&gt;0.24) )]]</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Xuse=corrnetscore.loc[[x   for x in corrnetscore.index if (  ( abs(corrnetscore.loc[x,'NetScore_x'])&gt;0.27) )]]</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>Xuse<span class="op">=</span><span class="bu">list</span>(Xuse[<span class="op">-</span><span class="dv">20</span>:<span class="op">-</span><span class="dv">1</span>].category.values)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>Xuse</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>['att_passing.1_x',
 '1/3_passing_x',
 'prgdist_possession_x',
 'ground_x',
 'cmp_passing.2_x',
 'att_passing.2_x',
 'totdist_passing_x',
 'touches_x',
 'cmp_passing_types_x',
 'cmp_passing_x',
 'rec_x',
 'targ_x',
 'live_possession_x',
 'prog_possession_x',
 'att_passing_types_x',
 'att_passing_x',
 'carries_x',
 'live_passing_types_x',
 'mid 3rd_possession_x']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>[predictors_.append(x) <span class="cf">for</span> x <span class="kw">in</span> Xuse]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, predictors_,<span class="st">'balanced'</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  23
Accuracy scores of train 1.000 and validation 0.485 sets</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="63">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>18</td>
      <td>101</td>
      <td>57</td>
    </tr>
    <tr>
      <th>L</th>
      <td>12</td>
      <td>203</td>
      <td>76</td>
    </tr>
    <tr>
      <th>W</th>
      <td>13</td>
      <td>131</td>
      <td>147</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>xAll<span class="op">=</span>pd.concat([valid_xs[predictors_]])</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(xAll)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>pc_draw <span class="op">=</span> <span class="dv">100</span><span class="op">*</span><span class="bu">len</span>(pred[pred<span class="op">==</span><span class="st">'D'</span>])<span class="op">/</span><span class="bu">len</span>(pred)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>pc_win <span class="op">=</span> <span class="dv">100</span><span class="op">*</span><span class="bu">len</span>(pred[pred<span class="op">==</span><span class="st">'W'</span>])<span class="op">/</span><span class="bu">len</span>(pred)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>pc_loss <span class="op">=</span> <span class="dv">100</span><span class="op">*</span><span class="bu">len</span>(pred[pred<span class="op">==</span><span class="st">'L'</span>])<span class="op">/</span><span class="bu">len</span>(pred)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Percentage draw </span><span class="sc">{:.1f}</span><span class="st">%, win </span><span class="sc">{:.1f}</span><span class="st">% and loss </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>( pc_draw,pc_win,pc_loss) )</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Percentage draw 5.7%, win 36.9% and loss 57.4%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>pc_draw <span class="op">=</span> <span class="dv">100</span><span class="op">*</span><span class="bu">len</span>(df[df[<span class="st">'Win_x'</span>]<span class="op">==</span><span class="st">'D'</span>])<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>pc_win <span class="op">=</span> <span class="dv">100</span><span class="op">*</span><span class="bu">len</span>(df[df[<span class="st">'Win_x'</span>]<span class="op">==</span><span class="st">'W'</span>])<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>pc_loss <span class="op">=</span> <span class="dv">100</span><span class="op">*</span><span class="bu">len</span>(df[df[<span class="st">'Win_x'</span>]<span class="op">==</span><span class="st">'L'</span>])<span class="op">/</span><span class="bu">len</span>(df)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Percentage draw </span><span class="sc">{:.1f}</span><span class="st">%, win </span><span class="sc">{:.1f}</span><span class="st">% and loss </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>( pc_draw,pc_win,pc_loss) )</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Percentage draw 22.8%, win 38.6% and loss 38.6%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>col_use <span class="op">=</span> fi[fi[<span class="st">'imp'</span>]<span class="op">&gt;</span><span class="fl">0.004</span>].cols.values</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>XX<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="fl">1e3</span>, <span class="fl">1e6</span>, <span class="fl">1e9</span>,<span class="fl">1e30</span>]</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> Draw_weght <span class="kw">in</span> XX:</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(Draw_weght)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, col_use,{<span class="st">'D'</span>:Draw_weght,<span class="st">'L'</span>:<span class="dv">1</span>,<span class="st">'W'</span>:<span class="dv">1</span>})</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    pred<span class="op">=</span>clf.predict(valid_xs[col_use])</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    ratio_draw_good<span class="op">=</span><span class="dv">100</span><span class="op">*</span>crosstab.iloc[<span class="dv">0</span>,<span class="dv">0</span>]<span class="op">/</span><span class="bu">sum</span>(crosstab.iloc[<span class="dv">0</span>,:])</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'weight draw = </span><span class="sc">{}</span><span class="st">, how many draws predicted </span><span class="sc">{:.1f}</span><span class="st">%'</span>.<span class="bu">format</span>(Draw_weght,ratio_draw_good))</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1
Number of parameters =  54
Accuracy scores of train 1.000 and validation 0.480 sets
weight draw = 1, how many draws predicted 2.8%
10
Number of parameters =  54
Accuracy scores of train 1.000 and validation 0.496 sets
weight draw = 10, how many draws predicted 6.2%
100
Number of parameters =  54
Accuracy scores of train 1.000 and validation 0.482 sets
weight draw = 100, how many draws predicted 4.0%
1000.0
Number of parameters =  54
Accuracy scores of train 1.000 and validation 0.474 sets
weight draw = 1000.0, how many draws predicted 5.7%
1000000.0
Number of parameters =  54
Accuracy scores of train 1.000 and validation 0.479 sets
weight draw = 1000000.0, how many draws predicted 4.5%
1000000000.0
Number of parameters =  54
Accuracy scores of train 1.000 and validation 0.503 sets
weight draw = 1000000000.0, how many draws predicted 6.2%
1e+30
Number of parameters =  54
Accuracy scores of train 0.227 and validation 0.232 sets
weight draw = 1e+30, how many draws predicted 100.0%</code></pre>
</div>
</div>
<section id="improve-the-results-from-hyper-parameters" class="level3">
<h3 class="anchored" data-anchor-id="improve-the-results-from-hyper-parameters">Improve the results from hyper-parameters</h3>
<p><code>HalvingRandomSearchCV</code>, <code>RandomizedSearchCV</code> and <code>GridSearchCV</code> can be used to search for the best hyperparameters.</p>
<p>The random ones donâ€™t go through all the options, but pick combinations randomly. So they will be quicker but may not get the best result. You may want to do the random ones to get a rough idea of parameters followed by grid search on a reduced range.</p>
<p>The most important arguments are</p>
<ul>
<li><code>cv</code> which is the number of folds to use for cross validation (we use the default values for cv of 5).</li>
<li><code>factor</code> the halving parameter (2 is used)</li>
<li>(or <code>n_iter</code> for RandomizedSearchCV, which controls the number of different combinations to try)</li>
</ul>
<p>More iterations or lower factor will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>n_estimators<span class="op">=</span>[<span class="dv">20</span>,<span class="dv">50</span>,<span class="dv">150</span>,<span class="dv">400</span>,<span class="dv">700</span>]</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of features to consider at every split</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>max_features <span class="op">=</span> [<span class="st">'log2'</span>,<span class="st">'sqrt'</span>,<span class="va">None</span>]</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Maximum number of levels in tree</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>max_depth<span class="op">=</span>[<span class="dv">10</span>,  <span class="dv">30</span>,  <span class="dv">70</span>,  <span class="dv">200</span>, <span class="va">None</span>]</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimum number of samples required to split a node</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>min_samples_split <span class="op">=</span> [<span class="fl">1.</span>,<span class="dv">2</span>, <span class="dv">10</span>,<span class="dv">50</span>]</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimum number of samples required at each leaf node</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>min_samples_leaf <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>,<span class="dv">10</span>]</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Method of selecting samples for training each tree</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>bootstrap <span class="op">=</span> [<span class="va">True</span>, <span class="va">False</span>]</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Weights associated with classes </span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>class_weight<span class="op">=</span>[<span class="st">"balanced"</span>, <span class="st">"balanced_subsample"</span>,<span class="va">None</span>]</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a><span class="co">#Complexity parameter used for Minimal Cost-Complexity Pruning.</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>ccp_alpha<span class="op">=</span>[<span class="fl">0.</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>]</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>random_grid <span class="op">=</span> {<span class="st">'n_estimators'</span>: n_estimators,</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>               <span class="st">'max_features'</span>: max_features,</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>               <span class="st">'max_depth'</span>: max_depth,</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>               <span class="st">'min_samples_split'</span>: min_samples_split,</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>               <span class="st">'min_samples_leaf'</span>: min_samples_leaf,</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>               <span class="st">'bootstrap'</span>: bootstrap,</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>               <span class="st">'class_weight'</span>:class_weight,</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>               <span class="st">'ccp_alpha'</span> : ccp_alpha</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>              }</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>rsh <span class="op">=</span> HalvingRandomSearchCV(estimator <span class="op">=</span> clf, param_distributions <span class="op">=</span> random_grid, <span class="op">\</span></span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>                              random_state<span class="op">=</span><span class="dv">42</span>, factor <span class="op">=</span> <span class="dv">2</span>)<span class="co"># Fit the random search model</span></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>rsh.fit(xs, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>HalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=2,
                      param_distributions={'bootstrap': [True, False],
                                           'ccp_alpha': [0.0, 0.1, 0.5],
                                           'class_weight': ['balanced',
                                                            'balanced_subsample',
                                                            None],
                                           'max_depth': [10, 30, 70, 200, None],
                                           'max_features': ['log2', 'sqrt',
                                                            None],
                                           'min_samples_leaf': [1, 2, 4, 10],
                                           'min_samples_split': [1.0, 2, 10,
                                                                 50],
                                           'n_estimators': [20, 50, 150, 400,
                                                            700]},
                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">HalvingRandomSearchCV</label><div class="sk-toggleable__content"><pre>HalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=2,
                      param_distributions={'bootstrap': [True, False],
                                           'ccp_alpha': [0.0, 0.1, 0.5],
                                           'class_weight': ['balanced',
                                                            'balanced_subsample',
                                                            None],
                                           'max_depth': [10, 30, 70, 200, None],
                                           'max_features': ['log2', 'sqrt',
                                                            None],
                                           'min_samples_leaf': [1, 2, 4, 10],
                                           'min_samples_split': [1.0, 2, 10,
                                                                 50],
                                           'n_estimators': [20, 50, 150, 400,
                                                            700]},
                      random_state=42)</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: RandomForestClassifier</label><div class="sk-toggleable__content"><pre>RandomForestClassifier()</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestClassifier</label><div class="sk-toggleable__content"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>rsh_best <span class="op">=</span> rsh.best_estimator_</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rsh_best)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy scores of train </span><span class="sc">{:.3f}</span><span class="st"> and validation </span><span class="sc">{:.3f}</span><span class="st"> sets'</span>.<span class="bu">format</span>(<span class="op">\</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>rsh_best.score(xs,y),rsh_best.score(valid_xs,valid_y)))</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>rsh_best.predict(valid_xs)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RandomForestClassifier(class_weight='balanced', max_depth=200,
                       max_features='log2', min_samples_leaf=4,
                       n_estimators=700)
Accuracy scores of train 0.981 and validation 0.522 sets</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="22">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>D</th>
      <th>L</th>
      <th>W</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>7</td>
      <td>85</td>
      <td>84</td>
    </tr>
    <tr>
      <th>L</th>
      <td>7</td>
      <td>196</td>
      <td>88</td>
    </tr>
    <tr>
      <th>W</th>
      <td>7</td>
      <td>91</td>
      <td>193</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">85</span><span class="op">+</span><span class="dv">7</span> <span class="op">+</span><span class="dv">196</span><span class="op">+</span><span class="dv">7</span> <span class="op">+</span><span class="dv">193</span>)<span class="op">/</span><span class="bu">len</span>(valid_xs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>0.6437994722955145</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(rsh.cv_results_)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"params_str"</span>] <span class="op">=</span> results.params.<span class="bu">apply</span>(<span class="bu">str</span>)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>results.drop_duplicates(subset<span class="op">=</span>(<span class="st">"params_str"</span>, <span class="st">"iter"</span>), inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>mean_scores <span class="op">=</span> results.pivot(</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">"iter"</span>, columns<span class="op">=</span><span class="st">"params_str"</span>, values<span class="op">=</span><span class="st">"mean_test_score"</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> mean_scores.plot(legend<span class="op">=</span><span class="va">False</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"iter=</span><span class="sc">{</span>i<span class="sc">}</span><span class="ch">\n</span><span class="ss">n_samples=</span><span class="sc">{</span>rsh<span class="sc">.</span>n_resources_[i]<span class="sc">}</span><span class="ch">\n</span><span class="ss">n_candidates=</span><span class="sc">{</span>rsh<span class="sc">.</span>n_candidates_[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(rsh.n_iterations_)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(<span class="bu">range</span>(rsh.n_iterations_))</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(labels, rotation<span class="op">=</span><span class="dv">45</span>, multialignment<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Scores of candidates over iterations"</span>)</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"mean test score"</span>, fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"iterations"</span>, fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-08-22-PredictingPremierLeagueMatches-Copy1_files/figure-html/cell-34-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="174">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># xs = train[predictors]</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># valid_xs = valid[predictors]</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># y = train[target]</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co"># valid_y = valid[target]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="174">
<pre><code>20      D
22      L
23      W
24      W
25      L
       ..
3035    L
3036    L
3037    L
3038    L
3039    W
Name: Win_x, Length: 3002, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="246">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> doLWD(yy):</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> yy<span class="op">==</span><span class="st">'W'</span>:</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">2</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> yy<span class="op">==</span><span class="st">'D'</span>:</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> yy<span class="op">==</span><span class="st">'L'</span>:</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>y2.copy()</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>valid_y<span class="op">=</span>valid_y2.copy()</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span> y2.<span class="bu">apply</span>(doLWD)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>valid_y<span class="op">=</span> valid_y2.<span class="bu">apply</span>(doLWD)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>random_grid <span class="op">=</span> {<span class="st">'n_estimators'</span>: [<span class="dv">50</span>,<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1_000</span>],</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>               <span class="st">'max_depth'</span>: [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>]</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>              }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[]</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>[predictors_.append(x) <span class="cf">for</span> x <span class="kw">in</span> xs]</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y,valid_y, predictors_)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>crosstab</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>,max_depth<span class="op">=</span><span class="dv">8</span>,learning_rate<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>clf.fit(xs, y,sample_weight<span class="op">=</span>classes_weights)</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a><span class="co"># pred=clf.predict(valid_xs)</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="co"># prec=precision_score(valid_y,pred,average='binary')</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a><span class="co"># f1=f1_score(valid_y,pred)</span></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(clf.score(xs,y), clf.score(valid_xs,valid_y))<span class="co">#,f1)</span></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>crosstab.columns.names<span class="op">=</span>[<span class="st">'predict'</span>]</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>crosstab.index.names<span class="op">=</span>[<span class="st">'actual'</span>]</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>crosstab</span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  326
Accuracy scores of train 1.000 and validation 0.521 sets</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'classes_weights' is not defined</code></pre>
</div>
</div>
<div class="cell" data-execution_count="226">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>precision_score(valid_y,clf.predict(valid_xs),pos_label<span class="op">=</span><span class="dv">1</span>,average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co"># crosstab.iloc[1,1]/(crosstab.iloc[1,1]+crosstab.iloc[0,1])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="226">
<pre><code>0.375</code></pre>
</div>
</div>
<div class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>y2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="166">
<pre><code>20      1
22      0
23      0
24      0
25      0
       ..
3035    0
3036    0
3037    0
3038    0
3039    0
Name: Win_x, Length: 3002, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># https://datascience.stackexchange.com/questions/16342/unbalanced-multiclass-data-with-xgboost</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> class_weight</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>classes_weights <span class="op">=</span> class_weight.compute_sample_weight(</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">'balanced'</span>,</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="237">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f1_eval(y_pred, dtrain):</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> dtrain.get_label()</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    err <span class="op">=</span> <span class="dv">1</span><span class="op">-</span>f1_score(y_true, np.<span class="bu">round</span>(y_pred))</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">'f1_err'</span>, err</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> doXGB(n,md):</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span>n, max_depth<span class="op">=</span>md,learning_rate<span class="op">=</span><span class="fl">0.01</span>,eval_metric<span class="op">=</span>f1_eval)</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    clf.fit(xs, y,sample_weight<span class="op">=</span>classes_weights)</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>    score_train <span class="op">=</span> clf.score(xs,y)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>    score_valid <span class="op">=</span> clf.score(valid_xs,valid_y)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="co">#     pred=clf.predict(valid_xs)</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    prec<span class="op">=</span>precision_score(valid_y,clf.predict(valid_xs),pos_label<span class="op">=</span><span class="dv">1</span>,average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>    f1<span class="op">=</span>f1_score(valid_y,clf.predict(valid_xs))</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [score_train, score_valid,prec,f1]</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>res_xgb <span class="op">=</span> np.zeros([<span class="bu">len</span>(random_grid[<span class="st">'n_estimators'</span>])<span class="op">*</span><span class="bu">len</span>(random_grid[<span class="st">'max_depth'</span>]),<span class="dv">6</span>])</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>i<span class="op">=</span><span class="dv">0</span></span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> md_vals <span class="kw">in</span> random_grid[<span class="st">'max_depth'</span>]:</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n_vals <span class="kw">in</span> random_grid[<span class="st">'n_estimators'</span>]:</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a>        res_xgb[i,<span class="dv">0</span>]<span class="op">=</span>n_vals</span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>        res_xgb[i,<span class="dv">1</span>]<span class="op">=</span>md_vals</span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'---'</span>)</span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(n_vals,md_vals)</span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a>        res_xgb[i,<span class="dv">2</span>:]<span class="op">=</span>doXGB(n_vals,md_vals)</span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(res_xgb[i,<span class="dv">2</span>:])</span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a>        i<span class="op">=</span>i<span class="op">+</span><span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>---
50 2
[0.42638241 0.39313984 0.23992674 0.36288089]
---
100 2
[0.5176549  0.46306069 0.23076923 0.32727273]
---
500 2
[0.6479014  0.62269129 0.28174603 0.3317757 ]
---
1000 2
[0.72251832 0.63588391 0.2706422  0.29949239]
---
50 4
[0.57594937 0.47757256 0.24418605 0.34653465]
---
100 4
[0.63291139 0.57124011 0.27076923 0.35129741]
---
500 4
[0.87308461 0.676781   0.2745098  0.25531915]
---
1000 4
[0.94703531 0.68997361 0.25619835 0.20875421]
---
50 6
[0.71652232 0.54485488 0.26462396 0.35514019]
---
100 6
[0.77948035 0.56332454 0.26586103 0.34714004]
---
500 6
[0.97401732 0.69656992 0.26315789 0.20689655]
---
1000 6
[0.99766822 0.72823219 0.29166667 0.16935484]
---
50 8
[0.84943371 0.5883905  0.24814815 0.30044843]
---
100 8
[0.88041306 0.64116095 0.28378378 0.31658291]
---
500 8
[0.99766822 0.72955145 0.22641509 0.10480349]
---
1000 8
[1.         0.76253298 0.375      0.0625    ]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="238">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>plt.plot(res_xgb[:,<span class="dv">0</span>],res_xgb[:,<span class="op">-</span><span class="dv">1</span>],<span class="st">'o'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-08-22-PredictingPremierLeagueMatches-Copy1_files/figure-html/cell-43-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, max_depth<span class="op">=</span><span class="dv">4</span>,num_class<span class="op">=</span><span class="dv">2</span>,eval_metric <span class="op">=</span><span class="st">'logloss'</span>,</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>                    learning_rate<span class="op">=</span><span class="fl">0.01</span>,objective<span class="op">=</span><span class="st">'binary:logisticrob'</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> class_weight</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>classes_weights <span class="op">=</span> class_weight.compute_sample_weight(</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">'balanced'</span>,</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>clf.fit(xs, y,sample_weight<span class="op">=</span>classes_weights)</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>pred<span class="op">=</span>clf.predict(valid_xs)</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred)</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>crosstab</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.metrics import balanced_accuracy_score</span></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a><span class="co"># balanced_accuracy_score(valid_y,pred)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['D' 'L' 'W']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>clf.score(valid_xs, valid_y),(crosstab.iloc[<span class="dv">0</span>,<span class="dv">0</span>]<span class="op">+</span>crosstab.iloc[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span>crosstab.iloc[<span class="dv">2</span>,<span class="dv">2</span>])<span class="op">/</span><span class="bu">len</span>(valid_y)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="co"># [x==max(x) for x in clf.predict_proba(valid_xs)]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="114">
<pre><code>(0.4630606860158311, 0.4630606860158311)</code></pre>
</div>
</div>
</section>
</section>
<section id="try-with-a-binary-question-does-the-team-win" class="level2">
<h2 class="anchored" data-anchor-id="try-with-a-binary-question-does-the-team-win">Try with a binary question: Does the team win?</h2>
<p>Model seems poor at predicting draws- none are predicted</p>
<p>And poor at losses- 50:50 on those</p>
<p>Because of this lets change the question to a binary one</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>y2<span class="op">=</span>y.copy()</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>valid_y2<span class="op">=</span>valid_y.copy()</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>want_binary<span class="op">=</span><span class="dv">1</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> want_binary<span class="op">==</span><span class="dv">1</span>:</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>    y2[y<span class="op">==</span><span class="st">'D'</span>]<span class="op">=</span><span class="st">'L'</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>    valid_y2[valid_y<span class="op">==</span><span class="st">'D'</span>]<span class="op">=</span><span class="st">'L'</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>y2[y2<span class="op">==</span><span class="st">'L'</span>]<span class="op">=</span><span class="dv">0</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>y2[y2<span class="op">==</span><span class="st">'W'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>y2<span class="op">=</span>y2.astype(<span class="st">'int'</span>)</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>valid_y2[valid_y2<span class="op">==</span><span class="st">'L'</span>]<span class="op">=</span><span class="dv">0</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>valid_y2[valid_y2<span class="op">==</span><span class="st">'W'</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>valid_y2<span class="op">=</span>valid_y2.astype(<span class="st">'int'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>col_use <span class="op">=</span> xs.columns</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, col_use)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>pred_class_RF<span class="op">=</span>clf.predict(valid_xs[col_use])</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Length of predictors is: '</span>,<span class="bu">len</span>(col_use))</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y, columns <span class="op">=</span> pred_class_RF)</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  340
Accuracy scores of train 1.000 and validation 0.669 sets
Length of predictors is:  340</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="30">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>D</th>
      <td>143</td>
      <td>33</td>
    </tr>
    <tr>
      <th>L</th>
      <td>257</td>
      <td>34</td>
    </tr>
    <tr>
      <th>W</th>
      <td>184</td>
      <td>107</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>pred_class_RF_basic4<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y2, columns <span class="op">=</span> pred_class_RF_basic4)</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Length of predictors is: '</span>,<span class="bu">len</span>(predictors_))</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy </span><span class="sc">{:.3f}</span><span class="st"> and precision </span><span class="sc">{:.3f}</span><span class="st"> of the validation data"</span>.<span class="op">\</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="bu">format</span>(accuracy_score(valid_y2, pred_class_RF_basic4),precision_score(valid_y2, pred_class_RF_basic4) ) )</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  4
Accuracy scores of train 0.995 and validation 0.656 sets
Length of predictors is:  4
The accuracy 0.656 and precision 0.560 of the validation data</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="31">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>358</td>
      <td>109</td>
    </tr>
    <tr>
      <th>1</th>
      <td>152</td>
      <td>139</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, xs.columns)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>fi <span class="op">=</span> rf_feat_importance(clf, xs)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>col_use <span class="op">=</span> fi[fi[<span class="st">'imp'</span>]<span class="op">&gt;</span><span class="fl">0.0042</span>].cols.values</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, col_use)</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>pred_class_RF_imp<span class="op">=</span>clf.predict(valid_xs[col_use])</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Length of predictors is: '</span>,<span class="bu">len</span>(col_use))</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy </span><span class="sc">{:.3f}</span><span class="st"> and precision </span><span class="sc">{:.3f}</span><span class="st"> of the validation data"</span>.<span class="op">\</span></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="bu">format</span>(accuracy_score(valid_y2, pred_class_RF_imp),precision_score(valid_y2, pred_class_RF_imp) ) )</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y2, columns <span class="op">=</span> pred_class_RF_imp)</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  340
Accuracy scores of train 1.000 and validation 0.669 sets
Number of parameters =  49
Accuracy scores of train 1.000 and validation 0.661 sets
Length of predictors is:  49
The accuracy 0.661 and precision 0.593 of the validation data</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="32">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>393</td>
      <td>74</td>
    </tr>
    <tr>
      <th>1</th>
      <td>183</td>
      <td>108</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>[predictors_.append(x) <span class="cf">for</span> x <span class="kw">in</span> col_use]</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_,<span class="st">'balanced'</span>)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>pred_class_RF_impBasic<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy </span><span class="sc">{:.3f}</span><span class="st"> and precision </span><span class="sc">{:.3f}</span><span class="st"> of the validation data"</span>.<span class="op">\</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="bu">format</span>(accuracy_score(valid_y2, pred_class_RF_impBasic),precision_score(valid_y2, pred_class_RF_impBasic) ) )</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Length of predictors is: '</span>,<span class="bu">len</span>(predictors_))</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y2, columns <span class="op">=</span> pred_class_RF_impBasic)</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  53
Accuracy scores of train 1.000 and validation 0.666 sets
The accuracy 0.666 and precision 0.628 of the validation data
Length of predictors is:  53</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="33">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>412</td>
      <td>55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>198</td>
      <td>93</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, Xuse)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>pred_class_RF_corr<span class="op">=</span>clf.predict(valid_xs[Xuse])</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy </span><span class="sc">{:.3f}</span><span class="st"> and precision </span><span class="sc">{:.3f}</span><span class="st"> of the validation data"</span>.<span class="op">\</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="bu">format</span>(accuracy_score(valid_y2, pred_class_RF_corr),precision_score(valid_y2, pred_class_RF_corr) ) )</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Length of predictors is: '</span>,<span class="bu">len</span>(Xuse))</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y2, columns <span class="op">=</span> pred_class_RF_corr)</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  19
Accuracy scores of train 1.000 and validation 0.632 sets
The accuracy 0.632 and precision 0.544 of the validation data
Length of predictors is:  19</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="34">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>405</td>
      <td>62</td>
    </tr>
    <tr>
      <th>1</th>
      <td>217</td>
      <td>74</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>[predictors_.append(x) <span class="cf">for</span> x <span class="kw">in</span> Xuse]</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_)</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>pred_class_RF_corrBasic<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'number of predictors ='</span>,<span class="bu">len</span>(predictors_))</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy </span><span class="sc">{:.3f}</span><span class="st"> and precision </span><span class="sc">{:.3f}</span><span class="st"> of the validation data"</span>.<span class="op">\</span></span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="bu">format</span>(accuracy_score(valid_y2, pred_class_RF_corrBasic),precision_score(valid_y2, pred_class_RF_corrBasic) ) )</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y2, columns <span class="op">=</span> pred_class_RF_corrBasic)</span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  23
Accuracy scores of train 1.000 and validation 0.656 sets
number of predictors = 23
The accuracy 0.656 and precision 0.604 of the validation data</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="35">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>410</td>
      <td>57</td>
    </tr>
    <tr>
      <th>1</th>
      <td>204</td>
      <td>87</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>predictors_<span class="op">=</span>[<span class="st">'round'</span>,<span class="st">'opponent_x'</span>,<span class="st">'team_x'</span>,<span class="st">'weekday'</span>]</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>[predictors_.append(x) <span class="cf">for</span> x <span class="kw">in</span> col_use]</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>clf<span class="op">=</span>do_fit_red_col(xs,valid_xs,y2,valid_y2, predictors_,<span class="st">'balanced'</span>)</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>pred_class_RF_balanced<span class="op">=</span>clf.predict(valid_xs[predictors_])</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The accuracy </span><span class="sc">{:.3f}</span><span class="st"> and precision </span><span class="sc">{:.3f}</span><span class="st"> of the validation data"</span>.<span class="op">\</span></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="bu">format</span>(accuracy_score(valid_y2, pred_class_RF_balanced),precision_score(valid_y2, pred_class_RF_balanced) ) )</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Length of predictors is: '</span>,<span class="bu">len</span>(predictors_))</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> valid_y2, columns <span class="op">=</span> pred_class_RF_balanced)</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of parameters =  53
Accuracy scores of train 1.000 and validation 0.666 sets
The accuracy 0.666 and precision 0.628 of the validation data
Length of predictors is:  53</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="36">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>col_0</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>Win_x</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>412</td>
      <td>55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>198</td>
      <td>93</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="try-as-a-regression-problem" class="level2">
<h2 class="anchored" data-anchor-id="try-as-a-regression-problem">Try as a regression problem</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>pd.read_csv(folda<span class="op">+</span><span class="st">'epl2017-2021_wivnetscore_both-HA.csv'</span>)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>dfAll.iloc[<span class="dv">20</span>:,:]</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>copy.copy(dfAll)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>,<span class="st">'opponent_y'</span>,<span class="st">'team_y'</span>])</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.dropna()</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"opponent_x"</span>] <span class="op">=</span> df[<span class="st">"opponent_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"team_x"</span>] <span class="op">=</span> df[<span class="st">"team_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>df.loc[cond].copy()</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>valid<span class="op">=</span>df.loc[<span class="op">~</span>cond].copy()</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'NetScore_x'</span></span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> train.columns <span class="cf">if</span> ((x <span class="op">!=</span> <span class="st">'Win_x'</span>) <span class="op">&amp;</span> (x <span class="op">!=</span> <span class="st">'NetScore_x'</span>) )]</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> train[predictors]</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>valid_xs <span class="op">=</span> valid[predictors]</span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train[target]</span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>valid_y <span class="op">=</span> valid[target]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>model_RF<span class="op">=</span>RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>model_RF.fit(xs,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_scores2(nom,predd, yy):</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    prec<span class="op">=</span>precision_score(predd, np.array(yy)) </span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    acc<span class="op">=</span>accuracy_score(predd, np.array(yy))</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">{}</span><span class="st">: accuracy = </span><span class="sc">{:.3f}</span><span class="st"> and precision = </span><span class="sc">{:.3f}</span><span class="st">"</span>.<span class="bu">format</span>(nom,acc,prec))</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_reg_scores(yy,preds,XX,binary<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>    yy<span class="op">=</span>copy.copy(yy)</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>    preds<span class="op">=</span>copy.copy(preds)</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> binary:</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>        yy[yy<span class="op">&gt;</span><span class="dv">0</span>],yy[yy<span class="op">&lt;=</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span>, <span class="dv">0</span></span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>        preds[preds<span class="op">&gt;=</span>XX], preds[preds<span class="op">&lt;</span>XX]<span class="op">=</span><span class="dv">1</span>, <span class="dv">0</span></span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>        get_scores2(<span class="bu">str</span>(model_RF.base_estimator),preds, yy)</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>        yy[yy<span class="op">&gt;</span><span class="dv">0</span>]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>        yy[yy<span class="op">==</span><span class="dv">0</span>]<span class="op">=</span><span class="dv">0</span></span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>        yy[yy<span class="op">&lt;</span><span class="dv">0</span>]<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>        preds[preds<span class="op">&gt;=</span>XX]<span class="op">=</span><span class="dv">1</span></span>
<span id="cb84-23"><a href="#cb84-23" aria-hidden="true" tabindex="-1"></a>        preds[preds<span class="op">&lt;-</span>XX]<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb84-24"><a href="#cb84-24" aria-hidden="true" tabindex="-1"></a>        preds[( (preds<span class="op">&gt;=-</span>XX) <span class="op">&amp;</span> (preds<span class="op">&lt;</span>XX) )]<span class="op">=</span><span class="dv">0</span></span>
<span id="cb84-25"><a href="#cb84-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb84-26"><a href="#cb84-26" aria-hidden="true" tabindex="-1"></a>        preds_yy<span class="op">=</span>np.array(preds<span class="op">-</span>yy)</span>
<span id="cb84-27"><a href="#cb84-27" aria-hidden="true" tabindex="-1"></a>        preds_yy<span class="op">=</span>preds<span class="op">-</span>yy</span>
<span id="cb84-28"><a href="#cb84-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>( <span class="bu">len</span>(preds_yy[preds_yy<span class="op">==</span><span class="dv">0</span>])<span class="op">/</span><span class="bu">len</span>(yy) )</span>
<span id="cb84-29"><a href="#cb84-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-30"><a href="#cb84-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb84-31"><a href="#cb84-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-32"><a href="#cb84-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-33"><a href="#cb84-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> preds,yy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>pred_reg_RF<span class="op">=</span>model_RF.predict(valid_xs)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>new_preds,new_y<span class="op">=</span>get_reg_scores(valid_y,pred_reg_RF,<span class="fl">.5</span>)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>new_preds,new_y<span class="op">=</span>get_reg_scores(valid_y,pred_reg_RF,<span class="fl">.25</span>,<span class="va">False</span>)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>crosstab.columns.name<span class="op">=</span><span class="st">'Predicted'</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>crosstab.index.name<span class="op">=</span><span class="st">'Actual'</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>(np.diag(np.array(crosstab))  )<span class="op">/</span>np.<span class="bu">sum</span>(np.<span class="bu">sum</span>(crosstab))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>model_XGB <span class="op">=</span> XGBRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>) <span class="co"># Your code here</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>model_XGB.fit(xs, y) </span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>pred_reg_XGB <span class="op">=</span> model_XGB.predict(valid_xs)</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>new_preds,new_y<span class="op">=</span>get_reg_scores(valid_y,pred_reg_XGB,<span class="fl">.5</span>)</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds)</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>crosstab.columns.name<span class="op">=</span><span class="st">'Predicted'</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>crosstab.index.name<span class="op">=</span><span class="st">'Actual'</span></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>model_ridge <span class="op">=</span> Ridge(alpha<span class="op">=</span><span class="dv">21</span>) <span class="co"># Your code here</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>model_ridge.fit(xs, y) </span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>pred_reg_ridge <span class="op">=</span> model_ridge.predict(valid_xs)</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>new_preds,new_y<span class="op">=</span>get_reg_scores(valid_y,pred_reg_ridge,<span class="fl">.5</span>)</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds)</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>crosstab.columns.name<span class="op">=</span><span class="st">'Predicted'</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>crosstab.index.name<span class="op">=</span><span class="st">'Actual'</span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="gradient-boosting-regressor" class="level3">
<h3 class="anchored" data-anchor-id="gradient-boosting-regressor">Gradient Boosting Regressor</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>pd.read_csv(folda<span class="op">+</span><span class="st">'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv'</span>)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>dfAll.iloc[<span class="dv">20</span>:,:]</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>copy.copy(dfAll)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>,<span class="st">'opponent_y'</span>,<span class="st">'team_y'</span>,<span class="st">'GoalsAgainst_x'</span>,<span class="st">'GoalsFor_x'</span>])</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.dropna()</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"opponent_x"</span>] <span class="op">=</span> df[<span class="st">"opponent_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"team_x"</span>] <span class="op">=</span> df[<span class="st">"team_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"venue_x"</span>] <span class="op">=</span> df[<span class="st">"venue_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>df.loc[cond].copy()</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>valid<span class="op">=</span>df.loc[<span class="op">~</span>cond].copy()</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>target<span class="op">=</span><span class="st">'NetScore_x'</span></span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> train.columns <span class="cf">if</span> ((x <span class="op">!=</span> <span class="st">'Win_x'</span>) <span class="op">&amp;</span> (x <span class="op">!=</span> <span class="st">'NetScore_x'</span>)  )]</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> train[predictors]</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>valid_xs <span class="op">=</span> valid[predictors]</span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train[target]</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a>valid_y <span class="op">=</span> valid[target]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets, ensemble</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_estimators"</span>: <span class="dv">500</span>,</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_depth"</span>: <span class="dv">4</span>,</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_samples_split"</span>: <span class="dv">5</span>,</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"learning_rate"</span>: <span class="fl">0.01</span>,</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"loss"</span>: <span class="st">"squared_error"</span>,</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> ensemble.GradientBoostingRegressor(<span class="op">**</span>params)</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>reg.fit(xs, y)</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(valid_y, reg.predict(valid_xs))</span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The mean squared error (MSE) on test set: </span><span class="sc">{:.4f}</span><span class="st">"</span>.<span class="bu">format</span>(mse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>test_score <span class="op">=</span> np.zeros((params[<span class="st">"n_estimators"</span>],), dtype<span class="op">=</span>np.float64)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, y_pred <span class="kw">in</span> <span class="bu">enumerate</span>(reg.staged_predict(valid_xs)):</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    test_score[i] <span class="op">=</span> reg.loss_(valid_y, y_pred)</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Deviance"</span>)</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>    np.arange(params[<span class="st">"n_estimators"</span>]) <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>    reg.train_score_,</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"b-"</span>,</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"Training Set Deviance"</span>,</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>    np.arange(params[<span class="st">"n_estimators"</span>]) <span class="op">+</span> <span class="dv">1</span>, test_score, <span class="st">"r-"</span>, label<span class="op">=</span><span class="st">"Test Set Deviance"</span></span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Boosting Iterations"</span>)</span>
<span id="cb93-19"><a href="#cb93-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Deviance"</span>)</span>
<span id="cb93-20"><a href="#cb93-20" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span>
<span id="cb93-21"><a href="#cb93-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>pred_reg_gradboost <span class="op">=</span> reg.predict(valid_xs)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>new_preds_comb,new_y<span class="op">=</span>get_reg_scores(valid_y, pred_reg_gradboost,<span class="fl">.5</span>)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds_comb)</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="regression-of-goals-for-and-goals-against" class="level2">
<h2 class="anchored" data-anchor-id="regression-of-goals-for-and-goals-against">Regression of Goals For and Goals Against</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>pd.read_csv(folda<span class="op">+</span><span class="st">'epl2017-2021_wivnetscoreAndGFGA_both-HA.csv'</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>dfAll<span class="op">=</span>dfAll.iloc[<span class="dv">20</span>:,:]</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>copy.copy(dfAll)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>,<span class="st">'opponent_y'</span>,<span class="st">'team_y'</span>,<span class="st">'NetScore_x'</span>])</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>df.dropna()</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"opponent_x"</span>] <span class="op">=</span> df[<span class="st">"opponent_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"team_x"</span>] <span class="op">=</span> df[<span class="st">"team_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"venue_x"</span>] <span class="op">=</span> df[<span class="st">"venue_x"</span>].astype(<span class="st">"category"</span>).cat.codes</span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>df.loc[cond].copy()</span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>valid<span class="op">=</span>df.loc[<span class="op">~</span>cond].copy()</span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>predictors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_scores2(nom,predd, yy):</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>    prec<span class="op">=</span>precision_score(predd, np.array(yy)) </span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>    acc<span class="op">=</span>accuracy_score(predd, np.array(yy))</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">{}</span><span class="st">: accuracy = </span><span class="sc">{:.3f}</span><span class="st"> and precision = </span><span class="sc">{:.3f}</span><span class="st">"</span>.<span class="bu">format</span>(nom,acc,prec))</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_reg_scores_Goals(yy,preds,XX,binary<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    yy<span class="op">=</span>copy.copy(yy)</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    preds<span class="op">=</span>copy.copy(preds)</span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>    yy[yy<span class="op">&gt;</span><span class="dv">0</span>],yy[yy<span class="op">&lt;=</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">1</span>, <span class="dv">0</span></span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>    preds[preds<span class="op">&gt;=</span>XX], preds[preds<span class="op">&lt;</span>XX]<span class="op">=</span><span class="dv">1</span>, <span class="dv">0</span></span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-16"><a href="#cb97-16" aria-hidden="true" tabindex="-1"></a>    get_scores2(<span class="st">'Regression RF'</span>,preds, yy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> doGFGA(target,train,valid,model<span class="op">=</span><span class="st">'RF'</span>):</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>    predictors <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> train.columns <span class="cf">if</span> ((x <span class="op">!=</span> <span class="st">'Win_x'</span>) <span class="op">&amp;</span> (x <span class="op">!=</span> <span class="st">'GoalsFor_x'</span>) <span class="op">&amp;</span> (x <span class="op">!=</span> <span class="st">'GoalsAgainst_x'</span>) )]</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>    xs <span class="op">=</span> train[predictors]</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>    valid_xs <span class="op">=</span> valid[predictors]</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> train[target]</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>    valid_y <span class="op">=</span> valid[target]</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> model<span class="op">!=</span><span class="st">'RF'</span>:</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'XGB'</span>)</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>        model_RF <span class="op">=</span> XGBRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>        model_RF<span class="op">=</span>RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'RF'</span>)</span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-19"><a href="#cb98-19" aria-hidden="true" tabindex="-1"></a>    model_RF.fit(xs,y)</span>
<span id="cb98-20"><a href="#cb98-20" aria-hidden="true" tabindex="-1"></a>    pred_RF<span class="op">=</span>model_RF.predict(valid_xs)</span>
<span id="cb98-21"><a href="#cb98-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-22"><a href="#cb98-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_RF</span>
<span id="cb98-23"><a href="#cb98-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-24"><a href="#cb98-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> doGFGA_outer(model<span class="op">=</span><span class="st">'RF'</span>):</span>
<span id="cb98-25"><a href="#cb98-25" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> <span class="st">'GoalsFor_x'</span></span>
<span id="cb98-26"><a href="#cb98-26" aria-hidden="true" tabindex="-1"></a>    pred_GF<span class="op">=</span>doGFGA(target,train,valid,model)</span>
<span id="cb98-27"><a href="#cb98-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-28"><a href="#cb98-28" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> <span class="st">'GoalsAgainst_x'</span></span>
<span id="cb98-29"><a href="#cb98-29" aria-hidden="true" tabindex="-1"></a>    pred_GA<span class="op">=</span>doGFGA(target,train,valid,model)</span>
<span id="cb98-30"><a href="#cb98-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-31"><a href="#cb98-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-32"><a href="#cb98-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-33"><a href="#cb98-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_GF, pred_GA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>pred_GF, pred_GA <span class="op">=</span> doGFGA_outer()</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>pred_reg_GFGA_RF<span class="op">=</span>pred_GF<span class="op">-</span>pred_GA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>new_preds_comb,new_y<span class="op">=</span>get_reg_scores(valid[<span class="st">'GoalsFor_x'</span>]<span class="op">-</span>valid[<span class="st">'GoalsAgainst_x'</span>],pred_reg_GFGA_RF,<span class="fl">.5</span>)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds_comb)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>new_preds_comb,new_y<span class="op">=</span>get_reg_scores(valid[<span class="st">'GoalsFor_x'</span>]<span class="op">-</span>valid[<span class="st">'GoalsAgainst_x'</span>],pred_reg_GFGA_RF,<span class="fl">.5</span>,<span class="va">False</span>)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds_comb)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from xgboost import XGBRegressor</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>pred_GF_, pred_GA_ <span class="op">=</span> doGFGA_outer(<span class="st">'XGB'</span>)</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>pred_reg_GFGA_XGB<span class="op">=</span>pred_GF<span class="op">-</span>pred_GA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>new_preds_comb_,new_y<span class="op">=</span>get_reg_scores(valid[<span class="st">'GoalsFor_x'</span>]<span class="op">-</span>valid[<span class="st">'GoalsAgainst_x'</span>],<span class="op">\</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>                                     pred_reg_GFGA_XGB,<span class="fl">.5</span>)</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds_comb_)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># # pred_RF</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="co"># new_preds_comb_,new_y=get_reg_scores(valid['GoalsFor_x']-valid['GoalsAgainst_x'],0.5*(pred_GF-pred_GA+pred_RF),.5)</span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="co"># valid_y</span></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a><span class="co"># crosstab=pd.crosstab(index = new_y, columns = new_preds_comb_)</span></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="co"># crosstab</span></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>pred_reg_GFGA_XGB[<span class="dv">0</span>:<span class="dv">10</span>],pred_reg_GFGA_RF[<span class="dv">0</span>:<span class="dv">10</span>]</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="ensembling" class="level3">
<h3 class="anchored" data-anchor-id="ensembling">Ensembling</h3>
<pre><code>Think back to the original reasoning behind why random forests work so well: each tree has errors, but those errors are not correlated with each other, so the average of those errors should tend towards zero once there are enough trees. Similar reasoning could be used to consider averaging the predictions of models trained using different algorithms.

In our case, we have two very different models.. It would be reasonable to expect that the kinds of errors that each one makes would be quite different. Therefore, we might expect that the average of their predictions would be better than either one's individual predictions.

from fastai</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>new_preds,new_y<span class="op">=</span>get_reg_scores(valid_y,</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>   (pred_reg_RF<span class="op">+</span>pred_reg_XGB<span class="op">+</span>pred_reg_gradboost)<span class="op">/</span><span class="dv">3</span>,<span class="fl">.5</span>)<span class="op">;</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds)</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>crosstab.columns.name<span class="op">=</span><span class="st">'Predicted'</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>crosstab.index.name<span class="op">=</span><span class="st">'Actual'</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>crosstab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>pred_BIG<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>( pred_reg_GFGA_RF <span class="op">+</span> pred_reg_RF )</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>new_preds_comb,new_y<span class="op">=</span>get_reg_scores(valid_y, pred_BIG,<span class="fl">.5</span>)</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a>crosstab<span class="op">=</span>pd.crosstab(index <span class="op">=</span> new_y, columns <span class="op">=</span> new_preds_comb)</span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>crosstab</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<table class="table">
<colgroup>
<col style="width: 35%">
<col style="width: 30%">
<col style="width: 23%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th>Accuracy W/L/D</th>
<th>Accuracy Win</th>
<th>Classification/Regression</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.489</td>
<td>0.669</td>
<td>Classification</td>
<td>RF with all parameters</td>
</tr>
<tr class="even">
<td>0.479</td>
<td>0.661</td>
<td>Classification</td>
<td>RF with 43 parameters from feature imp</td>
</tr>
<tr class="odd">
<td>0.487</td>
<td>0.666</td>
<td>Classification</td>
<td>RF as above with basic features</td>
</tr>
<tr class="even">
<td>0.484</td>
<td>0.656</td>
<td>Classification</td>
<td>RF with 4 basic features</td>
</tr>
<tr class="odd">
<td>0.479</td>
<td>-</td>
<td>Classification</td>
<td>RF with 4 basic ones + balanced</td>
</tr>
<tr class="even">
<td>0.485</td>
<td>0.656</td>
<td>Classification</td>
<td>RF with 23 correlation parameters plus basic</td>
</tr>
<tr class="odd">
<td>0.451</td>
<td>0.678</td>
<td>Regression</td>
<td>RF with all parameters on net score</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.657</td>
<td>Regression</td>
<td>XGB with all parameters on net score</td>
</tr>
<tr class="odd">
<td>-</td>
<td>0.639</td>
<td>Regression</td>
<td>Ridge with all parameters on net score</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.666</td>
<td>Regression</td>
<td>Grad boost with all parameters on net score</td>
</tr>
<tr class="odd">
<td>0.427</td>
<td>0.670</td>
<td>Regression</td>
<td>RF with all parameters on GF/GA</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.670</td>
<td>Regression</td>
<td>XGB with all parameters on GF/GA score</td>
</tr>
<tr class="odd">
<td>-</td>
<td>0.665</td>
<td>Regression</td>
<td>RF+XGB+Grad boost on netscore</td>
</tr>
<tr class="even">
<td>-</td>
<td>0.678</td>
<td>Regression</td>
<td>RF on netscore + RF on GF/GA</td>
</tr>
</tbody>
</table>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>